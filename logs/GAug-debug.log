2024-01-10 20:42:25,705 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f14a31d6550>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:42:26,409 - GAugM EPNet train, Epoch [  1/215]: loss 0.7210, auc 0.4153, ap 0.4426
2024-01-10 20:42:26,483 - GAugM EPNet train, Epoch [  2/215]: loss 0.7210, auc 0.5650, ap 0.5510
2024-01-10 20:42:26,542 - GAugM EPNet train, Epoch [  3/215]: loss 0.7209, auc 0.5012, ap 0.4987
2024-01-10 20:42:26,603 - GAugM EPNet train, Epoch [  4/215]: loss 0.7209, auc 0.4883, ap 0.5023
2024-01-10 20:42:26,661 - GAugM EPNet train, Epoch [  5/215]: loss 0.7209, auc 0.5144, ap 0.5357
2024-01-10 20:42:26,722 - GAugM EPNet train, Epoch [  6/215]: loss 0.7209, auc 0.4925, ap 0.4961
2024-01-10 20:42:26,786 - GAugM EPNet train, Epoch [  7/215]: loss 0.7209, auc 0.4082, ap 0.4455
2024-01-10 20:42:26,859 - GAugM EPNet train, Epoch [  8/215]: loss 0.7210, auc 0.5196, ap 0.5258
2024-01-10 20:42:26,920 - GAugM EPNet train, Epoch [  9/215]: loss 0.7209, auc 0.4165, ap 0.4607
2024-01-10 20:42:26,991 - GAugM EPNet train, Epoch [ 10/215]: loss 0.7208, auc 0.5628, ap 0.5556
2024-01-10 20:42:27,045 - GAugM EPNet train, Epoch [ 11/215]: loss 0.7209, auc 0.5278, ap 0.5329
2024-01-10 20:42:27,105 - GAugM EPNet train, Epoch [ 12/215]: loss 0.7210, auc 0.4916, ap 0.5012
2024-01-10 20:42:27,162 - GAugM EPNet train, Epoch [ 13/215]: loss 0.7209, auc 0.5634, ap 0.5491
2024-01-10 20:42:27,218 - GAugM EPNet train, Epoch [ 14/215]: loss 0.7209, auc 0.5397, ap 0.5203
2024-01-10 20:42:27,285 - GAugM EPNet train, Epoch [ 15/215]: loss 0.7210, auc 0.4530, ap 0.4928
2024-01-10 20:42:27,340 - GAugM EPNet train, Epoch [ 16/215]: loss 0.7209, auc 0.4891, ap 0.4885
2024-01-10 20:42:27,397 - GAugM EPNet train, Epoch [ 17/215]: loss 0.7210, auc 0.5774, ap 0.5530
2024-01-10 20:42:27,459 - GAugM EPNet train, Epoch [ 18/215]: loss 0.7210, auc 0.6369, ap 0.6274
2024-01-10 20:42:27,522 - GAugM EPNet train, Epoch [ 19/215]: loss 0.7209, auc 0.5167, ap 0.5006
2024-01-10 20:42:27,592 - GAugM EPNet train, Epoch [ 20/215]: loss 0.7210, auc 0.4564, ap 0.4790
2024-01-10 20:42:27,661 - GAugM EPNet train, Epoch [ 21/215]: loss 0.7209, auc 0.4672, ap 0.4755
2024-01-10 20:42:27,742 - GAugM EPNet train, Epoch [ 22/215]: loss 0.7210, auc 0.3537, ap 0.4104
2024-01-10 20:42:27,819 - GAugM EPNet train, Epoch [ 23/215]: loss 0.7208, auc 0.5011, ap 0.4981
2024-01-10 20:42:27,892 - GAugM EPNet train, Epoch [ 24/215]: loss 0.7209, auc 0.5164, ap 0.4935
2024-01-10 20:42:27,966 - GAugM EPNet train, Epoch [ 25/215]: loss 0.7209, auc 0.4872, ap 0.4878
2024-01-10 20:42:28,041 - GAugM EPNet train, Epoch [ 26/215]: loss 0.7210, auc 0.4817, ap 0.5125
2024-01-10 20:42:28,117 - GAugM EPNet train, Epoch [ 27/215]: loss 0.7209, auc 0.4578, ap 0.5041
2024-01-10 20:42:28,193 - GAugM EPNet train, Epoch [ 28/215]: loss 0.7209, auc 0.5417, ap 0.5220
2024-01-10 20:42:28,271 - GAugM EPNet train, Epoch [ 29/215]: loss 0.7210, auc 0.5611, ap 0.5389
2024-01-10 20:42:28,357 - GAugM EPNet train, Epoch [ 30/215]: loss 0.7209, auc 0.5696, ap 0.5850
2024-01-10 20:42:28,447 - GAugM EPNet train, Epoch [ 31/215]: loss 0.7208, auc 0.5091, ap 0.5081
2024-01-10 20:42:28,532 - GAugM EPNet train, Epoch [ 32/215]: loss 0.7210, auc 0.5858, ap 0.5561
2024-01-10 20:42:28,612 - GAugM EPNet train, Epoch [ 33/215]: loss 0.7209, auc 0.5431, ap 0.5744
2024-01-10 20:42:28,692 - GAugM EPNet train, Epoch [ 34/215]: loss 0.7209, auc 0.4911, ap 0.5188
2024-01-10 20:42:28,772 - GAugM EPNet train, Epoch [ 35/215]: loss 0.7209, auc 0.5924, ap 0.5826
2024-01-10 20:42:28,856 - GAugM EPNet train, Epoch [ 36/215]: loss 0.7209, auc 0.5691, ap 0.5747
2024-01-10 20:42:28,935 - GAugM EPNet train, Epoch [ 37/215]: loss 0.7209, auc 0.4683, ap 0.4890
2024-01-10 20:42:29,022 - GAugM EPNet train, Epoch [ 38/215]: loss 0.7209, auc 0.4694, ap 0.4644
2024-01-10 20:42:29,107 - GAugM EPNet train, Epoch [ 39/215]: loss 0.7208, auc 0.4544, ap 0.4807
2024-01-10 20:42:29,188 - GAugM EPNet train, Epoch [ 40/215]: loss 0.7210, auc 0.5347, ap 0.5031
2024-01-10 20:42:29,273 - GAugM EPNet train, Epoch [ 41/215]: loss 0.7210, auc 0.5338, ap 0.5513
2024-01-10 20:42:29,358 - GAugM EPNet train, Epoch [ 42/215]: loss 0.7209, auc 0.5488, ap 0.5565
2024-01-10 20:42:29,451 - GAugM EPNet train, Epoch [ 43/215]: loss 0.7208, auc 0.4537, ap 0.5037
2024-01-10 20:42:29,551 - GAugM EPNet train, Epoch [ 44/215]: loss 0.7208, auc 0.3674, ap 0.4235
2024-01-10 20:42:29,632 - GAugM EPNet train, Epoch [ 45/215]: loss 0.7209, auc 0.5408, ap 0.5664
2024-01-10 20:42:29,730 - GAugM EPNet train, Epoch [ 46/215]: loss 0.7209, auc 0.4445, ap 0.4510
2024-01-10 20:42:29,814 - GAugM EPNet train, Epoch [ 47/215]: loss 0.7210, auc 0.4263, ap 0.4754
2024-01-10 20:42:29,908 - GAugM EPNet train, Epoch [ 48/215]: loss 0.7210, auc 0.6198, ap 0.6211
2024-01-10 20:42:29,989 - GAugM EPNet train, Epoch [ 49/215]: loss 0.7209, auc 0.4895, ap 0.4924
2024-01-10 20:42:30,078 - GAugM EPNet train, Epoch [ 50/215]: loss 0.7210, auc 0.4701, ap 0.4705
2024-01-10 20:42:30,170 - GAugM EPNet train, Epoch [ 51/215]: loss 0.7210, auc 0.4706, ap 0.5115
2024-01-10 20:42:30,251 - GAugM EPNet train, Epoch [ 52/215]: loss 0.7209, auc 0.4760, ap 0.5018
2024-01-10 20:42:30,341 - GAugM EPNet train, Epoch [ 53/215]: loss 0.7209, auc 0.5256, ap 0.5460
2024-01-10 20:42:30,425 - GAugM EPNet train, Epoch [ 54/215]: loss 0.7211, auc 0.5087, ap 0.5278
2024-01-10 20:42:30,508 - GAugM EPNet train, Epoch [ 55/215]: loss 0.7209, auc 0.5886, ap 0.5833
2024-01-10 20:42:30,588 - GAugM EPNet train, Epoch [ 56/215]: loss 0.7208, auc 0.4883, ap 0.4812
2024-01-10 20:42:30,670 - GAugM EPNet train, Epoch [ 57/215]: loss 0.7209, auc 0.4737, ap 0.4608
2024-01-10 20:42:30,756 - GAugM EPNet train, Epoch [ 58/215]: loss 0.7210, auc 0.5071, ap 0.5612
2024-01-10 20:42:30,843 - GAugM EPNet train, Epoch [ 59/215]: loss 0.7211, auc 0.5502, ap 0.5208
2024-01-10 20:42:30,921 - GAugM EPNet train, Epoch [ 60/215]: loss 0.7210, auc 0.5100, ap 0.5023
2024-01-10 20:42:31,001 - GAugM EPNet train, Epoch [ 61/215]: loss 0.7209, auc 0.5059, ap 0.5303
2024-01-10 20:42:31,081 - GAugM EPNet train, Epoch [ 62/215]: loss 0.7210, auc 0.5424, ap 0.5639
2024-01-10 20:42:31,163 - GAugM EPNet train, Epoch [ 63/215]: loss 0.7208, auc 0.5132, ap 0.5223
2024-01-10 20:42:31,248 - GAugM EPNet train, Epoch [ 64/215]: loss 0.7208, auc 0.4897, ap 0.4992
2024-01-10 20:42:31,327 - GAugM EPNet train, Epoch [ 65/215]: loss 0.7208, auc 0.6027, ap 0.5817
2024-01-10 20:42:31,409 - GAugM EPNet train, Epoch [ 66/215]: loss 0.7209, auc 0.4890, ap 0.5071
2024-01-10 20:42:31,498 - GAugM EPNet train, Epoch [ 67/215]: loss 0.7209, auc 0.5447, ap 0.5315
2024-01-10 20:42:31,581 - GAugM EPNet train, Epoch [ 68/215]: loss 0.7210, auc 0.4553, ap 0.5017
2024-01-10 20:42:31,676 - GAugM EPNet train, Epoch [ 69/215]: loss 0.7210, auc 0.5078, ap 0.5297
2024-01-10 20:42:31,768 - GAugM EPNet train, Epoch [ 70/215]: loss 0.7210, auc 0.4842, ap 0.4711
2024-01-10 20:42:31,864 - GAugM EPNet train, Epoch [ 71/215]: loss 0.7210, auc 0.5352, ap 0.5426
2024-01-10 20:42:31,949 - GAugM EPNet train, Epoch [ 72/215]: loss 0.7210, auc 0.4397, ap 0.4930
2024-01-10 20:42:32,038 - GAugM EPNet train, Epoch [ 73/215]: loss 0.7209, auc 0.4701, ap 0.4779
2024-01-10 20:42:32,137 - GAugM EPNet train, Epoch [ 74/215]: loss 0.7209, auc 0.5221, ap 0.5410
2024-01-10 20:42:32,222 - GAugM EPNet train, Epoch [ 75/215]: loss 0.7210, auc 0.4489, ap 0.4549
2024-01-10 20:42:32,306 - GAugM EPNet train, Epoch [ 76/215]: loss 0.7209, auc 0.4740, ap 0.4807
2024-01-10 20:42:32,390 - GAugM EPNet train, Epoch [ 77/215]: loss 0.7208, auc 0.4838, ap 0.4898
2024-01-10 20:42:32,478 - GAugM EPNet train, Epoch [ 78/215]: loss 0.7209, auc 0.5196, ap 0.5050
2024-01-10 20:42:32,571 - GAugM EPNet train, Epoch [ 79/215]: loss 0.7208, auc 0.4333, ap 0.4594
2024-01-10 20:42:32,656 - GAugM EPNet train, Epoch [ 80/215]: loss 0.7209, auc 0.5728, ap 0.5503
2024-01-10 20:42:32,754 - GAugM EPNet train, Epoch [ 81/215]: loss 0.7209, auc 0.4430, ap 0.4513
2024-01-10 20:42:32,843 - GAugM EPNet train, Epoch [ 82/215]: loss 0.7210, auc 0.5301, ap 0.4985
2024-01-10 20:42:32,929 - GAugM EPNet train, Epoch [ 83/215]: loss 0.7209, auc 0.4430, ap 0.5003
2024-01-10 20:42:33,019 - GAugM EPNet train, Epoch [ 84/215]: loss 0.7209, auc 0.3699, ap 0.4246
2024-01-10 20:42:33,107 - GAugM EPNet train, Epoch [ 85/215]: loss 0.7210, auc 0.4121, ap 0.4467
2024-01-10 20:42:33,201 - GAugM EPNet train, Epoch [ 86/215]: loss 0.7208, auc 0.4769, ap 0.4764
2024-01-10 20:42:33,288 - GAugM EPNet train, Epoch [ 87/215]: loss 0.7209, auc 0.6162, ap 0.5984
2024-01-10 20:42:33,376 - GAugM EPNet train, Epoch [ 88/215]: loss 0.7210, auc 0.4975, ap 0.4895
2024-01-10 20:42:33,465 - GAugM EPNet train, Epoch [ 89/215]: loss 0.7210, auc 0.5244, ap 0.5590
2024-01-10 20:42:33,553 - GAugM EPNet train, Epoch [ 90/215]: loss 0.7209, auc 0.4664, ap 0.4661
2024-01-10 20:42:33,645 - GAugM EPNet train, Epoch [ 91/215]: loss 0.7208, auc 0.5007, ap 0.4998
2024-01-10 20:42:33,731 - GAugM EPNet train, Epoch [ 92/215]: loss 0.7209, auc 0.5582, ap 0.5822
2024-01-10 20:42:33,825 - GAugM EPNet train, Epoch [ 93/215]: loss 0.7209, auc 0.3606, ap 0.4253
2024-01-10 20:42:33,912 - GAugM EPNet train, Epoch [ 94/215]: loss 0.7210, auc 0.4213, ap 0.4673
2024-01-10 20:42:33,999 - GAugM EPNet train, Epoch [ 95/215]: loss 0.7210, auc 0.6023, ap 0.5619
2024-01-10 20:42:34,095 - GAugM EPNet train, Epoch [ 96/215]: loss 0.7209, auc 0.5230, ap 0.5135
2024-01-10 20:42:34,182 - GAugM EPNet train, Epoch [ 97/215]: loss 0.7209, auc 0.4350, ap 0.4954
2024-01-10 20:42:34,270 - GAugM EPNet train, Epoch [ 98/215]: loss 0.7209, auc 0.4612, ap 0.4752
2024-01-10 20:42:34,362 - GAugM EPNet train, Epoch [ 99/215]: loss 0.7209, auc 0.4413, ap 0.4849
2024-01-10 20:42:34,449 - GAugM EPNet train, Epoch [100/215]: loss 0.7210, auc 0.4644, ap 0.4697
2024-01-10 20:42:34,538 - GAugM EPNet train, Epoch [101/215]: loss 0.7210, auc 0.5404, ap 0.5826
2024-01-10 20:42:34,628 - GAugM EPNet train, Epoch [102/215]: loss 0.7209, auc 0.4731, ap 0.4661
2024-01-10 20:42:34,717 - GAugM EPNet train, Epoch [103/215]: loss 0.7209, auc 0.4769, ap 0.4827
2024-01-10 20:42:34,801 - GAugM EPNet train, Epoch [104/215]: loss 0.7209, auc 0.4850, ap 0.4996
2024-01-10 20:42:34,886 - GAugM EPNet train, Epoch [105/215]: loss 0.7209, auc 0.3966, ap 0.4369
2024-01-10 20:42:34,981 - GAugM EPNet train, Epoch [106/215]: loss 0.7210, auc 0.5374, ap 0.5539
2024-01-10 20:42:35,088 - GAugM EPNet train, Epoch [107/215]: loss 0.7210, auc 0.4489, ap 0.5000
2024-01-10 20:42:35,179 - GAugM EPNet train, Epoch [108/215]: loss 0.7208, auc 0.4642, ap 0.4814
2024-01-10 20:42:35,265 - GAugM EPNet train, Epoch [109/215]: loss 0.7210, auc 0.4519, ap 0.4796
2024-01-10 20:42:35,362 - GAugM EPNet train, Epoch [110/215]: loss 0.7209, auc 0.4589, ap 0.4637
2024-01-10 20:42:35,450 - GAugM EPNet train, Epoch [111/215]: loss 0.7210, auc 0.4811, ap 0.4842
2024-01-10 20:42:35,540 - GAugM EPNet train, Epoch [112/215]: loss 0.7209, auc 0.5329, ap 0.5379
2024-01-10 20:42:35,625 - GAugM EPNet train, Epoch [113/215]: loss 0.7210, auc 0.4678, ap 0.5028
2024-01-10 20:42:35,723 - GAugM EPNet train, Epoch [114/215]: loss 0.7209, auc 0.4122, ap 0.4469
2024-01-10 20:42:35,812 - GAugM EPNet train, Epoch [115/215]: loss 0.7210, auc 0.5349, ap 0.5110
2024-01-10 20:42:35,904 - GAugM EPNet train, Epoch [116/215]: loss 0.7209, auc 0.4697, ap 0.4806
2024-01-10 20:42:36,011 - GAugM EPNet train, Epoch [117/215]: loss 0.7208, auc 0.4560, ap 0.4733
2024-01-10 20:42:36,109 - GAugM EPNet train, Epoch [118/215]: loss 0.7209, auc 0.4683, ap 0.4719
2024-01-10 20:42:36,205 - GAugM EPNet train, Epoch [119/215]: loss 0.7209, auc 0.5068, ap 0.5239
2024-01-10 20:42:36,303 - GAugM EPNet train, Epoch [120/215]: loss 0.7210, auc 0.5114, ap 0.4929
2024-01-10 20:42:36,400 - GAugM EPNet train, Epoch [121/215]: loss 0.7210, auc 0.4863, ap 0.4984
2024-01-10 20:42:36,490 - GAugM EPNet train, Epoch [122/215]: loss 0.7209, auc 0.5397, ap 0.5584
2024-01-10 20:42:36,582 - GAugM EPNet train, Epoch [123/215]: loss 0.7209, auc 0.5041, ap 0.5024
2024-01-10 20:42:36,673 - GAugM EPNet train, Epoch [124/215]: loss 0.7210, auc 0.4569, ap 0.4649
2024-01-10 20:42:36,764 - GAugM EPNet train, Epoch [125/215]: loss 0.7209, auc 0.4724, ap 0.4974
2024-01-10 20:42:36,856 - GAugM EPNet train, Epoch [126/215]: loss 0.7210, auc 0.5094, ap 0.4901
2024-01-10 20:42:36,955 - GAugM EPNet train, Epoch [127/215]: loss 0.7209, auc 0.4779, ap 0.4806
2024-01-10 20:42:37,048 - GAugM EPNet train, Epoch [128/215]: loss 0.7210, auc 0.5050, ap 0.5013
2024-01-10 20:42:37,146 - GAugM EPNet train, Epoch [129/215]: loss 0.7208, auc 0.4617, ap 0.4839
2024-01-10 20:42:37,240 - GAugM EPNet train, Epoch [130/215]: loss 0.7210, auc 0.5813, ap 0.5596
2024-01-10 20:42:37,331 - GAugM EPNet train, Epoch [131/215]: loss 0.7210, auc 0.4850, ap 0.5299
2024-01-10 20:42:37,423 - GAugM EPNet train, Epoch [132/215]: loss 0.7209, auc 0.4961, ap 0.5153
2024-01-10 20:42:37,515 - GAugM EPNet train, Epoch [133/215]: loss 0.7209, auc 0.5032, ap 0.5289
2024-01-10 20:42:37,615 - GAugM EPNet train, Epoch [134/215]: loss 0.7210, auc 0.5185, ap 0.5662
2024-01-10 20:42:37,710 - GAugM EPNet train, Epoch [135/215]: loss 0.7209, auc 0.4098, ap 0.4518
2024-01-10 20:42:37,804 - GAugM EPNet train, Epoch [136/215]: loss 0.7209, auc 0.4614, ap 0.4874
2024-01-10 20:42:37,895 - GAugM EPNet train, Epoch [137/215]: loss 0.7210, auc 0.4559, ap 0.4833
2024-01-10 20:42:37,987 - GAugM EPNet train, Epoch [138/215]: loss 0.7210, auc 0.5434, ap 0.5362
2024-01-10 20:42:38,075 - GAugM EPNet train, Epoch [139/215]: loss 0.7210, auc 0.4689, ap 0.4629
2024-01-10 20:42:38,176 - GAugM EPNet train, Epoch [140/215]: loss 0.7209, auc 0.5274, ap 0.5612
2024-01-10 20:42:38,275 - GAugM EPNet train, Epoch [141/215]: loss 0.7209, auc 0.4685, ap 0.4763
2024-01-10 20:42:38,371 - GAugM EPNet train, Epoch [142/215]: loss 0.7209, auc 0.5404, ap 0.5240
2024-01-10 20:42:38,467 - GAugM EPNet train, Epoch [143/215]: loss 0.7209, auc 0.4623, ap 0.4712
2024-01-10 20:42:38,558 - GAugM EPNet train, Epoch [144/215]: loss 0.7209, auc 0.4964, ap 0.4981
2024-01-10 20:42:38,653 - GAugM EPNet train, Epoch [145/215]: loss 0.7209, auc 0.5365, ap 0.5551
2024-01-10 20:42:38,740 - GAugM EPNet train, Epoch [146/215]: loss 0.7209, auc 0.5041, ap 0.5115
2024-01-10 20:42:38,835 - GAugM EPNet train, Epoch [147/215]: loss 0.7209, auc 0.6162, ap 0.6399
2024-01-10 20:42:38,927 - GAugM EPNet train, Epoch [148/215]: loss 0.7209, auc 0.4897, ap 0.5084
2024-01-10 20:42:39,027 - GAugM EPNet train, Epoch [149/215]: loss 0.7208, auc 0.4389, ap 0.4517
2024-01-10 20:42:39,140 - GAugM EPNet train, Epoch [150/215]: loss 0.7209, auc 0.5406, ap 0.5341
2024-01-10 20:42:39,240 - GAugM EPNet train, Epoch [151/215]: loss 0.7209, auc 0.5331, ap 0.5436
2024-01-10 20:42:39,340 - GAugM EPNet train, Epoch [152/215]: loss 0.7209, auc 0.5578, ap 0.5361
2024-01-10 20:42:39,444 - GAugM EPNet train, Epoch [153/215]: loss 0.7209, auc 0.4802, ap 0.5255
2024-01-10 20:42:39,542 - GAugM EPNet train, Epoch [154/215]: loss 0.7209, auc 0.5436, ap 0.5745
2024-01-10 20:42:39,643 - GAugM EPNet train, Epoch [155/215]: loss 0.7209, auc 0.4795, ap 0.4866
2024-01-10 20:42:39,740 - GAugM EPNet train, Epoch [156/215]: loss 0.7209, auc 0.4165, ap 0.4376
2024-01-10 20:42:39,832 - GAugM EPNet train, Epoch [157/215]: loss 0.7209, auc 0.4979, ap 0.5113
2024-01-10 20:42:39,924 - GAugM EPNet train, Epoch [158/215]: loss 0.7208, auc 0.4977, ap 0.4997
2024-01-10 20:42:40,013 - GAugM EPNet train, Epoch [159/215]: loss 0.7208, auc 0.5178, ap 0.5182
2024-01-10 20:42:40,103 - GAugM EPNet train, Epoch [160/215]: loss 0.7209, auc 0.5295, ap 0.5376
2024-01-10 20:42:40,193 - GAugM EPNet train, Epoch [161/215]: loss 0.7209, auc 0.5536, ap 0.5385
2024-01-10 20:42:40,294 - GAugM EPNet train, Epoch [162/215]: loss 0.7209, auc 0.4943, ap 0.4892
2024-01-10 20:42:40,386 - GAugM EPNet train, Epoch [163/215]: loss 0.7209, auc 0.5240, ap 0.5115
2024-01-10 20:42:40,478 - GAugM EPNet train, Epoch [164/215]: loss 0.7211, auc 0.5267, ap 0.5274
2024-01-10 20:42:40,569 - GAugM EPNet train, Epoch [165/215]: loss 0.7210, auc 0.4425, ap 0.4599
2024-01-10 20:42:40,662 - GAugM EPNet train, Epoch [166/215]: loss 0.7208, auc 0.5000, ap 0.4999
2024-01-10 20:42:40,761 - GAugM EPNet train, Epoch [167/215]: loss 0.7209, auc 0.4726, ap 0.4962
2024-01-10 20:42:40,855 - GAugM EPNet train, Epoch [168/215]: loss 0.7209, auc 0.4258, ap 0.4915
2024-01-10 20:42:40,949 - GAugM EPNet train, Epoch [169/215]: loss 0.7209, auc 0.5201, ap 0.5754
2024-01-10 20:42:41,045 - GAugM EPNet train, Epoch [170/215]: loss 0.7210, auc 0.4920, ap 0.4810
2024-01-10 20:42:41,134 - GAugM EPNet train, Epoch [171/215]: loss 0.7209, auc 0.4665, ap 0.4876
2024-01-10 20:42:41,226 - GAugM EPNet train, Epoch [172/215]: loss 0.7208, auc 0.3944, ap 0.4454
2024-01-10 20:42:41,318 - GAugM EPNet train, Epoch [173/215]: loss 0.7209, auc 0.5329, ap 0.5501
2024-01-10 20:42:41,410 - GAugM EPNet train, Epoch [174/215]: loss 0.7209, auc 0.4911, ap 0.4893
2024-01-10 20:42:41,502 - GAugM EPNet train, Epoch [175/215]: loss 0.7209, auc 0.5778, ap 0.5323
2024-01-10 20:42:41,598 - GAugM EPNet train, Epoch [176/215]: loss 0.7209, auc 0.5374, ap 0.5095
2024-01-10 20:42:41,688 - GAugM EPNet train, Epoch [177/215]: loss 0.7210, auc 0.5482, ap 0.5477
2024-01-10 20:42:41,777 - GAugM EPNet train, Epoch [178/215]: loss 0.7210, auc 0.5331, ap 0.5620
2024-01-10 20:42:41,866 - GAugM EPNet train, Epoch [179/215]: loss 0.7210, auc 0.3891, ap 0.4465
2024-01-10 20:42:41,959 - GAugM EPNet train, Epoch [180/215]: loss 0.7210, auc 0.5879, ap 0.5901
2024-01-10 20:42:42,049 - GAugM EPNet train, Epoch [181/215]: loss 0.7209, auc 0.4046, ap 0.4278
2024-01-10 20:42:42,138 - GAugM EPNet train, Epoch [182/215]: loss 0.7209, auc 0.4836, ap 0.5060
2024-01-10 20:42:42,234 - GAugM EPNet train, Epoch [183/215]: loss 0.7210, auc 0.5333, ap 0.5269
2024-01-10 20:42:42,323 - GAugM EPNet train, Epoch [184/215]: loss 0.7209, auc 0.4272, ap 0.4801
2024-01-10 20:42:42,417 - GAugM EPNet train, Epoch [185/215]: loss 0.7209, auc 0.4769, ap 0.4884
2024-01-10 20:42:42,511 - GAugM EPNet train, Epoch [186/215]: loss 0.7208, auc 0.3982, ap 0.4406
2024-01-10 20:42:42,602 - GAugM EPNet train, Epoch [187/215]: loss 0.7209, auc 0.4318, ap 0.4549
2024-01-10 20:42:42,697 - GAugM EPNet train, Epoch [188/215]: loss 0.7209, auc 0.4414, ap 0.4564
2024-01-10 20:42:42,787 - GAugM EPNet train, Epoch [189/215]: loss 0.7209, auc 0.5139, ap 0.5303
2024-01-10 20:42:42,880 - GAugM EPNet train, Epoch [190/215]: loss 0.7209, auc 0.4681, ap 0.4829
2024-01-10 20:42:42,970 - GAugM EPNet train, Epoch [191/215]: loss 0.7209, auc 0.4345, ap 0.4712
2024-01-10 20:42:43,059 - GAugM EPNet train, Epoch [192/215]: loss 0.7209, auc 0.4795, ap 0.4773
2024-01-10 20:42:43,152 - GAugM EPNet train, Epoch [193/215]: loss 0.7209, auc 0.5676, ap 0.5674
2024-01-10 20:42:43,245 - GAugM EPNet train, Epoch [194/215]: loss 0.7209, auc 0.5637, ap 0.5381
2024-01-10 20:42:43,336 - GAugM EPNet train, Epoch [195/215]: loss 0.7209, auc 0.4792, ap 0.4932
2024-01-10 20:42:43,441 - GAugM EPNet train, Epoch [196/215]: loss 0.7208, auc 0.4665, ap 0.4660
2024-01-10 20:42:43,536 - GAugM EPNet train, Epoch [197/215]: loss 0.7210, auc 0.4817, ap 0.4929
2024-01-10 20:42:43,626 - GAugM EPNet train, Epoch [198/215]: loss 0.7210, auc 0.5116, ap 0.4961
2024-01-10 20:42:43,716 - GAugM EPNet train, Epoch [199/215]: loss 0.7209, auc 0.4632, ap 0.4921
2024-01-10 20:42:43,806 - GAugM EPNet train, Epoch [200/215]: loss 0.7210, auc 0.5313, ap 0.5611
2024-01-10 20:42:43,898 - GAugM EPNet train, Epoch [201/215]: loss 0.7209, auc 0.4482, ap 0.4414
2024-01-10 20:42:43,988 - GAugM EPNet train, Epoch [202/215]: loss 0.7210, auc 0.5247, ap 0.5791
2024-01-10 20:42:44,091 - GAugM EPNet train, Epoch [203/215]: loss 0.7210, auc 0.4920, ap 0.5237
2024-01-10 20:42:44,185 - GAugM EPNet train, Epoch [204/215]: loss 0.7209, auc 0.4728, ap 0.5121
2024-01-10 20:42:44,275 - GAugM EPNet train, Epoch [205/215]: loss 0.7209, auc 0.4977, ap 0.5250
2024-01-10 20:42:44,365 - GAugM EPNet train, Epoch [206/215]: loss 0.7209, auc 0.4674, ap 0.4993
2024-01-10 20:42:44,454 - GAugM EPNet train, Epoch [207/215]: loss 0.7210, auc 0.5011, ap 0.5314
2024-01-10 20:42:44,542 - GAugM EPNet train, Epoch [208/215]: loss 0.7209, auc 0.4347, ap 0.4999
2024-01-10 20:42:44,640 - GAugM EPNet train, Epoch [209/215]: loss 0.7210, auc 0.5546, ap 0.5376
2024-01-10 20:42:44,731 - GAugM EPNet train, Epoch [210/215]: loss 0.7209, auc 0.4605, ap 0.4713
2024-01-10 20:42:44,820 - GAugM EPNet train, Epoch [211/215]: loss 0.7210, auc 0.4737, ap 0.5057
2024-01-10 20:42:44,917 - GAugM EPNet train, Epoch [212/215]: loss 0.7210, auc 0.4473, ap 0.4823
2024-01-10 20:42:45,018 - GAugM EPNet train, Epoch [213/215]: loss 0.7208, auc 0.6461, ap 0.6551
2024-01-10 20:42:45,108 - GAugM EPNet train, Epoch [214/215]: loss 0.7210, auc 0.5379, ap 0.5330
2024-01-10 20:42:45,201 - GAugM EPNet train, Epoch [215/215]: loss 0.7210, auc 0.4838, ap 0.4911
2024-01-10 20:42:45,203 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f14a34b5050>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:42:45,967 - GAugM EPNet train, Epoch [  1/215]: loss 0.7210, auc 0.4340, ap 0.4611
2024-01-10 20:42:46,063 - GAugM EPNet train, Epoch [  2/215]: loss 0.7210, auc 0.4767, ap 0.4964
2024-01-10 20:42:46,156 - GAugM EPNet train, Epoch [  3/215]: loss 0.7209, auc 0.5489, ap 0.5581
2024-01-10 20:42:46,257 - GAugM EPNet train, Epoch [  4/215]: loss 0.7209, auc 0.3806, ap 0.4442
2024-01-10 20:42:46,357 - GAugM EPNet train, Epoch [  5/215]: loss 0.7209, auc 0.5806, ap 0.5552
2024-01-10 20:42:46,447 - GAugM EPNet train, Epoch [  6/215]: loss 0.7209, auc 0.5162, ap 0.5250
2024-01-10 20:42:46,538 - GAugM EPNet train, Epoch [  7/215]: loss 0.7209, auc 0.4731, ap 0.4710
2024-01-10 20:42:46,627 - GAugM EPNet train, Epoch [  8/215]: loss 0.7210, auc 0.4382, ap 0.4588
2024-01-10 20:42:46,718 - GAugM EPNet train, Epoch [  9/215]: loss 0.7209, auc 0.4137, ap 0.4542
2024-01-10 20:42:46,807 - GAugM EPNet train, Epoch [ 10/215]: loss 0.7208, auc 0.4443, ap 0.4652
2024-01-10 20:42:46,898 - GAugM EPNet train, Epoch [ 11/215]: loss 0.7209, auc 0.4977, ap 0.5437
2024-01-10 20:42:47,002 - GAugM EPNet train, Epoch [ 12/215]: loss 0.7210, auc 0.5091, ap 0.4909
2024-01-10 20:42:47,092 - GAugM EPNet train, Epoch [ 13/215]: loss 0.7209, auc 0.5799, ap 0.5929
2024-01-10 20:42:47,183 - GAugM EPNet train, Epoch [ 14/215]: loss 0.7209, auc 0.5279, ap 0.5191
2024-01-10 20:42:47,280 - GAugM EPNet train, Epoch [ 15/215]: loss 0.7210, auc 0.4229, ap 0.5014
2024-01-10 20:42:47,375 - GAugM EPNet train, Epoch [ 16/215]: loss 0.7209, auc 0.5689, ap 0.5829
2024-01-10 20:42:47,467 - GAugM EPNet train, Epoch [ 17/215]: loss 0.7210, auc 0.5557, ap 0.5711
2024-01-10 20:42:47,570 - GAugM EPNet train, Epoch [ 18/215]: loss 0.7210, auc 0.6426, ap 0.6144
2024-01-10 20:42:47,667 - GAugM EPNet train, Epoch [ 19/215]: loss 0.7209, auc 0.4980, ap 0.4930
2024-01-10 20:42:47,758 - GAugM EPNet train, Epoch [ 20/215]: loss 0.7210, auc 0.4717, ap 0.5151
2024-01-10 20:42:47,858 - GAugM EPNet train, Epoch [ 21/215]: loss 0.7209, auc 0.4831, ap 0.5062
2024-01-10 20:42:47,956 - GAugM EPNet train, Epoch [ 22/215]: loss 0.7210, auc 0.4482, ap 0.4877
2024-01-10 20:42:48,058 - GAugM EPNet train, Epoch [ 23/215]: loss 0.7208, auc 0.5230, ap 0.5455
2024-01-10 20:42:48,157 - GAugM EPNet train, Epoch [ 24/215]: loss 0.7209, auc 0.5251, ap 0.5265
2024-01-10 20:42:48,248 - GAugM EPNet train, Epoch [ 25/215]: loss 0.7209, auc 0.4610, ap 0.4778
2024-01-10 20:42:48,343 - GAugM EPNet train, Epoch [ 26/215]: loss 0.7210, auc 0.5644, ap 0.5674
2024-01-10 20:42:48,434 - GAugM EPNet train, Epoch [ 27/215]: loss 0.7209, auc 0.3745, ap 0.4619
2024-01-10 20:42:48,526 - GAugM EPNet train, Epoch [ 28/215]: loss 0.7209, auc 0.5482, ap 0.5357
2024-01-10 20:42:48,634 - GAugM EPNet train, Epoch [ 29/215]: loss 0.7210, auc 0.5144, ap 0.5413
2024-01-10 20:42:48,724 - GAugM EPNet train, Epoch [ 30/215]: loss 0.7209, auc 0.5646, ap 0.5482
2024-01-10 20:42:48,816 - GAugM EPNet train, Epoch [ 31/215]: loss 0.7208, auc 0.5675, ap 0.5615
2024-01-10 20:42:48,907 - GAugM EPNet train, Epoch [ 32/215]: loss 0.7210, auc 0.5938, ap 0.5809
2024-01-10 20:42:49,002 - GAugM EPNet train, Epoch [ 33/215]: loss 0.7209, auc 0.4977, ap 0.5096
2024-01-10 20:42:49,095 - GAugM EPNet train, Epoch [ 34/215]: loss 0.7209, auc 0.4066, ap 0.4381
2024-01-10 20:42:49,187 - GAugM EPNet train, Epoch [ 35/215]: loss 0.7209, auc 0.5465, ap 0.5400
2024-01-10 20:42:49,284 - GAugM EPNet train, Epoch [ 36/215]: loss 0.7209, auc 0.5735, ap 0.5525
2024-01-10 20:42:49,374 - GAugM EPNet train, Epoch [ 37/215]: loss 0.7209, auc 0.4966, ap 0.4771
2024-01-10 20:42:49,464 - GAugM EPNet train, Epoch [ 38/215]: loss 0.7209, auc 0.4813, ap 0.4855
2024-01-10 20:42:49,562 - GAugM EPNet train, Epoch [ 39/215]: loss 0.7208, auc 0.4514, ap 0.4968
2024-01-10 20:42:49,651 - GAugM EPNet train, Epoch [ 40/215]: loss 0.7210, auc 0.5329, ap 0.5352
2024-01-10 20:42:49,742 - GAugM EPNet train, Epoch [ 41/215]: loss 0.7210, auc 0.5173, ap 0.5469
2024-01-10 20:42:49,832 - GAugM EPNet train, Epoch [ 42/215]: loss 0.7209, auc 0.5016, ap 0.5316
2024-01-10 20:42:49,922 - GAugM EPNet train, Epoch [ 43/215]: loss 0.7208, auc 0.4461, ap 0.4738
2024-01-10 20:42:50,011 - GAugM EPNet train, Epoch [ 44/215]: loss 0.7208, auc 0.3905, ap 0.4420
2024-01-10 20:42:50,104 - GAugM EPNet train, Epoch [ 45/215]: loss 0.7209, auc 0.5297, ap 0.5676
2024-01-10 20:42:50,194 - GAugM EPNet train, Epoch [ 46/215]: loss 0.7209, auc 0.4439, ap 0.5011
2024-01-10 20:42:50,295 - GAugM EPNet train, Epoch [ 47/215]: loss 0.7210, auc 0.4859, ap 0.4825
2024-01-10 20:42:50,407 - GAugM EPNet train, Epoch [ 48/215]: loss 0.7210, auc 0.6244, ap 0.6210
2024-01-10 20:42:50,500 - GAugM EPNet train, Epoch [ 49/215]: loss 0.7209, auc 0.5251, ap 0.5374
2024-01-10 20:42:50,593 - GAugM EPNet train, Epoch [ 50/215]: loss 0.7210, auc 0.5400, ap 0.5512
2024-01-10 20:42:50,687 - GAugM EPNet train, Epoch [ 51/215]: loss 0.7210, auc 0.4553, ap 0.4884
2024-01-10 20:42:50,784 - GAugM EPNet train, Epoch [ 52/215]: loss 0.7209, auc 0.4179, ap 0.4806
2024-01-10 20:42:50,874 - GAugM EPNet train, Epoch [ 53/215]: loss 0.7209, auc 0.4482, ap 0.5039
2024-01-10 20:42:50,974 - GAugM EPNet train, Epoch [ 54/215]: loss 0.7211, auc 0.5892, ap 0.5928
2024-01-10 20:42:51,067 - GAugM EPNet train, Epoch [ 55/215]: loss 0.7209, auc 0.5988, ap 0.6122
2024-01-10 20:42:51,164 - GAugM EPNet train, Epoch [ 56/215]: loss 0.7208, auc 0.4543, ap 0.4958
2024-01-10 20:42:51,269 - GAugM EPNet train, Epoch [ 57/215]: loss 0.7209, auc 0.4632, ap 0.4605
2024-01-10 20:42:51,368 - GAugM EPNet train, Epoch [ 58/215]: loss 0.7210, auc 0.4774, ap 0.5442
2024-01-10 20:42:51,460 - GAugM EPNet train, Epoch [ 59/215]: loss 0.7211, auc 0.5400, ap 0.5523
2024-01-10 20:42:51,557 - GAugM EPNet train, Epoch [ 60/215]: loss 0.7210, auc 0.5230, ap 0.5070
2024-01-10 20:42:51,660 - GAugM EPNet train, Epoch [ 61/215]: loss 0.7209, auc 0.5151, ap 0.5110
2024-01-10 20:42:51,755 - GAugM EPNet train, Epoch [ 62/215]: loss 0.7210, auc 0.5240, ap 0.5295
2024-01-10 20:42:51,856 - GAugM EPNet train, Epoch [ 63/215]: loss 0.7208, auc 0.5443, ap 0.5238
2024-01-10 20:42:51,950 - GAugM EPNet train, Epoch [ 64/215]: loss 0.7208, auc 0.4596, ap 0.4939
2024-01-10 20:42:52,046 - GAugM EPNet train, Epoch [ 65/215]: loss 0.7208, auc 0.6397, ap 0.5906
2024-01-10 20:42:52,134 - GAugM EPNet train, Epoch [ 66/215]: loss 0.7209, auc 0.4325, ap 0.4572
2024-01-10 20:42:52,226 - GAugM EPNet train, Epoch [ 67/215]: loss 0.7209, auc 0.6234, ap 0.6292
2024-01-10 20:42:52,320 - GAugM EPNet train, Epoch [ 68/215]: loss 0.7210, auc 0.5301, ap 0.5604
2024-01-10 20:42:52,409 - GAugM EPNet train, Epoch [ 69/215]: loss 0.7210, auc 0.5344, ap 0.5482
2024-01-10 20:42:52,503 - GAugM EPNet train, Epoch [ 70/215]: loss 0.7210, auc 0.4923, ap 0.4826
2024-01-10 20:42:52,592 - GAugM EPNet train, Epoch [ 71/215]: loss 0.7210, auc 0.5020, ap 0.4800
2024-01-10 20:42:52,682 - GAugM EPNet train, Epoch [ 72/215]: loss 0.7210, auc 0.4991, ap 0.5197
2024-01-10 20:42:52,772 - GAugM EPNet train, Epoch [ 73/215]: loss 0.7209, auc 0.5151, ap 0.5127
2024-01-10 20:42:52,862 - GAugM EPNet train, Epoch [ 74/215]: loss 0.7209, auc 0.4525, ap 0.4916
2024-01-10 20:42:52,957 - GAugM EPNet train, Epoch [ 75/215]: loss 0.7210, auc 0.4272, ap 0.4743
2024-01-10 20:42:53,054 - GAugM EPNet train, Epoch [ 76/215]: loss 0.7209, auc 0.5532, ap 0.5655
2024-01-10 20:42:53,147 - GAugM EPNet train, Epoch [ 77/215]: loss 0.7208, auc 0.5607, ap 0.5895
2024-01-10 20:42:53,237 - GAugM EPNet train, Epoch [ 78/215]: loss 0.7209, auc 0.5361, ap 0.5256
2024-01-10 20:42:53,330 - GAugM EPNet train, Epoch [ 79/215]: loss 0.7208, auc 0.5546, ap 0.5593
2024-01-10 20:42:53,436 - GAugM EPNet train, Epoch [ 80/215]: loss 0.7209, auc 0.5365, ap 0.5240
2024-01-10 20:42:53,532 - GAugM EPNet train, Epoch [ 81/215]: loss 0.7209, auc 0.5667, ap 0.5521
2024-01-10 20:42:53,623 - GAugM EPNet train, Epoch [ 82/215]: loss 0.7210, auc 0.4696, ap 0.4646
2024-01-10 20:42:53,721 - GAugM EPNet train, Epoch [ 83/215]: loss 0.7209, auc 0.5116, ap 0.5405
2024-01-10 20:42:53,814 - GAugM EPNet train, Epoch [ 84/215]: loss 0.7209, auc 0.4407, ap 0.4958
2024-01-10 20:42:53,912 - GAugM EPNet train, Epoch [ 85/215]: loss 0.7210, auc 0.3877, ap 0.4291
2024-01-10 20:42:54,004 - GAugM EPNet train, Epoch [ 86/215]: loss 0.7208, auc 0.5347, ap 0.5431
2024-01-10 20:42:54,095 - GAugM EPNet train, Epoch [ 87/215]: loss 0.7209, auc 0.5226, ap 0.5215
2024-01-10 20:42:54,200 - GAugM EPNet train, Epoch [ 88/215]: loss 0.7210, auc 0.4418, ap 0.4945
2024-01-10 20:42:54,302 - GAugM EPNet train, Epoch [ 89/215]: loss 0.7210, auc 0.4852, ap 0.5162
2024-01-10 20:42:54,410 - GAugM EPNet train, Epoch [ 90/215]: loss 0.7209, auc 0.4966, ap 0.5390
2024-01-10 20:42:54,506 - GAugM EPNet train, Epoch [ 91/215]: loss 0.7208, auc 0.5760, ap 0.5416
2024-01-10 20:42:54,600 - GAugM EPNet train, Epoch [ 92/215]: loss 0.7209, auc 0.5860, ap 0.6033
2024-01-10 20:42:54,693 - GAugM EPNet train, Epoch [ 93/215]: loss 0.7209, auc 0.3848, ap 0.4555
2024-01-10 20:42:54,786 - GAugM EPNet train, Epoch [ 94/215]: loss 0.7210, auc 0.4546, ap 0.5047
2024-01-10 20:42:54,882 - GAugM EPNet train, Epoch [ 95/215]: loss 0.7210, auc 0.5376, ap 0.5261
2024-01-10 20:42:54,979 - GAugM EPNet train, Epoch [ 96/215]: loss 0.7209, auc 0.5532, ap 0.5383
2024-01-10 20:42:55,071 - GAugM EPNet train, Epoch [ 97/215]: loss 0.7209, auc 0.4283, ap 0.4716
2024-01-10 20:42:55,163 - GAugM EPNet train, Epoch [ 98/215]: loss 0.7209, auc 0.5522, ap 0.5308
2024-01-10 20:42:55,255 - GAugM EPNet train, Epoch [ 99/215]: loss 0.7209, auc 0.5066, ap 0.5374
2024-01-10 20:42:55,348 - GAugM EPNet train, Epoch [100/215]: loss 0.7210, auc 0.4931, ap 0.5277
2024-01-10 20:42:55,446 - GAugM EPNet train, Epoch [101/215]: loss 0.7210, auc 0.5436, ap 0.5851
2024-01-10 20:42:55,542 - GAugM EPNet train, Epoch [102/215]: loss 0.7209, auc 0.4820, ap 0.4870
2024-01-10 20:42:55,636 - GAugM EPNet train, Epoch [103/215]: loss 0.7209, auc 0.5358, ap 0.5714
2024-01-10 20:42:55,736 - GAugM EPNet train, Epoch [104/215]: loss 0.7209, auc 0.3866, ap 0.4389
2024-01-10 20:42:55,828 - GAugM EPNet train, Epoch [105/215]: loss 0.7209, auc 0.4414, ap 0.4742
2024-01-10 20:42:55,921 - GAugM EPNet train, Epoch [106/215]: loss 0.7210, auc 0.5290, ap 0.5476
2024-01-10 20:42:56,010 - GAugM EPNet train, Epoch [107/215]: loss 0.7210, auc 0.4973, ap 0.5110
2024-01-10 20:42:56,100 - GAugM EPNet train, Epoch [108/215]: loss 0.7208, auc 0.5614, ap 0.5556
2024-01-10 20:42:56,188 - GAugM EPNet train, Epoch [109/215]: loss 0.7210, auc 0.4268, ap 0.5045
2024-01-10 20:42:56,278 - GAugM EPNet train, Epoch [110/215]: loss 0.7209, auc 0.4414, ap 0.4587
2024-01-10 20:42:56,369 - GAugM EPNet train, Epoch [111/215]: loss 0.7210, auc 0.5294, ap 0.5290
2024-01-10 20:42:56,477 - GAugM EPNet train, Epoch [112/215]: loss 0.7209, auc 0.4528, ap 0.4954
2024-01-10 20:42:56,573 - GAugM EPNet train, Epoch [113/215]: loss 0.7210, auc 0.4991, ap 0.5467
2024-01-10 20:42:56,669 - GAugM EPNet train, Epoch [114/215]: loss 0.7209, auc 0.4649, ap 0.4798
2024-01-10 20:42:56,761 - GAugM EPNet train, Epoch [115/215]: loss 0.7210, auc 0.4938, ap 0.4970
2024-01-10 20:42:56,861 - GAugM EPNet train, Epoch [116/215]: loss 0.7209, auc 0.5023, ap 0.5121
2024-01-10 20:42:56,958 - GAugM EPNet train, Epoch [117/215]: loss 0.7208, auc 0.4379, ap 0.4681
2024-01-10 20:42:57,054 - GAugM EPNet train, Epoch [118/215]: loss 0.7209, auc 0.5094, ap 0.5568
2024-01-10 20:42:57,151 - GAugM EPNet train, Epoch [119/215]: loss 0.7209, auc 0.5098, ap 0.5509
2024-01-10 20:42:57,245 - GAugM EPNet train, Epoch [120/215]: loss 0.7210, auc 0.5219, ap 0.5001
2024-01-10 20:42:57,343 - GAugM EPNet train, Epoch [121/215]: loss 0.7210, auc 0.4610, ap 0.4730
2024-01-10 20:42:57,436 - GAugM EPNet train, Epoch [122/215]: loss 0.7209, auc 0.4770, ap 0.5240
2024-01-10 20:42:57,526 - GAugM EPNet train, Epoch [123/215]: loss 0.7209, auc 0.4813, ap 0.5057
2024-01-10 20:42:57,623 - GAugM EPNet train, Epoch [124/215]: loss 0.7210, auc 0.4802, ap 0.5143
2024-01-10 20:42:57,720 - GAugM EPNet train, Epoch [125/215]: loss 0.7209, auc 0.5109, ap 0.5410
2024-01-10 20:42:57,813 - GAugM EPNet train, Epoch [126/215]: loss 0.7210, auc 0.5052, ap 0.5179
2024-01-10 20:42:57,905 - GAugM EPNet train, Epoch [127/215]: loss 0.7209, auc 0.4902, ap 0.4946
2024-01-10 20:42:57,997 - GAugM EPNet train, Epoch [128/215]: loss 0.7210, auc 0.5347, ap 0.5489
2024-01-10 20:42:58,086 - GAugM EPNet train, Epoch [129/215]: loss 0.7208, auc 0.4293, ap 0.4737
2024-01-10 20:42:58,177 - GAugM EPNet train, Epoch [130/215]: loss 0.7210, auc 0.4575, ap 0.4797
2024-01-10 20:42:58,269 - GAugM EPNet train, Epoch [131/215]: loss 0.7210, auc 0.5044, ap 0.5635
2024-01-10 20:42:58,362 - GAugM EPNet train, Epoch [132/215]: loss 0.7209, auc 0.4685, ap 0.4850
2024-01-10 20:42:58,454 - GAugM EPNet train, Epoch [133/215]: loss 0.7209, auc 0.4984, ap 0.5119
2024-01-10 20:42:58,545 - GAugM EPNet train, Epoch [134/215]: loss 0.7210, auc 0.4867, ap 0.4907
2024-01-10 20:42:58,645 - GAugM EPNet train, Epoch [135/215]: loss 0.7209, auc 0.4105, ap 0.4979
2024-01-10 20:42:58,735 - GAugM EPNet train, Epoch [136/215]: loss 0.7209, auc 0.5276, ap 0.5103
2024-01-10 20:42:58,828 - GAugM EPNet train, Epoch [137/215]: loss 0.7210, auc 0.5020, ap 0.4978
2024-01-10 20:42:58,922 - GAugM EPNet train, Epoch [138/215]: loss 0.7210, auc 0.5333, ap 0.5154
2024-01-10 20:42:59,022 - GAugM EPNet train, Epoch [139/215]: loss 0.7210, auc 0.4528, ap 0.4700
2024-01-10 20:42:59,128 - GAugM EPNet train, Epoch [140/215]: loss 0.7209, auc 0.4614, ap 0.4972
2024-01-10 20:42:59,224 - GAugM EPNet train, Epoch [141/215]: loss 0.7209, auc 0.5098, ap 0.4826
2024-01-10 20:42:59,316 - GAugM EPNet train, Epoch [142/215]: loss 0.7209, auc 0.4692, ap 0.4971
2024-01-10 20:42:59,408 - GAugM EPNet train, Epoch [143/215]: loss 0.7209, auc 0.4600, ap 0.4904
2024-01-10 20:42:59,509 - GAugM EPNet train, Epoch [144/215]: loss 0.7209, auc 0.4333, ap 0.4508
2024-01-10 20:42:59,602 - GAugM EPNet train, Epoch [145/215]: loss 0.7209, auc 0.4867, ap 0.5338
2024-01-10 20:42:59,703 - GAugM EPNet train, Epoch [146/215]: loss 0.7209, auc 0.5044, ap 0.5504
2024-01-10 20:42:59,797 - GAugM EPNet train, Epoch [147/215]: loss 0.7209, auc 0.6618, ap 0.6737
2024-01-10 20:42:59,901 - GAugM EPNet train, Epoch [148/215]: loss 0.7209, auc 0.4931, ap 0.5425
2024-01-10 20:42:59,993 - GAugM EPNet train, Epoch [149/215]: loss 0.7208, auc 0.5404, ap 0.5753
2024-01-10 20:43:00,087 - GAugM EPNet train, Epoch [150/215]: loss 0.7209, auc 0.4863, ap 0.4976
2024-01-10 20:43:00,179 - GAugM EPNet train, Epoch [151/215]: loss 0.7209, auc 0.4738, ap 0.5149
2024-01-10 20:43:00,276 - GAugM EPNet train, Epoch [152/215]: loss 0.7209, auc 0.5504, ap 0.5536
2024-01-10 20:43:00,377 - GAugM EPNet train, Epoch [153/215]: loss 0.7209, auc 0.4464, ap 0.4851
2024-01-10 20:43:00,469 - GAugM EPNet train, Epoch [154/215]: loss 0.7209, auc 0.5692, ap 0.5990
2024-01-10 20:43:00,560 - GAugM EPNet train, Epoch [155/215]: loss 0.7209, auc 0.5297, ap 0.5366
2024-01-10 20:43:00,649 - GAugM EPNet train, Epoch [156/215]: loss 0.7209, auc 0.4389, ap 0.4686
2024-01-10 20:43:00,739 - GAugM EPNet train, Epoch [157/215]: loss 0.7209, auc 0.4817, ap 0.5044
2024-01-10 20:43:00,834 - GAugM EPNet train, Epoch [158/215]: loss 0.7208, auc 0.4877, ap 0.5004
2024-01-10 20:43:00,923 - GAugM EPNet train, Epoch [159/215]: loss 0.7208, auc 0.5465, ap 0.5324
2024-01-10 20:43:01,014 - GAugM EPNet train, Epoch [160/215]: loss 0.7209, auc 0.6095, ap 0.6247
2024-01-10 20:43:01,103 - GAugM EPNet train, Epoch [161/215]: loss 0.7209, auc 0.5319, ap 0.5330
2024-01-10 20:43:01,193 - GAugM EPNet train, Epoch [162/215]: loss 0.7209, auc 0.4187, ap 0.4418
2024-01-10 20:43:01,283 - GAugM EPNet train, Epoch [163/215]: loss 0.7209, auc 0.4610, ap 0.4742
2024-01-10 20:43:01,373 - GAugM EPNet train, Epoch [164/215]: loss 0.7211, auc 0.5539, ap 0.5346
2024-01-10 20:43:01,477 - GAugM EPNet train, Epoch [165/215]: loss 0.7210, auc 0.4649, ap 0.4730
2024-01-10 20:43:01,567 - GAugM EPNet train, Epoch [166/215]: loss 0.7208, auc 0.5244, ap 0.5258
2024-01-10 20:43:01,660 - GAugM EPNet train, Epoch [167/215]: loss 0.7209, auc 0.4133, ap 0.4537
2024-01-10 20:43:01,752 - GAugM EPNet train, Epoch [168/215]: loss 0.7209, auc 0.4842, ap 0.5135
2024-01-10 20:43:01,844 - GAugM EPNet train, Epoch [169/215]: loss 0.7209, auc 0.5393, ap 0.5733
2024-01-10 20:43:01,936 - GAugM EPNet train, Epoch [170/215]: loss 0.7210, auc 0.4567, ap 0.4685
2024-01-10 20:43:02,034 - GAugM EPNet train, Epoch [171/215]: loss 0.7209, auc 0.5411, ap 0.5299
2024-01-10 20:43:02,128 - GAugM EPNet train, Epoch [172/215]: loss 0.7208, auc 0.4489, ap 0.4732
2024-01-10 20:43:02,233 - GAugM EPNet train, Epoch [173/215]: loss 0.7209, auc 0.5554, ap 0.5497
2024-01-10 20:43:02,327 - GAugM EPNet train, Epoch [174/215]: loss 0.7209, auc 0.4717, ap 0.4722
2024-01-10 20:43:02,428 - GAugM EPNet train, Epoch [175/215]: loss 0.7209, auc 0.6123, ap 0.5823
2024-01-10 20:43:02,520 - GAugM EPNet train, Epoch [176/215]: loss 0.7209, auc 0.5468, ap 0.5442
2024-01-10 20:43:02,622 - GAugM EPNet train, Epoch [177/215]: loss 0.7210, auc 0.4400, ap 0.4698
2024-01-10 20:43:02,716 - GAugM EPNet train, Epoch [178/215]: loss 0.7210, auc 0.6034, ap 0.6089
2024-01-10 20:43:02,808 - GAugM EPNet train, Epoch [179/215]: loss 0.7210, auc 0.3784, ap 0.4360
2024-01-10 20:43:02,901 - GAugM EPNet train, Epoch [180/215]: loss 0.7210, auc 0.6038, ap 0.6429
2024-01-10 20:43:02,998 - GAugM EPNet train, Epoch [181/215]: loss 0.7209, auc 0.4293, ap 0.5127
2024-01-10 20:43:03,103 - GAugM EPNet train, Epoch [182/215]: loss 0.7209, auc 0.4689, ap 0.5009
2024-01-10 20:43:03,203 - GAugM EPNet train, Epoch [183/215]: loss 0.7210, auc 0.5760, ap 0.5486
2024-01-10 20:43:03,296 - GAugM EPNet train, Epoch [184/215]: loss 0.7209, auc 0.4713, ap 0.5108
2024-01-10 20:43:03,389 - GAugM EPNet train, Epoch [185/215]: loss 0.7209, auc 0.5137, ap 0.5124
2024-01-10 20:43:03,490 - GAugM EPNet train, Epoch [186/215]: loss 0.7208, auc 0.4343, ap 0.4968
2024-01-10 20:43:03,582 - GAugM EPNet train, Epoch [187/215]: loss 0.7209, auc 0.4795, ap 0.4818
2024-01-10 20:43:03,674 - GAugM EPNet train, Epoch [188/215]: loss 0.7209, auc 0.4112, ap 0.4339
2024-01-10 20:43:03,771 - GAugM EPNet train, Epoch [189/215]: loss 0.7209, auc 0.5959, ap 0.6086
2024-01-10 20:43:03,863 - GAugM EPNet train, Epoch [190/215]: loss 0.7209, auc 0.4436, ap 0.4559
2024-01-10 20:43:03,962 - GAugM EPNet train, Epoch [191/215]: loss 0.7209, auc 0.4365, ap 0.4931
2024-01-10 20:43:04,055 - GAugM EPNet train, Epoch [192/215]: loss 0.7209, auc 0.4842, ap 0.4691
2024-01-10 20:43:04,147 - GAugM EPNet train, Epoch [193/215]: loss 0.7209, auc 0.5315, ap 0.5364
2024-01-10 20:43:04,246 - GAugM EPNet train, Epoch [194/215]: loss 0.7209, auc 0.5123, ap 0.5066
2024-01-10 20:43:04,339 - GAugM EPNet train, Epoch [195/215]: loss 0.7209, auc 0.4585, ap 0.4694
2024-01-10 20:43:04,435 - GAugM EPNet train, Epoch [196/215]: loss 0.7208, auc 0.5764, ap 0.5558
2024-01-10 20:43:04,528 - GAugM EPNet train, Epoch [197/215]: loss 0.7210, auc 0.4699, ap 0.4909
2024-01-10 20:43:04,619 - GAugM EPNet train, Epoch [198/215]: loss 0.7210, auc 0.5340, ap 0.5386
2024-01-10 20:43:04,711 - GAugM EPNet train, Epoch [199/215]: loss 0.7209, auc 0.4763, ap 0.5243
2024-01-10 20:43:04,806 - GAugM EPNet train, Epoch [200/215]: loss 0.7210, auc 0.4628, ap 0.4951
2024-01-10 20:43:04,902 - GAugM EPNet train, Epoch [201/215]: loss 0.7209, auc 0.4624, ap 0.4907
2024-01-10 20:43:04,997 - GAugM EPNet train, Epoch [202/215]: loss 0.7210, auc 0.5208, ap 0.5723
2024-01-10 20:43:05,085 - GAugM EPNet train, Epoch [203/215]: loss 0.7210, auc 0.5963, ap 0.6180
2024-01-10 20:43:05,175 - GAugM EPNet train, Epoch [204/215]: loss 0.7209, auc 0.4429, ap 0.4641
2024-01-10 20:43:05,263 - GAugM EPNet train, Epoch [205/215]: loss 0.7209, auc 0.5244, ap 0.5502
2024-01-10 20:43:05,350 - GAugM EPNet train, Epoch [206/215]: loss 0.7209, auc 0.4685, ap 0.4974
2024-01-10 20:43:05,445 - GAugM EPNet train, Epoch [207/215]: loss 0.7210, auc 0.4795, ap 0.5157
2024-01-10 20:43:05,534 - GAugM EPNet train, Epoch [208/215]: loss 0.7209, auc 0.5297, ap 0.5729
2024-01-10 20:43:05,622 - GAugM EPNet train, Epoch [209/215]: loss 0.7210, auc 0.6155, ap 0.6429
2024-01-10 20:43:05,723 - GAugM EPNet train, Epoch [210/215]: loss 0.7209, auc 0.4162, ap 0.4435
2024-01-10 20:43:05,812 - GAugM EPNet train, Epoch [211/215]: loss 0.7210, auc 0.5094, ap 0.5390
2024-01-10 20:43:05,917 - GAugM EPNet train, Epoch [212/215]: loss 0.7210, auc 0.4598, ap 0.4768
2024-01-10 20:43:06,012 - GAugM EPNet train, Epoch [213/215]: loss 0.7208, auc 0.6148, ap 0.6520
2024-01-10 20:43:06,103 - GAugM EPNet train, Epoch [214/215]: loss 0.7210, auc 0.5144, ap 0.5362
2024-01-10 20:43:06,195 - GAugM EPNet train, Epoch [215/215]: loss 0.7210, auc 0.4792, ap 0.4881
2024-01-10 20:43:06,203 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f14a36e0750>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:43:06,982 - GAugM EPNet train, Epoch [  1/215]: loss 0.7210, auc 0.4694, ap 0.4857
2024-01-10 20:43:07,076 - GAugM EPNet train, Epoch [  2/215]: loss 0.7210, auc 0.5317, ap 0.5174
2024-01-10 20:43:07,168 - GAugM EPNet train, Epoch [  3/215]: loss 0.7209, auc 0.5876, ap 0.5610
2024-01-10 20:43:07,261 - GAugM EPNet train, Epoch [  4/215]: loss 0.7209, auc 0.5109, ap 0.5465
2024-01-10 20:43:07,353 - GAugM EPNet train, Epoch [  5/215]: loss 0.7209, auc 0.5787, ap 0.5702
2024-01-10 20:43:07,443 - GAugM EPNet train, Epoch [  6/215]: loss 0.7209, auc 0.5242, ap 0.5087
2024-01-10 20:43:07,534 - GAugM EPNet train, Epoch [  7/215]: loss 0.7209, auc 0.4416, ap 0.4501
2024-01-10 20:43:07,629 - GAugM EPNet train, Epoch [  8/215]: loss 0.7210, auc 0.5858, ap 0.5395
2024-01-10 20:43:07,723 - GAugM EPNet train, Epoch [  9/215]: loss 0.7209, auc 0.4395, ap 0.4602
2024-01-10 20:43:07,814 - GAugM EPNet train, Epoch [ 10/215]: loss 0.7208, auc 0.4929, ap 0.4920
2024-01-10 20:43:07,906 - GAugM EPNet train, Epoch [ 11/215]: loss 0.7209, auc 0.4562, ap 0.4840
2024-01-10 20:43:07,994 - GAugM EPNet train, Epoch [ 12/215]: loss 0.7210, auc 0.4470, ap 0.4717
2024-01-10 20:43:08,085 - GAugM EPNet train, Epoch [ 13/215]: loss 0.7209, auc 0.6198, ap 0.5812
2024-01-10 20:43:08,175 - GAugM EPNet train, Epoch [ 14/215]: loss 0.7209, auc 0.5066, ap 0.5033
2024-01-10 20:43:08,277 - GAugM EPNet train, Epoch [ 15/215]: loss 0.7210, auc 0.3770, ap 0.4336
2024-01-10 20:43:08,376 - GAugM EPNet train, Epoch [ 16/215]: loss 0.7209, auc 0.5764, ap 0.5542
2024-01-10 20:43:08,467 - GAugM EPNet train, Epoch [ 17/215]: loss 0.7210, auc 0.5584, ap 0.5447
2024-01-10 20:43:08,556 - GAugM EPNet train, Epoch [ 18/215]: loss 0.7210, auc 0.5578, ap 0.5422
2024-01-10 20:43:08,651 - GAugM EPNet train, Epoch [ 19/215]: loss 0.7209, auc 0.5208, ap 0.5106
2024-01-10 20:43:08,751 - GAugM EPNet train, Epoch [ 20/215]: loss 0.7210, auc 0.5447, ap 0.5443
2024-01-10 20:43:08,847 - GAugM EPNet train, Epoch [ 21/215]: loss 0.7209, auc 0.5117, ap 0.5249
2024-01-10 20:43:08,938 - GAugM EPNet train, Epoch [ 22/215]: loss 0.7210, auc 0.4003, ap 0.4502
2024-01-10 20:43:09,028 - GAugM EPNet train, Epoch [ 23/215]: loss 0.7208, auc 0.4475, ap 0.4607
2024-01-10 20:43:09,132 - GAugM EPNet train, Epoch [ 24/215]: loss 0.7209, auc 0.5532, ap 0.5487
2024-01-10 20:43:09,222 - GAugM EPNet train, Epoch [ 25/215]: loss 0.7209, auc 0.4523, ap 0.4706
2024-01-10 20:43:09,312 - GAugM EPNet train, Epoch [ 26/215]: loss 0.7210, auc 0.5158, ap 0.4967
2024-01-10 20:43:09,400 - GAugM EPNet train, Epoch [ 27/215]: loss 0.7209, auc 0.4409, ap 0.5034
2024-01-10 20:43:09,491 - GAugM EPNet train, Epoch [ 28/215]: loss 0.7209, auc 0.5785, ap 0.5808
2024-01-10 20:43:09,587 - GAugM EPNet train, Epoch [ 29/215]: loss 0.7210, auc 0.5586, ap 0.5557
2024-01-10 20:43:09,678 - GAugM EPNet train, Epoch [ 30/215]: loss 0.7209, auc 0.6120, ap 0.6200
2024-01-10 20:43:09,782 - GAugM EPNet train, Epoch [ 31/215]: loss 0.7208, auc 0.5043, ap 0.4950
2024-01-10 20:43:09,880 - GAugM EPNet train, Epoch [ 32/215]: loss 0.7210, auc 0.5609, ap 0.5471
2024-01-10 20:43:09,972 - GAugM EPNet train, Epoch [ 33/215]: loss 0.7209, auc 0.5963, ap 0.5537
2024-01-10 20:43:10,065 - GAugM EPNet train, Epoch [ 34/215]: loss 0.7209, auc 0.4203, ap 0.4436
2024-01-10 20:43:10,155 - GAugM EPNet train, Epoch [ 35/215]: loss 0.7209, auc 0.5692, ap 0.5439
2024-01-10 20:43:10,250 - GAugM EPNet train, Epoch [ 36/215]: loss 0.7209, auc 0.5513, ap 0.5421
2024-01-10 20:43:10,339 - GAugM EPNet train, Epoch [ 37/215]: loss 0.7209, auc 0.4742, ap 0.5115
2024-01-10 20:43:10,434 - GAugM EPNet train, Epoch [ 38/215]: loss 0.7209, auc 0.4480, ap 0.4638
2024-01-10 20:43:10,519 - GAugM EPNet train, Epoch [ 39/215]: loss 0.7208, auc 0.4729, ap 0.4897
2024-01-10 20:43:10,607 - GAugM EPNet train, Epoch [ 40/215]: loss 0.7210, auc 0.5616, ap 0.5381
2024-01-10 20:43:10,694 - GAugM EPNet train, Epoch [ 41/215]: loss 0.7210, auc 0.5256, ap 0.5346
2024-01-10 20:43:10,795 - GAugM EPNet train, Epoch [ 42/215]: loss 0.7209, auc 0.5376, ap 0.5673
2024-01-10 20:43:10,892 - GAugM EPNet train, Epoch [ 43/215]: loss 0.7208, auc 0.4779, ap 0.4839
2024-01-10 20:43:10,985 - GAugM EPNet train, Epoch [ 44/215]: loss 0.7208, auc 0.3736, ap 0.4166
2024-01-10 20:43:11,079 - GAugM EPNet train, Epoch [ 45/215]: loss 0.7209, auc 0.4818, ap 0.5168
2024-01-10 20:43:11,171 - GAugM EPNet train, Epoch [ 46/215]: loss 0.7209, auc 0.3629, ap 0.4294
2024-01-10 20:43:11,268 - GAugM EPNet train, Epoch [ 47/215]: loss 0.7210, auc 0.5281, ap 0.5145
2024-01-10 20:43:11,362 - GAugM EPNet train, Epoch [ 48/215]: loss 0.7210, auc 0.5776, ap 0.5686
2024-01-10 20:43:11,463 - GAugM EPNet train, Epoch [ 49/215]: loss 0.7209, auc 0.5603, ap 0.5483
2024-01-10 20:43:11,561 - GAugM EPNet train, Epoch [ 50/215]: loss 0.7210, auc 0.5146, ap 0.5060
2024-01-10 20:43:11,655 - GAugM EPNet train, Epoch [ 51/215]: loss 0.7210, auc 0.4571, ap 0.4856
2024-01-10 20:43:11,748 - GAugM EPNet train, Epoch [ 52/215]: loss 0.7209, auc 0.4491, ap 0.5033
2024-01-10 20:43:11,852 - GAugM EPNet train, Epoch [ 53/215]: loss 0.7209, auc 0.5475, ap 0.5384
2024-01-10 20:43:11,944 - GAugM EPNet train, Epoch [ 54/215]: loss 0.7211, auc 0.5103, ap 0.5182
2024-01-10 20:43:12,043 - GAugM EPNet train, Epoch [ 55/215]: loss 0.7209, auc 0.5787, ap 0.5978
2024-01-10 20:43:12,146 - GAugM EPNet train, Epoch [ 56/215]: loss 0.7208, auc 0.4592, ap 0.4877
2024-01-10 20:43:12,236 - GAugM EPNet train, Epoch [ 57/215]: loss 0.7209, auc 0.4187, ap 0.4438
2024-01-10 20:43:12,327 - GAugM EPNet train, Epoch [ 58/215]: loss 0.7210, auc 0.5182, ap 0.5524
2024-01-10 20:43:12,426 - GAugM EPNet train, Epoch [ 59/215]: loss 0.7211, auc 0.4537, ap 0.4537
2024-01-10 20:43:12,519 - GAugM EPNet train, Epoch [ 60/215]: loss 0.7210, auc 0.5269, ap 0.5128
2024-01-10 20:43:12,609 - GAugM EPNet train, Epoch [ 61/215]: loss 0.7209, auc 0.5194, ap 0.5034
2024-01-10 20:43:12,704 - GAugM EPNet train, Epoch [ 62/215]: loss 0.7210, auc 0.5792, ap 0.5720
2024-01-10 20:43:12,800 - GAugM EPNet train, Epoch [ 63/215]: loss 0.7208, auc 0.4729, ap 0.4714
2024-01-10 20:43:12,891 - GAugM EPNet train, Epoch [ 64/215]: loss 0.7208, auc 0.4608, ap 0.4967
2024-01-10 20:43:12,982 - GAugM EPNet train, Epoch [ 65/215]: loss 0.7208, auc 0.5459, ap 0.5570
2024-01-10 20:43:13,077 - GAugM EPNet train, Epoch [ 66/215]: loss 0.7209, auc 0.4238, ap 0.4589
2024-01-10 20:43:13,168 - GAugM EPNet train, Epoch [ 67/215]: loss 0.7209, auc 0.5895, ap 0.5614
2024-01-10 20:43:13,260 - GAugM EPNet train, Epoch [ 68/215]: loss 0.7210, auc 0.5541, ap 0.5613
2024-01-10 20:43:13,351 - GAugM EPNet train, Epoch [ 69/215]: loss 0.7210, auc 0.4455, ap 0.4645
2024-01-10 20:43:13,442 - GAugM EPNet train, Epoch [ 70/215]: loss 0.7210, auc 0.4751, ap 0.4851
2024-01-10 20:43:13,532 - GAugM EPNet train, Epoch [ 71/215]: loss 0.7210, auc 0.5632, ap 0.5532
2024-01-10 20:43:13,623 - GAugM EPNet train, Epoch [ 72/215]: loss 0.7210, auc 0.4350, ap 0.4554
2024-01-10 20:43:13,711 - GAugM EPNet train, Epoch [ 73/215]: loss 0.7209, auc 0.4941, ap 0.4879
2024-01-10 20:43:13,797 - GAugM EPNet train, Epoch [ 74/215]: loss 0.7209, auc 0.4966, ap 0.5350
2024-01-10 20:43:13,888 - GAugM EPNet train, Epoch [ 75/215]: loss 0.7210, auc 0.4215, ap 0.4525
2024-01-10 20:43:13,974 - GAugM EPNet train, Epoch [ 76/215]: loss 0.7209, auc 0.4849, ap 0.4830
2024-01-10 20:43:14,069 - GAugM EPNet train, Epoch [ 77/215]: loss 0.7208, auc 0.5440, ap 0.5647
2024-01-10 20:43:14,154 - GAugM EPNet train, Epoch [ 78/215]: loss 0.7209, auc 0.5007, ap 0.5066
2024-01-10 20:43:14,241 - GAugM EPNet train, Epoch [ 79/215]: loss 0.7208, auc 0.4970, ap 0.4981
2024-01-10 20:43:14,326 - GAugM EPNet train, Epoch [ 80/215]: loss 0.7209, auc 0.5488, ap 0.5263
2024-01-10 20:43:14,416 - GAugM EPNet train, Epoch [ 81/215]: loss 0.7209, auc 0.5477, ap 0.5085
2024-01-10 20:43:14,504 - GAugM EPNet train, Epoch [ 82/215]: loss 0.7210, auc 0.4804, ap 0.4843
2024-01-10 20:43:14,598 - GAugM EPNet train, Epoch [ 83/215]: loss 0.7209, auc 0.4345, ap 0.4668
2024-01-10 20:43:14,696 - GAugM EPNet train, Epoch [ 84/215]: loss 0.7209, auc 0.4585, ap 0.5202
2024-01-10 20:43:14,785 - GAugM EPNet train, Epoch [ 85/215]: loss 0.7210, auc 0.4569, ap 0.4865
2024-01-10 20:43:14,879 - GAugM EPNet train, Epoch [ 86/215]: loss 0.7208, auc 0.5543, ap 0.5347
2024-01-10 20:43:14,967 - GAugM EPNet train, Epoch [ 87/215]: loss 0.7209, auc 0.5303, ap 0.5198
2024-01-10 20:43:15,055 - GAugM EPNet train, Epoch [ 88/215]: loss 0.7210, auc 0.5117, ap 0.4876
2024-01-10 20:43:15,154 - GAugM EPNet train, Epoch [ 89/215]: loss 0.7210, auc 0.5224, ap 0.5330
2024-01-10 20:43:15,244 - GAugM EPNet train, Epoch [ 90/215]: loss 0.7209, auc 0.4754, ap 0.4978
2024-01-10 20:43:15,345 - GAugM EPNet train, Epoch [ 91/215]: loss 0.7208, auc 0.4883, ap 0.4750
2024-01-10 20:43:15,438 - GAugM EPNet train, Epoch [ 92/215]: loss 0.7209, auc 0.6219, ap 0.6069
2024-01-10 20:43:15,545 - GAugM EPNet train, Epoch [ 93/215]: loss 0.7209, auc 0.3791, ap 0.4399
2024-01-10 20:43:15,651 - GAugM EPNet train, Epoch [ 94/215]: loss 0.7210, auc 0.4667, ap 0.5055
2024-01-10 20:43:15,745 - GAugM EPNet train, Epoch [ 95/215]: loss 0.7210, auc 0.4662, ap 0.5215
2024-01-10 20:43:15,838 - GAugM EPNet train, Epoch [ 96/215]: loss 0.7209, auc 0.4931, ap 0.4996
2024-01-10 20:43:15,932 - GAugM EPNet train, Epoch [ 97/215]: loss 0.7209, auc 0.4923, ap 0.5288
2024-01-10 20:43:16,025 - GAugM EPNet train, Epoch [ 98/215]: loss 0.7209, auc 0.4559, ap 0.4842
2024-01-10 20:43:16,113 - GAugM EPNet train, Epoch [ 99/215]: loss 0.7209, auc 0.4591, ap 0.4673
2024-01-10 20:43:16,202 - GAugM EPNet train, Epoch [100/215]: loss 0.7210, auc 0.4938, ap 0.5195
2024-01-10 20:43:16,301 - GAugM EPNet train, Epoch [101/215]: loss 0.7210, auc 0.4649, ap 0.5108
2024-01-10 20:43:16,392 - GAugM EPNet train, Epoch [102/215]: loss 0.7209, auc 0.4425, ap 0.4655
2024-01-10 20:43:16,499 - GAugM EPNet train, Epoch [103/215]: loss 0.7209, auc 0.5082, ap 0.5371
2024-01-10 20:43:16,594 - GAugM EPNet train, Epoch [104/215]: loss 0.7209, auc 0.5128, ap 0.4922
2024-01-10 20:43:16,683 - GAugM EPNet train, Epoch [105/215]: loss 0.7209, auc 0.4363, ap 0.4609
2024-01-10 20:43:16,773 - GAugM EPNet train, Epoch [106/215]: loss 0.7210, auc 0.4281, ap 0.4460
2024-01-10 20:43:16,862 - GAugM EPNet train, Epoch [107/215]: loss 0.7210, auc 0.4295, ap 0.4849
2024-01-10 20:43:16,952 - GAugM EPNet train, Epoch [108/215]: loss 0.7208, auc 0.4462, ap 0.4530
2024-01-10 20:43:17,045 - GAugM EPNet train, Epoch [109/215]: loss 0.7210, auc 0.4066, ap 0.4229
2024-01-10 20:43:17,138 - GAugM EPNet train, Epoch [110/215]: loss 0.7209, auc 0.4858, ap 0.5187
2024-01-10 20:43:17,230 - GAugM EPNet train, Epoch [111/215]: loss 0.7210, auc 0.4728, ap 0.5028
2024-01-10 20:43:17,324 - GAugM EPNet train, Epoch [112/215]: loss 0.7209, auc 0.5294, ap 0.5213
2024-01-10 20:43:17,413 - GAugM EPNet train, Epoch [113/215]: loss 0.7210, auc 0.5352, ap 0.5460
2024-01-10 20:43:17,506 - GAugM EPNet train, Epoch [114/215]: loss 0.7209, auc 0.4494, ap 0.4745
2024-01-10 20:43:17,594 - GAugM EPNet train, Epoch [115/215]: loss 0.7210, auc 0.4957, ap 0.5039
2024-01-10 20:43:17,689 - GAugM EPNet train, Epoch [116/215]: loss 0.7209, auc 0.5117, ap 0.5448
2024-01-10 20:43:17,782 - GAugM EPNet train, Epoch [117/215]: loss 0.7208, auc 0.3647, ap 0.4135
2024-01-10 20:43:17,877 - GAugM EPNet train, Epoch [118/215]: loss 0.7209, auc 0.4179, ap 0.4594
2024-01-10 20:43:17,967 - GAugM EPNet train, Epoch [119/215]: loss 0.7209, auc 0.5356, ap 0.5668
2024-01-10 20:43:18,067 - GAugM EPNet train, Epoch [120/215]: loss 0.7210, auc 0.4906, ap 0.4989
2024-01-10 20:43:18,155 - GAugM EPNet train, Epoch [121/215]: loss 0.7210, auc 0.3984, ap 0.4447
2024-01-10 20:43:18,246 - GAugM EPNet train, Epoch [122/215]: loss 0.7209, auc 0.4457, ap 0.4686
2024-01-10 20:43:18,342 - GAugM EPNet train, Epoch [123/215]: loss 0.7209, auc 0.4799, ap 0.5393
2024-01-10 20:43:18,431 - GAugM EPNet train, Epoch [124/215]: loss 0.7210, auc 0.4858, ap 0.4912
2024-01-10 20:43:18,522 - GAugM EPNet train, Epoch [125/215]: loss 0.7209, auc 0.5036, ap 0.5183
2024-01-10 20:43:18,611 - GAugM EPNet train, Epoch [126/215]: loss 0.7210, auc 0.4993, ap 0.4889
2024-01-10 20:43:18,705 - GAugM EPNet train, Epoch [127/215]: loss 0.7209, auc 0.5073, ap 0.5030
2024-01-10 20:43:18,794 - GAugM EPNet train, Epoch [128/215]: loss 0.7210, auc 0.4911, ap 0.4767
2024-01-10 20:43:18,882 - GAugM EPNet train, Epoch [129/215]: loss 0.7208, auc 0.4331, ap 0.4503
2024-01-10 20:43:18,975 - GAugM EPNet train, Epoch [130/215]: loss 0.7210, auc 0.5450, ap 0.5523
2024-01-10 20:43:19,064 - GAugM EPNet train, Epoch [131/215]: loss 0.7210, auc 0.5329, ap 0.5623
2024-01-10 20:43:19,154 - GAugM EPNet train, Epoch [132/215]: loss 0.7209, auc 0.5349, ap 0.5229
2024-01-10 20:43:19,255 - GAugM EPNet train, Epoch [133/215]: loss 0.7209, auc 0.4902, ap 0.5297
2024-01-10 20:43:19,344 - GAugM EPNet train, Epoch [134/215]: loss 0.7210, auc 0.4772, ap 0.5175
2024-01-10 20:43:19,434 - GAugM EPNet train, Epoch [135/215]: loss 0.7209, auc 0.4373, ap 0.4740
2024-01-10 20:43:19,524 - GAugM EPNet train, Epoch [136/215]: loss 0.7209, auc 0.4929, ap 0.4998
2024-01-10 20:43:19,612 - GAugM EPNet train, Epoch [137/215]: loss 0.7210, auc 0.4445, ap 0.4683
2024-01-10 20:43:19,701 - GAugM EPNet train, Epoch [138/215]: loss 0.7210, auc 0.3797, ap 0.4208
2024-01-10 20:43:19,796 - GAugM EPNet train, Epoch [139/215]: loss 0.7210, auc 0.5139, ap 0.5113
2024-01-10 20:43:19,884 - GAugM EPNet train, Epoch [140/215]: loss 0.7209, auc 0.4948, ap 0.5191
2024-01-10 20:43:19,977 - GAugM EPNet train, Epoch [141/215]: loss 0.7209, auc 0.5137, ap 0.5285
2024-01-10 20:43:20,065 - GAugM EPNet train, Epoch [142/215]: loss 0.7209, auc 0.5214, ap 0.5373
2024-01-10 20:43:20,158 - GAugM EPNet train, Epoch [143/215]: loss 0.7209, auc 0.3985, ap 0.4202
2024-01-10 20:43:20,246 - GAugM EPNet train, Epoch [144/215]: loss 0.7209, auc 0.4751, ap 0.4917
2024-01-10 20:43:20,335 - GAugM EPNet train, Epoch [145/215]: loss 0.7209, auc 0.4624, ap 0.5277
2024-01-10 20:43:20,432 - GAugM EPNet train, Epoch [146/215]: loss 0.7209, auc 0.4612, ap 0.5019
2024-01-10 20:43:20,520 - GAugM EPNet train, Epoch [147/215]: loss 0.7209, auc 0.5938, ap 0.6215
2024-01-10 20:43:20,612 - GAugM EPNet train, Epoch [148/215]: loss 0.7209, auc 0.4968, ap 0.5293
2024-01-10 20:43:20,698 - GAugM EPNet train, Epoch [149/215]: loss 0.7208, auc 0.4875, ap 0.4896
2024-01-10 20:43:20,787 - GAugM EPNet train, Epoch [150/215]: loss 0.7209, auc 0.4445, ap 0.4594
2024-01-10 20:43:20,879 - GAugM EPNet train, Epoch [151/215]: loss 0.7209, auc 0.5824, ap 0.5564
2024-01-10 20:43:20,980 - GAugM EPNet train, Epoch [152/215]: loss 0.7209, auc 0.5849, ap 0.5965
2024-01-10 20:43:21,072 - GAugM EPNet train, Epoch [153/215]: loss 0.7209, auc 0.4843, ap 0.5328
2024-01-10 20:43:21,163 - GAugM EPNet train, Epoch [154/215]: loss 0.7209, auc 0.5194, ap 0.5333
2024-01-10 20:43:21,251 - GAugM EPNet train, Epoch [155/215]: loss 0.7209, auc 0.4569, ap 0.4749
2024-01-10 20:43:21,338 - GAugM EPNet train, Epoch [156/215]: loss 0.7209, auc 0.4393, ap 0.4856
2024-01-10 20:43:21,450 - GAugM EPNet train, Epoch [157/215]: loss 0.7209, auc 0.5253, ap 0.5298
2024-01-10 20:43:21,546 - GAugM EPNet train, Epoch [158/215]: loss 0.7208, auc 0.4377, ap 0.4540
2024-01-10 20:43:21,638 - GAugM EPNet train, Epoch [159/215]: loss 0.7208, auc 0.4414, ap 0.4631
2024-01-10 20:43:21,728 - GAugM EPNet train, Epoch [160/215]: loss 0.7209, auc 0.5482, ap 0.5223
2024-01-10 20:43:21,818 - GAugM EPNet train, Epoch [161/215]: loss 0.7209, auc 0.5835, ap 0.5766
2024-01-10 20:43:21,922 - GAugM EPNet train, Epoch [162/215]: loss 0.7209, auc 0.4932, ap 0.4905
2024-01-10 20:43:22,015 - GAugM EPNet train, Epoch [163/215]: loss 0.7209, auc 0.5078, ap 0.4992
2024-01-10 20:43:22,111 - GAugM EPNet train, Epoch [164/215]: loss 0.7211, auc 0.5094, ap 0.5075
2024-01-10 20:43:22,205 - GAugM EPNet train, Epoch [165/215]: loss 0.7210, auc 0.4502, ap 0.4589
2024-01-10 20:43:22,307 - GAugM EPNet train, Epoch [166/215]: loss 0.7208, auc 0.5381, ap 0.5302
2024-01-10 20:43:22,400 - GAugM EPNet train, Epoch [167/215]: loss 0.7209, auc 0.3866, ap 0.4266
2024-01-10 20:43:22,503 - GAugM EPNet train, Epoch [168/215]: loss 0.7209, auc 0.4959, ap 0.5249
2024-01-10 20:43:22,597 - GAugM EPNet train, Epoch [169/215]: loss 0.7209, auc 0.5441, ap 0.5644
2024-01-10 20:43:22,688 - GAugM EPNet train, Epoch [170/215]: loss 0.7210, auc 0.5126, ap 0.4838
2024-01-10 20:43:22,782 - GAugM EPNet train, Epoch [171/215]: loss 0.7209, auc 0.3920, ap 0.4506
2024-01-10 20:43:22,875 - GAugM EPNet train, Epoch [172/215]: loss 0.7208, auc 0.4733, ap 0.4850
2024-01-10 20:43:22,967 - GAugM EPNet train, Epoch [173/215]: loss 0.7209, auc 0.5934, ap 0.5983
2024-01-10 20:43:23,055 - GAugM EPNet train, Epoch [174/215]: loss 0.7209, auc 0.4525, ap 0.4802
2024-01-10 20:43:23,143 - GAugM EPNet train, Epoch [175/215]: loss 0.7209, auc 0.5910, ap 0.6084
2024-01-10 20:43:23,231 - GAugM EPNet train, Epoch [176/215]: loss 0.7209, auc 0.4708, ap 0.4687
2024-01-10 20:43:23,324 - GAugM EPNet train, Epoch [177/215]: loss 0.7210, auc 0.4452, ap 0.4550
2024-01-10 20:43:23,415 - GAugM EPNet train, Epoch [178/215]: loss 0.7210, auc 0.5388, ap 0.5564
2024-01-10 20:43:23,503 - GAugM EPNet train, Epoch [179/215]: loss 0.7210, auc 0.4240, ap 0.4878
2024-01-10 20:43:23,593 - GAugM EPNet train, Epoch [180/215]: loss 0.7210, auc 0.5557, ap 0.5576
2024-01-10 20:43:23,688 - GAugM EPNet train, Epoch [181/215]: loss 0.7209, auc 0.3750, ap 0.4346
2024-01-10 20:43:23,775 - GAugM EPNet train, Epoch [182/215]: loss 0.7209, auc 0.4137, ap 0.4760
2024-01-10 20:43:23,865 - GAugM EPNet train, Epoch [183/215]: loss 0.7210, auc 0.5306, ap 0.5283
2024-01-10 20:43:23,956 - GAugM EPNet train, Epoch [184/215]: loss 0.7209, auc 0.4530, ap 0.5082
2024-01-10 20:43:24,047 - GAugM EPNet train, Epoch [185/215]: loss 0.7209, auc 0.4696, ap 0.5063
2024-01-10 20:43:24,146 - GAugM EPNet train, Epoch [186/215]: loss 0.7208, auc 0.4349, ap 0.4845
2024-01-10 20:43:24,244 - GAugM EPNet train, Epoch [187/215]: loss 0.7209, auc 0.5059, ap 0.5108
2024-01-10 20:43:24,333 - GAugM EPNet train, Epoch [188/215]: loss 0.7209, auc 0.4886, ap 0.4941
2024-01-10 20:43:24,426 - GAugM EPNet train, Epoch [189/215]: loss 0.7209, auc 0.5443, ap 0.5751
2024-01-10 20:43:24,515 - GAugM EPNet train, Epoch [190/215]: loss 0.7209, auc 0.4923, ap 0.4916
2024-01-10 20:43:24,610 - GAugM EPNet train, Epoch [191/215]: loss 0.7209, auc 0.3975, ap 0.4588
2024-01-10 20:43:24,703 - GAugM EPNet train, Epoch [192/215]: loss 0.7209, auc 0.4534, ap 0.4483
2024-01-10 20:43:24,797 - GAugM EPNet train, Epoch [193/215]: loss 0.7209, auc 0.5007, ap 0.5117
2024-01-10 20:43:24,886 - GAugM EPNet train, Epoch [194/215]: loss 0.7209, auc 0.4260, ap 0.4608
2024-01-10 20:43:24,982 - GAugM EPNet train, Epoch [195/215]: loss 0.7209, auc 0.5002, ap 0.4928
2024-01-10 20:43:25,070 - GAugM EPNet train, Epoch [196/215]: loss 0.7208, auc 0.5032, ap 0.4922
2024-01-10 20:43:25,160 - GAugM EPNet train, Epoch [197/215]: loss 0.7210, auc 0.4464, ap 0.4688
2024-01-10 20:43:25,247 - GAugM EPNet train, Epoch [198/215]: loss 0.7210, auc 0.5541, ap 0.5361
2024-01-10 20:43:25,337 - GAugM EPNet train, Epoch [199/215]: loss 0.7209, auc 0.4653, ap 0.4894
2024-01-10 20:43:25,431 - GAugM EPNet train, Epoch [200/215]: loss 0.7210, auc 0.4939, ap 0.4882
2024-01-10 20:43:25,518 - GAugM EPNet train, Epoch [201/215]: loss 0.7209, auc 0.5098, ap 0.4876
2024-01-10 20:43:25,616 - GAugM EPNet train, Epoch [202/215]: loss 0.7210, auc 0.4318, ap 0.4843
2024-01-10 20:43:25,711 - GAugM EPNet train, Epoch [203/215]: loss 0.7210, auc 0.5584, ap 0.5565
2024-01-10 20:43:25,802 - GAugM EPNet train, Epoch [204/215]: loss 0.7209, auc 0.4477, ap 0.4683
2024-01-10 20:43:25,893 - GAugM EPNet train, Epoch [205/215]: loss 0.7209, auc 0.4308, ap 0.4618
2024-01-10 20:43:25,989 - GAugM EPNet train, Epoch [206/215]: loss 0.7209, auc 0.4377, ap 0.4499
2024-01-10 20:43:26,082 - GAugM EPNet train, Epoch [207/215]: loss 0.7210, auc 0.4621, ap 0.4641
2024-01-10 20:43:26,174 - GAugM EPNet train, Epoch [208/215]: loss 0.7209, auc 0.4397, ap 0.5038
2024-01-10 20:43:26,271 - GAugM EPNet train, Epoch [209/215]: loss 0.7210, auc 0.5249, ap 0.5185
2024-01-10 20:43:26,362 - GAugM EPNet train, Epoch [210/215]: loss 0.7209, auc 0.4582, ap 0.4841
2024-01-10 20:43:26,452 - GAugM EPNet train, Epoch [211/215]: loss 0.7210, auc 0.4979, ap 0.5014
2024-01-10 20:43:26,549 - GAugM EPNet train, Epoch [212/215]: loss 0.7210, auc 0.4758, ap 0.5060
2024-01-10 20:43:26,637 - GAugM EPNet train, Epoch [213/215]: loss 0.7208, auc 0.5821, ap 0.5813
2024-01-10 20:43:26,738 - GAugM EPNet train, Epoch [214/215]: loss 0.7210, auc 0.5032, ap 0.5162
2024-01-10 20:43:26,827 - GAugM EPNet train, Epoch [215/215]: loss 0.7210, auc 0.4656, ap 0.4931
2024-01-10 20:43:26,833 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f1499902290>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:43:27,590 - GAugM EPNet train, Epoch [  1/215]: loss 0.7210, auc 0.4138, ap 0.4390
2024-01-10 20:43:27,682 - GAugM EPNet train, Epoch [  2/215]: loss 0.7210, auc 0.5260, ap 0.5129
2024-01-10 20:43:27,773 - GAugM EPNet train, Epoch [  3/215]: loss 0.7209, auc 0.5865, ap 0.5841
2024-01-10 20:43:27,874 - GAugM EPNet train, Epoch [  4/215]: loss 0.7209, auc 0.5169, ap 0.5399
2024-01-10 20:43:27,966 - GAugM EPNet train, Epoch [  5/215]: loss 0.7209, auc 0.6177, ap 0.5906
2024-01-10 20:43:28,055 - GAugM EPNet train, Epoch [  6/215]: loss 0.7209, auc 0.4446, ap 0.4635
2024-01-10 20:43:28,159 - GAugM EPNet train, Epoch [  7/215]: loss 0.7209, auc 0.4115, ap 0.4289
2024-01-10 20:43:28,250 - GAugM EPNet train, Epoch [  8/215]: loss 0.7210, auc 0.4756, ap 0.4749
2024-01-10 20:43:28,337 - GAugM EPNet train, Epoch [  9/215]: loss 0.7209, auc 0.4576, ap 0.4582
2024-01-10 20:43:28,433 - GAugM EPNet train, Epoch [ 10/215]: loss 0.7208, auc 0.4706, ap 0.5096
2024-01-10 20:43:28,523 - GAugM EPNet train, Epoch [ 11/215]: loss 0.7209, auc 0.4751, ap 0.5127
2024-01-10 20:43:28,610 - GAugM EPNet train, Epoch [ 12/215]: loss 0.7210, auc 0.4601, ap 0.4746
2024-01-10 20:43:28,699 - GAugM EPNet train, Epoch [ 13/215]: loss 0.7209, auc 0.5511, ap 0.5650
2024-01-10 20:43:28,787 - GAugM EPNet train, Epoch [ 14/215]: loss 0.7209, auc 0.5226, ap 0.5230
2024-01-10 20:43:28,884 - GAugM EPNet train, Epoch [ 15/215]: loss 0.7210, auc 0.4244, ap 0.5021
2024-01-10 20:43:28,971 - GAugM EPNet train, Epoch [ 16/215]: loss 0.7209, auc 0.4952, ap 0.4961
2024-01-10 20:43:29,060 - GAugM EPNet train, Epoch [ 17/215]: loss 0.7210, auc 0.6278, ap 0.5964
2024-01-10 20:43:29,147 - GAugM EPNet train, Epoch [ 18/215]: loss 0.7210, auc 0.6185, ap 0.5913
2024-01-10 20:43:29,242 - GAugM EPNet train, Epoch [ 19/215]: loss 0.7209, auc 0.4003, ap 0.4231
2024-01-10 20:43:29,336 - GAugM EPNet train, Epoch [ 20/215]: loss 0.7210, auc 0.5290, ap 0.5780
2024-01-10 20:43:29,423 - GAugM EPNet train, Epoch [ 21/215]: loss 0.7209, auc 0.4895, ap 0.4857
2024-01-10 20:43:29,510 - GAugM EPNet train, Epoch [ 22/215]: loss 0.7210, auc 0.3014, ap 0.4016
2024-01-10 20:43:29,600 - GAugM EPNet train, Epoch [ 23/215]: loss 0.7208, auc 0.4712, ap 0.4836
2024-01-10 20:43:29,697 - GAugM EPNet train, Epoch [ 24/215]: loss 0.7209, auc 0.5295, ap 0.5093
2024-01-10 20:43:29,786 - GAugM EPNet train, Epoch [ 25/215]: loss 0.7209, auc 0.4254, ap 0.4458
2024-01-10 20:43:29,875 - GAugM EPNet train, Epoch [ 26/215]: loss 0.7210, auc 0.5007, ap 0.5156
2024-01-10 20:43:29,969 - GAugM EPNet train, Epoch [ 27/215]: loss 0.7209, auc 0.4505, ap 0.5090
2024-01-10 20:43:30,057 - GAugM EPNet train, Epoch [ 28/215]: loss 0.7209, auc 0.5372, ap 0.5560
2024-01-10 20:43:30,145 - GAugM EPNet train, Epoch [ 29/215]: loss 0.7210, auc 0.5792, ap 0.5694
2024-01-10 20:43:30,234 - GAugM EPNet train, Epoch [ 30/215]: loss 0.7209, auc 0.5520, ap 0.5177
2024-01-10 20:43:30,332 - GAugM EPNet train, Epoch [ 31/215]: loss 0.7208, auc 0.4888, ap 0.5227
2024-01-10 20:43:30,425 - GAugM EPNet train, Epoch [ 32/215]: loss 0.7210, auc 0.5568, ap 0.5298
2024-01-10 20:43:30,521 - GAugM EPNet train, Epoch [ 33/215]: loss 0.7209, auc 0.5030, ap 0.4990
2024-01-10 20:43:30,608 - GAugM EPNet train, Epoch [ 34/215]: loss 0.7209, auc 0.4656, ap 0.4698
2024-01-10 20:43:30,696 - GAugM EPNet train, Epoch [ 35/215]: loss 0.7209, auc 0.5591, ap 0.5278
2024-01-10 20:43:30,783 - GAugM EPNet train, Epoch [ 36/215]: loss 0.7209, auc 0.6159, ap 0.6137
2024-01-10 20:43:30,875 - GAugM EPNet train, Epoch [ 37/215]: loss 0.7209, auc 0.4466, ap 0.4554
2024-01-10 20:43:30,962 - GAugM EPNet train, Epoch [ 38/215]: loss 0.7209, auc 0.5082, ap 0.4822
2024-01-10 20:43:31,055 - GAugM EPNet train, Epoch [ 39/215]: loss 0.7208, auc 0.4672, ap 0.4922
2024-01-10 20:43:31,157 - GAugM EPNet train, Epoch [ 40/215]: loss 0.7210, auc 0.5671, ap 0.5254
2024-01-10 20:43:31,246 - GAugM EPNet train, Epoch [ 41/215]: loss 0.7210, auc 0.4984, ap 0.5010
2024-01-10 20:43:31,338 - GAugM EPNet train, Epoch [ 42/215]: loss 0.7209, auc 0.5372, ap 0.5441
2024-01-10 20:43:31,426 - GAugM EPNet train, Epoch [ 43/215]: loss 0.7208, auc 0.4619, ap 0.5090
2024-01-10 20:43:31,514 - GAugM EPNet train, Epoch [ 44/215]: loss 0.7208, auc 0.4505, ap 0.4724
2024-01-10 20:43:31,602 - GAugM EPNet train, Epoch [ 45/215]: loss 0.7209, auc 0.4480, ap 0.4965
2024-01-10 20:43:31,693 - GAugM EPNet train, Epoch [ 46/215]: loss 0.7209, auc 0.4785, ap 0.4996
2024-01-10 20:43:31,786 - GAugM EPNet train, Epoch [ 47/215]: loss 0.7210, auc 0.4808, ap 0.5040
2024-01-10 20:43:31,874 - GAugM EPNet train, Epoch [ 48/215]: loss 0.7210, auc 0.5902, ap 0.5874
2024-01-10 20:43:31,967 - GAugM EPNet train, Epoch [ 49/215]: loss 0.7209, auc 0.5091, ap 0.5254
2024-01-10 20:43:32,062 - GAugM EPNet train, Epoch [ 50/215]: loss 0.7210, auc 0.5821, ap 0.5438
2024-01-10 20:43:32,149 - GAugM EPNet train, Epoch [ 51/215]: loss 0.7210, auc 0.5018, ap 0.5223
2024-01-10 20:43:32,257 - GAugM EPNet train, Epoch [ 52/215]: loss 0.7209, auc 0.4968, ap 0.4976
2024-01-10 20:43:32,351 - GAugM EPNet train, Epoch [ 53/215]: loss 0.7209, auc 0.5598, ap 0.5539
2024-01-10 20:43:32,440 - GAugM EPNet train, Epoch [ 54/215]: loss 0.7211, auc 0.5272, ap 0.4946
2024-01-10 20:43:32,534 - GAugM EPNet train, Epoch [ 55/215]: loss 0.7209, auc 0.6182, ap 0.5888
2024-01-10 20:43:32,628 - GAugM EPNet train, Epoch [ 56/215]: loss 0.7208, auc 0.4957, ap 0.5001
2024-01-10 20:43:32,717 - GAugM EPNet train, Epoch [ 57/215]: loss 0.7209, auc 0.4605, ap 0.4693
2024-01-10 20:43:32,808 - GAugM EPNet train, Epoch [ 58/215]: loss 0.7210, auc 0.5283, ap 0.5785
2024-01-10 20:43:32,899 - GAugM EPNet train, Epoch [ 59/215]: loss 0.7211, auc 0.5171, ap 0.4964
2024-01-10 20:43:33,004 - GAugM EPNet train, Epoch [ 60/215]: loss 0.7210, auc 0.5100, ap 0.5017
2024-01-10 20:43:33,095 - GAugM EPNet train, Epoch [ 61/215]: loss 0.7209, auc 0.5091, ap 0.5300
2024-01-10 20:43:33,195 - GAugM EPNet train, Epoch [ 62/215]: loss 0.7210, auc 0.5475, ap 0.5426
2024-01-10 20:43:33,283 - GAugM EPNet train, Epoch [ 63/215]: loss 0.7208, auc 0.4272, ap 0.4410
2024-01-10 20:43:33,371 - GAugM EPNet train, Epoch [ 64/215]: loss 0.7208, auc 0.5069, ap 0.5121
2024-01-10 20:43:33,461 - GAugM EPNet train, Epoch [ 65/215]: loss 0.7208, auc 0.5578, ap 0.5527
2024-01-10 20:43:33,551 - GAugM EPNet train, Epoch [ 66/215]: loss 0.7209, auc 0.4767, ap 0.4982
2024-01-10 20:43:33,646 - GAugM EPNet train, Epoch [ 67/215]: loss 0.7209, auc 0.5326, ap 0.5171
2024-01-10 20:43:33,740 - GAugM EPNet train, Epoch [ 68/215]: loss 0.7210, auc 0.5607, ap 0.5911
2024-01-10 20:43:33,829 - GAugM EPNet train, Epoch [ 69/215]: loss 0.7210, auc 0.5112, ap 0.5199
2024-01-10 20:43:33,915 - GAugM EPNet train, Epoch [ 70/215]: loss 0.7210, auc 0.4400, ap 0.4498
2024-01-10 20:43:34,008 - GAugM EPNet train, Epoch [ 71/215]: loss 0.7210, auc 0.5388, ap 0.5167
2024-01-10 20:43:34,111 - GAugM EPNet train, Epoch [ 72/215]: loss 0.7210, auc 0.3973, ap 0.4299
2024-01-10 20:43:34,200 - GAugM EPNet train, Epoch [ 73/215]: loss 0.7209, auc 0.4931, ap 0.5044
2024-01-10 20:43:34,290 - GAugM EPNet train, Epoch [ 74/215]: loss 0.7209, auc 0.5753, ap 0.5454
2024-01-10 20:43:34,378 - GAugM EPNet train, Epoch [ 75/215]: loss 0.7210, auc 0.4715, ap 0.4830
2024-01-10 20:43:34,466 - GAugM EPNet train, Epoch [ 76/215]: loss 0.7209, auc 0.5361, ap 0.5257
2024-01-10 20:43:34,561 - GAugM EPNet train, Epoch [ 77/215]: loss 0.7208, auc 0.5486, ap 0.5594
2024-01-10 20:43:34,649 - GAugM EPNet train, Epoch [ 78/215]: loss 0.7209, auc 0.4551, ap 0.4716
2024-01-10 20:43:34,739 - GAugM EPNet train, Epoch [ 79/215]: loss 0.7208, auc 0.5103, ap 0.5112
2024-01-10 20:43:34,830 - GAugM EPNet train, Epoch [ 80/215]: loss 0.7209, auc 0.5466, ap 0.5284
2024-01-10 20:43:34,924 - GAugM EPNet train, Epoch [ 81/215]: loss 0.7209, auc 0.5603, ap 0.5193
2024-01-10 20:43:35,022 - GAugM EPNet train, Epoch [ 82/215]: loss 0.7210, auc 0.5417, ap 0.5202
2024-01-10 20:43:35,116 - GAugM EPNet train, Epoch [ 83/215]: loss 0.7209, auc 0.4379, ap 0.5028
2024-01-10 20:43:35,204 - GAugM EPNet train, Epoch [ 84/215]: loss 0.7209, auc 0.4032, ap 0.4533
2024-01-10 20:43:35,298 - GAugM EPNet train, Epoch [ 85/215]: loss 0.7210, auc 0.4831, ap 0.5091
2024-01-10 20:43:35,386 - GAugM EPNet train, Epoch [ 86/215]: loss 0.7208, auc 0.5381, ap 0.5894
2024-01-10 20:43:35,479 - GAugM EPNet train, Epoch [ 87/215]: loss 0.7209, auc 0.6419, ap 0.6339
2024-01-10 20:43:35,566 - GAugM EPNet train, Epoch [ 88/215]: loss 0.7210, auc 0.4206, ap 0.4694
2024-01-10 20:43:35,651 - GAugM EPNet train, Epoch [ 89/215]: loss 0.7210, auc 0.4840, ap 0.5136
2024-01-10 20:43:35,744 - GAugM EPNet train, Epoch [ 90/215]: loss 0.7209, auc 0.5221, ap 0.5152
2024-01-10 20:43:35,836 - GAugM EPNet train, Epoch [ 91/215]: loss 0.7208, auc 0.5511, ap 0.5185
2024-01-10 20:43:35,922 - GAugM EPNet train, Epoch [ 92/215]: loss 0.7209, auc 0.5936, ap 0.6019
2024-01-10 20:43:36,011 - GAugM EPNet train, Epoch [ 93/215]: loss 0.7209, auc 0.3820, ap 0.4761
2024-01-10 20:43:36,102 - GAugM EPNet train, Epoch [ 94/215]: loss 0.7210, auc 0.4023, ap 0.4399
2024-01-10 20:43:36,189 - GAugM EPNet train, Epoch [ 95/215]: loss 0.7210, auc 0.4970, ap 0.5203
2024-01-10 20:43:36,284 - GAugM EPNet train, Epoch [ 96/215]: loss 0.7209, auc 0.5651, ap 0.5810
2024-01-10 20:43:36,372 - GAugM EPNet train, Epoch [ 97/215]: loss 0.7209, auc 0.4847, ap 0.5324
2024-01-10 20:43:36,463 - GAugM EPNet train, Epoch [ 98/215]: loss 0.7209, auc 0.5068, ap 0.5023
2024-01-10 20:43:36,557 - GAugM EPNet train, Epoch [ 99/215]: loss 0.7209, auc 0.5194, ap 0.5285
2024-01-10 20:43:36,646 - GAugM EPNet train, Epoch [100/215]: loss 0.7210, auc 0.5374, ap 0.5425
2024-01-10 20:43:36,744 - GAugM EPNet train, Epoch [101/215]: loss 0.7210, auc 0.4717, ap 0.5369
2024-01-10 20:43:36,845 - GAugM EPNet train, Epoch [102/215]: loss 0.7209, auc 0.5381, ap 0.5211
2024-01-10 20:43:36,937 - GAugM EPNet train, Epoch [103/215]: loss 0.7209, auc 0.5185, ap 0.5505
2024-01-10 20:43:37,033 - GAugM EPNet train, Epoch [104/215]: loss 0.7209, auc 0.5021, ap 0.4798
2024-01-10 20:43:37,123 - GAugM EPNet train, Epoch [105/215]: loss 0.7209, auc 0.4190, ap 0.4458
2024-01-10 20:43:37,210 - GAugM EPNet train, Epoch [106/215]: loss 0.7210, auc 0.4441, ap 0.4690
2024-01-10 20:43:37,301 - GAugM EPNet train, Epoch [107/215]: loss 0.7210, auc 0.4543, ap 0.4875
2024-01-10 20:43:37,388 - GAugM EPNet train, Epoch [108/215]: loss 0.7208, auc 0.4982, ap 0.4911
2024-01-10 20:43:37,488 - GAugM EPNet train, Epoch [109/215]: loss 0.7210, auc 0.3823, ap 0.4182
2024-01-10 20:43:37,579 - GAugM EPNet train, Epoch [110/215]: loss 0.7209, auc 0.4393, ap 0.4814
2024-01-10 20:43:37,673 - GAugM EPNet train, Epoch [111/215]: loss 0.7210, auc 0.5148, ap 0.5322
2024-01-10 20:43:37,760 - GAugM EPNet train, Epoch [112/215]: loss 0.7209, auc 0.4341, ap 0.4715
2024-01-10 20:43:37,846 - GAugM EPNet train, Epoch [113/215]: loss 0.7210, auc 0.4630, ap 0.4878
2024-01-10 20:43:37,933 - GAugM EPNet train, Epoch [114/215]: loss 0.7209, auc 0.4263, ap 0.4403
2024-01-10 20:43:38,018 - GAugM EPNet train, Epoch [115/215]: loss 0.7210, auc 0.5472, ap 0.5374
2024-01-10 20:43:38,107 - GAugM EPNet train, Epoch [116/215]: loss 0.7209, auc 0.5196, ap 0.5341
2024-01-10 20:43:38,199 - GAugM EPNet train, Epoch [117/215]: loss 0.7208, auc 0.4226, ap 0.4528
2024-01-10 20:43:38,286 - GAugM EPNet train, Epoch [118/215]: loss 0.7209, auc 0.5151, ap 0.5055
2024-01-10 20:43:38,373 - GAugM EPNet train, Epoch [119/215]: loss 0.7209, auc 0.4744, ap 0.5079
2024-01-10 20:43:38,459 - GAugM EPNet train, Epoch [120/215]: loss 0.7210, auc 0.4810, ap 0.4870
2024-01-10 20:43:38,544 - GAugM EPNet train, Epoch [121/215]: loss 0.7210, auc 0.5685, ap 0.5555
2024-01-10 20:43:38,638 - GAugM EPNet train, Epoch [122/215]: loss 0.7209, auc 0.4890, ap 0.5011
2024-01-10 20:43:38,725 - GAugM EPNet train, Epoch [123/215]: loss 0.7209, auc 0.5121, ap 0.5181
2024-01-10 20:43:38,822 - GAugM EPNet train, Epoch [124/215]: loss 0.7210, auc 0.4518, ap 0.4544
2024-01-10 20:43:38,908 - GAugM EPNet train, Epoch [125/215]: loss 0.7209, auc 0.5274, ap 0.5121
2024-01-10 20:43:38,997 - GAugM EPNet train, Epoch [126/215]: loss 0.7210, auc 0.4487, ap 0.4740
2024-01-10 20:43:39,084 - GAugM EPNet train, Epoch [127/215]: loss 0.7209, auc 0.4874, ap 0.4874
2024-01-10 20:43:39,177 - GAugM EPNet train, Epoch [128/215]: loss 0.7210, auc 0.4813, ap 0.4729
2024-01-10 20:43:39,263 - GAugM EPNet train, Epoch [129/215]: loss 0.7208, auc 0.3971, ap 0.4420
2024-01-10 20:43:39,350 - GAugM EPNet train, Epoch [130/215]: loss 0.7210, auc 0.4948, ap 0.4851
2024-01-10 20:43:39,437 - GAugM EPNet train, Epoch [131/215]: loss 0.7210, auc 0.4589, ap 0.5121
2024-01-10 20:43:39,528 - GAugM EPNet train, Epoch [132/215]: loss 0.7209, auc 0.4911, ap 0.4891
2024-01-10 20:43:39,615 - GAugM EPNet train, Epoch [133/215]: loss 0.7209, auc 0.4925, ap 0.5322
2024-01-10 20:43:39,701 - GAugM EPNet train, Epoch [134/215]: loss 0.7210, auc 0.4913, ap 0.4985
2024-01-10 20:43:39,787 - GAugM EPNet train, Epoch [135/215]: loss 0.7209, auc 0.4016, ap 0.4435
2024-01-10 20:43:39,880 - GAugM EPNet train, Epoch [136/215]: loss 0.7209, auc 0.4487, ap 0.4711
2024-01-10 20:43:39,967 - GAugM EPNet train, Epoch [137/215]: loss 0.7210, auc 0.5071, ap 0.5143
2024-01-10 20:43:40,054 - GAugM EPNet train, Epoch [138/215]: loss 0.7210, auc 0.5402, ap 0.5323
2024-01-10 20:43:40,140 - GAugM EPNet train, Epoch [139/215]: loss 0.7210, auc 0.5066, ap 0.5080
2024-01-10 20:43:40,232 - GAugM EPNet train, Epoch [140/215]: loss 0.7209, auc 0.4760, ap 0.5286
2024-01-10 20:43:40,318 - GAugM EPNet train, Epoch [141/215]: loss 0.7209, auc 0.5158, ap 0.4998
2024-01-10 20:43:40,405 - GAugM EPNet train, Epoch [142/215]: loss 0.7209, auc 0.5335, ap 0.5490
2024-01-10 20:43:40,491 - GAugM EPNet train, Epoch [143/215]: loss 0.7209, auc 0.4792, ap 0.4846
2024-01-10 20:43:40,578 - GAugM EPNet train, Epoch [144/215]: loss 0.7209, auc 0.4674, ap 0.4967
2024-01-10 20:43:40,665 - GAugM EPNet train, Epoch [145/215]: loss 0.7209, auc 0.4614, ap 0.4946
2024-01-10 20:43:40,756 - GAugM EPNet train, Epoch [146/215]: loss 0.7209, auc 0.5190, ap 0.5409
2024-01-10 20:43:40,841 - GAugM EPNet train, Epoch [147/215]: loss 0.7209, auc 0.6173, ap 0.6317
2024-01-10 20:43:40,926 - GAugM EPNet train, Epoch [148/215]: loss 0.7209, auc 0.5155, ap 0.5194
2024-01-10 20:43:41,018 - GAugM EPNet train, Epoch [149/215]: loss 0.7208, auc 0.4989, ap 0.4917
2024-01-10 20:43:41,102 - GAugM EPNet train, Epoch [150/215]: loss 0.7209, auc 0.5253, ap 0.5191
2024-01-10 20:43:41,189 - GAugM EPNet train, Epoch [151/215]: loss 0.7209, auc 0.5550, ap 0.5544
2024-01-10 20:43:41,275 - GAugM EPNet train, Epoch [152/215]: loss 0.7209, auc 0.5383, ap 0.5360
2024-01-10 20:43:41,360 - GAugM EPNet train, Epoch [153/215]: loss 0.7209, auc 0.3799, ap 0.4172
2024-01-10 20:43:41,450 - GAugM EPNet train, Epoch [154/215]: loss 0.7209, auc 0.5872, ap 0.6187
2024-01-10 20:43:41,538 - GAugM EPNet train, Epoch [155/215]: loss 0.7209, auc 0.4794, ap 0.4967
2024-01-10 20:43:41,640 - GAugM EPNet train, Epoch [156/215]: loss 0.7209, auc 0.4204, ap 0.4533
2024-01-10 20:43:41,747 - GAugM EPNet train, Epoch [157/215]: loss 0.7209, auc 0.4911, ap 0.5117
2024-01-10 20:43:41,840 - GAugM EPNet train, Epoch [158/215]: loss 0.7208, auc 0.5308, ap 0.5196
2024-01-10 20:43:41,930 - GAugM EPNet train, Epoch [159/215]: loss 0.7208, auc 0.4808, ap 0.4958
2024-01-10 20:43:42,021 - GAugM EPNet train, Epoch [160/215]: loss 0.7209, auc 0.5840, ap 0.6027
2024-01-10 20:43:42,113 - GAugM EPNet train, Epoch [161/215]: loss 0.7209, auc 0.4826, ap 0.4676
2024-01-10 20:43:42,225 - GAugM EPNet train, Epoch [162/215]: loss 0.7209, auc 0.4450, ap 0.4580
2024-01-10 20:43:42,315 - GAugM EPNet train, Epoch [163/215]: loss 0.7209, auc 0.5383, ap 0.5148
2024-01-10 20:43:42,407 - GAugM EPNet train, Epoch [164/215]: loss 0.7211, auc 0.4854, ap 0.4872
2024-01-10 20:43:42,502 - GAugM EPNet train, Epoch [165/215]: loss 0.7210, auc 0.4190, ap 0.4789
2024-01-10 20:43:42,594 - GAugM EPNet train, Epoch [166/215]: loss 0.7208, auc 0.6210, ap 0.5823
2024-01-10 20:43:42,685 - GAugM EPNet train, Epoch [167/215]: loss 0.7209, auc 0.5388, ap 0.5426
2024-01-10 20:43:42,772 - GAugM EPNet train, Epoch [168/215]: loss 0.7209, auc 0.5046, ap 0.5589
2024-01-10 20:43:42,868 - GAugM EPNet train, Epoch [169/215]: loss 0.7209, auc 0.5304, ap 0.5487
2024-01-10 20:43:42,964 - GAugM EPNet train, Epoch [170/215]: loss 0.7210, auc 0.4849, ap 0.4888
2024-01-10 20:43:43,064 - GAugM EPNet train, Epoch [171/215]: loss 0.7209, auc 0.4108, ap 0.4496
2024-01-10 20:43:43,161 - GAugM EPNet train, Epoch [172/215]: loss 0.7208, auc 0.4373, ap 0.4667
2024-01-10 20:43:43,254 - GAugM EPNet train, Epoch [173/215]: loss 0.7209, auc 0.5630, ap 0.5819
2024-01-10 20:43:43,359 - GAugM EPNet train, Epoch [174/215]: loss 0.7209, auc 0.5164, ap 0.4967
2024-01-10 20:43:43,448 - GAugM EPNet train, Epoch [175/215]: loss 0.7209, auc 0.6155, ap 0.5788
2024-01-10 20:43:43,540 - GAugM EPNet train, Epoch [176/215]: loss 0.7209, auc 0.4989, ap 0.4945
2024-01-10 20:43:43,638 - GAugM EPNet train, Epoch [177/215]: loss 0.7210, auc 0.4258, ap 0.4537
2024-01-10 20:43:43,727 - GAugM EPNet train, Epoch [178/215]: loss 0.7210, auc 0.5488, ap 0.5735
2024-01-10 20:43:43,830 - GAugM EPNet train, Epoch [179/215]: loss 0.7210, auc 0.4306, ap 0.4984
2024-01-10 20:43:43,920 - GAugM EPNet train, Epoch [180/215]: loss 0.7210, auc 0.5027, ap 0.5296
2024-01-10 20:43:44,009 - GAugM EPNet train, Epoch [181/215]: loss 0.7209, auc 0.4343, ap 0.4702
2024-01-10 20:43:44,107 - GAugM EPNet train, Epoch [182/215]: loss 0.7209, auc 0.4438, ap 0.4546
2024-01-10 20:43:44,198 - GAugM EPNet train, Epoch [183/215]: loss 0.7210, auc 0.5303, ap 0.5152
2024-01-10 20:43:44,291 - GAugM EPNet train, Epoch [184/215]: loss 0.7209, auc 0.4941, ap 0.5077
2024-01-10 20:43:44,381 - GAugM EPNet train, Epoch [185/215]: loss 0.7209, auc 0.4728, ap 0.5015
2024-01-10 20:43:44,469 - GAugM EPNet train, Epoch [186/215]: loss 0.7208, auc 0.3873, ap 0.4477
2024-01-10 20:43:44,558 - GAugM EPNet train, Epoch [187/215]: loss 0.7209, auc 0.4603, ap 0.4799
2024-01-10 20:43:44,646 - GAugM EPNet train, Epoch [188/215]: loss 0.7209, auc 0.4423, ap 0.4565
2024-01-10 20:43:44,734 - GAugM EPNet train, Epoch [189/215]: loss 0.7209, auc 0.5226, ap 0.5684
2024-01-10 20:43:44,828 - GAugM EPNet train, Epoch [190/215]: loss 0.7209, auc 0.4023, ap 0.4429
2024-01-10 20:43:44,914 - GAugM EPNet train, Epoch [191/215]: loss 0.7209, auc 0.4032, ap 0.4443
2024-01-10 20:43:45,003 - GAugM EPNet train, Epoch [192/215]: loss 0.7209, auc 0.4582, ap 0.4501
2024-01-10 20:43:45,093 - GAugM EPNet train, Epoch [193/215]: loss 0.7209, auc 0.5534, ap 0.5671
2024-01-10 20:43:45,179 - GAugM EPNet train, Epoch [194/215]: loss 0.7209, auc 0.5463, ap 0.5546
2024-01-10 20:43:45,266 - GAugM EPNet train, Epoch [195/215]: loss 0.7209, auc 0.4434, ap 0.4697
2024-01-10 20:43:45,360 - GAugM EPNet train, Epoch [196/215]: loss 0.7208, auc 0.5253, ap 0.4960
2024-01-10 20:43:45,448 - GAugM EPNet train, Epoch [197/215]: loss 0.7210, auc 0.5571, ap 0.5593
2024-01-10 20:43:45,538 - GAugM EPNet train, Epoch [198/215]: loss 0.7210, auc 0.5265, ap 0.5176
2024-01-10 20:43:45,637 - GAugM EPNet train, Epoch [199/215]: loss 0.7209, auc 0.4455, ap 0.4968
2024-01-10 20:43:45,725 - GAugM EPNet train, Epoch [200/215]: loss 0.7210, auc 0.4783, ap 0.5281
2024-01-10 20:43:45,818 - GAugM EPNet train, Epoch [201/215]: loss 0.7209, auc 0.4710, ap 0.4832
2024-01-10 20:43:45,908 - GAugM EPNet train, Epoch [202/215]: loss 0.7210, auc 0.5477, ap 0.5691
2024-01-10 20:43:46,003 - GAugM EPNet train, Epoch [203/215]: loss 0.7210, auc 0.4767, ap 0.5111
2024-01-10 20:43:46,093 - GAugM EPNet train, Epoch [204/215]: loss 0.7209, auc 0.4494, ap 0.4615
2024-01-10 20:43:46,181 - GAugM EPNet train, Epoch [205/215]: loss 0.7209, auc 0.4952, ap 0.5230
2024-01-10 20:43:46,275 - GAugM EPNet train, Epoch [206/215]: loss 0.7209, auc 0.4331, ap 0.4529
2024-01-10 20:43:46,363 - GAugM EPNet train, Epoch [207/215]: loss 0.7210, auc 0.4733, ap 0.4876
2024-01-10 20:43:46,456 - GAugM EPNet train, Epoch [208/215]: loss 0.7209, auc 0.4183, ap 0.4929
2024-01-10 20:43:46,545 - GAugM EPNet train, Epoch [209/215]: loss 0.7210, auc 0.5767, ap 0.5728
2024-01-10 20:43:46,641 - GAugM EPNet train, Epoch [210/215]: loss 0.7209, auc 0.4614, ap 0.4780
2024-01-10 20:43:46,734 - GAugM EPNet train, Epoch [211/215]: loss 0.7210, auc 0.4911, ap 0.5056
2024-01-10 20:43:46,822 - GAugM EPNet train, Epoch [212/215]: loss 0.7210, auc 0.4300, ap 0.4498
2024-01-10 20:43:46,912 - GAugM EPNet train, Epoch [213/215]: loss 0.7208, auc 0.6848, ap 0.6640
2024-01-10 20:43:47,008 - GAugM EPNet train, Epoch [214/215]: loss 0.7210, auc 0.4939, ap 0.5022
2024-01-10 20:43:47,099 - GAugM EPNet train, Epoch [215/215]: loss 0.7210, auc 0.5271, ap 0.5388
2024-01-10 20:43:47,100 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f14a31d4ed0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:43:47,918 - GAugM EPNet train, Epoch [  1/215]: loss 0.7210, auc 0.5313, ap 0.5138
2024-01-10 20:43:48,016 - GAugM EPNet train, Epoch [  2/215]: loss 0.7210, auc 0.5260, ap 0.5282
2024-01-10 20:43:48,116 - GAugM EPNet train, Epoch [  3/215]: loss 0.7209, auc 0.5392, ap 0.5526
2024-01-10 20:43:48,214 - GAugM EPNet train, Epoch [  4/215]: loss 0.7209, auc 0.5068, ap 0.4963
2024-01-10 20:43:48,314 - GAugM EPNet train, Epoch [  5/215]: loss 0.7209, auc 0.5349, ap 0.5446
2024-01-10 20:43:48,407 - GAugM EPNet train, Epoch [  6/215]: loss 0.7209, auc 0.5064, ap 0.4949
2024-01-10 20:43:48,491 - GAugM EPNet train, Epoch [  7/215]: loss 0.7209, auc 0.4929, ap 0.4949
2024-01-10 20:43:48,574 - GAugM EPNet train, Epoch [  8/215]: loss 0.7210, auc 0.4947, ap 0.5350
2024-01-10 20:43:48,665 - GAugM EPNet train, Epoch [  9/215]: loss 0.7209, auc 0.4395, ap 0.4529
2024-01-10 20:43:48,741 - GAugM EPNet train, Epoch [ 10/215]: loss 0.7208, auc 0.5057, ap 0.5190
2024-01-10 20:43:48,818 - GAugM EPNet train, Epoch [ 11/215]: loss 0.7209, auc 0.5142, ap 0.5397
2024-01-10 20:43:48,903 - GAugM EPNet train, Epoch [ 12/215]: loss 0.7210, auc 0.5335, ap 0.5318
2024-01-10 20:43:48,989 - GAugM EPNet train, Epoch [ 13/215]: loss 0.7209, auc 0.5680, ap 0.5535
2024-01-10 20:43:49,074 - GAugM EPNet train, Epoch [ 14/215]: loss 0.7209, auc 0.5303, ap 0.5208
2024-01-10 20:43:49,158 - GAugM EPNet train, Epoch [ 15/215]: loss 0.7210, auc 0.4761, ap 0.5247
2024-01-10 20:43:49,239 - GAugM EPNet train, Epoch [ 16/215]: loss 0.7209, auc 0.4420, ap 0.4765
2024-01-10 20:43:49,323 - GAugM EPNet train, Epoch [ 17/215]: loss 0.7210, auc 0.5174, ap 0.5258
2024-01-10 20:43:49,413 - GAugM EPNet train, Epoch [ 18/215]: loss 0.7210, auc 0.6061, ap 0.5981
2024-01-10 20:43:49,497 - GAugM EPNet train, Epoch [ 19/215]: loss 0.7209, auc 0.5894, ap 0.5652
2024-01-10 20:43:49,580 - GAugM EPNet train, Epoch [ 20/215]: loss 0.7210, auc 0.5459, ap 0.5714
2024-01-10 20:43:49,661 - GAugM EPNet train, Epoch [ 21/215]: loss 0.7209, auc 0.4765, ap 0.5034
2024-01-10 20:43:49,742 - GAugM EPNet train, Epoch [ 22/215]: loss 0.7210, auc 0.4462, ap 0.4776
2024-01-10 20:43:49,824 - GAugM EPNet train, Epoch [ 23/215]: loss 0.7208, auc 0.5085, ap 0.5331
2024-01-10 20:43:49,905 - GAugM EPNet train, Epoch [ 24/215]: loss 0.7209, auc 0.4907, ap 0.5030
2024-01-10 20:43:49,994 - GAugM EPNet train, Epoch [ 25/215]: loss 0.7209, auc 0.4099, ap 0.4307
2024-01-10 20:43:50,084 - GAugM EPNet train, Epoch [ 26/215]: loss 0.7210, auc 0.5192, ap 0.5410
2024-01-10 20:43:50,173 - GAugM EPNet train, Epoch [ 27/215]: loss 0.7209, auc 0.4676, ap 0.5456
2024-01-10 20:43:50,260 - GAugM EPNet train, Epoch [ 28/215]: loss 0.7209, auc 0.5363, ap 0.5622
2024-01-10 20:43:50,339 - GAugM EPNet train, Epoch [ 29/215]: loss 0.7210, auc 0.4843, ap 0.5057
2024-01-10 20:43:50,423 - GAugM EPNet train, Epoch [ 30/215]: loss 0.7209, auc 0.5299, ap 0.5644
2024-01-10 20:43:50,510 - GAugM EPNet train, Epoch [ 31/215]: loss 0.7208, auc 0.5028, ap 0.5109
2024-01-10 20:43:50,588 - GAugM EPNet train, Epoch [ 32/215]: loss 0.7210, auc 0.5555, ap 0.5488
2024-01-10 20:43:50,672 - GAugM EPNet train, Epoch [ 33/215]: loss 0.7209, auc 0.5196, ap 0.5203
2024-01-10 20:43:50,755 - GAugM EPNet train, Epoch [ 34/215]: loss 0.7209, auc 0.3857, ap 0.4411
2024-01-10 20:43:50,843 - GAugM EPNet train, Epoch [ 35/215]: loss 0.7209, auc 0.5167, ap 0.5116
2024-01-10 20:43:50,924 - GAugM EPNet train, Epoch [ 36/215]: loss 0.7209, auc 0.5794, ap 0.5869
2024-01-10 20:43:51,003 - GAugM EPNet train, Epoch [ 37/215]: loss 0.7209, auc 0.4039, ap 0.4583
2024-01-10 20:43:51,082 - GAugM EPNet train, Epoch [ 38/215]: loss 0.7209, auc 0.5904, ap 0.5424
2024-01-10 20:43:51,159 - GAugM EPNet train, Epoch [ 39/215]: loss 0.7208, auc 0.4932, ap 0.5444
2024-01-10 20:43:51,256 - GAugM EPNet train, Epoch [ 40/215]: loss 0.7210, auc 0.5712, ap 0.5503
2024-01-10 20:43:51,345 - GAugM EPNet train, Epoch [ 41/215]: loss 0.7210, auc 0.4626, ap 0.5115
2024-01-10 20:43:51,422 - GAugM EPNet train, Epoch [ 42/215]: loss 0.7209, auc 0.6057, ap 0.6241
2024-01-10 20:43:51,504 - GAugM EPNet train, Epoch [ 43/215]: loss 0.7208, auc 0.5057, ap 0.5288
2024-01-10 20:43:51,584 - GAugM EPNet train, Epoch [ 44/215]: loss 0.7208, auc 0.4167, ap 0.4403
2024-01-10 20:43:51,671 - GAugM EPNet train, Epoch [ 45/215]: loss 0.7209, auc 0.5413, ap 0.5626
2024-01-10 20:43:51,765 - GAugM EPNet train, Epoch [ 46/215]: loss 0.7209, auc 0.4769, ap 0.4840
2024-01-10 20:43:51,845 - GAugM EPNet train, Epoch [ 47/215]: loss 0.7210, auc 0.4416, ap 0.4496
2024-01-10 20:43:51,934 - GAugM EPNet train, Epoch [ 48/215]: loss 0.7210, auc 0.5538, ap 0.5699
2024-01-10 20:43:52,021 - GAugM EPNet train, Epoch [ 49/215]: loss 0.7209, auc 0.5150, ap 0.5377
2024-01-10 20:43:52,102 - GAugM EPNet train, Epoch [ 50/215]: loss 0.7210, auc 0.5196, ap 0.5127
2024-01-10 20:43:52,189 - GAugM EPNet train, Epoch [ 51/215]: loss 0.7210, auc 0.4672, ap 0.5161
2024-01-10 20:43:52,269 - GAugM EPNet train, Epoch [ 52/215]: loss 0.7209, auc 0.4299, ap 0.5026
2024-01-10 20:43:52,357 - GAugM EPNet train, Epoch [ 53/215]: loss 0.7209, auc 0.5356, ap 0.5572
2024-01-10 20:43:52,446 - GAugM EPNet train, Epoch [ 54/215]: loss 0.7211, auc 0.5655, ap 0.5580
2024-01-10 20:43:52,527 - GAugM EPNet train, Epoch [ 55/215]: loss 0.7209, auc 0.6082, ap 0.6065
2024-01-10 20:43:52,604 - GAugM EPNet train, Epoch [ 56/215]: loss 0.7208, auc 0.5306, ap 0.5084
2024-01-10 20:43:52,679 - GAugM EPNet train, Epoch [ 57/215]: loss 0.7209, auc 0.4381, ap 0.4443
2024-01-10 20:43:52,758 - GAugM EPNet train, Epoch [ 58/215]: loss 0.7210, auc 0.5157, ap 0.5472
2024-01-10 20:43:52,833 - GAugM EPNet train, Epoch [ 59/215]: loss 0.7211, auc 0.4822, ap 0.5010
2024-01-10 20:43:52,915 - GAugM EPNet train, Epoch [ 60/215]: loss 0.7210, auc 0.4705, ap 0.4911
2024-01-10 20:43:52,992 - GAugM EPNet train, Epoch [ 61/215]: loss 0.7209, auc 0.5602, ap 0.5552
2024-01-10 20:43:53,087 - GAugM EPNet train, Epoch [ 62/215]: loss 0.7210, auc 0.5288, ap 0.5339
2024-01-10 20:43:53,180 - GAugM EPNet train, Epoch [ 63/215]: loss 0.7208, auc 0.5057, ap 0.5050
2024-01-10 20:43:53,271 - GAugM EPNet train, Epoch [ 64/215]: loss 0.7208, auc 0.5117, ap 0.5442
2024-01-10 20:43:53,360 - GAugM EPNet train, Epoch [ 65/215]: loss 0.7208, auc 0.5815, ap 0.6108
2024-01-10 20:43:53,443 - GAugM EPNet train, Epoch [ 66/215]: loss 0.7209, auc 0.4583, ap 0.4813
2024-01-10 20:43:53,536 - GAugM EPNet train, Epoch [ 67/215]: loss 0.7209, auc 0.5676, ap 0.5623
2024-01-10 20:43:53,626 - GAugM EPNet train, Epoch [ 68/215]: loss 0.7210, auc 0.4915, ap 0.5067
2024-01-10 20:43:53,723 - GAugM EPNet train, Epoch [ 69/215]: loss 0.7210, auc 0.4648, ap 0.4844
2024-01-10 20:43:53,810 - GAugM EPNet train, Epoch [ 70/215]: loss 0.7210, auc 0.4270, ap 0.4444
2024-01-10 20:43:53,899 - GAugM EPNet train, Epoch [ 71/215]: loss 0.7210, auc 0.5644, ap 0.5404
2024-01-10 20:43:53,985 - GAugM EPNet train, Epoch [ 72/215]: loss 0.7210, auc 0.4758, ap 0.4763
2024-01-10 20:43:54,079 - GAugM EPNet train, Epoch [ 73/215]: loss 0.7209, auc 0.4737, ap 0.4793
2024-01-10 20:43:54,168 - GAugM EPNet train, Epoch [ 74/215]: loss 0.7209, auc 0.5018, ap 0.5218
2024-01-10 20:43:54,255 - GAugM EPNet train, Epoch [ 75/215]: loss 0.7210, auc 0.4203, ap 0.4519
2024-01-10 20:43:54,343 - GAugM EPNet train, Epoch [ 76/215]: loss 0.7209, auc 0.4124, ap 0.4481
2024-01-10 20:43:54,431 - GAugM EPNet train, Epoch [ 77/215]: loss 0.7208, auc 0.6061, ap 0.5881
2024-01-10 20:43:54,522 - GAugM EPNet train, Epoch [ 78/215]: loss 0.7209, auc 0.4954, ap 0.4961
2024-01-10 20:43:54,617 - GAugM EPNet train, Epoch [ 79/215]: loss 0.7208, auc 0.5360, ap 0.5415
2024-01-10 20:43:54,706 - GAugM EPNet train, Epoch [ 80/215]: loss 0.7209, auc 0.6107, ap 0.5784
2024-01-10 20:43:54,796 - GAugM EPNet train, Epoch [ 81/215]: loss 0.7209, auc 0.5082, ap 0.5056
2024-01-10 20:43:54,886 - GAugM EPNet train, Epoch [ 82/215]: loss 0.7210, auc 0.5765, ap 0.5554
2024-01-10 20:43:54,969 - GAugM EPNet train, Epoch [ 83/215]: loss 0.7209, auc 0.4680, ap 0.5090
2024-01-10 20:43:55,060 - GAugM EPNet train, Epoch [ 84/215]: loss 0.7209, auc 0.4818, ap 0.4833
2024-01-10 20:43:55,150 - GAugM EPNet train, Epoch [ 85/215]: loss 0.7210, auc 0.4156, ap 0.4619
2024-01-10 20:43:55,233 - GAugM EPNet train, Epoch [ 86/215]: loss 0.7208, auc 0.4790, ap 0.4912
2024-01-10 20:43:55,321 - GAugM EPNet train, Epoch [ 87/215]: loss 0.7209, auc 0.5466, ap 0.5423
2024-01-10 20:43:55,414 - GAugM EPNet train, Epoch [ 88/215]: loss 0.7210, auc 0.4327, ap 0.4721
2024-01-10 20:43:55,496 - GAugM EPNet train, Epoch [ 89/215]: loss 0.7210, auc 0.4626, ap 0.4928
2024-01-10 20:43:55,583 - GAugM EPNet train, Epoch [ 90/215]: loss 0.7209, auc 0.4021, ap 0.4438
2024-01-10 20:43:55,663 - GAugM EPNet train, Epoch [ 91/215]: loss 0.7208, auc 0.5199, ap 0.4994
2024-01-10 20:43:55,742 - GAugM EPNet train, Epoch [ 92/215]: loss 0.7209, auc 0.5388, ap 0.5486
2024-01-10 20:43:55,827 - GAugM EPNet train, Epoch [ 93/215]: loss 0.7209, auc 0.4715, ap 0.4927
2024-01-10 20:43:55,907 - GAugM EPNet train, Epoch [ 94/215]: loss 0.7210, auc 0.4010, ap 0.4848
2024-01-10 20:43:55,992 - GAugM EPNet train, Epoch [ 95/215]: loss 0.7210, auc 0.4783, ap 0.5137
2024-01-10 20:43:56,082 - GAugM EPNet train, Epoch [ 96/215]: loss 0.7209, auc 0.5612, ap 0.5672
2024-01-10 20:43:56,166 - GAugM EPNet train, Epoch [ 97/215]: loss 0.7209, auc 0.4900, ap 0.5297
2024-01-10 20:43:56,256 - GAugM EPNet train, Epoch [ 98/215]: loss 0.7209, auc 0.4028, ap 0.4451
2024-01-10 20:43:56,339 - GAugM EPNet train, Epoch [ 99/215]: loss 0.7209, auc 0.4042, ap 0.4493
2024-01-10 20:43:56,426 - GAugM EPNet train, Epoch [100/215]: loss 0.7210, auc 0.5328, ap 0.5402
2024-01-10 20:43:56,523 - GAugM EPNet train, Epoch [101/215]: loss 0.7210, auc 0.5007, ap 0.5466
2024-01-10 20:43:56,608 - GAugM EPNet train, Epoch [102/215]: loss 0.7209, auc 0.4217, ap 0.4711
2024-01-10 20:43:56,693 - GAugM EPNet train, Epoch [103/215]: loss 0.7209, auc 0.4676, ap 0.5148
2024-01-10 20:43:56,782 - GAugM EPNet train, Epoch [104/215]: loss 0.7209, auc 0.4697, ap 0.5069
2024-01-10 20:43:56,861 - GAugM EPNet train, Epoch [105/215]: loss 0.7209, auc 0.4655, ap 0.4821
2024-01-10 20:43:56,953 - GAugM EPNet train, Epoch [106/215]: loss 0.7210, auc 0.5114, ap 0.5388
2024-01-10 20:43:57,039 - GAugM EPNet train, Epoch [107/215]: loss 0.7210, auc 0.4356, ap 0.4859
2024-01-10 20:43:57,129 - GAugM EPNet train, Epoch [108/215]: loss 0.7208, auc 0.5388, ap 0.5356
2024-01-10 20:43:57,210 - GAugM EPNet train, Epoch [109/215]: loss 0.7210, auc 0.4729, ap 0.4729
2024-01-10 20:43:57,299 - GAugM EPNet train, Epoch [110/215]: loss 0.7209, auc 0.4591, ap 0.4836
2024-01-10 20:43:57,386 - GAugM EPNet train, Epoch [111/215]: loss 0.7210, auc 0.5233, ap 0.5175
2024-01-10 20:43:57,471 - GAugM EPNet train, Epoch [112/215]: loss 0.7209, auc 0.5039, ap 0.5176
2024-01-10 20:43:57,555 - GAugM EPNet train, Epoch [113/215]: loss 0.7210, auc 0.4544, ap 0.4921
2024-01-10 20:43:57,644 - GAugM EPNet train, Epoch [114/215]: loss 0.7209, auc 0.4245, ap 0.4449
2024-01-10 20:43:57,731 - GAugM EPNet train, Epoch [115/215]: loss 0.7210, auc 0.5530, ap 0.5394
2024-01-10 20:43:57,819 - GAugM EPNet train, Epoch [116/215]: loss 0.7209, auc 0.5251, ap 0.5637
2024-01-10 20:43:57,912 - GAugM EPNet train, Epoch [117/215]: loss 0.7208, auc 0.4438, ap 0.4663
2024-01-10 20:43:57,998 - GAugM EPNet train, Epoch [118/215]: loss 0.7209, auc 0.5271, ap 0.5936
2024-01-10 20:43:58,088 - GAugM EPNet train, Epoch [119/215]: loss 0.7209, auc 0.5107, ap 0.5475
2024-01-10 20:43:58,173 - GAugM EPNet train, Epoch [120/215]: loss 0.7210, auc 0.4705, ap 0.4892
2024-01-10 20:43:58,265 - GAugM EPNet train, Epoch [121/215]: loss 0.7210, auc 0.3943, ap 0.4415
2024-01-10 20:43:58,354 - GAugM EPNet train, Epoch [122/215]: loss 0.7209, auc 0.4274, ap 0.4641
2024-01-10 20:43:58,438 - GAugM EPNet train, Epoch [123/215]: loss 0.7209, auc 0.5036, ap 0.5118
2024-01-10 20:43:58,535 - GAugM EPNet train, Epoch [124/215]: loss 0.7210, auc 0.4811, ap 0.4766
2024-01-10 20:43:58,623 - GAugM EPNet train, Epoch [125/215]: loss 0.7209, auc 0.4954, ap 0.5137
2024-01-10 20:43:58,709 - GAugM EPNet train, Epoch [126/215]: loss 0.7210, auc 0.5135, ap 0.5228
2024-01-10 20:43:58,792 - GAugM EPNet train, Epoch [127/215]: loss 0.7209, auc 0.4804, ap 0.4949
2024-01-10 20:43:58,881 - GAugM EPNet train, Epoch [128/215]: loss 0.7210, auc 0.5666, ap 0.5541
2024-01-10 20:43:58,965 - GAugM EPNet train, Epoch [129/215]: loss 0.7208, auc 0.4537, ap 0.4654
2024-01-10 20:43:59,056 - GAugM EPNet train, Epoch [130/215]: loss 0.7210, auc 0.5299, ap 0.5862
2024-01-10 20:43:59,142 - GAugM EPNet train, Epoch [131/215]: loss 0.7210, auc 0.5466, ap 0.5919
2024-01-10 20:43:59,227 - GAugM EPNet train, Epoch [132/215]: loss 0.7209, auc 0.5716, ap 0.5556
2024-01-10 20:43:59,312 - GAugM EPNet train, Epoch [133/215]: loss 0.7209, auc 0.4765, ap 0.5404
2024-01-10 20:43:59,400 - GAugM EPNet train, Epoch [134/215]: loss 0.7210, auc 0.5367, ap 0.5378
2024-01-10 20:43:59,490 - GAugM EPNet train, Epoch [135/215]: loss 0.7209, auc 0.4299, ap 0.4762
2024-01-10 20:43:59,589 - GAugM EPNet train, Epoch [136/215]: loss 0.7209, auc 0.4836, ap 0.4935
2024-01-10 20:43:59,677 - GAugM EPNet train, Epoch [137/215]: loss 0.7210, auc 0.4548, ap 0.4648
2024-01-10 20:43:59,765 - GAugM EPNet train, Epoch [138/215]: loss 0.7210, auc 0.4519, ap 0.4889
2024-01-10 20:43:59,858 - GAugM EPNet train, Epoch [139/215]: loss 0.7210, auc 0.4224, ap 0.4384
2024-01-10 20:43:59,943 - GAugM EPNet train, Epoch [140/215]: loss 0.7209, auc 0.5402, ap 0.5721
2024-01-10 20:44:00,044 - GAugM EPNet train, Epoch [141/215]: loss 0.7209, auc 0.5516, ap 0.5732
2024-01-10 20:44:00,133 - GAugM EPNet train, Epoch [142/215]: loss 0.7209, auc 0.4854, ap 0.5070
2024-01-10 20:44:00,223 - GAugM EPNet train, Epoch [143/215]: loss 0.7209, auc 0.4462, ap 0.4725
2024-01-10 20:44:00,314 - GAugM EPNet train, Epoch [144/215]: loss 0.7209, auc 0.5039, ap 0.5067
2024-01-10 20:44:00,405 - GAugM EPNet train, Epoch [145/215]: loss 0.7209, auc 0.4562, ap 0.5061
2024-01-10 20:44:00,495 - GAugM EPNet train, Epoch [146/215]: loss 0.7209, auc 0.5221, ap 0.5305
2024-01-10 20:44:00,585 - GAugM EPNet train, Epoch [147/215]: loss 0.7209, auc 0.5641, ap 0.5844
2024-01-10 20:44:00,688 - GAugM EPNet train, Epoch [148/215]: loss 0.7209, auc 0.4954, ap 0.5121
2024-01-10 20:44:00,777 - GAugM EPNet train, Epoch [149/215]: loss 0.7208, auc 0.5032, ap 0.4913
2024-01-10 20:44:00,863 - GAugM EPNet train, Epoch [150/215]: loss 0.7209, auc 0.4623, ap 0.4886
2024-01-10 20:44:00,958 - GAugM EPNet train, Epoch [151/215]: loss 0.7209, auc 0.5548, ap 0.5577
2024-01-10 20:44:01,044 - GAugM EPNet train, Epoch [152/215]: loss 0.7209, auc 0.5997, ap 0.5923
2024-01-10 20:44:01,133 - GAugM EPNet train, Epoch [153/215]: loss 0.7209, auc 0.5189, ap 0.5209
2024-01-10 20:44:01,227 - GAugM EPNet train, Epoch [154/215]: loss 0.7209, auc 0.4925, ap 0.5506
2024-01-10 20:44:01,315 - GAugM EPNet train, Epoch [155/215]: loss 0.7209, auc 0.5328, ap 0.5311
2024-01-10 20:44:01,403 - GAugM EPNet train, Epoch [156/215]: loss 0.7209, auc 0.4028, ap 0.4619
2024-01-10 20:44:01,496 - GAugM EPNet train, Epoch [157/215]: loss 0.7209, auc 0.4922, ap 0.4767
2024-01-10 20:44:01,587 - GAugM EPNet train, Epoch [158/215]: loss 0.7208, auc 0.4608, ap 0.5018
2024-01-10 20:44:01,683 - GAugM EPNet train, Epoch [159/215]: loss 0.7208, auc 0.4822, ap 0.4827
2024-01-10 20:44:01,768 - GAugM EPNet train, Epoch [160/215]: loss 0.7209, auc 0.5634, ap 0.5763
2024-01-10 20:44:01,856 - GAugM EPNet train, Epoch [161/215]: loss 0.7209, auc 0.4982, ap 0.4802
2024-01-10 20:44:01,943 - GAugM EPNet train, Epoch [162/215]: loss 0.7209, auc 0.5231, ap 0.5047
2024-01-10 20:44:02,036 - GAugM EPNet train, Epoch [163/215]: loss 0.7209, auc 0.4377, ap 0.4495
2024-01-10 20:44:02,125 - GAugM EPNet train, Epoch [164/215]: loss 0.7211, auc 0.5441, ap 0.5243
2024-01-10 20:44:02,215 - GAugM EPNet train, Epoch [165/215]: loss 0.7210, auc 0.4640, ap 0.4814
2024-01-10 20:44:02,307 - GAugM EPNet train, Epoch [166/215]: loss 0.7208, auc 0.5570, ap 0.5392
2024-01-10 20:44:02,401 - GAugM EPNet train, Epoch [167/215]: loss 0.7209, auc 0.4562, ap 0.4916
2024-01-10 20:44:02,495 - GAugM EPNet train, Epoch [168/215]: loss 0.7209, auc 0.5089, ap 0.5483
2024-01-10 20:44:02,580 - GAugM EPNet train, Epoch [169/215]: loss 0.7209, auc 0.5659, ap 0.5969
2024-01-10 20:44:02,672 - GAugM EPNet train, Epoch [170/215]: loss 0.7210, auc 0.4861, ap 0.4805
2024-01-10 20:44:02,761 - GAugM EPNet train, Epoch [171/215]: loss 0.7209, auc 0.4672, ap 0.4902
2024-01-10 20:44:02,845 - GAugM EPNet train, Epoch [172/215]: loss 0.7208, auc 0.4149, ap 0.4464
2024-01-10 20:44:02,935 - GAugM EPNet train, Epoch [173/215]: loss 0.7209, auc 0.5043, ap 0.5032
2024-01-10 20:44:03,020 - GAugM EPNet train, Epoch [174/215]: loss 0.7209, auc 0.5520, ap 0.5151
2024-01-10 20:44:03,107 - GAugM EPNet train, Epoch [175/215]: loss 0.7209, auc 0.6072, ap 0.5671
2024-01-10 20:44:03,196 - GAugM EPNet train, Epoch [176/215]: loss 0.7209, auc 0.5050, ap 0.4955
2024-01-10 20:44:03,281 - GAugM EPNet train, Epoch [177/215]: loss 0.7210, auc 0.5153, ap 0.4937
2024-01-10 20:44:03,367 - GAugM EPNet train, Epoch [178/215]: loss 0.7210, auc 0.5559, ap 0.5499
2024-01-10 20:44:03,458 - GAugM EPNet train, Epoch [179/215]: loss 0.7210, auc 0.4537, ap 0.5517
2024-01-10 20:44:03,554 - GAugM EPNet train, Epoch [180/215]: loss 0.7210, auc 0.6082, ap 0.6270
2024-01-10 20:44:03,642 - GAugM EPNet train, Epoch [181/215]: loss 0.7209, auc 0.4591, ap 0.4574
2024-01-10 20:44:03,726 - GAugM EPNet train, Epoch [182/215]: loss 0.7209, auc 0.4608, ap 0.4929
2024-01-10 20:44:03,814 - GAugM EPNet train, Epoch [183/215]: loss 0.7210, auc 0.5338, ap 0.5180
2024-01-10 20:44:03,911 - GAugM EPNet train, Epoch [184/215]: loss 0.7209, auc 0.4936, ap 0.5152
2024-01-10 20:44:04,000 - GAugM EPNet train, Epoch [185/215]: loss 0.7209, auc 0.4470, ap 0.4855
2024-01-10 20:44:04,089 - GAugM EPNet train, Epoch [186/215]: loss 0.7208, auc 0.4918, ap 0.5234
2024-01-10 20:44:04,180 - GAugM EPNet train, Epoch [187/215]: loss 0.7209, auc 0.5249, ap 0.5497
2024-01-10 20:44:04,275 - GAugM EPNet train, Epoch [188/215]: loss 0.7209, auc 0.4502, ap 0.4522
2024-01-10 20:44:04,363 - GAugM EPNet train, Epoch [189/215]: loss 0.7209, auc 0.4712, ap 0.5150
2024-01-10 20:44:04,452 - GAugM EPNet train, Epoch [190/215]: loss 0.7209, auc 0.4527, ap 0.4666
2024-01-10 20:44:04,540 - GAugM EPNet train, Epoch [191/215]: loss 0.7209, auc 0.5014, ap 0.5250
2024-01-10 20:44:04,627 - GAugM EPNet train, Epoch [192/215]: loss 0.7209, auc 0.5249, ap 0.4950
2024-01-10 20:44:04,713 - GAugM EPNet train, Epoch [193/215]: loss 0.7209, auc 0.4931, ap 0.4771
2024-01-10 20:44:04,803 - GAugM EPNet train, Epoch [194/215]: loss 0.7209, auc 0.4640, ap 0.4953
2024-01-10 20:44:04,888 - GAugM EPNet train, Epoch [195/215]: loss 0.7209, auc 0.4167, ap 0.4615
2024-01-10 20:44:04,984 - GAugM EPNet train, Epoch [196/215]: loss 0.7208, auc 0.5360, ap 0.5230
2024-01-10 20:44:05,074 - GAugM EPNet train, Epoch [197/215]: loss 0.7210, auc 0.4637, ap 0.4764
2024-01-10 20:44:05,161 - GAugM EPNet train, Epoch [198/215]: loss 0.7210, auc 0.5117, ap 0.4982
2024-01-10 20:44:05,245 - GAugM EPNet train, Epoch [199/215]: loss 0.7209, auc 0.4925, ap 0.5207
2024-01-10 20:44:05,330 - GAugM EPNet train, Epoch [200/215]: loss 0.7210, auc 0.4381, ap 0.4569
2024-01-10 20:44:05,415 - GAugM EPNet train, Epoch [201/215]: loss 0.7209, auc 0.4459, ap 0.4713
2024-01-10 20:44:05,513 - GAugM EPNet train, Epoch [202/215]: loss 0.7210, auc 0.5206, ap 0.5400
2024-01-10 20:44:05,608 - GAugM EPNet train, Epoch [203/215]: loss 0.7210, auc 0.4715, ap 0.4987
2024-01-10 20:44:05,696 - GAugM EPNet train, Epoch [204/215]: loss 0.7209, auc 0.4430, ap 0.4550
2024-01-10 20:44:05,782 - GAugM EPNet train, Epoch [205/215]: loss 0.7209, auc 0.4487, ap 0.5100
2024-01-10 20:44:05,872 - GAugM EPNet train, Epoch [206/215]: loss 0.7209, auc 0.4733, ap 0.4728
2024-01-10 20:44:05,959 - GAugM EPNet train, Epoch [207/215]: loss 0.7210, auc 0.4911, ap 0.5091
2024-01-10 20:44:06,053 - GAugM EPNet train, Epoch [208/215]: loss 0.7209, auc 0.4530, ap 0.4796
2024-01-10 20:44:06,141 - GAugM EPNet train, Epoch [209/215]: loss 0.7210, auc 0.5737, ap 0.5705
2024-01-10 20:44:06,234 - GAugM EPNet train, Epoch [210/215]: loss 0.7209, auc 0.4576, ap 0.4822
2024-01-10 20:44:06,328 - GAugM EPNet train, Epoch [211/215]: loss 0.7210, auc 0.5313, ap 0.5463
2024-01-10 20:44:06,424 - GAugM EPNet train, Epoch [212/215]: loss 0.7210, auc 0.4943, ap 0.5178
2024-01-10 20:44:06,512 - GAugM EPNet train, Epoch [213/215]: loss 0.7208, auc 0.6310, ap 0.6442
2024-01-10 20:44:06,606 - GAugM EPNet train, Epoch [214/215]: loss 0.7210, auc 0.5253, ap 0.5011
2024-01-10 20:44:06,693 - GAugM EPNet train, Epoch [215/215]: loss 0.7210, auc 0.4737, ap 0.5068
2024-01-10 20:44:06,700 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f1499a40c10>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:44:30,313 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f431b6bcd90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:44:31,029 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4010, ap 0.4410
2024-01-10 20:44:31,098 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5087, ap 0.4873
2024-01-10 20:44:31,153 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5326, ap 0.5167
2024-01-10 20:44:31,211 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4560, ap 0.5082
2024-01-10 20:44:31,273 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5406, ap 0.5518
2024-01-10 20:44:31,335 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4697, ap 0.4846
2024-01-10 20:44:31,400 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4553, ap 0.4542
2024-01-10 20:44:31,464 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4872, ap 0.4913
2024-01-10 20:44:31,522 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.5287, ap 0.5268
2024-01-10 20:44:31,586 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4418, ap 0.4851
2024-01-10 20:44:31,645 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4820, ap 0.4928
2024-01-10 20:44:31,709 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.5230, ap 0.5289
2024-01-10 20:44:31,770 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5771, ap 0.5918
2024-01-10 20:44:31,833 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.6169, ap 0.5942
2024-01-10 20:44:31,921 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3706, ap 0.4525
2024-01-10 20:44:32,000 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5561, ap 0.5445
2024-01-10 20:44:32,086 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5173, ap 0.5243
2024-01-10 20:44:32,163 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5568, ap 0.5503
2024-01-10 20:44:32,247 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5379, ap 0.5379
2024-01-10 20:44:32,327 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4945, ap 0.5068
2024-01-10 20:44:32,406 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5162, ap 0.5401
2024-01-10 20:44:32,486 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4576, ap 0.4937
2024-01-10 20:44:32,571 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.4827, ap 0.4820
2024-01-10 20:44:32,656 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5101, ap 0.4783
2024-01-10 20:44:32,735 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4226, ap 0.4453
2024-01-10 20:44:32,812 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5575, ap 0.5420
2024-01-10 20:44:32,892 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4699, ap 0.5325
2024-01-10 20:44:32,969 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5913, ap 0.5656
2024-01-10 20:44:33,068 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4642, ap 0.4841
2024-01-10 20:44:33,175 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5084, ap 0.5164
2024-01-10 20:44:33,180 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f431b344590>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:44:33,906 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4514, ap 0.4615
2024-01-10 20:44:34,004 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5082, ap 0.4911
2024-01-10 20:44:34,099 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.6474, ap 0.6095
2024-01-10 20:44:34,207 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.5395, ap 0.5585
2024-01-10 20:44:34,303 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5641, ap 0.5723
2024-01-10 20:44:34,410 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4359, ap 0.4547
2024-01-10 20:44:34,505 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4192, ap 0.4355
2024-01-10 20:44:34,606 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5221, ap 0.5048
2024-01-10 20:44:34,705 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4021, ap 0.4311
2024-01-10 20:44:34,808 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4583, ap 0.4651
2024-01-10 20:44:34,917 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.5278, ap 0.5432
2024-01-10 20:44:35,016 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4801, ap 0.4724
2024-01-10 20:44:35,121 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5721, ap 0.5231
2024-01-10 20:44:35,215 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5231, ap 0.5176
2024-01-10 20:44:35,328 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3978, ap 0.4570
2024-01-10 20:44:35,425 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5210, ap 0.5379
2024-01-10 20:44:35,541 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.4956, ap 0.4926
2024-01-10 20:44:35,643 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.6301, ap 0.5938
2024-01-10 20:44:35,759 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.4671, ap 0.4703
2024-01-10 20:44:35,863 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4998, ap 0.5166
2024-01-10 20:44:35,973 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.4776, ap 0.4736
2024-01-10 20:44:36,073 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3416, ap 0.4204
2024-01-10 20:44:36,186 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5215, ap 0.4996
2024-01-10 20:44:36,285 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5431, ap 0.5626
2024-01-10 20:44:36,392 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4274, ap 0.4508
2024-01-10 20:44:36,505 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5796, ap 0.5751
2024-01-10 20:44:36,620 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4106, ap 0.4471
2024-01-10 20:44:36,727 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5874, ap 0.5891
2024-01-10 20:44:36,830 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4512, ap 0.4763
2024-01-10 20:44:36,935 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5402, ap 0.5444
2024-01-10 20:44:36,942 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f4320039c90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:44:37,728 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4915, ap 0.4975
2024-01-10 20:44:37,828 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5783, ap 0.5480
2024-01-10 20:44:37,934 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5185, ap 0.5236
2024-01-10 20:44:38,030 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.5039, ap 0.5230
2024-01-10 20:44:38,131 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.6278, ap 0.6379
2024-01-10 20:44:38,227 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4470, ap 0.4729
2024-01-10 20:44:38,330 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.5053, ap 0.5131
2024-01-10 20:44:38,432 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5036, ap 0.5113
2024-01-10 20:44:38,528 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.5673, ap 0.5457
2024-01-10 20:44:38,633 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.5071, ap 0.5233
2024-01-10 20:44:38,736 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4470, ap 0.4644
2024-01-10 20:44:38,831 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4786, ap 0.4653
2024-01-10 20:44:38,943 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5374, ap 0.5183
2024-01-10 20:44:39,042 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5434, ap 0.5461
2024-01-10 20:44:39,143 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4672, ap 0.5028
2024-01-10 20:44:39,245 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5730, ap 0.5553
2024-01-10 20:44:39,351 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5242, ap 0.5256
2024-01-10 20:44:39,450 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5979, ap 0.5786
2024-01-10 20:44:39,546 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5032, ap 0.4997
2024-01-10 20:45:13,234 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f30316e6090>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:45:13,987 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4557, ap 0.4537
2024-01-10 20:45:14,078 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.4923, ap 0.4856
2024-01-10 20:45:14,161 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5886, ap 0.5538
2024-01-10 20:45:14,240 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.5607, ap 0.5569
2024-01-10 20:45:14,332 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5840, ap 0.5561
2024-01-10 20:45:14,424 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.5064, ap 0.4870
2024-01-10 20:45:14,514 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4384, ap 0.4505
2024-01-10 20:45:14,591 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5046, ap 0.4927
2024-01-10 20:45:14,677 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4153, ap 0.4416
2024-01-10 20:45:14,775 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4744, ap 0.4832
2024-01-10 20:45:14,869 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4687, ap 0.4915
2024-01-10 20:45:14,960 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4300, ap 0.4523
2024-01-10 20:45:15,064 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.6363, ap 0.6143
2024-01-10 20:45:15,164 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5206, ap 0.5091
2024-01-10 20:45:15,258 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4361, ap 0.4767
2024-01-10 20:45:15,359 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4528, ap 0.4898
2024-01-10 20:45:15,448 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5301, ap 0.5142
2024-01-10 20:45:15,543 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.6828, ap 0.6495
2024-01-10 20:45:15,636 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5634, ap 0.5480
2024-01-10 20:45:15,740 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.5071, ap 0.5109
2024-01-10 20:45:15,841 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.4781, ap 0.4811
2024-01-10 20:45:15,927 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3880, ap 0.4290
2024-01-10 20:45:16,017 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.4674, ap 0.4684
2024-01-10 20:45:16,119 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5390, ap 0.5134
2024-01-10 20:45:16,214 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4395, ap 0.4690
2024-01-10 20:45:16,310 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5522, ap 0.5253
2024-01-10 20:45:16,399 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4035, ap 0.4713
2024-01-10 20:45:16,502 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5441, ap 0.5270
2024-01-10 20:45:16,604 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4658, ap 0.4798
2024-01-10 20:45:16,717 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.4224, ap 0.4413
2024-01-10 20:45:16,718 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f3031566310>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:45:17,459 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.5190, ap 0.5009
2024-01-10 20:45:17,555 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.4802, ap 0.4892
2024-01-10 20:45:17,638 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.6296, ap 0.6020
2024-01-10 20:45:17,721 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4635, ap 0.4772
2024-01-10 20:45:17,812 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.6040, ap 0.6017
2024-01-10 20:45:17,904 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.5144, ap 0.4869
2024-01-10 20:45:17,981 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.5139, ap 0.4974
2024-01-10 20:45:18,056 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5392, ap 0.5434
2024-01-10 20:45:18,128 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4753, ap 0.4980
2024-01-10 20:45:18,199 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.5133, ap 0.5170
2024-01-10 20:45:18,274 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4352, ap 0.4590
2024-01-10 20:45:18,343 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4286, ap 0.4481
2024-01-10 20:45:18,413 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5311, ap 0.5221
2024-01-10 20:45:18,491 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.4717, ap 0.4956
2024-01-10 20:45:18,564 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4117, ap 0.4751
2024-01-10 20:45:18,638 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4808, ap 0.5045
2024-01-10 20:45:18,715 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.6011, ap 0.5871
2024-01-10 20:45:18,789 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.6120, ap 0.5832
2024-01-10 20:45:18,891 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5116, ap 0.5058
2024-01-10 20:45:18,983 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4459, ap 0.4859
2024-01-10 20:45:19,073 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.4731, ap 0.4885
2024-01-10 20:45:19,160 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3567, ap 0.4466
2024-01-10 20:45:19,246 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.4920, ap 0.4893
2024-01-10 20:45:19,332 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5322, ap 0.5164
2024-01-10 20:45:19,422 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4575, ap 0.4781
2024-01-10 20:45:19,510 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5924, ap 0.5742
2024-01-10 20:45:19,598 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4322, ap 0.4687
2024-01-10 20:45:19,684 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5221, ap 0.5286
2024-01-10 20:45:19,775 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4838, ap 0.4816
2024-01-10 20:45:19,858 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5746, ap 0.5944
2024-01-10 20:45:19,866 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f30319c1190>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:45:20,595 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4480, ap 0.4640
2024-01-10 20:45:20,690 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.4902, ap 0.4837
2024-01-10 20:45:20,774 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5856, ap 0.5873
2024-01-10 20:45:20,860 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4525, ap 0.5140
2024-01-10 20:45:20,964 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5226, ap 0.5581
2024-01-10 20:45:21,049 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4891, ap 0.4941
2024-01-10 20:45:21,135 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4083, ap 0.4413
2024-01-10 20:45:21,224 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4884, ap 0.4940
2024-01-10 20:45:21,310 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4425, ap 0.4936
2024-01-10 20:45:21,395 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4293, ap 0.4671
2024-01-10 20:45:21,483 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4735, ap 0.4927
2024-01-10 20:45:21,572 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.5044, ap 0.5313
2024-01-10 20:45:21,661 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5829, ap 0.6110
2024-01-10 20:45:21,748 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5518, ap 0.5688
2024-01-10 20:45:21,835 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4261, ap 0.4932
2024-01-10 20:45:21,917 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4724, ap 0.5221
2024-01-10 20:45:22,005 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5128, ap 0.5239
2024-01-10 20:45:22,093 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.6185, ap 0.6129
2024-01-10 20:45:22,178 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.4601, ap 0.4747
2024-01-10 20:45:22,262 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4235, ap 0.4705
2024-01-10 20:45:22,351 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5507, ap 0.5480
2024-01-10 20:45:22,438 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4151, ap 0.4576
2024-01-10 20:45:22,523 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5050, ap 0.5229
2024-01-10 20:45:22,607 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5578, ap 0.5570
2024-01-10 20:45:22,690 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4325, ap 0.4689
2024-01-10 20:45:22,774 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.4575, ap 0.5039
2024-01-10 20:45:22,862 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4852, ap 0.5095
2024-01-10 20:45:22,946 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5356, ap 0.5786
2024-01-10 20:45:23,030 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4952, ap 0.5250
2024-01-10 20:45:23,118 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5244, ap 0.5599
2024-01-10 20:45:23,125 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f3023d38a50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:45:23,887 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.5110, ap 0.5015
2024-01-10 20:45:23,992 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5605, ap 0.5512
2024-01-10 20:45:24,083 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.6068, ap 0.5793
2024-01-10 20:45:24,176 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.5399, ap 0.5718
2024-01-10 20:45:24,269 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5114, ap 0.5082
2024-01-10 20:45:24,358 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4514, ap 0.4649
2024-01-10 20:45:24,451 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4537, ap 0.4573
2024-01-10 20:45:24,540 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4160, ap 0.4566
2024-01-10 20:45:24,629 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4868, ap 0.5006
2024-01-10 20:45:24,716 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.5205, ap 0.5154
2024-01-10 20:45:24,810 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.5333, ap 0.5617
2024-01-10 20:45:24,898 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.5020, ap 0.4887
2024-01-10 20:45:24,988 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5486, ap 0.5315
2024-01-10 20:45:25,074 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5482, ap 0.5203
2024-01-10 20:45:25,161 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4598, ap 0.4839
2024-01-10 20:45:25,254 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5342, ap 0.5520
2024-01-10 20:45:25,347 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5393, ap 0.5344
2024-01-10 20:45:25,433 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5085, ap 0.5307
2024-01-10 20:45:25,523 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5091, ap 0.4942
2024-01-10 20:45:25,610 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.5110, ap 0.5276
2024-01-10 20:45:25,697 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5214, ap 0.5435
2024-01-10 20:45:25,784 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3743, ap 0.4482
2024-01-10 20:45:25,870 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.4891, ap 0.5121
2024-01-10 20:45:25,961 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5477, ap 0.4996
2024-01-10 20:45:26,062 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4865, ap 0.4931
2024-01-10 20:45:26,158 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5700, ap 0.5656
2024-01-10 20:45:26,261 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4263, ap 0.4514
2024-01-10 20:45:26,355 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5178, ap 0.5181
2024-01-10 20:45:26,451 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.5222, ap 0.5164
2024-01-10 20:45:26,550 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5379, ap 0.5420
2024-01-10 20:45:26,560 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f3031bf0050>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:45:27,281 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4644, ap 0.4703
2024-01-10 20:45:27,373 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.4644, ap 0.4868
2024-01-10 20:45:27,465 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.6093, ap 0.5953
2024-01-10 20:45:27,554 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.5221, ap 0.5502
2024-01-10 20:45:27,650 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5128, ap 0.5417
2024-01-10 20:45:27,739 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4651, ap 0.4783
2024-01-10 20:45:27,835 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4541, ap 0.4580
2024-01-10 20:45:27,931 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4915, ap 0.4892
2024-01-10 20:45:28,023 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4833, ap 0.5151
2024-01-10 20:45:28,118 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4658, ap 0.4791
2024-01-10 20:45:28,207 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.5039, ap 0.5264
2024-01-10 20:45:28,301 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.5160, ap 0.5080
2024-01-10 20:45:28,391 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5267, ap 0.5634
2024-01-10 20:45:28,484 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.4868, ap 0.5128
2024-01-10 20:45:28,571 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3523, ap 0.4260
2024-01-10 20:45:28,661 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4897, ap 0.5205
2024-01-10 20:45:28,749 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5171, ap 0.5264
2024-01-10 20:45:28,837 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5762, ap 0.5620
2024-01-10 20:45:28,924 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5879, ap 0.5461
2024-01-10 20:45:29,012 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4964, ap 0.5246
2024-01-10 20:45:29,105 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.4918, ap 0.4859
2024-01-10 20:45:29,190 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4053, ap 0.4668
2024-01-10 20:45:29,280 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5281, ap 0.5384
2024-01-10 20:45:29,379 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5648, ap 0.5585
2024-01-10 20:45:29,475 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.5883, ap 0.5648
2024-01-10 20:45:29,569 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5961, ap 0.6231
2024-01-10 20:45:29,662 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4601, ap 0.4958
2024-01-10 20:45:29,756 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5723, ap 0.5866
2024-01-10 20:45:29,859 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4608, ap 0.4867
2024-01-10 20:45:29,956 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5424, ap 0.5415
2024-01-10 20:45:29,961 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f3031800d90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:45:30,797 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4432, ap 0.4566
2024-01-10 20:45:30,891 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5052, ap 0.5125
2024-01-10 20:45:30,986 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5543, ap 0.5363
2024-01-10 20:45:31,080 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4877, ap 0.5237
2024-01-10 20:45:31,166 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5628, ap 0.5590
2024-01-10 20:45:31,252 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4639, ap 0.4648
2024-01-10 20:45:31,335 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4738, ap 0.4714
2024-01-10 20:45:31,415 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5358, ap 0.5318
2024-01-10 20:45:31,493 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.5059, ap 0.5000
2024-01-10 20:45:31,572 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4849, ap 0.4990
2024-01-10 20:45:31,650 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4258, ap 0.4652
2024-01-10 20:45:31,729 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.5379, ap 0.5378
2024-01-10 20:45:31,811 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5664, ap 0.5576
2024-01-10 20:45:31,887 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.4806, ap 0.4804
2024-01-10 20:45:31,972 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4172, ap 0.4716
2024-01-10 20:45:32,053 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5059, ap 0.5328
2024-01-10 20:45:32,133 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5222, ap 0.5391
2024-01-10 20:45:32,222 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5497, ap 0.5546
2024-01-10 20:45:32,311 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5233, ap 0.5198
2024-01-10 20:45:32,395 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4877, ap 0.5181
2024-01-10 20:45:32,472 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.4422, ap 0.4966
2024-01-10 20:45:32,553 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3738, ap 0.4302
2024-01-10 20:45:32,636 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5333, ap 0.5379
2024-01-10 20:45:32,718 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5322, ap 0.5487
2024-01-10 20:45:32,805 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4322, ap 0.4503
2024-01-10 20:45:32,883 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5265, ap 0.5693
2024-01-10 20:45:32,963 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4571, ap 0.5109
2024-01-10 20:45:33,040 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5354, ap 0.5570
2024-01-10 20:45:33,119 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4845, ap 0.5025
2024-01-10 20:45:33,198 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.4553, ap 0.4926
2024-01-10 20:45:33,205 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f3023f07850>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:45:33,932 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4430, ap 0.4636
2024-01-10 20:45:34,025 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.4583, ap 0.4807
2024-01-10 20:45:34,116 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5776, ap 0.5804
2024-01-10 20:45:34,206 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.5078, ap 0.5212
2024-01-10 20:45:34,300 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5210, ap 0.5477
2024-01-10 20:45:34,392 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.5805, ap 0.5507
2024-01-10 20:45:34,482 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4324, ap 0.4451
2024-01-10 20:45:34,574 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5096, ap 0.5173
2024-01-10 20:45:34,670 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4861, ap 0.4975
2024-01-10 20:45:34,755 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4516, ap 0.4958
2024-01-10 20:45:34,843 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4708, ap 0.5192
2024-01-10 20:45:34,927 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4893, ap 0.4982
2024-01-10 20:45:35,013 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5488, ap 0.5461
2024-01-10 20:45:35,110 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5384, ap 0.5488
2024-01-10 20:45:35,199 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4135, ap 0.4721
2024-01-10 20:45:35,297 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4548, ap 0.4706
2024-01-10 20:45:35,386 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5958, ap 0.5797
2024-01-10 20:45:35,479 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5773, ap 0.5638
2024-01-10 20:45:35,569 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5541, ap 0.5270
2024-01-10 20:45:35,654 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.5117, ap 0.5485
2024-01-10 20:45:35,744 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5281, ap 0.5039
2024-01-10 20:45:35,829 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4135, ap 0.4686
2024-01-10 20:45:35,910 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5498, ap 0.5454
2024-01-10 20:45:35,995 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5046, ap 0.5057
2024-01-10 20:45:36,082 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.3925, ap 0.4366
2024-01-10 20:45:36,189 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5929, ap 0.5940
2024-01-10 20:45:36,276 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4359, ap 0.4997
2024-01-10 20:45:36,361 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.6011, ap 0.6179
2024-01-10 20:45:36,453 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4822, ap 0.4928
2024-01-10 20:45:36,539 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.4676, ap 0.5010
2024-01-10 20:45:36,554 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f3031583b10>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:45:37,259 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4555, ap 0.4499
2024-01-10 20:45:37,346 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5155, ap 0.4942
2024-01-10 20:45:37,441 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5251, ap 0.5395
2024-01-10 20:45:37,526 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4726, ap 0.4802
2024-01-10 20:45:37,610 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5651, ap 0.5805
2024-01-10 20:45:37,693 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.5584, ap 0.5651
2024-01-10 20:45:37,779 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.3850, ap 0.4200
2024-01-10 20:45:37,862 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4948, ap 0.5059
2024-01-10 20:45:37,949 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.5249, ap 0.5466
2024-01-10 20:45:38,048 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4747, ap 0.4729
2024-01-10 20:45:38,140 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4939, ap 0.4981
2024-01-10 20:45:38,227 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4270, ap 0.4824
2024-01-10 20:45:38,308 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5481, ap 0.5182
2024-01-10 20:45:38,399 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5274, ap 0.5170
2024-01-10 20:45:38,483 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3396, ap 0.4176
2024-01-10 20:45:38,573 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5821, ap 0.5606
2024-01-10 20:45:38,665 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5655, ap 0.5377
2024-01-10 20:45:38,752 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5643, ap 0.5906
2024-01-10 20:45:38,839 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5299, ap 0.5124
2024-01-10 20:45:38,922 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4413, ap 0.4609
2024-01-10 20:45:39,020 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5233, ap 0.5431
2024-01-10 20:45:39,113 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4010, ap 0.4411
2024-01-10 20:45:39,212 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5044, ap 0.5038
2024-01-10 20:45:39,303 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.6073, ap 0.5540
2024-01-10 20:45:39,397 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4560, ap 0.4616
2024-01-10 20:45:39,487 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5497, ap 0.5560
2024-01-10 20:45:39,582 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4486, ap 0.5027
2024-01-10 20:45:39,671 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5388, ap 0.5393
2024-01-10 20:45:39,755 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.5491, ap 0.5396
2024-01-10 20:45:39,841 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5700, ap 0.5859
2024-01-10 20:45:39,855 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f3023f07ad0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:45:40,587 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4874, ap 0.4789
2024-01-10 20:45:40,678 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5434, ap 0.5164
2024-01-10 20:45:40,768 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5221, ap 0.5270
2024-01-10 20:45:40,856 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4763, ap 0.5283
2024-01-10 20:45:40,944 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5967, ap 0.5913
2024-01-10 20:45:41,033 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.5222, ap 0.5229
2024-01-10 20:45:41,129 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4279, ap 0.4534
2024-01-10 20:45:41,219 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4491, ap 0.4742
2024-01-10 20:45:41,308 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4343, ap 0.4785
2024-01-10 20:45:41,399 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.5016, ap 0.4899
2024-01-10 20:45:41,488 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.5482, ap 0.5561
2024-01-10 20:45:41,585 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4397, ap 0.4795
2024-01-10 20:45:41,676 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5917, ap 0.6034
2024-01-10 20:45:41,770 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5632, ap 0.5479
2024-01-10 20:45:41,864 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4530, ap 0.5112
2024-01-10 20:45:41,950 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4993, ap 0.5076
2024-01-10 20:45:42,040 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.6383, ap 0.6075
2024-01-10 20:45:42,135 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5790, ap 0.5891
2024-01-10 20:45:42,223 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5493, ap 0.5297
2024-01-10 20:45:42,316 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4297, ap 0.4566
2024-01-10 20:45:42,405 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5139, ap 0.5157
2024-01-10 20:45:42,491 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4222, ap 0.4724
2024-01-10 20:45:42,576 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5014, ap 0.5038
2024-01-10 20:45:42,665 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5107, ap 0.5305
2024-01-10 20:45:42,752 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4794, ap 0.5040
2024-01-10 20:45:42,840 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.4893, ap 0.5183
2024-01-10 20:45:42,928 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4591, ap 0.5335
2024-01-10 20:45:43,015 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5233, ap 0.5630
2024-01-10 20:45:43,116 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4920, ap 0.4979
2024-01-10 20:45:43,216 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5221, ap 0.5407
2024-01-10 20:45:43,229 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f3031864110>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 20:45:43,991 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.5283, ap 0.5207
2024-01-10 20:45:44,081 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5424, ap 0.5348
2024-01-10 20:45:44,166 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5292, ap 0.5202
2024-01-10 20:45:44,251 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4904, ap 0.5415
2024-01-10 20:45:44,345 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.6054, ap 0.6293
2024-01-10 20:45:44,432 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4806, ap 0.4746
2024-01-10 20:45:44,504 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4747, ap 0.4746
2024-01-10 20:45:44,577 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4381, ap 0.4734
2024-01-10 20:45:44,656 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4379, ap 0.4813
2024-01-10 20:45:44,731 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4471, ap 0.4886
2024-01-10 20:45:44,816 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.5265, ap 0.5489
2024-01-10 20:45:44,908 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4284, ap 0.4594
2024-01-10 20:45:44,999 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5646, ap 0.5534
2024-01-10 20:45:45,084 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5593, ap 0.5875
2024-01-10 20:45:45,177 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3549, ap 0.4301
2024-01-10 20:45:45,268 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5582, ap 0.5717
2024-01-10 20:45:45,363 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5239, ap 0.5219
2024-01-10 20:45:45,450 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5178, ap 0.5593
2024-01-10 20:45:45,543 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5358, ap 0.5312
2024-01-10 20:45:45,626 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4632, ap 0.5103
2024-01-10 20:45:45,713 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5189, ap 0.5479
2024-01-10 20:45:45,809 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4181, ap 0.4436
2024-01-10 20:45:45,895 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.4998, ap 0.5174
2024-01-10 20:45:45,984 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5607, ap 0.5675
2024-01-10 20:45:46,072 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4026, ap 0.4497
2024-01-10 20:45:46,159 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5803, ap 0.5565
2024-01-10 20:45:46,250 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.5756, ap 0.6324
2024-01-10 20:45:46,335 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5105, ap 0.5352
2024-01-10 20:45:46,433 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.5317, ap 0.5455
2024-01-10 20:45:46,520 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5837, ap 0.6316
2024-01-10 21:49:35,478 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f6cea9ce1d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:49:36,207 - GAugM EPNet train, Epoch [  1/295]: loss 0.7210, auc 0.5262, ap 0.4924
2024-01-10 21:49:36,277 - GAugM EPNet train, Epoch [  2/295]: loss 0.7210, auc 0.4569, ap 0.4651
2024-01-10 21:49:36,334 - GAugM EPNet train, Epoch [  3/295]: loss 0.7209, auc 0.6125, ap 0.5979
2024-01-10 21:49:36,390 - GAugM EPNet train, Epoch [  4/295]: loss 0.7209, auc 0.6146, ap 0.6089
2024-01-10 21:49:36,460 - GAugM EPNet train, Epoch [  5/295]: loss 0.7209, auc 0.5041, ap 0.4963
2024-01-10 21:49:36,526 - GAugM EPNet train, Epoch [  6/295]: loss 0.7209, auc 0.5703, ap 0.5219
2024-01-10 21:49:36,589 - GAugM EPNet train, Epoch [  7/295]: loss 0.7209, auc 0.4672, ap 0.4561
2024-01-10 21:49:36,656 - GAugM EPNet train, Epoch [  8/295]: loss 0.7210, auc 0.5027, ap 0.4925
2024-01-10 21:49:36,720 - GAugM EPNet train, Epoch [  9/295]: loss 0.7209, auc 0.4121, ap 0.4345
2024-01-10 21:49:36,782 - GAugM EPNet train, Epoch [ 10/295]: loss 0.7208, auc 0.4341, ap 0.4502
2024-01-10 21:49:36,847 - GAugM EPNet train, Epoch [ 11/295]: loss 0.7209, auc 0.5210, ap 0.5196
2024-01-10 21:49:36,909 - GAugM EPNet train, Epoch [ 12/295]: loss 0.7210, auc 0.4523, ap 0.4606
2024-01-10 21:49:36,977 - GAugM EPNet train, Epoch [ 13/295]: loss 0.7209, auc 0.5210, ap 0.5302
2024-01-10 21:49:37,038 - GAugM EPNet train, Epoch [ 14/295]: loss 0.7209, auc 0.5481, ap 0.5309
2024-01-10 21:49:37,100 - GAugM EPNet train, Epoch [ 15/295]: loss 0.7210, auc 0.4114, ap 0.4406
2024-01-10 21:49:37,182 - GAugM EPNet train, Epoch [ 16/295]: loss 0.7209, auc 0.5470, ap 0.5342
2024-01-10 21:49:37,276 - GAugM EPNet train, Epoch [ 17/295]: loss 0.7210, auc 0.5673, ap 0.5417
2024-01-10 21:49:37,364 - GAugM EPNet train, Epoch [ 18/295]: loss 0.7210, auc 0.5929, ap 0.5659
2024-01-10 21:49:37,453 - GAugM EPNet train, Epoch [ 19/295]: loss 0.7209, auc 0.5331, ap 0.5014
2024-01-10 21:49:37,542 - GAugM EPNet train, Epoch [ 20/295]: loss 0.7210, auc 0.5886, ap 0.5838
2024-01-10 21:49:37,630 - GAugM EPNet train, Epoch [ 21/295]: loss 0.7209, auc 0.4551, ap 0.4798
2024-01-10 21:49:37,720 - GAugM EPNet train, Epoch [ 22/295]: loss 0.7210, auc 0.3973, ap 0.4423
2024-01-10 21:49:37,805 - GAugM EPNet train, Epoch [ 23/295]: loss 0.7208, auc 0.5263, ap 0.5379
2024-01-10 21:49:37,896 - GAugM EPNet train, Epoch [ 24/295]: loss 0.7209, auc 0.5107, ap 0.5182
2024-01-10 21:49:37,982 - GAugM EPNet train, Epoch [ 25/295]: loss 0.7209, auc 0.4637, ap 0.4730
2024-01-10 21:49:38,074 - GAugM EPNet train, Epoch [ 26/295]: loss 0.7210, auc 0.5751, ap 0.5820
2024-01-10 21:49:38,163 - GAugM EPNet train, Epoch [ 27/295]: loss 0.7209, auc 0.3960, ap 0.4808
2024-01-10 21:49:38,254 - GAugM EPNet train, Epoch [ 28/295]: loss 0.7209, auc 0.6314, ap 0.6480
2024-01-10 21:49:38,341 - GAugM EPNet train, Epoch [ 29/295]: loss 0.7210, auc 0.5573, ap 0.5362
2024-01-10 21:49:38,425 - GAugM EPNet train, Epoch [ 30/295]: loss 0.7209, auc 0.4829, ap 0.4731
2024-01-10 21:49:38,508 - GAugM EPNet train, Epoch [ 31/295]: loss 0.7208, auc 0.5166, ap 0.5384
2024-01-10 21:49:38,594 - GAugM EPNet train, Epoch [ 32/295]: loss 0.7210, auc 0.5609, ap 0.5554
2024-01-10 21:49:38,682 - GAugM EPNet train, Epoch [ 33/295]: loss 0.7209, auc 0.4633, ap 0.5162
2024-01-10 21:49:38,767 - GAugM EPNet train, Epoch [ 34/295]: loss 0.7209, auc 0.4171, ap 0.4465
2024-01-10 21:49:38,849 - GAugM EPNet train, Epoch [ 35/295]: loss 0.7209, auc 0.5368, ap 0.5311
2024-01-10 21:49:38,932 - GAugM EPNet train, Epoch [ 36/295]: loss 0.7209, auc 0.6404, ap 0.6162
2024-01-10 21:49:39,018 - GAugM EPNet train, Epoch [ 37/295]: loss 0.7209, auc 0.5481, ap 0.5536
2024-01-10 21:49:39,105 - GAugM EPNet train, Epoch [ 38/295]: loss 0.7209, auc 0.4260, ap 0.4455
2024-01-10 21:49:39,187 - GAugM EPNet train, Epoch [ 39/295]: loss 0.7208, auc 0.4931, ap 0.5192
2024-01-10 21:49:39,288 - GAugM EPNet train, Epoch [ 40/295]: loss 0.7210, auc 0.5696, ap 0.5568
2024-01-10 21:49:39,379 - GAugM EPNet train, Epoch [ 41/295]: loss 0.7210, auc 0.5215, ap 0.5376
2024-01-10 21:49:39,466 - GAugM EPNet train, Epoch [ 42/295]: loss 0.7209, auc 0.5655, ap 0.5648
2024-01-10 21:49:39,552 - GAugM EPNet train, Epoch [ 43/295]: loss 0.7208, auc 0.4021, ap 0.4505
2024-01-10 21:49:39,644 - GAugM EPNet train, Epoch [ 44/295]: loss 0.7208, auc 0.4566, ap 0.4765
2024-01-10 21:49:39,730 - GAugM EPNet train, Epoch [ 45/295]: loss 0.7209, auc 0.5511, ap 0.5602
2024-01-10 21:49:39,819 - GAugM EPNet train, Epoch [ 46/295]: loss 0.7209, auc 0.4925, ap 0.5033
2024-01-10 21:49:39,900 - GAugM EPNet train, Epoch [ 47/295]: loss 0.7210, auc 0.5077, ap 0.5025
2024-01-10 21:49:39,982 - GAugM EPNet train, Epoch [ 48/295]: loss 0.7210, auc 0.6413, ap 0.6189
2024-01-10 21:49:40,062 - GAugM EPNet train, Epoch [ 49/295]: loss 0.7209, auc 0.5698, ap 0.5654
2024-01-10 21:49:40,144 - GAugM EPNet train, Epoch [ 50/295]: loss 0.7210, auc 0.4729, ap 0.4818
2024-01-10 21:49:40,226 - GAugM EPNet train, Epoch [ 51/295]: loss 0.7210, auc 0.4484, ap 0.5352
2024-01-10 21:49:40,309 - GAugM EPNet train, Epoch [ 52/295]: loss 0.7209, auc 0.4692, ap 0.5207
2024-01-10 21:49:40,388 - GAugM EPNet train, Epoch [ 53/295]: loss 0.7209, auc 0.5413, ap 0.5180
2024-01-10 21:49:40,467 - GAugM EPNet train, Epoch [ 54/295]: loss 0.7211, auc 0.5545, ap 0.5344
2024-01-10 21:49:40,547 - GAugM EPNet train, Epoch [ 55/295]: loss 0.7209, auc 0.5244, ap 0.5349
2024-01-10 21:49:40,625 - GAugM EPNet train, Epoch [ 56/295]: loss 0.7208, auc 0.5263, ap 0.5294
2024-01-10 21:49:40,704 - GAugM EPNet train, Epoch [ 57/295]: loss 0.7209, auc 0.5142, ap 0.5158
2024-01-10 21:49:40,784 - GAugM EPNet train, Epoch [ 58/295]: loss 0.7210, auc 0.5299, ap 0.5839
2024-01-10 21:49:40,866 - GAugM EPNet train, Epoch [ 59/295]: loss 0.7211, auc 0.4843, ap 0.5165
2024-01-10 21:49:40,947 - GAugM EPNet train, Epoch [ 60/295]: loss 0.7210, auc 0.4984, ap 0.5006
2024-01-10 21:49:41,030 - GAugM EPNet train, Epoch [ 61/295]: loss 0.7209, auc 0.6047, ap 0.5785
2024-01-10 21:49:41,108 - GAugM EPNet train, Epoch [ 62/295]: loss 0.7210, auc 0.5324, ap 0.5265
2024-01-10 21:49:41,188 - GAugM EPNet train, Epoch [ 63/295]: loss 0.7208, auc 0.4970, ap 0.4873
2024-01-10 21:49:41,272 - GAugM EPNet train, Epoch [ 64/295]: loss 0.7208, auc 0.4854, ap 0.4997
2024-01-10 21:49:41,377 - GAugM EPNet train, Epoch [ 65/295]: loss 0.7208, auc 0.4865, ap 0.4945
2024-01-10 21:49:41,472 - GAugM EPNet train, Epoch [ 66/295]: loss 0.7209, auc 0.5377, ap 0.5490
2024-01-10 21:49:41,570 - GAugM EPNet train, Epoch [ 67/295]: loss 0.7209, auc 0.4945, ap 0.4964
2024-01-10 21:49:41,663 - GAugM EPNet train, Epoch [ 68/295]: loss 0.7210, auc 0.4907, ap 0.5102
2024-01-10 21:49:41,750 - GAugM EPNet train, Epoch [ 69/295]: loss 0.7210, auc 0.5279, ap 0.5581
2024-01-10 21:49:41,837 - GAugM EPNet train, Epoch [ 70/295]: loss 0.7210, auc 0.4995, ap 0.4954
2024-01-10 21:49:41,937 - GAugM EPNet train, Epoch [ 71/295]: loss 0.7210, auc 0.5246, ap 0.4984
2024-01-10 21:49:42,025 - GAugM EPNet train, Epoch [ 72/295]: loss 0.7210, auc 0.5283, ap 0.5193
2024-01-10 21:49:42,108 - GAugM EPNet train, Epoch [ 73/295]: loss 0.7209, auc 0.5562, ap 0.5351
2024-01-10 21:49:42,198 - GAugM EPNet train, Epoch [ 74/295]: loss 0.7209, auc 0.5612, ap 0.5715
2024-01-10 21:49:42,287 - GAugM EPNet train, Epoch [ 75/295]: loss 0.7210, auc 0.3754, ap 0.4250
2024-01-10 21:49:42,381 - GAugM EPNet train, Epoch [ 76/295]: loss 0.7209, auc 0.4623, ap 0.4931
2024-01-10 21:49:42,465 - GAugM EPNet train, Epoch [ 77/295]: loss 0.7208, auc 0.6029, ap 0.6061
2024-01-10 21:49:42,550 - GAugM EPNet train, Epoch [ 78/295]: loss 0.7209, auc 0.4665, ap 0.4721
2024-01-10 21:49:42,635 - GAugM EPNet train, Epoch [ 79/295]: loss 0.7208, auc 0.5089, ap 0.5041
2024-01-10 21:49:42,726 - GAugM EPNet train, Epoch [ 80/295]: loss 0.7209, auc 0.5285, ap 0.5112
2024-01-10 21:49:42,816 - GAugM EPNet train, Epoch [ 81/295]: loss 0.7209, auc 0.4519, ap 0.4610
2024-01-10 21:49:42,900 - GAugM EPNet train, Epoch [ 82/295]: loss 0.7210, auc 0.5324, ap 0.5244
2024-01-10 21:49:42,984 - GAugM EPNet train, Epoch [ 83/295]: loss 0.7209, auc 0.5053, ap 0.5403
2024-01-10 21:49:43,073 - GAugM EPNet train, Epoch [ 84/295]: loss 0.7209, auc 0.4386, ap 0.4850
2024-01-10 21:49:43,160 - GAugM EPNet train, Epoch [ 85/295]: loss 0.7210, auc 0.4416, ap 0.4697
2024-01-10 21:49:43,254 - GAugM EPNet train, Epoch [ 86/295]: loss 0.7208, auc 0.5279, ap 0.5095
2024-01-10 21:49:43,341 - GAugM EPNet train, Epoch [ 87/295]: loss 0.7209, auc 0.5007, ap 0.4883
2024-01-10 21:49:43,424 - GAugM EPNet train, Epoch [ 88/295]: loss 0.7210, auc 0.4900, ap 0.5075
2024-01-10 21:49:43,507 - GAugM EPNet train, Epoch [ 89/295]: loss 0.7210, auc 0.4865, ap 0.5207
2024-01-10 21:49:43,593 - GAugM EPNet train, Epoch [ 90/295]: loss 0.7209, auc 0.4701, ap 0.4914
2024-01-10 21:49:43,681 - GAugM EPNet train, Epoch [ 91/295]: loss 0.7208, auc 0.5498, ap 0.5141
2024-01-10 21:49:43,765 - GAugM EPNet train, Epoch [ 92/295]: loss 0.7209, auc 0.6185, ap 0.5834
2024-01-10 21:49:43,847 - GAugM EPNet train, Epoch [ 93/295]: loss 0.7209, auc 0.3661, ap 0.4401
2024-01-10 21:49:43,934 - GAugM EPNet train, Epoch [ 94/295]: loss 0.7210, auc 0.4190, ap 0.4926
2024-01-10 21:49:44,026 - GAugM EPNet train, Epoch [ 95/295]: loss 0.7210, auc 0.4957, ap 0.5210
2024-01-10 21:49:44,109 - GAugM EPNet train, Epoch [ 96/295]: loss 0.7209, auc 0.5637, ap 0.5441
2024-01-10 21:49:44,194 - GAugM EPNet train, Epoch [ 97/295]: loss 0.7209, auc 0.4786, ap 0.5017
2024-01-10 21:49:44,284 - GAugM EPNet train, Epoch [ 98/295]: loss 0.7209, auc 0.4576, ap 0.4716
2024-01-10 21:49:44,380 - GAugM EPNet train, Epoch [ 99/295]: loss 0.7209, auc 0.5203, ap 0.5212
2024-01-10 21:49:44,475 - GAugM EPNet train, Epoch [100/295]: loss 0.7210, auc 0.5943, ap 0.5997
2024-01-10 21:49:44,569 - GAugM EPNet train, Epoch [101/295]: loss 0.7210, auc 0.4249, ap 0.4966
2024-01-10 21:49:44,666 - GAugM EPNet train, Epoch [102/295]: loss 0.7209, auc 0.4701, ap 0.4819
2024-01-10 21:49:44,759 - GAugM EPNet train, Epoch [103/295]: loss 0.7209, auc 0.4902, ap 0.5072
2024-01-10 21:49:44,847 - GAugM EPNet train, Epoch [104/295]: loss 0.7209, auc 0.4434, ap 0.4569
2024-01-10 21:49:44,939 - GAugM EPNet train, Epoch [105/295]: loss 0.7209, auc 0.4525, ap 0.4593
2024-01-10 21:49:45,034 - GAugM EPNet train, Epoch [106/295]: loss 0.7210, auc 0.4665, ap 0.4983
2024-01-10 21:49:45,126 - GAugM EPNet train, Epoch [107/295]: loss 0.7210, auc 0.4601, ap 0.4848
2024-01-10 21:49:45,221 - GAugM EPNet train, Epoch [108/295]: loss 0.7208, auc 0.5125, ap 0.5349
2024-01-10 21:49:45,310 - GAugM EPNet train, Epoch [109/295]: loss 0.7210, auc 0.5171, ap 0.5114
2024-01-10 21:49:45,402 - GAugM EPNet train, Epoch [110/295]: loss 0.7209, auc 0.4121, ap 0.4687
2024-01-10 21:49:45,493 - GAugM EPNet train, Epoch [111/295]: loss 0.7210, auc 0.5356, ap 0.5480
2024-01-10 21:49:45,581 - GAugM EPNet train, Epoch [112/295]: loss 0.7209, auc 0.4964, ap 0.4934
2024-01-10 21:49:45,675 - GAugM EPNet train, Epoch [113/295]: loss 0.7210, auc 0.4842, ap 0.5102
2024-01-10 21:49:45,762 - GAugM EPNet train, Epoch [114/295]: loss 0.7209, auc 0.4672, ap 0.4728
2024-01-10 21:49:45,854 - GAugM EPNet train, Epoch [115/295]: loss 0.7210, auc 0.5587, ap 0.5694
2024-01-10 21:49:45,939 - GAugM EPNet train, Epoch [116/295]: loss 0.7209, auc 0.5940, ap 0.6066
2024-01-10 21:49:46,031 - GAugM EPNet train, Epoch [117/295]: loss 0.7208, auc 0.4292, ap 0.4671
2024-01-10 21:49:46,121 - GAugM EPNet train, Epoch [118/295]: loss 0.7209, auc 0.4160, ap 0.4593
2024-01-10 21:49:46,202 - GAugM EPNet train, Epoch [119/295]: loss 0.7209, auc 0.4886, ap 0.5160
2024-01-10 21:49:46,289 - GAugM EPNet train, Epoch [120/295]: loss 0.7210, auc 0.5481, ap 0.5298
2024-01-10 21:49:46,378 - GAugM EPNet train, Epoch [121/295]: loss 0.7210, auc 0.4155, ap 0.4500
2024-01-10 21:49:46,467 - GAugM EPNet train, Epoch [122/295]: loss 0.7209, auc 0.4612, ap 0.4836
2024-01-10 21:49:46,553 - GAugM EPNet train, Epoch [123/295]: loss 0.7209, auc 0.4947, ap 0.5315
2024-01-10 21:49:46,641 - GAugM EPNet train, Epoch [124/295]: loss 0.7210, auc 0.5025, ap 0.4857
2024-01-10 21:49:46,730 - GAugM EPNet train, Epoch [125/295]: loss 0.7209, auc 0.4509, ap 0.4684
2024-01-10 21:49:46,817 - GAugM EPNet train, Epoch [126/295]: loss 0.7210, auc 0.5520, ap 0.5212
2024-01-10 21:49:46,909 - GAugM EPNet train, Epoch [127/295]: loss 0.7209, auc 0.4948, ap 0.4973
2024-01-10 21:49:46,994 - GAugM EPNet train, Epoch [128/295]: loss 0.7210, auc 0.4890, ap 0.4919
2024-01-10 21:49:47,081 - GAugM EPNet train, Epoch [129/295]: loss 0.7208, auc 0.4074, ap 0.4450
2024-01-10 21:49:47,170 - GAugM EPNet train, Epoch [130/295]: loss 0.7210, auc 0.4327, ap 0.4867
2024-01-10 21:49:47,263 - GAugM EPNet train, Epoch [131/295]: loss 0.7210, auc 0.5178, ap 0.5600
2024-01-10 21:49:47,348 - GAugM EPNet train, Epoch [132/295]: loss 0.7209, auc 0.5477, ap 0.5325
2024-01-10 21:49:47,436 - GAugM EPNet train, Epoch [133/295]: loss 0.7209, auc 0.4366, ap 0.4883
2024-01-10 21:49:47,521 - GAugM EPNet train, Epoch [134/295]: loss 0.7210, auc 0.5344, ap 0.5211
2024-01-10 21:49:47,608 - GAugM EPNet train, Epoch [135/295]: loss 0.7209, auc 0.4106, ap 0.4630
2024-01-10 21:49:47,700 - GAugM EPNet train, Epoch [136/295]: loss 0.7209, auc 0.5004, ap 0.5017
2024-01-10 21:49:47,787 - GAugM EPNet train, Epoch [137/295]: loss 0.7210, auc 0.5242, ap 0.5355
2024-01-10 21:49:47,875 - GAugM EPNet train, Epoch [138/295]: loss 0.7210, auc 0.5228, ap 0.5382
2024-01-10 21:49:47,966 - GAugM EPNet train, Epoch [139/295]: loss 0.7210, auc 0.4683, ap 0.4862
2024-01-10 21:49:48,056 - GAugM EPNet train, Epoch [140/295]: loss 0.7209, auc 0.4715, ap 0.4979
2024-01-10 21:49:48,160 - GAugM EPNet train, Epoch [141/295]: loss 0.7209, auc 0.5064, ap 0.4848
2024-01-10 21:49:48,265 - GAugM EPNet train, Epoch [142/295]: loss 0.7209, auc 0.5182, ap 0.5319
2024-01-10 21:49:48,358 - GAugM EPNet train, Epoch [143/295]: loss 0.7209, auc 0.4359, ap 0.4678
2024-01-10 21:49:48,451 - GAugM EPNet train, Epoch [144/295]: loss 0.7209, auc 0.5377, ap 0.5429
2024-01-10 21:49:48,554 - GAugM EPNet train, Epoch [145/295]: loss 0.7209, auc 0.4598, ap 0.5114
2024-01-10 21:49:48,648 - GAugM EPNet train, Epoch [146/295]: loss 0.7209, auc 0.5174, ap 0.5420
2024-01-10 21:49:48,743 - GAugM EPNet train, Epoch [147/295]: loss 0.7209, auc 0.6152, ap 0.6321
2024-01-10 21:49:48,839 - GAugM EPNet train, Epoch [148/295]: loss 0.7209, auc 0.4347, ap 0.4588
2024-01-10 21:49:48,940 - GAugM EPNet train, Epoch [149/295]: loss 0.7208, auc 0.5046, ap 0.5233
2024-01-10 21:49:49,045 - GAugM EPNet train, Epoch [150/295]: loss 0.7209, auc 0.4128, ap 0.4505
2024-01-10 21:49:49,144 - GAugM EPNet train, Epoch [151/295]: loss 0.7209, auc 0.5584, ap 0.5527
2024-01-10 21:49:49,234 - GAugM EPNet train, Epoch [152/295]: loss 0.7209, auc 0.5869, ap 0.5712
2024-01-10 21:49:49,327 - GAugM EPNet train, Epoch [153/295]: loss 0.7209, auc 0.3907, ap 0.4430
2024-01-10 21:49:49,419 - GAugM EPNet train, Epoch [154/295]: loss 0.7209, auc 0.5961, ap 0.5805
2024-01-10 21:49:49,509 - GAugM EPNet train, Epoch [155/295]: loss 0.7209, auc 0.5121, ap 0.5421
2024-01-10 21:49:49,596 - GAugM EPNet train, Epoch [156/295]: loss 0.7209, auc 0.4131, ap 0.4504
2024-01-10 21:49:49,689 - GAugM EPNet train, Epoch [157/295]: loss 0.7209, auc 0.5303, ap 0.5376
2024-01-10 21:49:49,779 - GAugM EPNet train, Epoch [158/295]: loss 0.7208, auc 0.4594, ap 0.4798
2024-01-10 21:49:49,867 - GAugM EPNet train, Epoch [159/295]: loss 0.7208, auc 0.4786, ap 0.4905
2024-01-10 21:49:49,955 - GAugM EPNet train, Epoch [160/295]: loss 0.7209, auc 0.5299, ap 0.5245
2024-01-10 21:49:50,043 - GAugM EPNet train, Epoch [161/295]: loss 0.7209, auc 0.5255, ap 0.5122
2024-01-10 21:49:50,134 - GAugM EPNet train, Epoch [162/295]: loss 0.7209, auc 0.4580, ap 0.4708
2024-01-10 21:49:50,228 - GAugM EPNet train, Epoch [163/295]: loss 0.7209, auc 0.4996, ap 0.4970
2024-01-10 21:49:50,315 - GAugM EPNet train, Epoch [164/295]: loss 0.7211, auc 0.4729, ap 0.4610
2024-01-10 21:49:50,406 - GAugM EPNet train, Epoch [165/295]: loss 0.7210, auc 0.4373, ap 0.4644
2024-01-10 21:49:50,504 - GAugM EPNet train, Epoch [166/295]: loss 0.7208, auc 0.5392, ap 0.5200
2024-01-10 21:49:50,603 - GAugM EPNet train, Epoch [167/295]: loss 0.7209, auc 0.4349, ap 0.4662
2024-01-10 21:49:50,699 - GAugM EPNet train, Epoch [168/295]: loss 0.7209, auc 0.4573, ap 0.4894
2024-01-10 21:49:50,800 - GAugM EPNet train, Epoch [169/295]: loss 0.7209, auc 0.5351, ap 0.5537
2024-01-10 21:49:50,889 - GAugM EPNet train, Epoch [170/295]: loss 0.7210, auc 0.3868, ap 0.4282
2024-01-10 21:49:50,977 - GAugM EPNet train, Epoch [171/295]: loss 0.7209, auc 0.4085, ap 0.4755
2024-01-10 21:49:51,068 - GAugM EPNet train, Epoch [172/295]: loss 0.7208, auc 0.5012, ap 0.4929
2024-01-10 21:49:51,161 - GAugM EPNet train, Epoch [173/295]: loss 0.7209, auc 0.5705, ap 0.5954
2024-01-10 21:49:51,249 - GAugM EPNet train, Epoch [174/295]: loss 0.7209, auc 0.4628, ap 0.4680
2024-01-10 21:49:51,336 - GAugM EPNet train, Epoch [175/295]: loss 0.7209, auc 0.6611, ap 0.6330
2024-01-10 21:49:51,426 - GAugM EPNet train, Epoch [176/295]: loss 0.7209, auc 0.5078, ap 0.4927
2024-01-10 21:49:51,514 - GAugM EPNet train, Epoch [177/295]: loss 0.7210, auc 0.4169, ap 0.4373
2024-01-10 21:49:51,607 - GAugM EPNet train, Epoch [178/295]: loss 0.7210, auc 0.5965, ap 0.6031
2024-01-10 21:49:51,694 - GAugM EPNet train, Epoch [179/295]: loss 0.7210, auc 0.4160, ap 0.4566
2024-01-10 21:49:51,781 - GAugM EPNet train, Epoch [180/295]: loss 0.7210, auc 0.5320, ap 0.5525
2024-01-10 21:49:51,867 - GAugM EPNet train, Epoch [181/295]: loss 0.7209, auc 0.4268, ap 0.4454
2024-01-10 21:49:51,953 - GAugM EPNet train, Epoch [182/295]: loss 0.7209, auc 0.5021, ap 0.5219
2024-01-10 21:49:52,043 - GAugM EPNet train, Epoch [183/295]: loss 0.7210, auc 0.5078, ap 0.5075
2024-01-10 21:49:52,129 - GAugM EPNet train, Epoch [184/295]: loss 0.7209, auc 0.5016, ap 0.5285
2024-01-10 21:49:52,221 - GAugM EPNet train, Epoch [185/295]: loss 0.7209, auc 0.5701, ap 0.5645
2024-01-10 21:49:52,312 - GAugM EPNet train, Epoch [186/295]: loss 0.7208, auc 0.4612, ap 0.5018
2024-01-10 21:49:52,400 - GAugM EPNet train, Epoch [187/295]: loss 0.7209, auc 0.4948, ap 0.4970
2024-01-10 21:49:52,487 - GAugM EPNet train, Epoch [188/295]: loss 0.7209, auc 0.4487, ap 0.4680
2024-01-10 21:49:52,574 - GAugM EPNet train, Epoch [189/295]: loss 0.7209, auc 0.6088, ap 0.6206
2024-01-10 21:49:52,666 - GAugM EPNet train, Epoch [190/295]: loss 0.7209, auc 0.4626, ap 0.4732
2024-01-10 21:49:52,753 - GAugM EPNet train, Epoch [191/295]: loss 0.7209, auc 0.4701, ap 0.4983
2024-01-10 21:49:52,844 - GAugM EPNet train, Epoch [192/295]: loss 0.7209, auc 0.4818, ap 0.4665
2024-01-10 21:49:52,932 - GAugM EPNet train, Epoch [193/295]: loss 0.7209, auc 0.4783, ap 0.4663
2024-01-10 21:49:53,026 - GAugM EPNet train, Epoch [194/295]: loss 0.7209, auc 0.4915, ap 0.4926
2024-01-10 21:49:53,115 - GAugM EPNet train, Epoch [195/295]: loss 0.7209, auc 0.5513, ap 0.5366
2024-01-10 21:49:53,202 - GAugM EPNet train, Epoch [196/295]: loss 0.7208, auc 0.5669, ap 0.5355
2024-01-10 21:49:53,294 - GAugM EPNet train, Epoch [197/295]: loss 0.7210, auc 0.5036, ap 0.5146
2024-01-10 21:49:53,387 - GAugM EPNet train, Epoch [198/295]: loss 0.7210, auc 0.4687, ap 0.4891
2024-01-10 21:49:53,476 - GAugM EPNet train, Epoch [199/295]: loss 0.7209, auc 0.5247, ap 0.5254
2024-01-10 21:49:53,566 - GAugM EPNet train, Epoch [200/295]: loss 0.7210, auc 0.5004, ap 0.5136
2024-01-10 21:49:53,669 - GAugM EPNet train, Epoch [201/295]: loss 0.7209, auc 0.4897, ap 0.4967
2024-01-10 21:49:53,766 - GAugM EPNet train, Epoch [202/295]: loss 0.7210, auc 0.4562, ap 0.4935
2024-01-10 21:49:53,851 - GAugM EPNet train, Epoch [203/295]: loss 0.7210, auc 0.5609, ap 0.5730
2024-01-10 21:49:53,945 - GAugM EPNet train, Epoch [204/295]: loss 0.7209, auc 0.4646, ap 0.4953
2024-01-10 21:49:54,034 - GAugM EPNet train, Epoch [205/295]: loss 0.7209, auc 0.4562, ap 0.4824
2024-01-10 21:49:54,126 - GAugM EPNet train, Epoch [206/295]: loss 0.7209, auc 0.3540, ap 0.4061
2024-01-10 21:49:54,210 - GAugM EPNet train, Epoch [207/295]: loss 0.7210, auc 0.4416, ap 0.4707
2024-01-10 21:49:54,297 - GAugM EPNet train, Epoch [208/295]: loss 0.7209, auc 0.5303, ap 0.5669
2024-01-10 21:49:54,384 - GAugM EPNet train, Epoch [209/295]: loss 0.7210, auc 0.5397, ap 0.5377
2024-01-10 21:49:54,468 - GAugM EPNet train, Epoch [210/295]: loss 0.7209, auc 0.4660, ap 0.4722
2024-01-10 21:49:54,559 - GAugM EPNet train, Epoch [211/295]: loss 0.7210, auc 0.5443, ap 0.5548
2024-01-10 21:49:54,648 - GAugM EPNet train, Epoch [212/295]: loss 0.7210, auc 0.4751, ap 0.4772
2024-01-10 21:49:54,734 - GAugM EPNet train, Epoch [213/295]: loss 0.7208, auc 0.6207, ap 0.6407
2024-01-10 21:49:54,843 - GAugM EPNet train, Epoch [214/295]: loss 0.7210, auc 0.4705, ap 0.4672
2024-01-10 21:49:54,945 - GAugM EPNet train, Epoch [215/295]: loss 0.7210, auc 0.4608, ap 0.4905
2024-01-10 21:49:55,040 - GAugM EPNet train, Epoch [216/295]: loss 0.7209, auc 0.5557, ap 0.5346
2024-01-10 21:49:55,129 - GAugM EPNet train, Epoch [217/295]: loss 0.7209, auc 0.5413, ap 0.5647
2024-01-10 21:49:55,218 - GAugM EPNet train, Epoch [218/295]: loss 0.7209, auc 0.5329, ap 0.5674
2024-01-10 21:49:55,308 - GAugM EPNet train, Epoch [219/295]: loss 0.7208, auc 0.4699, ap 0.5003
2024-01-10 21:49:55,401 - GAugM EPNet train, Epoch [220/295]: loss 0.7210, auc 0.4977, ap 0.5135
2024-01-10 21:49:55,489 - GAugM EPNet train, Epoch [221/295]: loss 0.7209, auc 0.5723, ap 0.5666
2024-01-10 21:49:55,584 - GAugM EPNet train, Epoch [222/295]: loss 0.7209, auc 0.4630, ap 0.4741
2024-01-10 21:49:55,684 - GAugM EPNet train, Epoch [223/295]: loss 0.7209, auc 0.5473, ap 0.5496
2024-01-10 21:49:55,775 - GAugM EPNet train, Epoch [224/295]: loss 0.7210, auc 0.4692, ap 0.4627
2024-01-10 21:49:55,869 - GAugM EPNet train, Epoch [225/295]: loss 0.7209, auc 0.4886, ap 0.5186
2024-01-10 21:49:55,960 - GAugM EPNet train, Epoch [226/295]: loss 0.7210, auc 0.4587, ap 0.4990
2024-01-10 21:49:56,051 - GAugM EPNet train, Epoch [227/295]: loss 0.7210, auc 0.6100, ap 0.6037
2024-01-10 21:49:56,141 - GAugM EPNet train, Epoch [228/295]: loss 0.7209, auc 0.5014, ap 0.4964
2024-01-10 21:49:56,227 - GAugM EPNet train, Epoch [229/295]: loss 0.7209, auc 0.4995, ap 0.5125
2024-01-10 21:49:56,321 - GAugM EPNet train, Epoch [230/295]: loss 0.7209, auc 0.4697, ap 0.4954
2024-01-10 21:49:56,411 - GAugM EPNet train, Epoch [231/295]: loss 0.7209, auc 0.5123, ap 0.5057
2024-01-10 21:49:56,506 - GAugM EPNet train, Epoch [232/295]: loss 0.7209, auc 0.4772, ap 0.5170
2024-01-10 21:49:56,606 - GAugM EPNet train, Epoch [233/295]: loss 0.7210, auc 0.5103, ap 0.5236
2024-01-10 21:49:56,693 - GAugM EPNet train, Epoch [234/295]: loss 0.7209, auc 0.4932, ap 0.5292
2024-01-10 21:49:56,779 - GAugM EPNet train, Epoch [235/295]: loss 0.7209, auc 0.4923, ap 0.4810
2024-01-10 21:49:56,878 - GAugM EPNet train, Epoch [236/295]: loss 0.7209, auc 0.5166, ap 0.5120
2024-01-10 21:49:56,970 - GAugM EPNet train, Epoch [237/295]: loss 0.7210, auc 0.5285, ap 0.4973
2024-01-10 21:49:57,058 - GAugM EPNet train, Epoch [238/295]: loss 0.7210, auc 0.4991, ap 0.4901
2024-01-10 21:49:57,160 - GAugM EPNet train, Epoch [239/295]: loss 0.7209, auc 0.4651, ap 0.5298
2024-01-10 21:49:57,259 - GAugM EPNet train, Epoch [240/295]: loss 0.7209, auc 0.5392, ap 0.5237
2024-01-10 21:49:57,354 - GAugM EPNet train, Epoch [241/295]: loss 0.7209, auc 0.5409, ap 0.5239
2024-01-10 21:49:57,462 - GAugM EPNet train, Epoch [242/295]: loss 0.7210, auc 0.4950, ap 0.5085
2024-01-10 21:49:57,557 - GAugM EPNet train, Epoch [243/295]: loss 0.7210, auc 0.5271, ap 0.5515
2024-01-10 21:49:57,653 - GAugM EPNet train, Epoch [244/295]: loss 0.7209, auc 0.5032, ap 0.5263
2024-01-10 21:49:57,750 - GAugM EPNet train, Epoch [245/295]: loss 0.7210, auc 0.4973, ap 0.4865
2024-01-10 21:49:57,843 - GAugM EPNet train, Epoch [246/295]: loss 0.7208, auc 0.5235, ap 0.5087
2024-01-10 21:49:57,935 - GAugM EPNet train, Epoch [247/295]: loss 0.7209, auc 0.5214, ap 0.5114
2024-01-10 21:49:58,030 - GAugM EPNet train, Epoch [248/295]: loss 0.7211, auc 0.5954, ap 0.5673
2024-01-10 21:49:58,126 - GAugM EPNet train, Epoch [249/295]: loss 0.7209, auc 0.4705, ap 0.4858
2024-01-10 21:49:58,226 - GAugM EPNet train, Epoch [250/295]: loss 0.7208, auc 0.5360, ap 0.5217
2024-01-10 21:49:58,330 - GAugM EPNet train, Epoch [251/295]: loss 0.7209, auc 0.5150, ap 0.5203
2024-01-10 21:49:58,425 - GAugM EPNet train, Epoch [252/295]: loss 0.7210, auc 0.5438, ap 0.5455
2024-01-10 21:49:58,523 - GAugM EPNet train, Epoch [253/295]: loss 0.7209, auc 0.6257, ap 0.5852
2024-01-10 21:49:58,618 - GAugM EPNet train, Epoch [254/295]: loss 0.7210, auc 0.4925, ap 0.5223
2024-01-10 21:49:58,710 - GAugM EPNet train, Epoch [255/295]: loss 0.7209, auc 0.4744, ap 0.4975
2024-01-10 21:49:58,802 - GAugM EPNet train, Epoch [256/295]: loss 0.7210, auc 0.3665, ap 0.4617
2024-01-10 21:49:58,905 - GAugM EPNet train, Epoch [257/295]: loss 0.7210, auc 0.5292, ap 0.5313
2024-01-10 21:49:58,994 - GAugM EPNet train, Epoch [258/295]: loss 0.7208, auc 0.5050, ap 0.5345
2024-01-10 21:49:59,096 - GAugM EPNet train, Epoch [259/295]: loss 0.7208, auc 0.6000, ap 0.5459
2024-01-10 21:49:59,196 - GAugM EPNet train, Epoch [260/295]: loss 0.7210, auc 0.5577, ap 0.5476
2024-01-10 21:49:59,287 - GAugM EPNet train, Epoch [261/295]: loss 0.7209, auc 0.4434, ap 0.4824
2024-01-10 21:49:59,382 - GAugM EPNet train, Epoch [262/295]: loss 0.7208, auc 0.4808, ap 0.5075
2024-01-10 21:49:59,473 - GAugM EPNet train, Epoch [263/295]: loss 0.7209, auc 0.5372, ap 0.5595
2024-01-10 21:49:59,562 - GAugM EPNet train, Epoch [264/295]: loss 0.7210, auc 0.5231, ap 0.5115
2024-01-10 21:49:59,654 - GAugM EPNet train, Epoch [265/295]: loss 0.7209, auc 0.5555, ap 0.6028
2024-01-10 21:49:59,754 - GAugM EPNet train, Epoch [266/295]: loss 0.7209, auc 0.4993, ap 0.4779
2024-01-10 21:49:59,848 - GAugM EPNet train, Epoch [267/295]: loss 0.7210, auc 0.4416, ap 0.4616
2024-01-10 21:49:59,944 - GAugM EPNet train, Epoch [268/295]: loss 0.7210, auc 0.4845, ap 0.5084
2024-01-10 21:50:00,037 - GAugM EPNet train, Epoch [269/295]: loss 0.7209, auc 0.5169, ap 0.5319
2024-01-10 21:50:00,126 - GAugM EPNet train, Epoch [270/295]: loss 0.7210, auc 0.4288, ap 0.4508
2024-01-10 21:50:00,218 - GAugM EPNet train, Epoch [271/295]: loss 0.7209, auc 0.4863, ap 0.4957
2024-01-10 21:50:00,312 - GAugM EPNet train, Epoch [272/295]: loss 0.7209, auc 0.5609, ap 0.5699
2024-01-10 21:50:00,413 - GAugM EPNet train, Epoch [273/295]: loss 0.7209, auc 0.4936, ap 0.4988
2024-01-10 21:50:00,504 - GAugM EPNet train, Epoch [274/295]: loss 0.7209, auc 0.5498, ap 0.5360
2024-01-10 21:50:00,592 - GAugM EPNet train, Epoch [275/295]: loss 0.7208, auc 0.3998, ap 0.4533
2024-01-10 21:50:00,685 - GAugM EPNet train, Epoch [276/295]: loss 0.7210, auc 0.5384, ap 0.5525
2024-01-10 21:50:00,781 - GAugM EPNet train, Epoch [277/295]: loss 0.7208, auc 0.4854, ap 0.5490
2024-01-10 21:50:00,872 - GAugM EPNet train, Epoch [278/295]: loss 0.7209, auc 0.5835, ap 0.5788
2024-01-10 21:50:00,971 - GAugM EPNet train, Epoch [279/295]: loss 0.7209, auc 0.5669, ap 0.5422
2024-01-10 21:50:01,064 - GAugM EPNet train, Epoch [280/295]: loss 0.7209, auc 0.3510, ap 0.4118
2024-01-10 21:50:01,153 - GAugM EPNet train, Epoch [281/295]: loss 0.7209, auc 0.5947, ap 0.5840
2024-01-10 21:50:01,252 - GAugM EPNet train, Epoch [282/295]: loss 0.7209, auc 0.5349, ap 0.5292
2024-01-10 21:50:01,342 - GAugM EPNet train, Epoch [283/295]: loss 0.7209, auc 0.5132, ap 0.5168
2024-01-10 21:50:01,433 - GAugM EPNet train, Epoch [284/295]: loss 0.7209, auc 0.4890, ap 0.5018
2024-01-10 21:50:01,527 - GAugM EPNet train, Epoch [285/295]: loss 0.7209, auc 0.4897, ap 0.4891
2024-01-10 21:50:01,617 - GAugM EPNet train, Epoch [286/295]: loss 0.7209, auc 0.4671, ap 0.5066
2024-01-10 21:50:01,714 - GAugM EPNet train, Epoch [287/295]: loss 0.7209, auc 0.5121, ap 0.5303
2024-01-10 21:50:01,805 - GAugM EPNet train, Epoch [288/295]: loss 0.7210, auc 0.5541, ap 0.5822
2024-01-10 21:50:01,894 - GAugM EPNet train, Epoch [289/295]: loss 0.7209, auc 0.4728, ap 0.5268
2024-01-10 21:50:01,985 - GAugM EPNet train, Epoch [290/295]: loss 0.7210, auc 0.5698, ap 0.5487
2024-01-10 21:50:02,080 - GAugM EPNet train, Epoch [291/295]: loss 0.7210, auc 0.4655, ap 0.4885
2024-01-10 21:50:02,167 - GAugM EPNet train, Epoch [292/295]: loss 0.7209, auc 0.4761, ap 0.4695
2024-01-10 21:50:02,256 - GAugM EPNet train, Epoch [293/295]: loss 0.7210, auc 0.5447, ap 0.5259
2024-01-10 21:50:02,343 - GAugM EPNet train, Epoch [294/295]: loss 0.7211, auc 0.5224, ap 0.5363
2024-01-10 21:50:02,433 - GAugM EPNet train, Epoch [295/295]: loss 0.7209, auc 0.5002, ap 0.4940
2024-01-10 21:50:02,435 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f6ceaa55b50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:50:03,176 - GAugM EPNet train, Epoch [  1/295]: loss 0.7210, auc 0.4614, ap 0.4681
2024-01-10 21:50:03,274 - GAugM EPNet train, Epoch [  2/295]: loss 0.7210, auc 0.4352, ap 0.4476
2024-01-10 21:50:03,365 - GAugM EPNet train, Epoch [  3/295]: loss 0.7209, auc 0.5810, ap 0.5522
2024-01-10 21:50:03,462 - GAugM EPNet train, Epoch [  4/295]: loss 0.7209, auc 0.4511, ap 0.4551
2024-01-10 21:50:03,559 - GAugM EPNet train, Epoch [  5/295]: loss 0.7209, auc 0.5646, ap 0.5565
2024-01-10 21:50:03,651 - GAugM EPNet train, Epoch [  6/295]: loss 0.7209, auc 0.4891, ap 0.4931
2024-01-10 21:50:03,745 - GAugM EPNet train, Epoch [  7/295]: loss 0.7209, auc 0.4407, ap 0.4546
2024-01-10 21:50:03,835 - GAugM EPNet train, Epoch [  8/295]: loss 0.7210, auc 0.5482, ap 0.5295
2024-01-10 21:50:03,927 - GAugM EPNet train, Epoch [  9/295]: loss 0.7209, auc 0.4507, ap 0.4821
2024-01-10 21:50:04,031 - GAugM EPNet train, Epoch [ 10/295]: loss 0.7208, auc 0.5324, ap 0.5205
2024-01-10 21:50:04,127 - GAugM EPNet train, Epoch [ 11/295]: loss 0.7209, auc 0.4610, ap 0.4621
2024-01-10 21:50:04,221 - GAugM EPNet train, Epoch [ 12/295]: loss 0.7210, auc 0.5212, ap 0.5320
2024-01-10 21:50:04,307 - GAugM EPNet train, Epoch [ 13/295]: loss 0.7209, auc 0.6120, ap 0.6179
2024-01-10 21:50:04,397 - GAugM EPNet train, Epoch [ 14/295]: loss 0.7209, auc 0.5105, ap 0.5101
2024-01-10 21:50:04,488 - GAugM EPNet train, Epoch [ 15/295]: loss 0.7210, auc 0.3964, ap 0.4596
2024-01-10 21:50:04,577 - GAugM EPNet train, Epoch [ 16/295]: loss 0.7209, auc 0.5294, ap 0.5242
2024-01-10 21:50:04,666 - GAugM EPNet train, Epoch [ 17/295]: loss 0.7210, auc 0.5069, ap 0.4986
2024-01-10 21:50:04,758 - GAugM EPNet train, Epoch [ 18/295]: loss 0.7210, auc 0.5927, ap 0.5695
2024-01-10 21:50:04,855 - GAugM EPNet train, Epoch [ 19/295]: loss 0.7209, auc 0.4993, ap 0.4897
2024-01-10 21:50:04,945 - GAugM EPNet train, Epoch [ 20/295]: loss 0.7210, auc 0.5397, ap 0.5419
2024-01-10 21:50:05,035 - GAugM EPNet train, Epoch [ 21/295]: loss 0.7209, auc 0.5233, ap 0.5207
2024-01-10 21:50:05,130 - GAugM EPNet train, Epoch [ 22/295]: loss 0.7210, auc 0.4005, ap 0.4396
2024-01-10 21:50:05,223 - GAugM EPNet train, Epoch [ 23/295]: loss 0.7208, auc 0.4644, ap 0.4691
2024-01-10 21:50:05,314 - GAugM EPNet train, Epoch [ 24/295]: loss 0.7209, auc 0.5372, ap 0.5296
2024-01-10 21:50:05,406 - GAugM EPNet train, Epoch [ 25/295]: loss 0.7209, auc 0.4874, ap 0.4970
2024-01-10 21:50:05,502 - GAugM EPNet train, Epoch [ 26/295]: loss 0.7210, auc 0.4664, ap 0.4749
2024-01-10 21:50:05,599 - GAugM EPNet train, Epoch [ 27/295]: loss 0.7209, auc 0.4532, ap 0.5070
2024-01-10 21:50:05,691 - GAugM EPNet train, Epoch [ 28/295]: loss 0.7209, auc 0.5422, ap 0.5454
2024-01-10 21:50:05,779 - GAugM EPNet train, Epoch [ 29/295]: loss 0.7210, auc 0.5087, ap 0.5257
2024-01-10 21:50:05,870 - GAugM EPNet train, Epoch [ 30/295]: loss 0.7209, auc 0.5251, ap 0.5649
2024-01-10 21:50:05,970 - GAugM EPNet train, Epoch [ 31/295]: loss 0.7208, auc 0.5274, ap 0.5331
2024-01-10 21:50:06,066 - GAugM EPNet train, Epoch [ 32/295]: loss 0.7210, auc 0.5591, ap 0.5419
2024-01-10 21:50:06,154 - GAugM EPNet train, Epoch [ 33/295]: loss 0.7209, auc 0.4863, ap 0.4788
2024-01-10 21:50:06,250 - GAugM EPNet train, Epoch [ 34/295]: loss 0.7209, auc 0.4795, ap 0.4972
2024-01-10 21:50:06,340 - GAugM EPNet train, Epoch [ 35/295]: loss 0.7209, auc 0.5472, ap 0.5241
2024-01-10 21:50:06,428 - GAugM EPNet train, Epoch [ 36/295]: loss 0.7209, auc 0.6057, ap 0.5953
2024-01-10 21:50:06,526 - GAugM EPNet train, Epoch [ 37/295]: loss 0.7209, auc 0.4831, ap 0.4945
2024-01-10 21:50:06,618 - GAugM EPNet train, Epoch [ 38/295]: loss 0.7209, auc 0.4436, ap 0.4502
2024-01-10 21:50:06,720 - GAugM EPNet train, Epoch [ 39/295]: loss 0.7208, auc 0.4553, ap 0.4822
2024-01-10 21:50:06,819 - GAugM EPNet train, Epoch [ 40/295]: loss 0.7210, auc 0.6182, ap 0.5662
2024-01-10 21:50:06,911 - GAugM EPNet train, Epoch [ 41/295]: loss 0.7210, auc 0.5267, ap 0.5278
2024-01-10 21:50:07,000 - GAugM EPNet train, Epoch [ 42/295]: loss 0.7209, auc 0.4596, ap 0.5082
2024-01-10 21:50:07,091 - GAugM EPNet train, Epoch [ 43/295]: loss 0.7208, auc 0.4265, ap 0.4572
2024-01-10 21:50:07,190 - GAugM EPNet train, Epoch [ 44/295]: loss 0.7208, auc 0.4261, ap 0.4752
2024-01-10 21:50:07,283 - GAugM EPNet train, Epoch [ 45/295]: loss 0.7209, auc 0.5064, ap 0.5197
2024-01-10 21:50:07,385 - GAugM EPNet train, Epoch [ 46/295]: loss 0.7209, auc 0.4144, ap 0.4635
2024-01-10 21:50:07,484 - GAugM EPNet train, Epoch [ 47/295]: loss 0.7210, auc 0.4776, ap 0.4809
2024-01-10 21:50:07,579 - GAugM EPNet train, Epoch [ 48/295]: loss 0.7210, auc 0.6157, ap 0.6050
2024-01-10 21:50:07,669 - GAugM EPNet train, Epoch [ 49/295]: loss 0.7209, auc 0.5190, ap 0.5306
2024-01-10 21:50:07,764 - GAugM EPNet train, Epoch [ 50/295]: loss 0.7210, auc 0.6020, ap 0.5616
2024-01-10 21:50:07,856 - GAugM EPNet train, Epoch [ 51/295]: loss 0.7210, auc 0.5169, ap 0.5209
2024-01-10 21:50:07,951 - GAugM EPNet train, Epoch [ 52/295]: loss 0.7209, auc 0.3905, ap 0.4255
2024-01-10 21:50:08,046 - GAugM EPNet train, Epoch [ 53/295]: loss 0.7209, auc 0.4984, ap 0.5076
2024-01-10 21:50:08,137 - GAugM EPNet train, Epoch [ 54/295]: loss 0.7211, auc 0.5837, ap 0.5615
2024-01-10 21:50:08,232 - GAugM EPNet train, Epoch [ 55/295]: loss 0.7209, auc 0.5888, ap 0.5892
2024-01-10 21:50:08,330 - GAugM EPNet train, Epoch [ 56/295]: loss 0.7208, auc 0.5422, ap 0.5105
2024-01-10 21:50:08,439 - GAugM EPNet train, Epoch [ 57/295]: loss 0.7209, auc 0.5028, ap 0.5104
2024-01-10 21:50:08,534 - GAugM EPNet train, Epoch [ 58/295]: loss 0.7210, auc 0.5064, ap 0.5325
2024-01-10 21:50:08,623 - GAugM EPNet train, Epoch [ 59/295]: loss 0.7211, auc 0.5078, ap 0.4838
2024-01-10 21:50:08,715 - GAugM EPNet train, Epoch [ 60/295]: loss 0.7210, auc 0.5418, ap 0.5380
2024-01-10 21:50:08,810 - GAugM EPNet train, Epoch [ 61/295]: loss 0.7209, auc 0.4956, ap 0.4845
2024-01-10 21:50:08,902 - GAugM EPNet train, Epoch [ 62/295]: loss 0.7210, auc 0.5363, ap 0.5749
2024-01-10 21:50:08,993 - GAugM EPNet train, Epoch [ 63/295]: loss 0.7208, auc 0.3797, ap 0.4224
2024-01-10 21:50:09,086 - GAugM EPNet train, Epoch [ 64/295]: loss 0.7208, auc 0.4135, ap 0.4662
2024-01-10 21:50:09,183 - GAugM EPNet train, Epoch [ 65/295]: loss 0.7208, auc 0.5792, ap 0.5697
2024-01-10 21:50:09,279 - GAugM EPNet train, Epoch [ 66/295]: loss 0.7209, auc 0.4553, ap 0.5111
2024-01-10 21:50:09,369 - GAugM EPNet train, Epoch [ 67/295]: loss 0.7209, auc 0.5361, ap 0.5113
2024-01-10 21:50:09,466 - GAugM EPNet train, Epoch [ 68/295]: loss 0.7210, auc 0.5379, ap 0.5356
2024-01-10 21:50:09,559 - GAugM EPNet train, Epoch [ 69/295]: loss 0.7210, auc 0.4913, ap 0.5220
2024-01-10 21:50:09,647 - GAugM EPNet train, Epoch [ 70/295]: loss 0.7210, auc 0.4009, ap 0.4294
2024-01-10 21:50:09,735 - GAugM EPNet train, Epoch [ 71/295]: loss 0.7210, auc 0.6056, ap 0.5650
2024-01-10 21:50:09,824 - GAugM EPNet train, Epoch [ 72/295]: loss 0.7210, auc 0.3959, ap 0.4224
2024-01-10 21:50:09,911 - GAugM EPNet train, Epoch [ 73/295]: loss 0.7209, auc 0.4952, ap 0.4946
2024-01-10 21:50:10,003 - GAugM EPNet train, Epoch [ 74/295]: loss 0.7209, auc 0.5221, ap 0.5207
2024-01-10 21:50:10,091 - GAugM EPNet train, Epoch [ 75/295]: loss 0.7210, auc 0.4765, ap 0.5179
2024-01-10 21:50:10,194 - GAugM EPNet train, Epoch [ 76/295]: loss 0.7209, auc 0.4785, ap 0.4692
2024-01-10 21:50:10,282 - GAugM EPNet train, Epoch [ 77/295]: loss 0.7208, auc 0.5545, ap 0.5599
2024-01-10 21:50:10,374 - GAugM EPNet train, Epoch [ 78/295]: loss 0.7209, auc 0.5171, ap 0.5308
2024-01-10 21:50:10,462 - GAugM EPNet train, Epoch [ 79/295]: loss 0.7208, auc 0.4651, ap 0.4625
2024-01-10 21:50:10,554 - GAugM EPNet train, Epoch [ 80/295]: loss 0.7209, auc 0.5619, ap 0.5400
2024-01-10 21:50:10,642 - GAugM EPNet train, Epoch [ 81/295]: loss 0.7209, auc 0.5239, ap 0.4895
2024-01-10 21:50:10,735 - GAugM EPNet train, Epoch [ 82/295]: loss 0.7210, auc 0.5545, ap 0.5360
2024-01-10 21:50:10,824 - GAugM EPNet train, Epoch [ 83/295]: loss 0.7209, auc 0.4288, ap 0.4626
2024-01-10 21:50:10,920 - GAugM EPNet train, Epoch [ 84/295]: loss 0.7209, auc 0.3971, ap 0.4643
2024-01-10 21:50:11,015 - GAugM EPNet train, Epoch [ 85/295]: loss 0.7210, auc 0.4324, ap 0.4451
2024-01-10 21:50:11,102 - GAugM EPNet train, Epoch [ 86/295]: loss 0.7208, auc 0.5123, ap 0.4915
2024-01-10 21:50:11,199 - GAugM EPNet train, Epoch [ 87/295]: loss 0.7209, auc 0.5489, ap 0.5318
2024-01-10 21:50:11,288 - GAugM EPNet train, Epoch [ 88/295]: loss 0.7210, auc 0.4875, ap 0.5308
2024-01-10 21:50:11,384 - GAugM EPNet train, Epoch [ 89/295]: loss 0.7210, auc 0.5132, ap 0.5426
2024-01-10 21:50:11,472 - GAugM EPNet train, Epoch [ 90/295]: loss 0.7209, auc 0.4804, ap 0.4977
2024-01-10 21:50:11,559 - GAugM EPNet train, Epoch [ 91/295]: loss 0.7208, auc 0.5402, ap 0.4998
2024-01-10 21:50:11,646 - GAugM EPNet train, Epoch [ 92/295]: loss 0.7209, auc 0.6787, ap 0.6416
2024-01-10 21:50:11,741 - GAugM EPNet train, Epoch [ 93/295]: loss 0.7209, auc 0.3606, ap 0.4071
2024-01-10 21:50:11,827 - GAugM EPNet train, Epoch [ 94/295]: loss 0.7210, auc 0.4055, ap 0.4339
2024-01-10 21:50:11,918 - GAugM EPNet train, Epoch [ 95/295]: loss 0.7210, auc 0.5249, ap 0.5323
2024-01-10 21:50:12,006 - GAugM EPNet train, Epoch [ 96/295]: loss 0.7209, auc 0.5477, ap 0.5251
2024-01-10 21:50:12,093 - GAugM EPNet train, Epoch [ 97/295]: loss 0.7209, auc 0.4190, ap 0.4796
2024-01-10 21:50:12,181 - GAugM EPNet train, Epoch [ 98/295]: loss 0.7209, auc 0.4628, ap 0.4809
2024-01-10 21:50:12,274 - GAugM EPNet train, Epoch [ 99/295]: loss 0.7209, auc 0.4806, ap 0.4938
2024-01-10 21:50:12,365 - GAugM EPNet train, Epoch [100/295]: loss 0.7210, auc 0.4959, ap 0.5141
2024-01-10 21:50:12,458 - GAugM EPNet train, Epoch [101/295]: loss 0.7210, auc 0.4388, ap 0.5078
2024-01-10 21:50:12,554 - GAugM EPNet train, Epoch [102/295]: loss 0.7209, auc 0.4735, ap 0.4763
2024-01-10 21:50:12,642 - GAugM EPNet train, Epoch [103/295]: loss 0.7209, auc 0.4553, ap 0.5099
2024-01-10 21:50:12,731 - GAugM EPNet train, Epoch [104/295]: loss 0.7209, auc 0.4076, ap 0.4432
2024-01-10 21:50:12,821 - GAugM EPNet train, Epoch [105/295]: loss 0.7209, auc 0.4309, ap 0.4458
2024-01-10 21:50:12,912 - GAugM EPNet train, Epoch [106/295]: loss 0.7210, auc 0.4820, ap 0.4727
2024-01-10 21:50:13,007 - GAugM EPNet train, Epoch [107/295]: loss 0.7210, auc 0.4617, ap 0.5098
2024-01-10 21:50:13,095 - GAugM EPNet train, Epoch [108/295]: loss 0.7208, auc 0.5781, ap 0.5735
2024-01-10 21:50:13,184 - GAugM EPNet train, Epoch [109/295]: loss 0.7210, auc 0.4258, ap 0.4752
2024-01-10 21:50:13,273 - GAugM EPNet train, Epoch [110/295]: loss 0.7209, auc 0.4580, ap 0.4603
2024-01-10 21:50:13,365 - GAugM EPNet train, Epoch [111/295]: loss 0.7210, auc 0.5057, ap 0.5287
2024-01-10 21:50:13,453 - GAugM EPNet train, Epoch [112/295]: loss 0.7209, auc 0.5465, ap 0.5545
2024-01-10 21:50:13,542 - GAugM EPNet train, Epoch [113/295]: loss 0.7210, auc 0.4085, ap 0.4426
2024-01-10 21:50:13,639 - GAugM EPNet train, Epoch [114/295]: loss 0.7209, auc 0.4430, ap 0.4583
2024-01-10 21:50:13,727 - GAugM EPNet train, Epoch [115/295]: loss 0.7210, auc 0.4856, ap 0.4793
2024-01-10 21:50:13,821 - GAugM EPNet train, Epoch [116/295]: loss 0.7209, auc 0.4774, ap 0.4959
2024-01-10 21:50:13,909 - GAugM EPNet train, Epoch [117/295]: loss 0.7208, auc 0.4227, ap 0.4510
2024-01-10 21:50:14,009 - GAugM EPNet train, Epoch [118/295]: loss 0.7209, auc 0.4733, ap 0.5057
2024-01-10 21:50:14,105 - GAugM EPNet train, Epoch [119/295]: loss 0.7209, auc 0.5053, ap 0.5336
2024-01-10 21:50:14,205 - GAugM EPNet train, Epoch [120/295]: loss 0.7210, auc 0.4098, ap 0.4288
2024-01-10 21:50:14,296 - GAugM EPNet train, Epoch [121/295]: loss 0.7210, auc 0.4521, ap 0.4609
2024-01-10 21:50:14,388 - GAugM EPNet train, Epoch [122/295]: loss 0.7209, auc 0.4813, ap 0.5149
2024-01-10 21:50:14,480 - GAugM EPNet train, Epoch [123/295]: loss 0.7209, auc 0.4858, ap 0.5097
2024-01-10 21:50:14,576 - GAugM EPNet train, Epoch [124/295]: loss 0.7210, auc 0.4432, ap 0.4493
2024-01-10 21:50:14,669 - GAugM EPNet train, Epoch [125/295]: loss 0.7209, auc 0.5340, ap 0.5215
2024-01-10 21:50:14,765 - GAugM EPNet train, Epoch [126/295]: loss 0.7210, auc 0.5602, ap 0.5650
2024-01-10 21:50:14,855 - GAugM EPNet train, Epoch [127/295]: loss 0.7209, auc 0.5445, ap 0.5243
2024-01-10 21:50:14,946 - GAugM EPNet train, Epoch [128/295]: loss 0.7210, auc 0.4827, ap 0.4790
2024-01-10 21:50:15,042 - GAugM EPNet train, Epoch [129/295]: loss 0.7208, auc 0.4439, ap 0.4567
2024-01-10 21:50:15,138 - GAugM EPNet train, Epoch [130/295]: loss 0.7210, auc 0.4236, ap 0.4565
2024-01-10 21:50:15,229 - GAugM EPNet train, Epoch [131/295]: loss 0.7210, auc 0.5589, ap 0.5540
2024-01-10 21:50:15,319 - GAugM EPNet train, Epoch [132/295]: loss 0.7209, auc 0.5322, ap 0.5305
2024-01-10 21:50:15,413 - GAugM EPNet train, Epoch [133/295]: loss 0.7209, auc 0.4660, ap 0.5290
2024-01-10 21:50:15,502 - GAugM EPNet train, Epoch [134/295]: loss 0.7210, auc 0.5516, ap 0.5643
2024-01-10 21:50:15,606 - GAugM EPNet train, Epoch [135/295]: loss 0.7209, auc 0.3902, ap 0.4387
2024-01-10 21:50:15,699 - GAugM EPNet train, Epoch [136/295]: loss 0.7209, auc 0.5109, ap 0.5005
2024-01-10 21:50:15,793 - GAugM EPNet train, Epoch [137/295]: loss 0.7210, auc 0.4179, ap 0.4406
2024-01-10 21:50:15,884 - GAugM EPNet train, Epoch [138/295]: loss 0.7210, auc 0.5397, ap 0.5224
2024-01-10 21:50:15,971 - GAugM EPNet train, Epoch [139/295]: loss 0.7210, auc 0.4728, ap 0.4933
2024-01-10 21:50:16,061 - GAugM EPNet train, Epoch [140/295]: loss 0.7209, auc 0.4660, ap 0.5187
2024-01-10 21:50:16,156 - GAugM EPNet train, Epoch [141/295]: loss 0.7209, auc 0.5267, ap 0.5031
2024-01-10 21:50:16,258 - GAugM EPNet train, Epoch [142/295]: loss 0.7209, auc 0.4941, ap 0.5168
2024-01-10 21:50:16,348 - GAugM EPNet train, Epoch [143/295]: loss 0.7209, auc 0.4459, ap 0.4597
2024-01-10 21:50:16,436 - GAugM EPNet train, Epoch [144/295]: loss 0.7209, auc 0.4689, ap 0.4949
2024-01-10 21:50:16,530 - GAugM EPNet train, Epoch [145/295]: loss 0.7209, auc 0.4452, ap 0.4768
2024-01-10 21:50:16,622 - GAugM EPNet train, Epoch [146/295]: loss 0.7209, auc 0.5995, ap 0.5844
2024-01-10 21:50:16,711 - GAugM EPNet train, Epoch [147/295]: loss 0.7209, auc 0.6063, ap 0.6305
2024-01-10 21:50:16,800 - GAugM EPNet train, Epoch [148/295]: loss 0.7209, auc 0.4681, ap 0.4923
2024-01-10 21:50:16,888 - GAugM EPNet train, Epoch [149/295]: loss 0.7208, auc 0.5415, ap 0.5256
2024-01-10 21:50:16,980 - GAugM EPNet train, Epoch [150/295]: loss 0.7209, auc 0.5080, ap 0.4971
2024-01-10 21:50:17,072 - GAugM EPNet train, Epoch [151/295]: loss 0.7209, auc 0.4867, ap 0.4791
2024-01-10 21:50:17,162 - GAugM EPNet train, Epoch [152/295]: loss 0.7209, auc 0.5034, ap 0.4808
2024-01-10 21:50:17,249 - GAugM EPNet train, Epoch [153/295]: loss 0.7209, auc 0.4872, ap 0.5223
2024-01-10 21:50:17,338 - GAugM EPNet train, Epoch [154/295]: loss 0.7209, auc 0.5703, ap 0.5997
2024-01-10 21:50:17,430 - GAugM EPNet train, Epoch [155/295]: loss 0.7209, auc 0.5260, ap 0.5110
2024-01-10 21:50:17,530 - GAugM EPNet train, Epoch [156/295]: loss 0.7209, auc 0.5046, ap 0.5168
2024-01-10 21:50:17,646 - GAugM EPNet train, Epoch [157/295]: loss 0.7209, auc 0.5185, ap 0.5041
2024-01-10 21:50:17,742 - GAugM EPNet train, Epoch [158/295]: loss 0.7208, auc 0.4322, ap 0.4609
2024-01-10 21:50:17,841 - GAugM EPNet train, Epoch [159/295]: loss 0.7208, auc 0.5091, ap 0.4995
2024-01-10 21:50:17,941 - GAugM EPNet train, Epoch [160/295]: loss 0.7209, auc 0.4996, ap 0.5234
2024-01-10 21:50:18,034 - GAugM EPNet train, Epoch [161/295]: loss 0.7209, auc 0.4311, ap 0.4672
2024-01-10 21:50:18,138 - GAugM EPNet train, Epoch [162/295]: loss 0.7209, auc 0.4105, ap 0.4367
2024-01-10 21:50:18,235 - GAugM EPNet train, Epoch [163/295]: loss 0.7209, auc 0.4096, ap 0.4357
2024-01-10 21:50:18,335 - GAugM EPNet train, Epoch [164/295]: loss 0.7211, auc 0.4868, ap 0.4778
2024-01-10 21:50:18,430 - GAugM EPNet train, Epoch [165/295]: loss 0.7210, auc 0.4511, ap 0.4807
2024-01-10 21:50:18,528 - GAugM EPNet train, Epoch [166/295]: loss 0.7208, auc 0.6095, ap 0.5954
2024-01-10 21:50:18,612 - GAugM EPNet train, Epoch [167/295]: loss 0.7209, auc 0.4397, ap 0.4702
2024-01-10 21:50:18,699 - GAugM EPNet train, Epoch [168/295]: loss 0.7209, auc 0.4938, ap 0.5422
2024-01-10 21:50:18,790 - GAugM EPNet train, Epoch [169/295]: loss 0.7209, auc 0.5933, ap 0.5899
2024-01-10 21:50:18,882 - GAugM EPNet train, Epoch [170/295]: loss 0.7210, auc 0.5522, ap 0.5184
2024-01-10 21:50:18,981 - GAugM EPNet train, Epoch [171/295]: loss 0.7209, auc 0.5037, ap 0.5193
2024-01-10 21:50:19,072 - GAugM EPNet train, Epoch [172/295]: loss 0.7208, auc 0.4261, ap 0.4538
2024-01-10 21:50:19,158 - GAugM EPNet train, Epoch [173/295]: loss 0.7209, auc 0.5796, ap 0.5736
2024-01-10 21:50:19,253 - GAugM EPNet train, Epoch [174/295]: loss 0.7209, auc 0.4308, ap 0.4501
2024-01-10 21:50:19,357 - GAugM EPNet train, Epoch [175/295]: loss 0.7209, auc 0.6413, ap 0.6076
2024-01-10 21:50:19,453 - GAugM EPNet train, Epoch [176/295]: loss 0.7209, auc 0.5313, ap 0.5057
2024-01-10 21:50:19,551 - GAugM EPNet train, Epoch [177/295]: loss 0.7210, auc 0.4973, ap 0.4839
2024-01-10 21:50:19,648 - GAugM EPNet train, Epoch [178/295]: loss 0.7210, auc 0.5484, ap 0.5291
2024-01-10 21:50:19,753 - GAugM EPNet train, Epoch [179/295]: loss 0.7210, auc 0.4030, ap 0.4550
2024-01-10 21:50:19,848 - GAugM EPNet train, Epoch [180/295]: loss 0.7210, auc 0.5676, ap 0.5987
2024-01-10 21:50:19,949 - GAugM EPNet train, Epoch [181/295]: loss 0.7209, auc 0.5077, ap 0.4893
2024-01-10 21:50:20,042 - GAugM EPNet train, Epoch [182/295]: loss 0.7209, auc 0.4836, ap 0.5013
2024-01-10 21:50:20,142 - GAugM EPNet train, Epoch [183/295]: loss 0.7210, auc 0.5400, ap 0.5452
2024-01-10 21:50:20,239 - GAugM EPNet train, Epoch [184/295]: loss 0.7209, auc 0.4991, ap 0.5181
2024-01-10 21:50:20,338 - GAugM EPNet train, Epoch [185/295]: loss 0.7209, auc 0.4559, ap 0.4820
2024-01-10 21:50:20,436 - GAugM EPNet train, Epoch [186/295]: loss 0.7208, auc 0.4429, ap 0.4639
2024-01-10 21:50:20,540 - GAugM EPNet train, Epoch [187/295]: loss 0.7209, auc 0.5336, ap 0.5077
2024-01-10 21:50:20,634 - GAugM EPNet train, Epoch [188/295]: loss 0.7209, auc 0.4729, ap 0.4642
2024-01-10 21:50:20,731 - GAugM EPNet train, Epoch [189/295]: loss 0.7209, auc 0.5566, ap 0.5712
2024-01-10 21:50:20,824 - GAugM EPNet train, Epoch [190/295]: loss 0.7209, auc 0.4548, ap 0.4821
2024-01-10 21:50:20,915 - GAugM EPNet train, Epoch [191/295]: loss 0.7209, auc 0.4671, ap 0.5035
2024-01-10 21:50:21,010 - GAugM EPNet train, Epoch [192/295]: loss 0.7209, auc 0.5123, ap 0.4817
2024-01-10 21:50:21,104 - GAugM EPNet train, Epoch [193/295]: loss 0.7209, auc 0.5641, ap 0.5839
2024-01-10 21:50:21,197 - GAugM EPNet train, Epoch [194/295]: loss 0.7209, auc 0.3886, ap 0.4204
2024-01-10 21:50:21,293 - GAugM EPNet train, Epoch [195/295]: loss 0.7209, auc 0.4667, ap 0.4928
2024-01-10 21:50:21,385 - GAugM EPNet train, Epoch [196/295]: loss 0.7208, auc 0.5386, ap 0.5033
2024-01-10 21:50:21,476 - GAugM EPNet train, Epoch [197/295]: loss 0.7210, auc 0.4991, ap 0.5010
2024-01-10 21:50:21,565 - GAugM EPNet train, Epoch [198/295]: loss 0.7210, auc 0.5319, ap 0.5100
2024-01-10 21:50:21,667 - GAugM EPNet train, Epoch [199/295]: loss 0.7209, auc 0.4760, ap 0.4924
2024-01-10 21:50:21,767 - GAugM EPNet train, Epoch [200/295]: loss 0.7210, auc 0.4941, ap 0.5133
2024-01-10 21:50:21,859 - GAugM EPNet train, Epoch [201/295]: loss 0.7209, auc 0.4238, ap 0.4438
2024-01-10 21:50:21,950 - GAugM EPNet train, Epoch [202/295]: loss 0.7210, auc 0.5627, ap 0.5754
2024-01-10 21:50:22,048 - GAugM EPNet train, Epoch [203/295]: loss 0.7210, auc 0.5214, ap 0.5650
2024-01-10 21:50:22,144 - GAugM EPNet train, Epoch [204/295]: loss 0.7209, auc 0.4422, ap 0.4681
2024-01-10 21:50:22,236 - GAugM EPNet train, Epoch [205/295]: loss 0.7209, auc 0.5151, ap 0.5499
2024-01-10 21:50:22,327 - GAugM EPNet train, Epoch [206/295]: loss 0.7209, auc 0.4156, ap 0.4304
2024-01-10 21:50:22,423 - GAugM EPNet train, Epoch [207/295]: loss 0.7210, auc 0.4090, ap 0.4557
2024-01-10 21:50:22,530 - GAugM EPNet train, Epoch [208/295]: loss 0.7209, auc 0.3658, ap 0.4178
2024-01-10 21:50:22,628 - GAugM EPNet train, Epoch [209/295]: loss 0.7210, auc 0.5573, ap 0.5342
2024-01-10 21:50:22,724 - GAugM EPNet train, Epoch [210/295]: loss 0.7209, auc 0.5173, ap 0.5100
2024-01-10 21:50:22,823 - GAugM EPNet train, Epoch [211/295]: loss 0.7210, auc 0.5189, ap 0.5098
2024-01-10 21:50:22,917 - GAugM EPNet train, Epoch [212/295]: loss 0.7210, auc 0.4799, ap 0.4794
2024-01-10 21:50:23,010 - GAugM EPNet train, Epoch [213/295]: loss 0.7208, auc 0.6497, ap 0.6469
2024-01-10 21:50:23,113 - GAugM EPNet train, Epoch [214/295]: loss 0.7210, auc 0.5144, ap 0.5131
2024-01-10 21:50:23,207 - GAugM EPNet train, Epoch [215/295]: loss 0.7210, auc 0.4037, ap 0.4517
2024-01-10 21:50:23,308 - GAugM EPNet train, Epoch [216/295]: loss 0.7209, auc 0.4455, ap 0.4576
2024-01-10 21:50:23,401 - GAugM EPNet train, Epoch [217/295]: loss 0.7209, auc 0.4954, ap 0.5635
2024-01-10 21:50:23,502 - GAugM EPNet train, Epoch [218/295]: loss 0.7209, auc 0.5358, ap 0.5354
2024-01-10 21:50:23,597 - GAugM EPNet train, Epoch [219/295]: loss 0.7208, auc 0.4794, ap 0.4869
2024-01-10 21:50:23,688 - GAugM EPNet train, Epoch [220/295]: loss 0.7210, auc 0.4600, ap 0.4803
2024-01-10 21:50:23,787 - GAugM EPNet train, Epoch [221/295]: loss 0.7209, auc 0.5817, ap 0.5525
2024-01-10 21:50:23,879 - GAugM EPNet train, Epoch [222/295]: loss 0.7209, auc 0.5133, ap 0.4957
2024-01-10 21:50:23,972 - GAugM EPNet train, Epoch [223/295]: loss 0.7209, auc 0.4815, ap 0.4875
2024-01-10 21:50:24,073 - GAugM EPNet train, Epoch [224/295]: loss 0.7210, auc 0.4778, ap 0.4903
2024-01-10 21:50:24,165 - GAugM EPNet train, Epoch [225/295]: loss 0.7209, auc 0.4863, ap 0.4888
2024-01-10 21:50:24,256 - GAugM EPNet train, Epoch [226/295]: loss 0.7210, auc 0.4188, ap 0.4555
2024-01-10 21:50:24,347 - GAugM EPNet train, Epoch [227/295]: loss 0.7210, auc 0.5506, ap 0.5391
2024-01-10 21:50:24,443 - GAugM EPNet train, Epoch [228/295]: loss 0.7209, auc 0.4737, ap 0.4852
2024-01-10 21:50:24,540 - GAugM EPNet train, Epoch [229/295]: loss 0.7209, auc 0.4254, ap 0.4431
2024-01-10 21:50:24,636 - GAugM EPNet train, Epoch [230/295]: loss 0.7209, auc 0.4726, ap 0.5011
2024-01-10 21:50:24,733 - GAugM EPNet train, Epoch [231/295]: loss 0.7209, auc 0.5217, ap 0.5187
2024-01-10 21:50:24,829 - GAugM EPNet train, Epoch [232/295]: loss 0.7209, auc 0.5806, ap 0.5649
2024-01-10 21:50:24,927 - GAugM EPNet train, Epoch [233/295]: loss 0.7210, auc 0.4936, ap 0.5117
2024-01-10 21:50:25,017 - GAugM EPNet train, Epoch [234/295]: loss 0.7209, auc 0.4055, ap 0.4625
2024-01-10 21:50:25,123 - GAugM EPNet train, Epoch [235/295]: loss 0.7209, auc 0.4813, ap 0.4966
2024-01-10 21:50:25,217 - GAugM EPNet train, Epoch [236/295]: loss 0.7209, auc 0.5091, ap 0.5147
2024-01-10 21:50:25,314 - GAugM EPNet train, Epoch [237/295]: loss 0.7210, auc 0.4687, ap 0.4880
2024-01-10 21:50:25,407 - GAugM EPNet train, Epoch [238/295]: loss 0.7210, auc 0.5153, ap 0.4999
2024-01-10 21:50:25,502 - GAugM EPNet train, Epoch [239/295]: loss 0.7209, auc 0.4350, ap 0.4879
2024-01-10 21:50:25,599 - GAugM EPNet train, Epoch [240/295]: loss 0.7209, auc 0.5376, ap 0.4987
2024-01-10 21:50:25,690 - GAugM EPNet train, Epoch [241/295]: loss 0.7209, auc 0.4827, ap 0.4734
2024-01-10 21:50:25,786 - GAugM EPNet train, Epoch [242/295]: loss 0.7210, auc 0.3960, ap 0.4283
2024-01-10 21:50:25,881 - GAugM EPNet train, Epoch [243/295]: loss 0.7210, auc 0.5224, ap 0.5580
2024-01-10 21:50:25,978 - GAugM EPNet train, Epoch [244/295]: loss 0.7209, auc 0.5602, ap 0.5838
2024-01-10 21:50:26,073 - GAugM EPNet train, Epoch [245/295]: loss 0.7210, auc 0.4751, ap 0.4862
2024-01-10 21:50:26,166 - GAugM EPNet train, Epoch [246/295]: loss 0.7208, auc 0.4879, ap 0.5066
2024-01-10 21:50:26,254 - GAugM EPNet train, Epoch [247/295]: loss 0.7209, auc 0.5036, ap 0.4906
2024-01-10 21:50:26,344 - GAugM EPNet train, Epoch [248/295]: loss 0.7211, auc 0.4600, ap 0.4868
2024-01-10 21:50:26,432 - GAugM EPNet train, Epoch [249/295]: loss 0.7209, auc 0.4973, ap 0.4738
2024-01-10 21:50:26,522 - GAugM EPNet train, Epoch [250/295]: loss 0.7208, auc 0.3968, ap 0.4315
2024-01-10 21:50:26,612 - GAugM EPNet train, Epoch [251/295]: loss 0.7209, auc 0.4605, ap 0.4923
2024-01-10 21:50:26,706 - GAugM EPNet train, Epoch [252/295]: loss 0.7210, auc 0.5660, ap 0.5824
2024-01-10 21:50:26,796 - GAugM EPNet train, Epoch [253/295]: loss 0.7209, auc 0.5669, ap 0.5377
2024-01-10 21:50:26,884 - GAugM EPNet train, Epoch [254/295]: loss 0.7210, auc 0.4683, ap 0.4756
2024-01-10 21:50:26,979 - GAugM EPNet train, Epoch [255/295]: loss 0.7209, auc 0.4854, ap 0.5045
2024-01-10 21:50:27,067 - GAugM EPNet train, Epoch [256/295]: loss 0.7210, auc 0.3969, ap 0.4711
2024-01-10 21:50:27,166 - GAugM EPNet train, Epoch [257/295]: loss 0.7210, auc 0.4829, ap 0.4767
2024-01-10 21:50:27,259 - GAugM EPNet train, Epoch [258/295]: loss 0.7208, auc 0.5077, ap 0.5277
2024-01-10 21:50:27,348 - GAugM EPNet train, Epoch [259/295]: loss 0.7208, auc 0.5910, ap 0.5637
2024-01-10 21:50:27,443 - GAugM EPNet train, Epoch [260/295]: loss 0.7210, auc 0.4689, ap 0.4637
2024-01-10 21:50:27,535 - GAugM EPNet train, Epoch [261/295]: loss 0.7209, auc 0.4614, ap 0.4825
2024-01-10 21:50:27,626 - GAugM EPNet train, Epoch [262/295]: loss 0.7208, auc 0.4728, ap 0.4873
2024-01-10 21:50:27,721 - GAugM EPNet train, Epoch [263/295]: loss 0.7209, auc 0.4834, ap 0.4782
2024-01-10 21:50:27,811 - GAugM EPNet train, Epoch [264/295]: loss 0.7210, auc 0.4899, ap 0.5040
2024-01-10 21:50:27,903 - GAugM EPNet train, Epoch [265/295]: loss 0.7209, auc 0.5429, ap 0.5918
2024-01-10 21:50:27,998 - GAugM EPNet train, Epoch [266/295]: loss 0.7209, auc 0.4929, ap 0.5294
2024-01-10 21:50:28,088 - GAugM EPNet train, Epoch [267/295]: loss 0.7210, auc 0.4813, ap 0.4752
2024-01-10 21:50:28,184 - GAugM EPNet train, Epoch [268/295]: loss 0.7210, auc 0.4845, ap 0.5425
2024-01-10 21:50:28,274 - GAugM EPNet train, Epoch [269/295]: loss 0.7209, auc 0.5107, ap 0.5222
2024-01-10 21:50:28,366 - GAugM EPNet train, Epoch [270/295]: loss 0.7210, auc 0.4745, ap 0.5232
2024-01-10 21:50:28,457 - GAugM EPNet train, Epoch [271/295]: loss 0.7209, auc 0.4708, ap 0.4898
2024-01-10 21:50:28,550 - GAugM EPNet train, Epoch [272/295]: loss 0.7209, auc 0.5085, ap 0.5193
2024-01-10 21:50:28,639 - GAugM EPNet train, Epoch [273/295]: loss 0.7209, auc 0.4503, ap 0.4727
2024-01-10 21:50:28,730 - GAugM EPNet train, Epoch [274/295]: loss 0.7209, auc 0.5132, ap 0.4996
2024-01-10 21:50:28,819 - GAugM EPNet train, Epoch [275/295]: loss 0.7208, auc 0.4260, ap 0.4480
2024-01-10 21:50:28,914 - GAugM EPNet train, Epoch [276/295]: loss 0.7210, auc 0.5077, ap 0.5339
2024-01-10 21:50:29,008 - GAugM EPNet train, Epoch [277/295]: loss 0.7208, auc 0.4247, ap 0.4763
2024-01-10 21:50:29,120 - GAugM EPNet train, Epoch [278/295]: loss 0.7209, auc 0.5016, ap 0.5380
2024-01-10 21:50:29,216 - GAugM EPNet train, Epoch [279/295]: loss 0.7209, auc 0.4678, ap 0.4666
2024-01-10 21:50:29,309 - GAugM EPNet train, Epoch [280/295]: loss 0.7209, auc 0.3485, ap 0.3984
2024-01-10 21:50:29,400 - GAugM EPNet train, Epoch [281/295]: loss 0.7209, auc 0.5724, ap 0.5620
2024-01-10 21:50:29,493 - GAugM EPNet train, Epoch [282/295]: loss 0.7209, auc 0.4407, ap 0.4639
2024-01-10 21:50:29,584 - GAugM EPNet train, Epoch [283/295]: loss 0.7209, auc 0.5183, ap 0.5347
2024-01-10 21:50:29,676 - GAugM EPNet train, Epoch [284/295]: loss 0.7209, auc 0.4222, ap 0.4600
2024-01-10 21:50:29,768 - GAugM EPNet train, Epoch [285/295]: loss 0.7209, auc 0.5336, ap 0.5179
2024-01-10 21:50:29,863 - GAugM EPNet train, Epoch [286/295]: loss 0.7209, auc 0.4203, ap 0.4496
2024-01-10 21:50:29,958 - GAugM EPNet train, Epoch [287/295]: loss 0.7209, auc 0.4979, ap 0.5435
2024-01-10 21:50:30,058 - GAugM EPNet train, Epoch [288/295]: loss 0.7210, auc 0.5294, ap 0.5570
2024-01-10 21:50:30,153 - GAugM EPNet train, Epoch [289/295]: loss 0.7209, auc 0.4927, ap 0.4873
2024-01-10 21:50:30,250 - GAugM EPNet train, Epoch [290/295]: loss 0.7210, auc 0.5098, ap 0.5094
2024-01-10 21:50:30,346 - GAugM EPNet train, Epoch [291/295]: loss 0.7210, auc 0.4461, ap 0.4488
2024-01-10 21:50:30,448 - GAugM EPNet train, Epoch [292/295]: loss 0.7209, auc 0.4567, ap 0.4886
2024-01-10 21:50:30,541 - GAugM EPNet train, Epoch [293/295]: loss 0.7210, auc 0.5150, ap 0.5009
2024-01-10 21:50:30,642 - GAugM EPNet train, Epoch [294/295]: loss 0.7211, auc 0.4347, ap 0.4560
2024-01-10 21:50:30,733 - GAugM EPNet train, Epoch [295/295]: loss 0.7209, auc 0.3984, ap 0.4290
2024-01-10 21:50:30,759 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f6ceaa56bd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:50:31,649 - GAugM EPNet train, Epoch [  1/295]: loss 0.7210, auc 0.4578, ap 0.4726
2024-01-10 21:50:31,741 - GAugM EPNet train, Epoch [  2/295]: loss 0.7210, auc 0.4897, ap 0.4818
2024-01-10 21:50:31,827 - GAugM EPNet train, Epoch [  3/295]: loss 0.7209, auc 0.5619, ap 0.5388
2024-01-10 21:50:31,911 - GAugM EPNet train, Epoch [  4/295]: loss 0.7209, auc 0.4961, ap 0.5121
2024-01-10 21:50:32,002 - GAugM EPNet train, Epoch [  5/295]: loss 0.7209, auc 0.5311, ap 0.5365
2024-01-10 21:50:32,097 - GAugM EPNet train, Epoch [  6/295]: loss 0.7209, auc 0.5340, ap 0.5084
2024-01-10 21:50:32,182 - GAugM EPNet train, Epoch [  7/295]: loss 0.7209, auc 0.4502, ap 0.4543
2024-01-10 21:50:32,271 - GAugM EPNet train, Epoch [  8/295]: loss 0.7210, auc 0.4731, ap 0.5014
2024-01-10 21:50:32,360 - GAugM EPNet train, Epoch [  9/295]: loss 0.7209, auc 0.5381, ap 0.5139
2024-01-10 21:50:32,457 - GAugM EPNet train, Epoch [ 10/295]: loss 0.7208, auc 0.5167, ap 0.5187
2024-01-10 21:50:32,548 - GAugM EPNet train, Epoch [ 11/295]: loss 0.7209, auc 0.5011, ap 0.5070
2024-01-10 21:50:32,633 - GAugM EPNet train, Epoch [ 12/295]: loss 0.7210, auc 0.5246, ap 0.5274
2024-01-10 21:50:32,716 - GAugM EPNet train, Epoch [ 13/295]: loss 0.7209, auc 0.5498, ap 0.5216
2024-01-10 21:50:32,813 - GAugM EPNet train, Epoch [ 14/295]: loss 0.7209, auc 0.5744, ap 0.5555
2024-01-10 21:50:32,902 - GAugM EPNet train, Epoch [ 15/295]: loss 0.7210, auc 0.3782, ap 0.4369
2024-01-10 21:50:32,992 - GAugM EPNet train, Epoch [ 16/295]: loss 0.7209, auc 0.5263, ap 0.5351
2024-01-10 21:50:33,077 - GAugM EPNet train, Epoch [ 17/295]: loss 0.7210, auc 0.6079, ap 0.5774
2024-01-10 21:50:33,164 - GAugM EPNet train, Epoch [ 18/295]: loss 0.7210, auc 0.6420, ap 0.6126
2024-01-10 21:50:33,250 - GAugM EPNet train, Epoch [ 19/295]: loss 0.7209, auc 0.4883, ap 0.4855
2024-01-10 21:50:33,334 - GAugM EPNet train, Epoch [ 20/295]: loss 0.7210, auc 0.4918, ap 0.5145
2024-01-10 21:50:33,417 - GAugM EPNet train, Epoch [ 21/295]: loss 0.7209, auc 0.5470, ap 0.5452
2024-01-10 21:50:33,501 - GAugM EPNet train, Epoch [ 22/295]: loss 0.7210, auc 0.4454, ap 0.4630
2024-01-10 21:50:33,587 - GAugM EPNet train, Epoch [ 23/295]: loss 0.7208, auc 0.4576, ap 0.4784
2024-01-10 21:50:33,669 - GAugM EPNet train, Epoch [ 24/295]: loss 0.7209, auc 0.5093, ap 0.5225
2024-01-10 21:50:33,750 - GAugM EPNet train, Epoch [ 25/295]: loss 0.7209, auc 0.4192, ap 0.4448
2024-01-10 21:50:33,825 - GAugM EPNet train, Epoch [ 26/295]: loss 0.7210, auc 0.5619, ap 0.5845
2024-01-10 21:50:33,898 - GAugM EPNet train, Epoch [ 27/295]: loss 0.7209, auc 0.4082, ap 0.4737
2024-01-10 21:50:33,980 - GAugM EPNet train, Epoch [ 28/295]: loss 0.7209, auc 0.5961, ap 0.6046
2024-01-10 21:50:34,055 - GAugM EPNet train, Epoch [ 29/295]: loss 0.7210, auc 0.5142, ap 0.5106
2024-01-10 21:50:34,128 - GAugM EPNet train, Epoch [ 30/295]: loss 0.7209, auc 0.4484, ap 0.4984
2024-01-10 21:50:34,206 - GAugM EPNet train, Epoch [ 31/295]: loss 0.7208, auc 0.4624, ap 0.4956
2024-01-10 21:50:34,301 - GAugM EPNet train, Epoch [ 32/295]: loss 0.7210, auc 0.5239, ap 0.5209
2024-01-10 21:50:34,392 - GAugM EPNet train, Epoch [ 33/295]: loss 0.7209, auc 0.4224, ap 0.4412
2024-01-10 21:50:34,483 - GAugM EPNet train, Epoch [ 34/295]: loss 0.7209, auc 0.4687, ap 0.4691
2024-01-10 21:50:34,576 - GAugM EPNet train, Epoch [ 35/295]: loss 0.7209, auc 0.5611, ap 0.5592
2024-01-10 21:50:34,666 - GAugM EPNet train, Epoch [ 36/295]: loss 0.7209, auc 0.5311, ap 0.5275
2024-01-10 21:50:34,754 - GAugM EPNet train, Epoch [ 37/295]: loss 0.7209, auc 0.4487, ap 0.4770
2024-01-10 21:50:34,856 - GAugM EPNet train, Epoch [ 38/295]: loss 0.7209, auc 0.4181, ap 0.4422
2024-01-10 21:50:34,946 - GAugM EPNet train, Epoch [ 39/295]: loss 0.7208, auc 0.3966, ap 0.4495
2024-01-10 21:50:35,035 - GAugM EPNet train, Epoch [ 40/295]: loss 0.7210, auc 0.5878, ap 0.5542
2024-01-10 21:50:35,130 - GAugM EPNet train, Epoch [ 41/295]: loss 0.7210, auc 0.4792, ap 0.5072
2024-01-10 21:50:35,221 - GAugM EPNet train, Epoch [ 42/295]: loss 0.7209, auc 0.4644, ap 0.5053
2024-01-10 21:50:35,314 - GAugM EPNet train, Epoch [ 43/295]: loss 0.7208, auc 0.4341, ap 0.4825
2024-01-10 21:50:35,411 - GAugM EPNet train, Epoch [ 44/295]: loss 0.7208, auc 0.3936, ap 0.4619
2024-01-10 21:50:35,502 - GAugM EPNet train, Epoch [ 45/295]: loss 0.7209, auc 0.5543, ap 0.5263
2024-01-10 21:50:35,599 - GAugM EPNet train, Epoch [ 46/295]: loss 0.7209, auc 0.4217, ap 0.4636
2024-01-10 21:50:35,690 - GAugM EPNet train, Epoch [ 47/295]: loss 0.7210, auc 0.4389, ap 0.4433
2024-01-10 21:50:35,779 - GAugM EPNet train, Epoch [ 48/295]: loss 0.7210, auc 0.5691, ap 0.5883
2024-01-10 21:50:35,869 - GAugM EPNet train, Epoch [ 49/295]: loss 0.7209, auc 0.5249, ap 0.5176
2024-01-10 21:50:35,971 - GAugM EPNet train, Epoch [ 50/295]: loss 0.7210, auc 0.5441, ap 0.5242
2024-01-10 21:50:36,063 - GAugM EPNet train, Epoch [ 51/295]: loss 0.7210, auc 0.5367, ap 0.5503
2024-01-10 21:50:36,155 - GAugM EPNet train, Epoch [ 52/295]: loss 0.7209, auc 0.4208, ap 0.4323
2024-01-10 21:50:36,242 - GAugM EPNet train, Epoch [ 53/295]: loss 0.7209, auc 0.5146, ap 0.5241
2024-01-10 21:50:36,328 - GAugM EPNet train, Epoch [ 54/295]: loss 0.7211, auc 0.4818, ap 0.4706
2024-01-10 21:50:36,415 - GAugM EPNet train, Epoch [ 55/295]: loss 0.7209, auc 0.5728, ap 0.5630
2024-01-10 21:50:36,509 - GAugM EPNet train, Epoch [ 56/295]: loss 0.7208, auc 0.5164, ap 0.5317
2024-01-10 21:50:36,597 - GAugM EPNet train, Epoch [ 57/295]: loss 0.7209, auc 0.5271, ap 0.5064
2024-01-10 21:50:36,683 - GAugM EPNet train, Epoch [ 58/295]: loss 0.7210, auc 0.4808, ap 0.5482
2024-01-10 21:50:36,777 - GAugM EPNet train, Epoch [ 59/295]: loss 0.7211, auc 0.5263, ap 0.5262
2024-01-10 21:50:36,870 - GAugM EPNet train, Epoch [ 60/295]: loss 0.7210, auc 0.5322, ap 0.5292
2024-01-10 21:50:36,958 - GAugM EPNet train, Epoch [ 61/295]: loss 0.7209, auc 0.5655, ap 0.5586
2024-01-10 21:50:37,057 - GAugM EPNet train, Epoch [ 62/295]: loss 0.7210, auc 0.4972, ap 0.5028
2024-01-10 21:50:37,145 - GAugM EPNet train, Epoch [ 63/295]: loss 0.7208, auc 0.4571, ap 0.4618
2024-01-10 21:50:37,245 - GAugM EPNet train, Epoch [ 64/295]: loss 0.7208, auc 0.4672, ap 0.5127
2024-01-10 21:50:37,327 - GAugM EPNet train, Epoch [ 65/295]: loss 0.7208, auc 0.5680, ap 0.5488
2024-01-10 21:50:37,418 - GAugM EPNet train, Epoch [ 66/295]: loss 0.7209, auc 0.3850, ap 0.4358
2024-01-10 21:50:37,511 - GAugM EPNet train, Epoch [ 67/295]: loss 0.7209, auc 0.5625, ap 0.5240
2024-01-10 21:50:37,607 - GAugM EPNet train, Epoch [ 68/295]: loss 0.7210, auc 0.5477, ap 0.5544
2024-01-10 21:50:37,698 - GAugM EPNet train, Epoch [ 69/295]: loss 0.7210, auc 0.5187, ap 0.5122
2024-01-10 21:50:37,785 - GAugM EPNet train, Epoch [ 70/295]: loss 0.7210, auc 0.5109, ap 0.5092
2024-01-10 21:50:37,862 - GAugM EPNet train, Epoch [ 71/295]: loss 0.7210, auc 0.6057, ap 0.5666
2024-01-10 21:50:37,956 - GAugM EPNet train, Epoch [ 72/295]: loss 0.7210, auc 0.4535, ap 0.4766
2024-01-10 21:50:38,047 - GAugM EPNet train, Epoch [ 73/295]: loss 0.7209, auc 0.4320, ap 0.4432
2024-01-10 21:50:38,148 - GAugM EPNet train, Epoch [ 74/295]: loss 0.7209, auc 0.5135, ap 0.5351
2024-01-10 21:50:38,238 - GAugM EPNet train, Epoch [ 75/295]: loss 0.7210, auc 0.4405, ap 0.4698
2024-01-10 21:50:38,328 - GAugM EPNet train, Epoch [ 76/295]: loss 0.7209, auc 0.4637, ap 0.4600
2024-01-10 21:50:38,421 - GAugM EPNet train, Epoch [ 77/295]: loss 0.7208, auc 0.5862, ap 0.5639
2024-01-10 21:50:38,511 - GAugM EPNet train, Epoch [ 78/295]: loss 0.7209, auc 0.5053, ap 0.4987
2024-01-10 21:50:38,603 - GAugM EPNet train, Epoch [ 79/295]: loss 0.7208, auc 0.5221, ap 0.5262
2024-01-10 21:50:38,694 - GAugM EPNet train, Epoch [ 80/295]: loss 0.7209, auc 0.5634, ap 0.5551
2024-01-10 21:50:38,772 - GAugM EPNet train, Epoch [ 81/295]: loss 0.7209, auc 0.5046, ap 0.4956
2024-01-10 21:50:38,855 - GAugM EPNet train, Epoch [ 82/295]: loss 0.7210, auc 0.5733, ap 0.5706
2024-01-10 21:50:38,942 - GAugM EPNet train, Epoch [ 83/295]: loss 0.7209, auc 0.4416, ap 0.4631
2024-01-10 21:50:39,027 - GAugM EPNet train, Epoch [ 84/295]: loss 0.7209, auc 0.4400, ap 0.4525
2024-01-10 21:50:39,120 - GAugM EPNet train, Epoch [ 85/295]: loss 0.7210, auc 0.4484, ap 0.4498
2024-01-10 21:50:39,211 - GAugM EPNet train, Epoch [ 86/295]: loss 0.7208, auc 0.4516, ap 0.4773
2024-01-10 21:50:39,301 - GAugM EPNet train, Epoch [ 87/295]: loss 0.7209, auc 0.5114, ap 0.4849
2024-01-10 21:50:39,390 - GAugM EPNet train, Epoch [ 88/295]: loss 0.7210, auc 0.4708, ap 0.5182
2024-01-10 21:50:39,473 - GAugM EPNet train, Epoch [ 89/295]: loss 0.7210, auc 0.4327, ap 0.4778
2024-01-10 21:50:39,553 - GAugM EPNet train, Epoch [ 90/295]: loss 0.7209, auc 0.5096, ap 0.5281
2024-01-10 21:50:39,635 - GAugM EPNet train, Epoch [ 91/295]: loss 0.7208, auc 0.5630, ap 0.5323
2024-01-10 21:50:39,717 - GAugM EPNet train, Epoch [ 92/295]: loss 0.7209, auc 0.5335, ap 0.5325
2024-01-10 21:50:39,801 - GAugM EPNet train, Epoch [ 93/295]: loss 0.7209, auc 0.4409, ap 0.4725
2024-01-10 21:50:39,901 - GAugM EPNet train, Epoch [ 94/295]: loss 0.7210, auc 0.4229, ap 0.4569
2024-01-10 21:50:39,984 - GAugM EPNet train, Epoch [ 95/295]: loss 0.7210, auc 0.5007, ap 0.5004
2024-01-10 21:50:40,068 - GAugM EPNet train, Epoch [ 96/295]: loss 0.7209, auc 0.4715, ap 0.4866
2024-01-10 21:50:40,158 - GAugM EPNet train, Epoch [ 97/295]: loss 0.7209, auc 0.4594, ap 0.5014
2024-01-10 21:50:40,244 - GAugM EPNet train, Epoch [ 98/295]: loss 0.7209, auc 0.4576, ap 0.4709
2024-01-10 21:50:40,328 - GAugM EPNet train, Epoch [ 99/295]: loss 0.7209, auc 0.5125, ap 0.5513
2024-01-10 21:50:40,415 - GAugM EPNet train, Epoch [100/295]: loss 0.7210, auc 0.4872, ap 0.5153
2024-01-10 21:50:40,497 - GAugM EPNet train, Epoch [101/295]: loss 0.7210, auc 0.4473, ap 0.4592
2024-01-10 21:50:40,577 - GAugM EPNet train, Epoch [102/295]: loss 0.7209, auc 0.4993, ap 0.5334
2024-01-10 21:50:40,666 - GAugM EPNet train, Epoch [103/295]: loss 0.7209, auc 0.4891, ap 0.5101
2024-01-10 21:50:40,753 - GAugM EPNet train, Epoch [104/295]: loss 0.7209, auc 0.4249, ap 0.4660
2024-01-10 21:50:40,836 - GAugM EPNet train, Epoch [105/295]: loss 0.7209, auc 0.4810, ap 0.4994
2024-01-10 21:50:40,918 - GAugM EPNet train, Epoch [106/295]: loss 0.7210, auc 0.4922, ap 0.4766
2024-01-10 21:50:41,005 - GAugM EPNet train, Epoch [107/295]: loss 0.7210, auc 0.4074, ap 0.4549
2024-01-10 21:50:41,086 - GAugM EPNet train, Epoch [108/295]: loss 0.7208, auc 0.4672, ap 0.4699
2024-01-10 21:50:41,167 - GAugM EPNet train, Epoch [109/295]: loss 0.7210, auc 0.5342, ap 0.5195
2024-01-10 21:50:41,250 - GAugM EPNet train, Epoch [110/295]: loss 0.7209, auc 0.4822, ap 0.5070
2024-01-10 21:50:41,333 - GAugM EPNet train, Epoch [111/295]: loss 0.7210, auc 0.5701, ap 0.5413
2024-01-10 21:50:41,418 - GAugM EPNet train, Epoch [112/295]: loss 0.7209, auc 0.4776, ap 0.5057
2024-01-10 21:50:41,513 - GAugM EPNet train, Epoch [113/295]: loss 0.7210, auc 0.4005, ap 0.4667
2024-01-10 21:50:41,604 - GAugM EPNet train, Epoch [114/295]: loss 0.7209, auc 0.3807, ap 0.4278
2024-01-10 21:50:41,704 - GAugM EPNet train, Epoch [115/295]: loss 0.7210, auc 0.5477, ap 0.5135
2024-01-10 21:50:41,790 - GAugM EPNet train, Epoch [116/295]: loss 0.7209, auc 0.5249, ap 0.5437
2024-01-10 21:50:41,871 - GAugM EPNet train, Epoch [117/295]: loss 0.7208, auc 0.4761, ap 0.4984
2024-01-10 21:50:41,954 - GAugM EPNet train, Epoch [118/295]: loss 0.7209, auc 0.4309, ap 0.4885
2024-01-10 21:50:42,037 - GAugM EPNet train, Epoch [119/295]: loss 0.7209, auc 0.5043, ap 0.5271
2024-01-10 21:50:42,115 - GAugM EPNet train, Epoch [120/295]: loss 0.7210, auc 0.5046, ap 0.5185
2024-01-10 21:50:42,224 - GAugM EPNet train, Epoch [121/295]: loss 0.7210, auc 0.4446, ap 0.4644
2024-01-10 21:50:42,321 - GAugM EPNet train, Epoch [122/295]: loss 0.7209, auc 0.5363, ap 0.5430
2024-01-10 21:50:42,420 - GAugM EPNet train, Epoch [123/295]: loss 0.7209, auc 0.4217, ap 0.4504
2024-01-10 21:50:42,508 - GAugM EPNet train, Epoch [124/295]: loss 0.7210, auc 0.5046, ap 0.4902
2024-01-10 21:50:42,596 - GAugM EPNet train, Epoch [125/295]: loss 0.7209, auc 0.4498, ap 0.4836
2024-01-10 21:50:42,686 - GAugM EPNet train, Epoch [126/295]: loss 0.7210, auc 0.5370, ap 0.5305
2024-01-10 21:50:42,777 - GAugM EPNet train, Epoch [127/295]: loss 0.7209, auc 0.4834, ap 0.4889
2024-01-10 21:50:42,868 - GAugM EPNet train, Epoch [128/295]: loss 0.7210, auc 0.5367, ap 0.5425
2024-01-10 21:50:42,952 - GAugM EPNet train, Epoch [129/295]: loss 0.7208, auc 0.4402, ap 0.4515
2024-01-10 21:50:43,046 - GAugM EPNet train, Epoch [130/295]: loss 0.7210, auc 0.4391, ap 0.4690
2024-01-10 21:50:43,136 - GAugM EPNet train, Epoch [131/295]: loss 0.7210, auc 0.5794, ap 0.5604
2024-01-10 21:50:43,223 - GAugM EPNet train, Epoch [132/295]: loss 0.7209, auc 0.5370, ap 0.5318
2024-01-10 21:50:43,320 - GAugM EPNet train, Epoch [133/295]: loss 0.7209, auc 0.5595, ap 0.5730
2024-01-10 21:50:43,410 - GAugM EPNet train, Epoch [134/295]: loss 0.7210, auc 0.5126, ap 0.5356
2024-01-10 21:50:43,500 - GAugM EPNet train, Epoch [135/295]: loss 0.7209, auc 0.3355, ap 0.4135
2024-01-10 21:50:43,591 - GAugM EPNet train, Epoch [136/295]: loss 0.7209, auc 0.5491, ap 0.5185
2024-01-10 21:50:43,680 - GAugM EPNet train, Epoch [137/295]: loss 0.7210, auc 0.4402, ap 0.4683
2024-01-10 21:50:43,776 - GAugM EPNet train, Epoch [138/295]: loss 0.7210, auc 0.5787, ap 0.5576
2024-01-10 21:50:43,863 - GAugM EPNet train, Epoch [139/295]: loss 0.7210, auc 0.5452, ap 0.5440
2024-01-10 21:50:43,953 - GAugM EPNet train, Epoch [140/295]: loss 0.7209, auc 0.4352, ap 0.4661
2024-01-10 21:50:44,046 - GAugM EPNet train, Epoch [141/295]: loss 0.7209, auc 0.4818, ap 0.4663
2024-01-10 21:50:44,142 - GAugM EPNet train, Epoch [142/295]: loss 0.7209, auc 0.5449, ap 0.5277
2024-01-10 21:50:44,226 - GAugM EPNet train, Epoch [143/295]: loss 0.7209, auc 0.4737, ap 0.4816
2024-01-10 21:50:44,319 - GAugM EPNet train, Epoch [144/295]: loss 0.7209, auc 0.4566, ap 0.4612
2024-01-10 21:50:44,406 - GAugM EPNet train, Epoch [145/295]: loss 0.7209, auc 0.4324, ap 0.4925
2024-01-10 21:50:44,518 - GAugM EPNet train, Epoch [146/295]: loss 0.7209, auc 0.6125, ap 0.5799
2024-01-10 21:50:44,619 - GAugM EPNet train, Epoch [147/295]: loss 0.7209, auc 0.6084, ap 0.6154
2024-01-10 21:50:44,709 - GAugM EPNet train, Epoch [148/295]: loss 0.7209, auc 0.4696, ap 0.4901
2024-01-10 21:50:44,798 - GAugM EPNet train, Epoch [149/295]: loss 0.7208, auc 0.5196, ap 0.5113
2024-01-10 21:50:44,893 - GAugM EPNet train, Epoch [150/295]: loss 0.7209, auc 0.5295, ap 0.5113
2024-01-10 21:50:44,983 - GAugM EPNet train, Epoch [151/295]: loss 0.7209, auc 0.5349, ap 0.5119
2024-01-10 21:50:45,076 - GAugM EPNet train, Epoch [152/295]: loss 0.7209, auc 0.5253, ap 0.5600
2024-01-10 21:50:45,167 - GAugM EPNet train, Epoch [153/295]: loss 0.7209, auc 0.4067, ap 0.4567
2024-01-10 21:50:45,259 - GAugM EPNet train, Epoch [154/295]: loss 0.7209, auc 0.5352, ap 0.5530
2024-01-10 21:50:45,349 - GAugM EPNet train, Epoch [155/295]: loss 0.7209, auc 0.5267, ap 0.5044
2024-01-10 21:50:45,440 - GAugM EPNet train, Epoch [156/295]: loss 0.7209, auc 0.4594, ap 0.4623
2024-01-10 21:50:45,536 - GAugM EPNet train, Epoch [157/295]: loss 0.7209, auc 0.4836, ap 0.4695
2024-01-10 21:50:45,626 - GAugM EPNet train, Epoch [158/295]: loss 0.7208, auc 0.4480, ap 0.4628
2024-01-10 21:50:45,719 - GAugM EPNet train, Epoch [159/295]: loss 0.7208, auc 0.4381, ap 0.4634
2024-01-10 21:50:45,809 - GAugM EPNet train, Epoch [160/295]: loss 0.7209, auc 0.5698, ap 0.5701
2024-01-10 21:50:45,897 - GAugM EPNet train, Epoch [161/295]: loss 0.7209, auc 0.5208, ap 0.5000
2024-01-10 21:50:45,986 - GAugM EPNet train, Epoch [162/295]: loss 0.7209, auc 0.4875, ap 0.4883
2024-01-10 21:50:46,085 - GAugM EPNet train, Epoch [163/295]: loss 0.7209, auc 0.4569, ap 0.4708
2024-01-10 21:50:46,175 - GAugM EPNet train, Epoch [164/295]: loss 0.7211, auc 0.4413, ap 0.4460
2024-01-10 21:50:46,263 - GAugM EPNet train, Epoch [165/295]: loss 0.7210, auc 0.4808, ap 0.4927
2024-01-10 21:50:46,354 - GAugM EPNet train, Epoch [166/295]: loss 0.7208, auc 0.5473, ap 0.5349
2024-01-10 21:50:46,448 - GAugM EPNet train, Epoch [167/295]: loss 0.7209, auc 0.4868, ap 0.4882
2024-01-10 21:50:46,536 - GAugM EPNet train, Epoch [168/295]: loss 0.7209, auc 0.4879, ap 0.5236
2024-01-10 21:50:46,626 - GAugM EPNet train, Epoch [169/295]: loss 0.7209, auc 0.5518, ap 0.5732
2024-01-10 21:50:46,715 - GAugM EPNet train, Epoch [170/295]: loss 0.7210, auc 0.4502, ap 0.4568
2024-01-10 21:50:46,812 - GAugM EPNet train, Epoch [171/295]: loss 0.7209, auc 0.4979, ap 0.5070
2024-01-10 21:50:46,909 - GAugM EPNet train, Epoch [172/295]: loss 0.7208, auc 0.5080, ap 0.4992
2024-01-10 21:50:47,000 - GAugM EPNet train, Epoch [173/295]: loss 0.7209, auc 0.5737, ap 0.5951
2024-01-10 21:50:47,095 - GAugM EPNet train, Epoch [174/295]: loss 0.7209, auc 0.4493, ap 0.4511
2024-01-10 21:50:47,182 - GAugM EPNet train, Epoch [175/295]: loss 0.7209, auc 0.6743, ap 0.6402
2024-01-10 21:50:47,270 - GAugM EPNet train, Epoch [176/295]: loss 0.7209, auc 0.5135, ap 0.5131
2024-01-10 21:50:47,358 - GAugM EPNet train, Epoch [177/295]: loss 0.7210, auc 0.4980, ap 0.4903
2024-01-10 21:50:47,455 - GAugM EPNet train, Epoch [178/295]: loss 0.7210, auc 0.5384, ap 0.5699
2024-01-10 21:50:47,541 - GAugM EPNet train, Epoch [179/295]: loss 0.7210, auc 0.4651, ap 0.4991
2024-01-10 21:50:47,633 - GAugM EPNet train, Epoch [180/295]: loss 0.7210, auc 0.5285, ap 0.5553
2024-01-10 21:50:47,723 - GAugM EPNet train, Epoch [181/295]: loss 0.7209, auc 0.4706, ap 0.4813
2024-01-10 21:50:47,813 - GAugM EPNet train, Epoch [182/295]: loss 0.7209, auc 0.4794, ap 0.5063
2024-01-10 21:50:47,912 - GAugM EPNet train, Epoch [183/295]: loss 0.7210, auc 0.5459, ap 0.5401
2024-01-10 21:50:48,001 - GAugM EPNet train, Epoch [184/295]: loss 0.7209, auc 0.5607, ap 0.5604
2024-01-10 21:50:48,099 - GAugM EPNet train, Epoch [185/295]: loss 0.7209, auc 0.4972, ap 0.5004
2024-01-10 21:50:48,188 - GAugM EPNet train, Epoch [186/295]: loss 0.7208, auc 0.4534, ap 0.4806
2024-01-10 21:50:48,286 - GAugM EPNet train, Epoch [187/295]: loss 0.7209, auc 0.4810, ap 0.4903
2024-01-10 21:50:48,374 - GAugM EPNet train, Epoch [188/295]: loss 0.7209, auc 0.4085, ap 0.4322
2024-01-10 21:50:48,463 - GAugM EPNet train, Epoch [189/295]: loss 0.7209, auc 0.5532, ap 0.5729
2024-01-10 21:50:48,555 - GAugM EPNet train, Epoch [190/295]: loss 0.7209, auc 0.4096, ap 0.4291
2024-01-10 21:50:48,642 - GAugM EPNet train, Epoch [191/295]: loss 0.7209, auc 0.4260, ap 0.4648
2024-01-10 21:50:48,730 - GAugM EPNet train, Epoch [192/295]: loss 0.7209, auc 0.5484, ap 0.5149
2024-01-10 21:50:48,822 - GAugM EPNet train, Epoch [193/295]: loss 0.7209, auc 0.5876, ap 0.5690
2024-01-10 21:50:48,913 - GAugM EPNet train, Epoch [194/295]: loss 0.7209, auc 0.4886, ap 0.4745
2024-01-10 21:50:49,001 - GAugM EPNet train, Epoch [195/295]: loss 0.7209, auc 0.4972, ap 0.5098
2024-01-10 21:50:49,094 - GAugM EPNet train, Epoch [196/295]: loss 0.7208, auc 0.5185, ap 0.4974
2024-01-10 21:50:49,186 - GAugM EPNet train, Epoch [197/295]: loss 0.7210, auc 0.4872, ap 0.4847
2024-01-10 21:50:49,273 - GAugM EPNet train, Epoch [198/295]: loss 0.7210, auc 0.4712, ap 0.4992
2024-01-10 21:50:49,374 - GAugM EPNet train, Epoch [199/295]: loss 0.7209, auc 0.4589, ap 0.4769
2024-01-10 21:50:49,464 - GAugM EPNet train, Epoch [200/295]: loss 0.7210, auc 0.4445, ap 0.4570
2024-01-10 21:50:49,554 - GAugM EPNet train, Epoch [201/295]: loss 0.7209, auc 0.3750, ap 0.4105
2024-01-10 21:50:49,641 - GAugM EPNet train, Epoch [202/295]: loss 0.7210, auc 0.5299, ap 0.5565
2024-01-10 21:50:49,738 - GAugM EPNet train, Epoch [203/295]: loss 0.7210, auc 0.5075, ap 0.5309
2024-01-10 21:50:49,827 - GAugM EPNet train, Epoch [204/295]: loss 0.7209, auc 0.4361, ap 0.4598
2024-01-10 21:50:49,915 - GAugM EPNet train, Epoch [205/295]: loss 0.7209, auc 0.4729, ap 0.4677
2024-01-10 21:50:50,002 - GAugM EPNet train, Epoch [206/295]: loss 0.7209, auc 0.3686, ap 0.4182
2024-01-10 21:50:50,089 - GAugM EPNet train, Epoch [207/295]: loss 0.7210, auc 0.4128, ap 0.4327
2024-01-10 21:50:50,176 - GAugM EPNet train, Epoch [208/295]: loss 0.7209, auc 0.4324, ap 0.4673
2024-01-10 21:50:50,266 - GAugM EPNet train, Epoch [209/295]: loss 0.7210, auc 0.5614, ap 0.5375
2024-01-10 21:50:50,355 - GAugM EPNet train, Epoch [210/295]: loss 0.7209, auc 0.4001, ap 0.4385
2024-01-10 21:50:50,442 - GAugM EPNet train, Epoch [211/295]: loss 0.7210, auc 0.5468, ap 0.5497
2024-01-10 21:50:50,529 - GAugM EPNet train, Epoch [212/295]: loss 0.7210, auc 0.4555, ap 0.4751
2024-01-10 21:50:50,627 - GAugM EPNet train, Epoch [213/295]: loss 0.7208, auc 0.6527, ap 0.6692
2024-01-10 21:50:50,724 - GAugM EPNet train, Epoch [214/295]: loss 0.7210, auc 0.5466, ap 0.5550
2024-01-10 21:50:50,811 - GAugM EPNet train, Epoch [215/295]: loss 0.7210, auc 0.5402, ap 0.5568
2024-01-10 21:50:50,907 - GAugM EPNet train, Epoch [216/295]: loss 0.7209, auc 0.5030, ap 0.4885
2024-01-10 21:50:50,999 - GAugM EPNet train, Epoch [217/295]: loss 0.7209, auc 0.5591, ap 0.5603
2024-01-10 21:50:51,087 - GAugM EPNet train, Epoch [218/295]: loss 0.7209, auc 0.5657, ap 0.5823
2024-01-10 21:50:51,173 - GAugM EPNet train, Epoch [219/295]: loss 0.7208, auc 0.4560, ap 0.4602
2024-01-10 21:50:51,263 - GAugM EPNet train, Epoch [220/295]: loss 0.7210, auc 0.4300, ap 0.4631
2024-01-10 21:50:51,351 - GAugM EPNet train, Epoch [221/295]: loss 0.7209, auc 0.5805, ap 0.5622
2024-01-10 21:50:51,443 - GAugM EPNet train, Epoch [222/295]: loss 0.7209, auc 0.3811, ap 0.4231
2024-01-10 21:50:51,529 - GAugM EPNet train, Epoch [223/295]: loss 0.7209, auc 0.5438, ap 0.5547
2024-01-10 21:50:51,615 - GAugM EPNet train, Epoch [224/295]: loss 0.7210, auc 0.4464, ap 0.4467
2024-01-10 21:50:51,707 - GAugM EPNet train, Epoch [225/295]: loss 0.7209, auc 0.4765, ap 0.4854
2024-01-10 21:50:51,806 - GAugM EPNet train, Epoch [226/295]: loss 0.7210, auc 0.5064, ap 0.4965
2024-01-10 21:50:51,895 - GAugM EPNet train, Epoch [227/295]: loss 0.7210, auc 0.5651, ap 0.5510
2024-01-10 21:50:51,982 - GAugM EPNet train, Epoch [228/295]: loss 0.7209, auc 0.4299, ap 0.4770
2024-01-10 21:50:52,070 - GAugM EPNet train, Epoch [229/295]: loss 0.7209, auc 0.4923, ap 0.4914
2024-01-10 21:50:52,170 - GAugM EPNet train, Epoch [230/295]: loss 0.7209, auc 0.4188, ap 0.4556
2024-01-10 21:50:52,258 - GAugM EPNet train, Epoch [231/295]: loss 0.7209, auc 0.5522, ap 0.5169
2024-01-10 21:50:52,346 - GAugM EPNet train, Epoch [232/295]: loss 0.7209, auc 0.5274, ap 0.5262
2024-01-10 21:50:52,434 - GAugM EPNet train, Epoch [233/295]: loss 0.7210, auc 0.5342, ap 0.5667
2024-01-10 21:50:52,524 - GAugM EPNet train, Epoch [234/295]: loss 0.7209, auc 0.4306, ap 0.4586
2024-01-10 21:50:52,613 - GAugM EPNet train, Epoch [235/295]: loss 0.7209, auc 0.5073, ap 0.4964
2024-01-10 21:50:52,709 - GAugM EPNet train, Epoch [236/295]: loss 0.7209, auc 0.4902, ap 0.4876
2024-01-10 21:50:52,807 - GAugM EPNet train, Epoch [237/295]: loss 0.7210, auc 0.4783, ap 0.4996
2024-01-10 21:50:52,899 - GAugM EPNet train, Epoch [238/295]: loss 0.7210, auc 0.5319, ap 0.5374
2024-01-10 21:50:52,990 - GAugM EPNet train, Epoch [239/295]: loss 0.7209, auc 0.4562, ap 0.5055
2024-01-10 21:50:53,078 - GAugM EPNet train, Epoch [240/295]: loss 0.7209, auc 0.4384, ap 0.4442
2024-01-10 21:50:53,174 - GAugM EPNet train, Epoch [241/295]: loss 0.7209, auc 0.5114, ap 0.4932
2024-01-10 21:50:53,262 - GAugM EPNet train, Epoch [242/295]: loss 0.7210, auc 0.4185, ap 0.4746
2024-01-10 21:50:53,348 - GAugM EPNet train, Epoch [243/295]: loss 0.7210, auc 0.4979, ap 0.5161
2024-01-10 21:50:53,441 - GAugM EPNet train, Epoch [244/295]: loss 0.7209, auc 0.5498, ap 0.5338
2024-01-10 21:50:53,528 - GAugM EPNet train, Epoch [245/295]: loss 0.7210, auc 0.4849, ap 0.4929
2024-01-10 21:50:53,615 - GAugM EPNet train, Epoch [246/295]: loss 0.7208, auc 0.5224, ap 0.5276
2024-01-10 21:50:53,703 - GAugM EPNet train, Epoch [247/295]: loss 0.7209, auc 0.5417, ap 0.5230
2024-01-10 21:50:53,795 - GAugM EPNet train, Epoch [248/295]: loss 0.7211, auc 0.5655, ap 0.5817
2024-01-10 21:50:53,882 - GAugM EPNet train, Epoch [249/295]: loss 0.7209, auc 0.5146, ap 0.5016
2024-01-10 21:50:53,972 - GAugM EPNet train, Epoch [250/295]: loss 0.7208, auc 0.5338, ap 0.5321
2024-01-10 21:50:54,071 - GAugM EPNet train, Epoch [251/295]: loss 0.7209, auc 0.5363, ap 0.5357
2024-01-10 21:50:54,160 - GAugM EPNet train, Epoch [252/295]: loss 0.7210, auc 0.5417, ap 0.5485
2024-01-10 21:50:54,256 - GAugM EPNet train, Epoch [253/295]: loss 0.7209, auc 0.6353, ap 0.5753
2024-01-10 21:50:54,346 - GAugM EPNet train, Epoch [254/295]: loss 0.7210, auc 0.4541, ap 0.4789
2024-01-10 21:50:54,433 - GAugM EPNet train, Epoch [255/295]: loss 0.7209, auc 0.5388, ap 0.5581
2024-01-10 21:50:54,525 - GAugM EPNet train, Epoch [256/295]: loss 0.7210, auc 0.3466, ap 0.4377
2024-01-10 21:50:54,616 - GAugM EPNet train, Epoch [257/295]: loss 0.7210, auc 0.5299, ap 0.5454
2024-01-10 21:50:54,712 - GAugM EPNet train, Epoch [258/295]: loss 0.7208, auc 0.4370, ap 0.4734
2024-01-10 21:50:54,800 - GAugM EPNet train, Epoch [259/295]: loss 0.7208, auc 0.5716, ap 0.5434
2024-01-10 21:50:54,888 - GAugM EPNet train, Epoch [260/295]: loss 0.7210, auc 0.4954, ap 0.5174
2024-01-10 21:50:54,982 - GAugM EPNet train, Epoch [261/295]: loss 0.7209, auc 0.3590, ap 0.4082
2024-01-10 21:50:55,070 - GAugM EPNet train, Epoch [262/295]: loss 0.7208, auc 0.4989, ap 0.5000
2024-01-10 21:50:55,157 - GAugM EPNet train, Epoch [263/295]: loss 0.7209, auc 0.4824, ap 0.4906
2024-01-10 21:50:55,250 - GAugM EPNet train, Epoch [264/295]: loss 0.7210, auc 0.4541, ap 0.4698
2024-01-10 21:50:55,338 - GAugM EPNet train, Epoch [265/295]: loss 0.7209, auc 0.5228, ap 0.5323
2024-01-10 21:50:55,425 - GAugM EPNet train, Epoch [266/295]: loss 0.7209, auc 0.5178, ap 0.4945
2024-01-10 21:50:55,517 - GAugM EPNet train, Epoch [267/295]: loss 0.7210, auc 0.5114, ap 0.5053
2024-01-10 21:50:55,612 - GAugM EPNet train, Epoch [268/295]: loss 0.7210, auc 0.5408, ap 0.5516
2024-01-10 21:50:55,701 - GAugM EPNet train, Epoch [269/295]: loss 0.7209, auc 0.4824, ap 0.5103
2024-01-10 21:50:55,790 - GAugM EPNet train, Epoch [270/295]: loss 0.7210, auc 0.4722, ap 0.4791
2024-01-10 21:50:55,883 - GAugM EPNet train, Epoch [271/295]: loss 0.7209, auc 0.4664, ap 0.4919
2024-01-10 21:50:55,982 - GAugM EPNet train, Epoch [272/295]: loss 0.7209, auc 0.4715, ap 0.5063
2024-01-10 21:50:56,070 - GAugM EPNet train, Epoch [273/295]: loss 0.7209, auc 0.4957, ap 0.4938
2024-01-10 21:50:56,161 - GAugM EPNet train, Epoch [274/295]: loss 0.7209, auc 0.5203, ap 0.4979
2024-01-10 21:50:56,248 - GAugM EPNet train, Epoch [275/295]: loss 0.7208, auc 0.4347, ap 0.4542
2024-01-10 21:50:56,339 - GAugM EPNet train, Epoch [276/295]: loss 0.7210, auc 0.5185, ap 0.5136
2024-01-10 21:50:56,431 - GAugM EPNet train, Epoch [277/295]: loss 0.7208, auc 0.4883, ap 0.5177
2024-01-10 21:50:56,518 - GAugM EPNet train, Epoch [278/295]: loss 0.7209, auc 0.5365, ap 0.5601
2024-01-10 21:50:56,610 - GAugM EPNet train, Epoch [279/295]: loss 0.7209, auc 0.4697, ap 0.4954
2024-01-10 21:50:56,698 - GAugM EPNet train, Epoch [280/295]: loss 0.7209, auc 0.4276, ap 0.4390
2024-01-10 21:50:56,786 - GAugM EPNet train, Epoch [281/295]: loss 0.7209, auc 0.5958, ap 0.5593
2024-01-10 21:50:56,880 - GAugM EPNet train, Epoch [282/295]: loss 0.7209, auc 0.5110, ap 0.4905
2024-01-10 21:50:56,967 - GAugM EPNet train, Epoch [283/295]: loss 0.7209, auc 0.5253, ap 0.5340
2024-01-10 21:50:57,055 - GAugM EPNet train, Epoch [284/295]: loss 0.7209, auc 0.4231, ap 0.4475
2024-01-10 21:50:57,147 - GAugM EPNet train, Epoch [285/295]: loss 0.7209, auc 0.5167, ap 0.4941
2024-01-10 21:50:57,237 - GAugM EPNet train, Epoch [286/295]: loss 0.7209, auc 0.4817, ap 0.4876
2024-01-10 21:50:57,331 - GAugM EPNet train, Epoch [287/295]: loss 0.7209, auc 0.4082, ap 0.4536
2024-01-10 21:50:57,425 - GAugM EPNet train, Epoch [288/295]: loss 0.7210, auc 0.5623, ap 0.5670
2024-01-10 21:50:57,511 - GAugM EPNet train, Epoch [289/295]: loss 0.7209, auc 0.4098, ap 0.4347
2024-01-10 21:50:57,599 - GAugM EPNet train, Epoch [290/295]: loss 0.7210, auc 0.5317, ap 0.5245
2024-01-10 21:50:57,685 - GAugM EPNet train, Epoch [291/295]: loss 0.7210, auc 0.3861, ap 0.4249
2024-01-10 21:50:57,772 - GAugM EPNet train, Epoch [292/295]: loss 0.7209, auc 0.4263, ap 0.4552
2024-01-10 21:50:57,858 - GAugM EPNet train, Epoch [293/295]: loss 0.7210, auc 0.4927, ap 0.4803
2024-01-10 21:50:57,951 - GAugM EPNet train, Epoch [294/295]: loss 0.7211, auc 0.4555, ap 0.4828
2024-01-10 21:50:58,047 - GAugM EPNet train, Epoch [295/295]: loss 0.7209, auc 0.4340, ap 0.4410
2024-01-10 21:50:58,052 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f6cea8fbf90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:50:58,865 - GAugM EPNet train, Epoch [  1/295]: loss 0.7210, auc 0.4836, ap 0.5020
2024-01-10 21:50:58,966 - GAugM EPNet train, Epoch [  2/295]: loss 0.7210, auc 0.5004, ap 0.5016
2024-01-10 21:50:59,060 - GAugM EPNet train, Epoch [  3/295]: loss 0.7209, auc 0.6107, ap 0.5883
2024-01-10 21:50:59,153 - GAugM EPNet train, Epoch [  4/295]: loss 0.7209, auc 0.5009, ap 0.5361
2024-01-10 21:50:59,246 - GAugM EPNet train, Epoch [  5/295]: loss 0.7209, auc 0.6201, ap 0.6164
2024-01-10 21:50:59,344 - GAugM EPNet train, Epoch [  6/295]: loss 0.7209, auc 0.4966, ap 0.5075
2024-01-10 21:50:59,437 - GAugM EPNet train, Epoch [  7/295]: loss 0.7209, auc 0.4505, ap 0.4492
2024-01-10 21:50:59,522 - GAugM EPNet train, Epoch [  8/295]: loss 0.7210, auc 0.5294, ap 0.5391
2024-01-10 21:50:59,614 - GAugM EPNet train, Epoch [  9/295]: loss 0.7209, auc 0.5253, ap 0.5230
2024-01-10 21:50:59,691 - GAugM EPNet train, Epoch [ 10/295]: loss 0.7208, auc 0.5390, ap 0.5556
2024-01-10 21:50:59,768 - GAugM EPNet train, Epoch [ 11/295]: loss 0.7209, auc 0.4952, ap 0.5384
2024-01-10 21:50:59,857 - GAugM EPNet train, Epoch [ 12/295]: loss 0.7210, auc 0.4904, ap 0.5015
2024-01-10 21:50:59,944 - GAugM EPNet train, Epoch [ 13/295]: loss 0.7209, auc 0.5990, ap 0.6030
2024-01-10 21:51:00,023 - GAugM EPNet train, Epoch [ 14/295]: loss 0.7209, auc 0.5595, ap 0.5549
2024-01-10 21:51:00,110 - GAugM EPNet train, Epoch [ 15/295]: loss 0.7210, auc 0.4689, ap 0.5262
2024-01-10 21:51:00,188 - GAugM EPNet train, Epoch [ 16/295]: loss 0.7209, auc 0.5511, ap 0.5660
2024-01-10 21:51:00,275 - GAugM EPNet train, Epoch [ 17/295]: loss 0.7210, auc 0.5319, ap 0.5255
2024-01-10 21:51:00,363 - GAugM EPNet train, Epoch [ 18/295]: loss 0.7210, auc 0.5360, ap 0.5500
2024-01-10 21:51:00,441 - GAugM EPNet train, Epoch [ 19/295]: loss 0.7209, auc 0.5760, ap 0.5465
2024-01-10 21:51:00,529 - GAugM EPNet train, Epoch [ 20/295]: loss 0.7210, auc 0.4906, ap 0.5101
2024-01-10 21:51:00,614 - GAugM EPNet train, Epoch [ 21/295]: loss 0.7209, auc 0.4904, ap 0.4820
2024-01-10 21:51:00,692 - GAugM EPNet train, Epoch [ 22/295]: loss 0.7210, auc 0.4245, ap 0.4397
2024-01-10 21:51:00,784 - GAugM EPNet train, Epoch [ 23/295]: loss 0.7208, auc 0.5046, ap 0.5261
2024-01-10 21:51:00,863 - GAugM EPNet train, Epoch [ 24/295]: loss 0.7209, auc 0.4569, ap 0.4861
2024-01-10 21:51:00,953 - GAugM EPNet train, Epoch [ 25/295]: loss 0.7209, auc 0.4781, ap 0.5049
2024-01-10 21:51:01,034 - GAugM EPNet train, Epoch [ 26/295]: loss 0.7210, auc 0.5279, ap 0.5309
2024-01-10 21:51:01,109 - GAugM EPNet train, Epoch [ 27/295]: loss 0.7209, auc 0.4313, ap 0.4759
2024-01-10 21:51:01,211 - GAugM EPNet train, Epoch [ 28/295]: loss 0.7209, auc 0.5466, ap 0.5722
2024-01-10 21:51:01,301 - GAugM EPNet train, Epoch [ 29/295]: loss 0.7210, auc 0.4817, ap 0.4824
2024-01-10 21:51:01,380 - GAugM EPNet train, Epoch [ 30/295]: loss 0.7209, auc 0.5765, ap 0.5845
2024-01-10 21:51:01,458 - GAugM EPNet train, Epoch [ 31/295]: loss 0.7208, auc 0.4954, ap 0.5202
2024-01-10 21:51:01,535 - GAugM EPNet train, Epoch [ 32/295]: loss 0.7210, auc 0.5452, ap 0.5503
2024-01-10 21:51:01,614 - GAugM EPNet train, Epoch [ 33/295]: loss 0.7209, auc 0.5635, ap 0.5267
2024-01-10 21:51:01,690 - GAugM EPNet train, Epoch [ 34/295]: loss 0.7209, auc 0.4624, ap 0.4788
2024-01-10 21:51:01,771 - GAugM EPNet train, Epoch [ 35/295]: loss 0.7209, auc 0.4423, ap 0.4614
2024-01-10 21:51:01,851 - GAugM EPNet train, Epoch [ 36/295]: loss 0.7209, auc 0.6157, ap 0.5862
2024-01-10 21:51:01,930 - GAugM EPNet train, Epoch [ 37/295]: loss 0.7209, auc 0.4667, ap 0.4716
2024-01-10 21:51:02,006 - GAugM EPNet train, Epoch [ 38/295]: loss 0.7209, auc 0.5475, ap 0.5342
2024-01-10 21:51:02,084 - GAugM EPNet train, Epoch [ 39/295]: loss 0.7208, auc 0.4493, ap 0.4906
2024-01-10 21:51:02,170 - GAugM EPNet train, Epoch [ 40/295]: loss 0.7210, auc 0.5881, ap 0.5688
2024-01-10 21:51:02,257 - GAugM EPNet train, Epoch [ 41/295]: loss 0.7210, auc 0.4422, ap 0.5193
2024-01-10 21:51:02,346 - GAugM EPNet train, Epoch [ 42/295]: loss 0.7209, auc 0.5205, ap 0.5296
2024-01-10 21:51:02,432 - GAugM EPNet train, Epoch [ 43/295]: loss 0.7208, auc 0.4559, ap 0.4955
2024-01-10 21:51:02,522 - GAugM EPNet train, Epoch [ 44/295]: loss 0.7208, auc 0.4496, ap 0.4811
2024-01-10 21:51:02,610 - GAugM EPNet train, Epoch [ 45/295]: loss 0.7209, auc 0.6125, ap 0.6259
2024-01-10 21:51:02,705 - GAugM EPNet train, Epoch [ 46/295]: loss 0.7209, auc 0.4171, ap 0.4982
2024-01-10 21:51:02,802 - GAugM EPNet train, Epoch [ 47/295]: loss 0.7210, auc 0.4555, ap 0.4895
2024-01-10 21:51:02,891 - GAugM EPNet train, Epoch [ 48/295]: loss 0.7210, auc 0.6387, ap 0.6510
2024-01-10 21:51:02,979 - GAugM EPNet train, Epoch [ 49/295]: loss 0.7209, auc 0.5456, ap 0.5446
2024-01-10 21:51:03,073 - GAugM EPNet train, Epoch [ 50/295]: loss 0.7210, auc 0.5304, ap 0.5375
2024-01-10 21:51:03,163 - GAugM EPNet train, Epoch [ 51/295]: loss 0.7210, auc 0.4863, ap 0.5474
2024-01-10 21:51:03,252 - GAugM EPNet train, Epoch [ 52/295]: loss 0.7209, auc 0.4062, ap 0.4741
2024-01-10 21:51:03,354 - GAugM EPNet train, Epoch [ 53/295]: loss 0.7209, auc 0.5344, ap 0.5725
2024-01-10 21:51:03,443 - GAugM EPNet train, Epoch [ 54/295]: loss 0.7211, auc 0.5667, ap 0.5787
2024-01-10 21:51:03,530 - GAugM EPNet train, Epoch [ 55/295]: loss 0.7209, auc 0.5434, ap 0.5841
2024-01-10 21:51:03,624 - GAugM EPNet train, Epoch [ 56/295]: loss 0.7208, auc 0.4943, ap 0.5034
2024-01-10 21:51:03,713 - GAugM EPNet train, Epoch [ 57/295]: loss 0.7209, auc 0.5313, ap 0.5394
2024-01-10 21:51:03,809 - GAugM EPNet train, Epoch [ 58/295]: loss 0.7210, auc 0.5139, ap 0.5402
2024-01-10 21:51:03,896 - GAugM EPNet train, Epoch [ 59/295]: loss 0.7211, auc 0.4600, ap 0.4619
2024-01-10 21:51:03,984 - GAugM EPNet train, Epoch [ 60/295]: loss 0.7210, auc 0.5005, ap 0.5028
2024-01-10 21:51:04,080 - GAugM EPNet train, Epoch [ 61/295]: loss 0.7209, auc 0.5212, ap 0.5445
2024-01-10 21:51:04,175 - GAugM EPNet train, Epoch [ 62/295]: loss 0.7210, auc 0.5856, ap 0.5840
2024-01-10 21:51:04,263 - GAugM EPNet train, Epoch [ 63/295]: loss 0.7208, auc 0.4640, ap 0.4741
2024-01-10 21:51:04,353 - GAugM EPNet train, Epoch [ 64/295]: loss 0.7208, auc 0.5091, ap 0.5261
2024-01-10 21:51:04,439 - GAugM EPNet train, Epoch [ 65/295]: loss 0.7208, auc 0.5386, ap 0.5525
2024-01-10 21:51:04,524 - GAugM EPNet train, Epoch [ 66/295]: loss 0.7209, auc 0.4133, ap 0.4576
2024-01-10 21:51:04,610 - GAugM EPNet train, Epoch [ 67/295]: loss 0.7209, auc 0.5192, ap 0.5212
2024-01-10 21:51:04,696 - GAugM EPNet train, Epoch [ 68/295]: loss 0.7210, auc 0.5842, ap 0.5812
2024-01-10 21:51:04,779 - GAugM EPNet train, Epoch [ 69/295]: loss 0.7210, auc 0.4845, ap 0.5220
2024-01-10 21:51:04,864 - GAugM EPNet train, Epoch [ 70/295]: loss 0.7210, auc 0.4696, ap 0.4844
2024-01-10 21:51:04,951 - GAugM EPNet train, Epoch [ 71/295]: loss 0.7210, auc 0.4906, ap 0.5062
2024-01-10 21:51:05,040 - GAugM EPNet train, Epoch [ 72/295]: loss 0.7210, auc 0.4532, ap 0.4937
2024-01-10 21:51:05,126 - GAugM EPNet train, Epoch [ 73/295]: loss 0.7209, auc 0.4715, ap 0.4804
2024-01-10 21:51:05,218 - GAugM EPNet train, Epoch [ 74/295]: loss 0.7209, auc 0.4802, ap 0.4913
2024-01-10 21:51:05,302 - GAugM EPNet train, Epoch [ 75/295]: loss 0.7210, auc 0.5183, ap 0.5595
2024-01-10 21:51:05,404 - GAugM EPNet train, Epoch [ 76/295]: loss 0.7209, auc 0.4160, ap 0.4504
2024-01-10 21:51:05,492 - GAugM EPNet train, Epoch [ 77/295]: loss 0.7208, auc 0.6009, ap 0.6180
2024-01-10 21:51:05,584 - GAugM EPNet train, Epoch [ 78/295]: loss 0.7209, auc 0.5418, ap 0.5295
2024-01-10 21:51:05,681 - GAugM EPNet train, Epoch [ 79/295]: loss 0.7208, auc 0.4106, ap 0.4343
2024-01-10 21:51:05,768 - GAugM EPNet train, Epoch [ 80/295]: loss 0.7209, auc 0.5676, ap 0.5618
2024-01-10 21:51:05,853 - GAugM EPNet train, Epoch [ 81/295]: loss 0.7209, auc 0.4769, ap 0.5038
2024-01-10 21:51:05,944 - GAugM EPNet train, Epoch [ 82/295]: loss 0.7210, auc 0.4480, ap 0.4695
2024-01-10 21:51:06,042 - GAugM EPNet train, Epoch [ 83/295]: loss 0.7209, auc 0.4398, ap 0.4880
2024-01-10 21:51:06,128 - GAugM EPNet train, Epoch [ 84/295]: loss 0.7209, auc 0.4988, ap 0.5481
2024-01-10 21:51:06,217 - GAugM EPNet train, Epoch [ 85/295]: loss 0.7210, auc 0.3734, ap 0.4340
2024-01-10 21:51:06,303 - GAugM EPNet train, Epoch [ 86/295]: loss 0.7208, auc 0.5538, ap 0.5437
2024-01-10 21:51:06,393 - GAugM EPNet train, Epoch [ 87/295]: loss 0.7209, auc 0.5059, ap 0.5051
2024-01-10 21:51:06,480 - GAugM EPNet train, Epoch [ 88/295]: loss 0.7210, auc 0.4717, ap 0.5023
2024-01-10 21:51:06,582 - GAugM EPNet train, Epoch [ 89/295]: loss 0.7210, auc 0.5301, ap 0.5473
2024-01-10 21:51:06,678 - GAugM EPNet train, Epoch [ 90/295]: loss 0.7209, auc 0.4425, ap 0.4689
2024-01-10 21:51:06,763 - GAugM EPNet train, Epoch [ 91/295]: loss 0.7208, auc 0.4446, ap 0.4587
2024-01-10 21:51:06,848 - GAugM EPNet train, Epoch [ 92/295]: loss 0.7209, auc 0.6390, ap 0.6157
2024-01-10 21:51:06,941 - GAugM EPNet train, Epoch [ 93/295]: loss 0.7209, auc 0.3952, ap 0.4688
2024-01-10 21:51:07,028 - GAugM EPNet train, Epoch [ 94/295]: loss 0.7210, auc 0.4381, ap 0.5147
2024-01-10 21:51:07,111 - GAugM EPNet train, Epoch [ 95/295]: loss 0.7210, auc 0.5016, ap 0.5223
2024-01-10 21:51:07,208 - GAugM EPNet train, Epoch [ 96/295]: loss 0.7209, auc 0.5415, ap 0.5848
2024-01-10 21:51:07,295 - GAugM EPNet train, Epoch [ 97/295]: loss 0.7209, auc 0.4005, ap 0.4662
2024-01-10 21:51:07,384 - GAugM EPNet train, Epoch [ 98/295]: loss 0.7209, auc 0.4046, ap 0.4406
2024-01-10 21:51:07,465 - GAugM EPNet train, Epoch [ 99/295]: loss 0.7209, auc 0.5342, ap 0.5432
2024-01-10 21:51:07,538 - GAugM EPNet train, Epoch [100/295]: loss 0.7210, auc 0.4567, ap 0.4985
2024-01-10 21:51:07,625 - GAugM EPNet train, Epoch [101/295]: loss 0.7210, auc 0.4703, ap 0.5571
2024-01-10 21:51:07,724 - GAugM EPNet train, Epoch [102/295]: loss 0.7209, auc 0.5105, ap 0.5206
2024-01-10 21:51:07,810 - GAugM EPNet train, Epoch [103/295]: loss 0.7209, auc 0.4452, ap 0.5046
2024-01-10 21:51:07,899 - GAugM EPNet train, Epoch [104/295]: loss 0.7209, auc 0.3521, ap 0.4055
2024-01-10 21:51:07,978 - GAugM EPNet train, Epoch [105/295]: loss 0.7209, auc 0.4941, ap 0.5211
2024-01-10 21:51:08,058 - GAugM EPNet train, Epoch [106/295]: loss 0.7210, auc 0.4187, ap 0.4522
2024-01-10 21:51:08,142 - GAugM EPNet train, Epoch [107/295]: loss 0.7210, auc 0.4069, ap 0.4635
2024-01-10 21:51:08,227 - GAugM EPNet train, Epoch [108/295]: loss 0.7208, auc 0.5239, ap 0.5153
2024-01-10 21:51:08,309 - GAugM EPNet train, Epoch [109/295]: loss 0.7210, auc 0.4405, ap 0.4891
2024-01-10 21:51:08,396 - GAugM EPNet train, Epoch [110/295]: loss 0.7209, auc 0.4916, ap 0.5199
2024-01-10 21:51:08,492 - GAugM EPNet train, Epoch [111/295]: loss 0.7210, auc 0.4719, ap 0.4937
2024-01-10 21:51:08,578 - GAugM EPNet train, Epoch [112/295]: loss 0.7209, auc 0.4865, ap 0.5397
2024-01-10 21:51:08,657 - GAugM EPNet train, Epoch [113/295]: loss 0.7210, auc 0.5221, ap 0.5770
2024-01-10 21:51:08,750 - GAugM EPNet train, Epoch [114/295]: loss 0.7209, auc 0.4632, ap 0.4726
2024-01-10 21:51:08,848 - GAugM EPNet train, Epoch [115/295]: loss 0.7210, auc 0.4375, ap 0.4608
2024-01-10 21:51:08,933 - GAugM EPNet train, Epoch [116/295]: loss 0.7209, auc 0.5427, ap 0.5464
2024-01-10 21:51:09,022 - GAugM EPNet train, Epoch [117/295]: loss 0.7208, auc 0.4548, ap 0.4993
2024-01-10 21:51:09,110 - GAugM EPNet train, Epoch [118/295]: loss 0.7209, auc 0.5133, ap 0.5548
2024-01-10 21:51:09,195 - GAugM EPNet train, Epoch [119/295]: loss 0.7209, auc 0.5358, ap 0.5622
2024-01-10 21:51:09,281 - GAugM EPNet train, Epoch [120/295]: loss 0.7210, auc 0.5075, ap 0.4904
2024-01-10 21:51:09,366 - GAugM EPNet train, Epoch [121/295]: loss 0.7210, auc 0.4484, ap 0.4775
2024-01-10 21:51:09,447 - GAugM EPNet train, Epoch [122/295]: loss 0.7209, auc 0.4941, ap 0.5418
2024-01-10 21:51:09,540 - GAugM EPNet train, Epoch [123/295]: loss 0.7209, auc 0.5093, ap 0.5346
2024-01-10 21:51:09,619 - GAugM EPNet train, Epoch [124/295]: loss 0.7210, auc 0.4961, ap 0.4912
2024-01-10 21:51:09,707 - GAugM EPNet train, Epoch [125/295]: loss 0.7209, auc 0.4418, ap 0.4674
2024-01-10 21:51:09,793 - GAugM EPNet train, Epoch [126/295]: loss 0.7210, auc 0.5514, ap 0.5613
2024-01-10 21:51:09,878 - GAugM EPNet train, Epoch [127/295]: loss 0.7209, auc 0.5071, ap 0.5110
2024-01-10 21:51:09,970 - GAugM EPNet train, Epoch [128/295]: loss 0.7210, auc 0.5822, ap 0.5555
2024-01-10 21:51:10,049 - GAugM EPNet train, Epoch [129/295]: loss 0.7208, auc 0.4001, ap 0.4482
2024-01-10 21:51:10,140 - GAugM EPNet train, Epoch [130/295]: loss 0.7210, auc 0.4443, ap 0.4510
2024-01-10 21:51:10,242 - GAugM EPNet train, Epoch [131/295]: loss 0.7210, auc 0.5643, ap 0.6020
2024-01-10 21:51:10,328 - GAugM EPNet train, Epoch [132/295]: loss 0.7209, auc 0.5527, ap 0.5426
2024-01-10 21:51:10,417 - GAugM EPNet train, Epoch [133/295]: loss 0.7209, auc 0.4927, ap 0.5545
2024-01-10 21:51:10,502 - GAugM EPNet train, Epoch [134/295]: loss 0.7210, auc 0.4528, ap 0.4581
2024-01-10 21:51:10,586 - GAugM EPNet train, Epoch [135/295]: loss 0.7209, auc 0.3905, ap 0.4447
2024-01-10 21:51:10,673 - GAugM EPNet train, Epoch [136/295]: loss 0.7209, auc 0.5077, ap 0.5148
2024-01-10 21:51:10,772 - GAugM EPNet train, Epoch [137/295]: loss 0.7210, auc 0.4349, ap 0.4864
2024-01-10 21:51:10,875 - GAugM EPNet train, Epoch [138/295]: loss 0.7210, auc 0.4637, ap 0.4777
2024-01-10 21:51:10,970 - GAugM EPNet train, Epoch [139/295]: loss 0.7210, auc 0.5924, ap 0.5839
2024-01-10 21:51:11,068 - GAugM EPNet train, Epoch [140/295]: loss 0.7209, auc 0.4886, ap 0.5426
2024-01-10 21:51:11,177 - GAugM EPNet train, Epoch [141/295]: loss 0.7209, auc 0.5587, ap 0.5560
2024-01-10 21:51:11,270 - GAugM EPNet train, Epoch [142/295]: loss 0.7209, auc 0.4361, ap 0.4822
2024-01-10 21:51:11,350 - GAugM EPNet train, Epoch [143/295]: loss 0.7209, auc 0.4247, ap 0.4707
2024-01-10 21:51:11,447 - GAugM EPNet train, Epoch [144/295]: loss 0.7209, auc 0.4357, ap 0.4612
2024-01-10 21:51:11,539 - GAugM EPNet train, Epoch [145/295]: loss 0.7209, auc 0.3795, ap 0.4746
2024-01-10 21:51:11,631 - GAugM EPNet train, Epoch [146/295]: loss 0.7209, auc 0.5034, ap 0.5061
2024-01-10 21:51:11,723 - GAugM EPNet train, Epoch [147/295]: loss 0.7209, auc 0.5260, ap 0.5686
2024-01-10 21:51:11,815 - GAugM EPNet train, Epoch [148/295]: loss 0.7209, auc 0.4455, ap 0.5036
2024-01-10 21:51:11,908 - GAugM EPNet train, Epoch [149/295]: loss 0.7208, auc 0.5447, ap 0.5677
2024-01-10 21:51:12,000 - GAugM EPNet train, Epoch [150/295]: loss 0.7209, auc 0.4877, ap 0.4946
2024-01-10 21:51:12,090 - GAugM EPNet train, Epoch [151/295]: loss 0.7209, auc 0.5593, ap 0.5555
2024-01-10 21:51:12,182 - GAugM EPNet train, Epoch [152/295]: loss 0.7209, auc 0.5274, ap 0.5420
2024-01-10 21:51:12,273 - GAugM EPNet train, Epoch [153/295]: loss 0.7209, auc 0.4891, ap 0.5362
2024-01-10 21:51:12,356 - GAugM EPNet train, Epoch [154/295]: loss 0.7209, auc 0.5151, ap 0.5431
2024-01-10 21:51:12,436 - GAugM EPNet train, Epoch [155/295]: loss 0.7209, auc 0.4616, ap 0.4933
2024-01-10 21:51:12,536 - GAugM EPNet train, Epoch [156/295]: loss 0.7209, auc 0.4454, ap 0.4900
2024-01-10 21:51:12,628 - GAugM EPNet train, Epoch [157/295]: loss 0.7209, auc 0.5050, ap 0.4917
2024-01-10 21:51:12,723 - GAugM EPNet train, Epoch [158/295]: loss 0.7208, auc 0.4537, ap 0.4923
2024-01-10 21:51:12,813 - GAugM EPNet train, Epoch [159/295]: loss 0.7208, auc 0.4672, ap 0.4640
2024-01-10 21:51:12,906 - GAugM EPNet train, Epoch [160/295]: loss 0.7209, auc 0.5525, ap 0.5570
2024-01-10 21:51:12,999 - GAugM EPNet train, Epoch [161/295]: loss 0.7209, auc 0.4715, ap 0.4972
2024-01-10 21:51:13,091 - GAugM EPNet train, Epoch [162/295]: loss 0.7209, auc 0.5117, ap 0.5241
2024-01-10 21:51:13,185 - GAugM EPNet train, Epoch [163/295]: loss 0.7209, auc 0.5187, ap 0.5312
2024-01-10 21:51:13,281 - GAugM EPNet train, Epoch [164/295]: loss 0.7211, auc 0.6273, ap 0.6001
2024-01-10 21:51:13,386 - GAugM EPNet train, Epoch [165/295]: loss 0.7210, auc 0.4475, ap 0.4600
2024-01-10 21:51:13,478 - GAugM EPNet train, Epoch [166/295]: loss 0.7208, auc 0.5678, ap 0.5557
2024-01-10 21:51:13,575 - GAugM EPNet train, Epoch [167/295]: loss 0.7209, auc 0.5125, ap 0.5102
2024-01-10 21:51:13,672 - GAugM EPNet train, Epoch [168/295]: loss 0.7209, auc 0.5087, ap 0.5545
2024-01-10 21:51:13,770 - GAugM EPNet train, Epoch [169/295]: loss 0.7209, auc 0.5436, ap 0.5490
2024-01-10 21:51:13,867 - GAugM EPNet train, Epoch [170/295]: loss 0.7210, auc 0.5523, ap 0.5404
2024-01-10 21:51:13,958 - GAugM EPNet train, Epoch [171/295]: loss 0.7209, auc 0.4972, ap 0.4986
2024-01-10 21:51:14,051 - GAugM EPNet train, Epoch [172/295]: loss 0.7208, auc 0.4541, ap 0.4770
2024-01-10 21:51:14,152 - GAugM EPNet train, Epoch [173/295]: loss 0.7209, auc 0.5358, ap 0.5406
2024-01-10 21:51:14,246 - GAugM EPNet train, Epoch [174/295]: loss 0.7209, auc 0.3957, ap 0.4488
2024-01-10 21:51:14,342 - GAugM EPNet train, Epoch [175/295]: loss 0.7209, auc 0.6273, ap 0.6319
2024-01-10 21:51:14,435 - GAugM EPNet train, Epoch [176/295]: loss 0.7209, auc 0.4966, ap 0.5023
2024-01-10 21:51:14,535 - GAugM EPNet train, Epoch [177/295]: loss 0.7210, auc 0.4535, ap 0.4603
2024-01-10 21:51:14,626 - GAugM EPNet train, Epoch [178/295]: loss 0.7210, auc 0.6111, ap 0.6393
2024-01-10 21:51:14,709 - GAugM EPNet train, Epoch [179/295]: loss 0.7210, auc 0.4991, ap 0.5297
2024-01-10 21:51:14,802 - GAugM EPNet train, Epoch [180/295]: loss 0.7210, auc 0.5591, ap 0.6050
2024-01-10 21:51:14,893 - GAugM EPNet train, Epoch [181/295]: loss 0.7209, auc 0.3791, ap 0.4228
2024-01-10 21:51:14,995 - GAugM EPNet train, Epoch [182/295]: loss 0.7209, auc 0.4324, ap 0.4951
2024-01-10 21:51:15,088 - GAugM EPNet train, Epoch [183/295]: loss 0.7210, auc 0.5450, ap 0.5409
2024-01-10 21:51:15,181 - GAugM EPNet train, Epoch [184/295]: loss 0.7209, auc 0.5584, ap 0.5675
2024-01-10 21:51:15,277 - GAugM EPNet train, Epoch [185/295]: loss 0.7209, auc 0.5000, ap 0.5170
2024-01-10 21:51:15,367 - GAugM EPNet train, Epoch [186/295]: loss 0.7208, auc 0.4651, ap 0.5251
2024-01-10 21:51:15,460 - GAugM EPNet train, Epoch [187/295]: loss 0.7209, auc 0.5244, ap 0.5174
2024-01-10 21:51:15,554 - GAugM EPNet train, Epoch [188/295]: loss 0.7209, auc 0.4628, ap 0.4721
2024-01-10 21:51:15,654 - GAugM EPNet train, Epoch [189/295]: loss 0.7209, auc 0.5160, ap 0.5620
2024-01-10 21:51:15,744 - GAugM EPNet train, Epoch [190/295]: loss 0.7209, auc 0.4571, ap 0.4862
2024-01-10 21:51:15,840 - GAugM EPNet train, Epoch [191/295]: loss 0.7209, auc 0.4306, ap 0.5106
2024-01-10 21:51:15,932 - GAugM EPNet train, Epoch [192/295]: loss 0.7209, auc 0.5078, ap 0.5027
2024-01-10 21:51:16,027 - GAugM EPNet train, Epoch [193/295]: loss 0.7209, auc 0.5623, ap 0.5396
2024-01-10 21:51:16,118 - GAugM EPNet train, Epoch [194/295]: loss 0.7209, auc 0.4429, ap 0.4770
2024-01-10 21:51:16,211 - GAugM EPNet train, Epoch [195/295]: loss 0.7209, auc 0.4808, ap 0.5009
2024-01-10 21:51:16,307 - GAugM EPNet train, Epoch [196/295]: loss 0.7208, auc 0.5637, ap 0.5832
2024-01-10 21:51:16,407 - GAugM EPNet train, Epoch [197/295]: loss 0.7210, auc 0.4970, ap 0.5155
2024-01-10 21:51:16,500 - GAugM EPNet train, Epoch [198/295]: loss 0.7210, auc 0.5395, ap 0.5270
2024-01-10 21:51:16,590 - GAugM EPNet train, Epoch [199/295]: loss 0.7209, auc 0.5831, ap 0.5941
2024-01-10 21:51:16,681 - GAugM EPNet train, Epoch [200/295]: loss 0.7210, auc 0.4621, ap 0.4935
2024-01-10 21:51:16,777 - GAugM EPNet train, Epoch [201/295]: loss 0.7209, auc 0.4843, ap 0.5292
2024-01-10 21:51:16,872 - GAugM EPNet train, Epoch [202/295]: loss 0.7210, auc 0.4656, ap 0.5424
2024-01-10 21:51:16,974 - GAugM EPNet train, Epoch [203/295]: loss 0.7210, auc 0.5822, ap 0.6035
2024-01-10 21:51:17,068 - GAugM EPNet train, Epoch [204/295]: loss 0.7209, auc 0.4511, ap 0.4803
2024-01-10 21:51:17,157 - GAugM EPNet train, Epoch [205/295]: loss 0.7209, auc 0.4276, ap 0.4743
2024-01-10 21:51:17,255 - GAugM EPNet train, Epoch [206/295]: loss 0.7209, auc 0.4181, ap 0.4677
2024-01-10 21:51:17,356 - GAugM EPNet train, Epoch [207/295]: loss 0.7210, auc 0.5313, ap 0.5481
2024-01-10 21:51:17,450 - GAugM EPNet train, Epoch [208/295]: loss 0.7209, auc 0.4299, ap 0.4990
2024-01-10 21:51:17,546 - GAugM EPNet train, Epoch [209/295]: loss 0.7210, auc 0.6116, ap 0.5821
2024-01-10 21:51:17,636 - GAugM EPNet train, Epoch [210/295]: loss 0.7209, auc 0.4007, ap 0.4434
2024-01-10 21:51:17,727 - GAugM EPNet train, Epoch [211/295]: loss 0.7210, auc 0.5344, ap 0.5723
2024-01-10 21:51:17,833 - GAugM EPNet train, Epoch [212/295]: loss 0.7210, auc 0.4238, ap 0.4586
2024-01-10 21:51:17,936 - GAugM EPNet train, Epoch [213/295]: loss 0.7208, auc 0.5570, ap 0.5816
2024-01-10 21:51:18,031 - GAugM EPNet train, Epoch [214/295]: loss 0.7210, auc 0.5142, ap 0.5161
2024-01-10 21:51:18,130 - GAugM EPNet train, Epoch [215/295]: loss 0.7210, auc 0.4551, ap 0.4999
2024-01-10 21:51:18,230 - GAugM EPNet train, Epoch [216/295]: loss 0.7209, auc 0.5276, ap 0.5208
2024-01-10 21:51:18,324 - GAugM EPNet train, Epoch [217/295]: loss 0.7209, auc 0.6064, ap 0.6253
2024-01-10 21:51:18,419 - GAugM EPNet train, Epoch [218/295]: loss 0.7209, auc 0.6221, ap 0.6515
2024-01-10 21:51:18,513 - GAugM EPNet train, Epoch [219/295]: loss 0.7208, auc 0.5365, ap 0.5333
2024-01-10 21:51:18,606 - GAugM EPNet train, Epoch [220/295]: loss 0.7210, auc 0.4710, ap 0.5289
2024-01-10 21:51:18,688 - GAugM EPNet train, Epoch [221/295]: loss 0.7209, auc 0.6257, ap 0.6225
2024-01-10 21:51:18,781 - GAugM EPNet train, Epoch [222/295]: loss 0.7209, auc 0.5498, ap 0.5399
2024-01-10 21:51:18,877 - GAugM EPNet train, Epoch [223/295]: loss 0.7209, auc 0.5009, ap 0.5236
2024-01-10 21:51:18,966 - GAugM EPNet train, Epoch [224/295]: loss 0.7210, auc 0.4457, ap 0.4664
2024-01-10 21:51:19,060 - GAugM EPNet train, Epoch [225/295]: loss 0.7209, auc 0.4439, ap 0.4655
2024-01-10 21:51:19,152 - GAugM EPNet train, Epoch [226/295]: loss 0.7210, auc 0.4813, ap 0.4969
2024-01-10 21:51:19,245 - GAugM EPNet train, Epoch [227/295]: loss 0.7210, auc 0.6070, ap 0.6071
2024-01-10 21:51:19,344 - GAugM EPNet train, Epoch [228/295]: loss 0.7209, auc 0.4781, ap 0.4945
2024-01-10 21:51:19,437 - GAugM EPNet train, Epoch [229/295]: loss 0.7209, auc 0.4872, ap 0.4898
2024-01-10 21:51:19,528 - GAugM EPNet train, Epoch [230/295]: loss 0.7209, auc 0.5052, ap 0.5230
2024-01-10 21:51:19,625 - GAugM EPNet train, Epoch [231/295]: loss 0.7209, auc 0.4405, ap 0.4684
2024-01-10 21:51:19,719 - GAugM EPNet train, Epoch [232/295]: loss 0.7209, auc 0.4539, ap 0.4863
2024-01-10 21:51:19,818 - GAugM EPNet train, Epoch [233/295]: loss 0.7210, auc 0.5002, ap 0.5224
2024-01-10 21:51:19,910 - GAugM EPNet train, Epoch [234/295]: loss 0.7209, auc 0.3542, ap 0.4336
2024-01-10 21:51:19,989 - GAugM EPNet train, Epoch [235/295]: loss 0.7209, auc 0.4658, ap 0.4886
2024-01-10 21:51:20,083 - GAugM EPNet train, Epoch [236/295]: loss 0.7209, auc 0.5098, ap 0.5315
2024-01-10 21:51:20,185 - GAugM EPNet train, Epoch [237/295]: loss 0.7210, auc 0.5219, ap 0.5327
2024-01-10 21:51:20,279 - GAugM EPNet train, Epoch [238/295]: loss 0.7210, auc 0.4242, ap 0.4976
2024-01-10 21:51:20,378 - GAugM EPNet train, Epoch [239/295]: loss 0.7209, auc 0.4708, ap 0.5433
2024-01-10 21:51:20,472 - GAugM EPNet train, Epoch [240/295]: loss 0.7209, auc 0.4845, ap 0.4869
2024-01-10 21:51:20,566 - GAugM EPNet train, Epoch [241/295]: loss 0.7209, auc 0.4810, ap 0.5068
2024-01-10 21:51:20,651 - GAugM EPNet train, Epoch [242/295]: loss 0.7210, auc 0.4461, ap 0.4681
2024-01-10 21:51:20,745 - GAugM EPNet train, Epoch [243/295]: loss 0.7210, auc 0.5684, ap 0.6237
2024-01-10 21:51:20,840 - GAugM EPNet train, Epoch [244/295]: loss 0.7209, auc 0.5673, ap 0.5662
2024-01-10 21:51:20,932 - GAugM EPNet train, Epoch [245/295]: loss 0.7210, auc 0.4740, ap 0.4903
2024-01-10 21:51:21,027 - GAugM EPNet train, Epoch [246/295]: loss 0.7208, auc 0.5260, ap 0.5371
2024-01-10 21:51:21,127 - GAugM EPNet train, Epoch [247/295]: loss 0.7209, auc 0.5502, ap 0.5359
2024-01-10 21:51:21,220 - GAugM EPNet train, Epoch [248/295]: loss 0.7211, auc 0.5575, ap 0.5789
2024-01-10 21:51:21,310 - GAugM EPNet train, Epoch [249/295]: loss 0.7209, auc 0.4589, ap 0.5043
2024-01-10 21:51:21,401 - GAugM EPNet train, Epoch [250/295]: loss 0.7208, auc 0.4623, ap 0.5121
2024-01-10 21:51:21,494 - GAugM EPNet train, Epoch [251/295]: loss 0.7209, auc 0.5377, ap 0.5495
2024-01-10 21:51:21,581 - GAugM EPNet train, Epoch [252/295]: loss 0.7210, auc 0.5527, ap 0.5822
2024-01-10 21:51:21,662 - GAugM EPNet train, Epoch [253/295]: loss 0.7209, auc 0.5616, ap 0.5355
2024-01-10 21:51:21,757 - GAugM EPNet train, Epoch [254/295]: loss 0.7210, auc 0.5044, ap 0.5441
2024-01-10 21:51:21,856 - GAugM EPNet train, Epoch [255/295]: loss 0.7209, auc 0.5342, ap 0.5328
2024-01-10 21:51:21,955 - GAugM EPNet train, Epoch [256/295]: loss 0.7210, auc 0.3825, ap 0.4459
2024-01-10 21:51:22,049 - GAugM EPNet train, Epoch [257/295]: loss 0.7210, auc 0.5726, ap 0.5749
2024-01-10 21:51:22,136 - GAugM EPNet train, Epoch [258/295]: loss 0.7208, auc 0.5206, ap 0.5596
2024-01-10 21:51:22,226 - GAugM EPNet train, Epoch [259/295]: loss 0.7208, auc 0.6237, ap 0.5949
2024-01-10 21:51:22,343 - GAugM EPNet train, Epoch [260/295]: loss 0.7210, auc 0.5785, ap 0.5544
2024-01-10 21:51:22,438 - GAugM EPNet train, Epoch [261/295]: loss 0.7209, auc 0.4372, ap 0.4926
2024-01-10 21:51:22,533 - GAugM EPNet train, Epoch [262/295]: loss 0.7208, auc 0.4818, ap 0.4996
2024-01-10 21:51:22,619 - GAugM EPNet train, Epoch [263/295]: loss 0.7209, auc 0.5020, ap 0.5096
2024-01-10 21:51:22,728 - GAugM EPNet train, Epoch [264/295]: loss 0.7210, auc 0.5077, ap 0.5326
2024-01-10 21:51:22,832 - GAugM EPNet train, Epoch [265/295]: loss 0.7209, auc 0.4931, ap 0.5274
2024-01-10 21:51:22,928 - GAugM EPNet train, Epoch [266/295]: loss 0.7209, auc 0.4831, ap 0.4997
2024-01-10 21:51:23,029 - GAugM EPNet train, Epoch [267/295]: loss 0.7210, auc 0.5338, ap 0.5579
2024-01-10 21:51:23,116 - GAugM EPNet train, Epoch [268/295]: loss 0.7210, auc 0.4382, ap 0.4738
2024-01-10 21:51:23,206 - GAugM EPNet train, Epoch [269/295]: loss 0.7209, auc 0.4927, ap 0.5202
2024-01-10 21:51:23,304 - GAugM EPNet train, Epoch [270/295]: loss 0.7210, auc 0.4724, ap 0.5134
2024-01-10 21:51:23,395 - GAugM EPNet train, Epoch [271/295]: loss 0.7209, auc 0.4535, ap 0.4974
2024-01-10 21:51:23,486 - GAugM EPNet train, Epoch [272/295]: loss 0.7209, auc 0.4660, ap 0.5246
2024-01-10 21:51:23,576 - GAugM EPNet train, Epoch [273/295]: loss 0.7209, auc 0.5068, ap 0.5400
2024-01-10 21:51:23,671 - GAugM EPNet train, Epoch [274/295]: loss 0.7209, auc 0.4726, ap 0.4802
2024-01-10 21:51:23,763 - GAugM EPNet train, Epoch [275/295]: loss 0.7208, auc 0.3921, ap 0.4441
2024-01-10 21:51:23,858 - GAugM EPNet train, Epoch [276/295]: loss 0.7210, auc 0.4806, ap 0.5243
2024-01-10 21:51:23,951 - GAugM EPNet train, Epoch [277/295]: loss 0.7208, auc 0.4304, ap 0.4547
2024-01-10 21:51:24,046 - GAugM EPNet train, Epoch [278/295]: loss 0.7209, auc 0.5308, ap 0.5448
2024-01-10 21:51:24,141 - GAugM EPNet train, Epoch [279/295]: loss 0.7209, auc 0.4448, ap 0.5022
2024-01-10 21:51:24,243 - GAugM EPNet train, Epoch [280/295]: loss 0.7209, auc 0.4082, ap 0.4314
2024-01-10 21:51:24,336 - GAugM EPNet train, Epoch [281/295]: loss 0.7209, auc 0.5616, ap 0.5707
2024-01-10 21:51:24,424 - GAugM EPNet train, Epoch [282/295]: loss 0.7209, auc 0.4991, ap 0.5200
2024-01-10 21:51:24,518 - GAugM EPNet train, Epoch [283/295]: loss 0.7209, auc 0.4644, ap 0.4841
2024-01-10 21:51:24,610 - GAugM EPNet train, Epoch [284/295]: loss 0.7209, auc 0.4494, ap 0.4958
2024-01-10 21:51:24,702 - GAugM EPNet train, Epoch [285/295]: loss 0.7209, auc 0.5555, ap 0.5818
2024-01-10 21:51:24,790 - GAugM EPNet train, Epoch [286/295]: loss 0.7209, auc 0.4644, ap 0.5044
2024-01-10 21:51:24,886 - GAugM EPNet train, Epoch [287/295]: loss 0.7209, auc 0.5785, ap 0.5892
2024-01-10 21:51:24,977 - GAugM EPNet train, Epoch [288/295]: loss 0.7210, auc 0.4548, ap 0.5236
2024-01-10 21:51:25,064 - GAugM EPNet train, Epoch [289/295]: loss 0.7209, auc 0.4738, ap 0.4916
2024-01-10 21:51:25,163 - GAugM EPNet train, Epoch [290/295]: loss 0.7210, auc 0.4610, ap 0.4749
2024-01-10 21:51:25,261 - GAugM EPNet train, Epoch [291/295]: loss 0.7210, auc 0.4315, ap 0.4659
2024-01-10 21:51:25,360 - GAugM EPNet train, Epoch [292/295]: loss 0.7209, auc 0.4361, ap 0.4685
2024-01-10 21:51:25,458 - GAugM EPNet train, Epoch [293/295]: loss 0.7210, auc 0.4203, ap 0.4559
2024-01-10 21:51:25,547 - GAugM EPNet train, Epoch [294/295]: loss 0.7211, auc 0.4875, ap 0.5019
2024-01-10 21:51:25,636 - GAugM EPNet train, Epoch [295/295]: loss 0.7209, auc 0.4697, ap 0.4811
2024-01-10 21:51:25,656 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f6ceaed8090>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:51:26,407 - GAugM EPNet train, Epoch [  1/295]: loss 0.7210, auc 0.4637, ap 0.4791
2024-01-10 21:51:26,499 - GAugM EPNet train, Epoch [  2/295]: loss 0.7210, auc 0.4915, ap 0.5093
2024-01-10 21:51:26,580 - GAugM EPNet train, Epoch [  3/295]: loss 0.7209, auc 0.5548, ap 0.5293
2024-01-10 21:51:26,655 - GAugM EPNet train, Epoch [  4/295]: loss 0.7209, auc 0.4769, ap 0.5004
2024-01-10 21:51:26,745 - GAugM EPNet train, Epoch [  5/295]: loss 0.7209, auc 0.5968, ap 0.5793
2024-01-10 21:51:26,821 - GAugM EPNet train, Epoch [  6/295]: loss 0.7209, auc 0.5413, ap 0.5272
2024-01-10 21:51:26,897 - GAugM EPNet train, Epoch [  7/295]: loss 0.7209, auc 0.4964, ap 0.4917
2024-01-10 21:51:26,973 - GAugM EPNet train, Epoch [  8/295]: loss 0.7210, auc 0.4591, ap 0.4713
2024-01-10 21:51:27,052 - GAugM EPNet train, Epoch [  9/295]: loss 0.7209, auc 0.4580, ap 0.4669
2024-01-10 21:51:27,129 - GAugM EPNet train, Epoch [ 10/295]: loss 0.7208, auc 0.4861, ap 0.5212
2024-01-10 21:51:27,214 - GAugM EPNet train, Epoch [ 11/295]: loss 0.7209, auc 0.5224, ap 0.5211
2024-01-10 21:51:27,294 - GAugM EPNet train, Epoch [ 12/295]: loss 0.7210, auc 0.4616, ap 0.4619
2024-01-10 21:51:27,369 - GAugM EPNet train, Epoch [ 13/295]: loss 0.7209, auc 0.6054, ap 0.6140
2024-01-10 21:51:27,447 - GAugM EPNet train, Epoch [ 14/295]: loss 0.7209, auc 0.5370, ap 0.5478
2024-01-10 21:51:27,522 - GAugM EPNet train, Epoch [ 15/295]: loss 0.7210, auc 0.4110, ap 0.4698
2024-01-10 21:51:27,597 - GAugM EPNet train, Epoch [ 16/295]: loss 0.7209, auc 0.5438, ap 0.5646
2024-01-10 21:51:27,677 - GAugM EPNet train, Epoch [ 17/295]: loss 0.7210, auc 0.5103, ap 0.5060
2024-01-10 21:51:27,750 - GAugM EPNet train, Epoch [ 18/295]: loss 0.7210, auc 0.5954, ap 0.5895
2024-01-10 21:51:27,825 - GAugM EPNet train, Epoch [ 19/295]: loss 0.7209, auc 0.4623, ap 0.4790
2024-01-10 21:51:27,904 - GAugM EPNet train, Epoch [ 20/295]: loss 0.7210, auc 0.5046, ap 0.5289
2024-01-10 21:51:27,982 - GAugM EPNet train, Epoch [ 21/295]: loss 0.7209, auc 0.5295, ap 0.5595
2024-01-10 21:51:28,061 - GAugM EPNet train, Epoch [ 22/295]: loss 0.7210, auc 0.4316, ap 0.4670
2024-01-10 21:51:28,136 - GAugM EPNet train, Epoch [ 23/295]: loss 0.7208, auc 0.4972, ap 0.5029
2024-01-10 21:51:28,210 - GAugM EPNet train, Epoch [ 24/295]: loss 0.7209, auc 0.5132, ap 0.5275
2024-01-10 21:51:28,286 - GAugM EPNet train, Epoch [ 25/295]: loss 0.7209, auc 0.4975, ap 0.4919
2024-01-10 21:51:28,366 - GAugM EPNet train, Epoch [ 26/295]: loss 0.7210, auc 0.5502, ap 0.5888
2024-01-10 21:51:28,440 - GAugM EPNet train, Epoch [ 27/295]: loss 0.7209, auc 0.3868, ap 0.4442
2024-01-10 21:51:28,514 - GAugM EPNet train, Epoch [ 28/295]: loss 0.7209, auc 0.5253, ap 0.5528
2024-01-10 21:51:28,599 - GAugM EPNet train, Epoch [ 29/295]: loss 0.7210, auc 0.4655, ap 0.4684
2024-01-10 21:51:28,678 - GAugM EPNet train, Epoch [ 30/295]: loss 0.7209, auc 0.5196, ap 0.5219
2024-01-10 21:51:28,752 - GAugM EPNet train, Epoch [ 31/295]: loss 0.7208, auc 0.4911, ap 0.4967
2024-01-10 21:51:28,845 - GAugM EPNet train, Epoch [ 32/295]: loss 0.7210, auc 0.5449, ap 0.5200
2024-01-10 21:51:28,920 - GAugM EPNet train, Epoch [ 33/295]: loss 0.7209, auc 0.5427, ap 0.5450
2024-01-10 21:51:28,999 - GAugM EPNet train, Epoch [ 34/295]: loss 0.7209, auc 0.4986, ap 0.5020
2024-01-10 21:51:29,075 - GAugM EPNet train, Epoch [ 35/295]: loss 0.7209, auc 0.5676, ap 0.5505
2024-01-10 21:51:29,162 - GAugM EPNet train, Epoch [ 36/295]: loss 0.7209, auc 0.5619, ap 0.5811
2024-01-10 21:51:29,239 - GAugM EPNet train, Epoch [ 37/295]: loss 0.7209, auc 0.4530, ap 0.4790
2024-01-10 21:51:29,314 - GAugM EPNet train, Epoch [ 38/295]: loss 0.7209, auc 0.4306, ap 0.4438
2024-01-10 21:51:29,410 - GAugM EPNet train, Epoch [ 39/295]: loss 0.7208, auc 0.5199, ap 0.5507
2024-01-10 21:51:29,492 - GAugM EPNet train, Epoch [ 40/295]: loss 0.7210, auc 0.5605, ap 0.5431
2024-01-10 21:51:29,573 - GAugM EPNet train, Epoch [ 41/295]: loss 0.7210, auc 0.4954, ap 0.5150
2024-01-10 21:51:29,653 - GAugM EPNet train, Epoch [ 42/295]: loss 0.7209, auc 0.5160, ap 0.5221
2024-01-10 21:51:29,732 - GAugM EPNet train, Epoch [ 43/295]: loss 0.7208, auc 0.3989, ap 0.4380
2024-01-10 21:51:29,810 - GAugM EPNet train, Epoch [ 44/295]: loss 0.7208, auc 0.4608, ap 0.4872
2024-01-10 21:51:29,885 - GAugM EPNet train, Epoch [ 45/295]: loss 0.7209, auc 0.4961, ap 0.5279
2024-01-10 21:51:29,960 - GAugM EPNet train, Epoch [ 46/295]: loss 0.7209, auc 0.4776, ap 0.4968
2024-01-10 21:51:30,044 - GAugM EPNet train, Epoch [ 47/295]: loss 0.7210, auc 0.4402, ap 0.4846
2024-01-10 21:51:30,120 - GAugM EPNet train, Epoch [ 48/295]: loss 0.7210, auc 0.5630, ap 0.5948
2024-01-10 21:51:30,195 - GAugM EPNet train, Epoch [ 49/295]: loss 0.7209, auc 0.4861, ap 0.5146
2024-01-10 21:51:30,273 - GAugM EPNet train, Epoch [ 50/295]: loss 0.7210, auc 0.5862, ap 0.5854
2024-01-10 21:51:30,352 - GAugM EPNet train, Epoch [ 51/295]: loss 0.7210, auc 0.4801, ap 0.5355
2024-01-10 21:51:30,428 - GAugM EPNet train, Epoch [ 52/295]: loss 0.7209, auc 0.4626, ap 0.5213
2024-01-10 21:51:30,502 - GAugM EPNet train, Epoch [ 53/295]: loss 0.7209, auc 0.5157, ap 0.5293
2024-01-10 21:51:30,577 - GAugM EPNet train, Epoch [ 54/295]: loss 0.7211, auc 0.5420, ap 0.5160
2024-01-10 21:51:30,669 - GAugM EPNet train, Epoch [ 55/295]: loss 0.7209, auc 0.5837, ap 0.5686
2024-01-10 21:51:30,748 - GAugM EPNet train, Epoch [ 56/295]: loss 0.7208, auc 0.4961, ap 0.5065
2024-01-10 21:51:30,822 - GAugM EPNet train, Epoch [ 57/295]: loss 0.7209, auc 0.4359, ap 0.4654
2024-01-10 21:51:30,898 - GAugM EPNet train, Epoch [ 58/295]: loss 0.7210, auc 0.4758, ap 0.5357
2024-01-10 21:51:30,985 - GAugM EPNet train, Epoch [ 59/295]: loss 0.7211, auc 0.5313, ap 0.5419
2024-01-10 21:51:31,063 - GAugM EPNet train, Epoch [ 60/295]: loss 0.7210, auc 0.5046, ap 0.5034
2024-01-10 21:51:31,139 - GAugM EPNet train, Epoch [ 61/295]: loss 0.7209, auc 0.5231, ap 0.5114
2024-01-10 21:51:31,217 - GAugM EPNet train, Epoch [ 62/295]: loss 0.7210, auc 0.5107, ap 0.5218
2024-01-10 21:51:31,297 - GAugM EPNet train, Epoch [ 63/295]: loss 0.7208, auc 0.5028, ap 0.5015
2024-01-10 21:51:31,383 - GAugM EPNet train, Epoch [ 64/295]: loss 0.7208, auc 0.4907, ap 0.4987
2024-01-10 21:51:31,472 - GAugM EPNet train, Epoch [ 65/295]: loss 0.7208, auc 0.6054, ap 0.6059
2024-01-10 21:51:31,553 - GAugM EPNet train, Epoch [ 66/295]: loss 0.7209, auc 0.5345, ap 0.5347
2024-01-10 21:51:31,638 - GAugM EPNet train, Epoch [ 67/295]: loss 0.7209, auc 0.5085, ap 0.5159
2024-01-10 21:51:31,717 - GAugM EPNet train, Epoch [ 68/295]: loss 0.7210, auc 0.4911, ap 0.5064
2024-01-10 21:51:31,799 - GAugM EPNet train, Epoch [ 69/295]: loss 0.7210, auc 0.4769, ap 0.5309
2024-01-10 21:51:31,892 - GAugM EPNet train, Epoch [ 70/295]: loss 0.7210, auc 0.4028, ap 0.4341
2024-01-10 21:51:31,989 - GAugM EPNet train, Epoch [ 71/295]: loss 0.7210, auc 0.4818, ap 0.4799
2024-01-10 21:51:32,084 - GAugM EPNet train, Epoch [ 72/295]: loss 0.7210, auc 0.4619, ap 0.4940
2024-01-10 21:51:32,184 - GAugM EPNet train, Epoch [ 73/295]: loss 0.7209, auc 0.4932, ap 0.4862
2024-01-10 21:51:32,269 - GAugM EPNet train, Epoch [ 74/295]: loss 0.7209, auc 0.5267, ap 0.5117
2024-01-10 21:51:32,357 - GAugM EPNet train, Epoch [ 75/295]: loss 0.7210, auc 0.4883, ap 0.5343
2024-01-10 21:51:32,437 - GAugM EPNet train, Epoch [ 76/295]: loss 0.7209, auc 0.5021, ap 0.4948
2024-01-10 21:51:32,517 - GAugM EPNet train, Epoch [ 77/295]: loss 0.7208, auc 0.5684, ap 0.6112
2024-01-10 21:51:32,612 - GAugM EPNet train, Epoch [ 78/295]: loss 0.7209, auc 0.5224, ap 0.5359
2024-01-10 21:51:32,705 - GAugM EPNet train, Epoch [ 79/295]: loss 0.7208, auc 0.5292, ap 0.5261
2024-01-10 21:51:32,790 - GAugM EPNet train, Epoch [ 80/295]: loss 0.7209, auc 0.5933, ap 0.5552
2024-01-10 21:51:32,867 - GAugM EPNet train, Epoch [ 81/295]: loss 0.7209, auc 0.5605, ap 0.5413
2024-01-10 21:51:32,964 - GAugM EPNet train, Epoch [ 82/295]: loss 0.7210, auc 0.5616, ap 0.5461
2024-01-10 21:51:33,045 - GAugM EPNet train, Epoch [ 83/295]: loss 0.7209, auc 0.4039, ap 0.4771
2024-01-10 21:51:33,133 - GAugM EPNet train, Epoch [ 84/295]: loss 0.7209, auc 0.4356, ap 0.4521
2024-01-10 21:51:33,215 - GAugM EPNet train, Epoch [ 85/295]: loss 0.7210, auc 0.4377, ap 0.4479
2024-01-10 21:51:33,308 - GAugM EPNet train, Epoch [ 86/295]: loss 0.7208, auc 0.4737, ap 0.5019
2024-01-10 21:51:33,391 - GAugM EPNet train, Epoch [ 87/295]: loss 0.7209, auc 0.5146, ap 0.5306
2024-01-10 21:51:33,470 - GAugM EPNet train, Epoch [ 88/295]: loss 0.7210, auc 0.4893, ap 0.5160
2024-01-10 21:51:33,560 - GAugM EPNet train, Epoch [ 89/295]: loss 0.7210, auc 0.4455, ap 0.4929
2024-01-10 21:51:33,644 - GAugM EPNet train, Epoch [ 90/295]: loss 0.7209, auc 0.5206, ap 0.5623
2024-01-10 21:51:33,734 - GAugM EPNet train, Epoch [ 91/295]: loss 0.7208, auc 0.5349, ap 0.5266
2024-01-10 21:51:33,813 - GAugM EPNet train, Epoch [ 92/295]: loss 0.7209, auc 0.6118, ap 0.6137
2024-01-10 21:51:33,895 - GAugM EPNet train, Epoch [ 93/295]: loss 0.7209, auc 0.4210, ap 0.4950
2024-01-10 21:51:33,975 - GAugM EPNet train, Epoch [ 94/295]: loss 0.7210, auc 0.4473, ap 0.4665
2024-01-10 21:51:34,052 - GAugM EPNet train, Epoch [ 95/295]: loss 0.7210, auc 0.5320, ap 0.5244
2024-01-10 21:51:34,138 - GAugM EPNet train, Epoch [ 96/295]: loss 0.7209, auc 0.5217, ap 0.5085
2024-01-10 21:51:34,217 - GAugM EPNet train, Epoch [ 97/295]: loss 0.7209, auc 0.4292, ap 0.4616
2024-01-10 21:51:34,295 - GAugM EPNet train, Epoch [ 98/295]: loss 0.7209, auc 0.3679, ap 0.4292
2024-01-10 21:51:34,377 - GAugM EPNet train, Epoch [ 99/295]: loss 0.7209, auc 0.5399, ap 0.5512
2024-01-10 21:51:34,455 - GAugM EPNet train, Epoch [100/295]: loss 0.7210, auc 0.4911, ap 0.5027
2024-01-10 21:51:34,534 - GAugM EPNet train, Epoch [101/295]: loss 0.7210, auc 0.5231, ap 0.5727
2024-01-10 21:51:34,620 - GAugM EPNet train, Epoch [102/295]: loss 0.7209, auc 0.4366, ap 0.4514
2024-01-10 21:51:34,700 - GAugM EPNet train, Epoch [103/295]: loss 0.7209, auc 0.5025, ap 0.5460
2024-01-10 21:51:34,776 - GAugM EPNet train, Epoch [104/295]: loss 0.7209, auc 0.4032, ap 0.4558
2024-01-10 21:51:34,855 - GAugM EPNet train, Epoch [105/295]: loss 0.7209, auc 0.4658, ap 0.4882
2024-01-10 21:51:34,935 - GAugM EPNet train, Epoch [106/295]: loss 0.7210, auc 0.5039, ap 0.5160
2024-01-10 21:51:35,012 - GAugM EPNet train, Epoch [107/295]: loss 0.7210, auc 0.4744, ap 0.5022
2024-01-10 21:51:35,092 - GAugM EPNet train, Epoch [108/295]: loss 0.7208, auc 0.5502, ap 0.5494
2024-01-10 21:51:35,167 - GAugM EPNet train, Epoch [109/295]: loss 0.7210, auc 0.4494, ap 0.4912
2024-01-10 21:51:35,250 - GAugM EPNet train, Epoch [110/295]: loss 0.7209, auc 0.4761, ap 0.4855
2024-01-10 21:51:35,329 - GAugM EPNet train, Epoch [111/295]: loss 0.7210, auc 0.5651, ap 0.5887
2024-01-10 21:51:35,407 - GAugM EPNet train, Epoch [112/295]: loss 0.7209, auc 0.4776, ap 0.4960
2024-01-10 21:51:35,484 - GAugM EPNet train, Epoch [113/295]: loss 0.7210, auc 0.5516, ap 0.5876
2024-01-10 21:51:35,560 - GAugM EPNet train, Epoch [114/295]: loss 0.7209, auc 0.5196, ap 0.5084
2024-01-10 21:51:35,637 - GAugM EPNet train, Epoch [115/295]: loss 0.7210, auc 0.4818, ap 0.4843
2024-01-10 21:51:35,723 - GAugM EPNet train, Epoch [116/295]: loss 0.7209, auc 0.4968, ap 0.4935
2024-01-10 21:51:35,803 - GAugM EPNet train, Epoch [117/295]: loss 0.7208, auc 0.4619, ap 0.4750
2024-01-10 21:51:35,884 - GAugM EPNet train, Epoch [118/295]: loss 0.7209, auc 0.5612, ap 0.5712
2024-01-10 21:51:35,961 - GAugM EPNet train, Epoch [119/295]: loss 0.7209, auc 0.5078, ap 0.5087
2024-01-10 21:51:36,039 - GAugM EPNet train, Epoch [120/295]: loss 0.7210, auc 0.5018, ap 0.5090
2024-01-10 21:51:36,120 - GAugM EPNet train, Epoch [121/295]: loss 0.7210, auc 0.4541, ap 0.4864
2024-01-10 21:51:36,198 - GAugM EPNet train, Epoch [122/295]: loss 0.7209, auc 0.3943, ap 0.4752
2024-01-10 21:51:36,275 - GAugM EPNet train, Epoch [123/295]: loss 0.7209, auc 0.4749, ap 0.4977
2024-01-10 21:51:36,351 - GAugM EPNet train, Epoch [124/295]: loss 0.7210, auc 0.4697, ap 0.4970
2024-01-10 21:51:36,445 - GAugM EPNet train, Epoch [125/295]: loss 0.7209, auc 0.4733, ap 0.4853
2024-01-10 21:51:36,523 - GAugM EPNet train, Epoch [126/295]: loss 0.7210, auc 0.5406, ap 0.5309
2024-01-10 21:51:36,600 - GAugM EPNet train, Epoch [127/295]: loss 0.7209, auc 0.4181, ap 0.4467
2024-01-10 21:51:36,683 - GAugM EPNet train, Epoch [128/295]: loss 0.7210, auc 0.5413, ap 0.5155
2024-01-10 21:51:36,765 - GAugM EPNet train, Epoch [129/295]: loss 0.7208, auc 0.4658, ap 0.4787
2024-01-10 21:51:36,859 - GAugM EPNet train, Epoch [130/295]: loss 0.7210, auc 0.4078, ap 0.4420
2024-01-10 21:51:36,949 - GAugM EPNet train, Epoch [131/295]: loss 0.7210, auc 0.5025, ap 0.5336
2024-01-10 21:51:37,040 - GAugM EPNet train, Epoch [132/295]: loss 0.7209, auc 0.5466, ap 0.5376
2024-01-10 21:51:37,132 - GAugM EPNet train, Epoch [133/295]: loss 0.7209, auc 0.4338, ap 0.4890
2024-01-10 21:51:37,230 - GAugM EPNet train, Epoch [134/295]: loss 0.7210, auc 0.4441, ap 0.4717
2024-01-10 21:51:37,314 - GAugM EPNet train, Epoch [135/295]: loss 0.7209, auc 0.4049, ap 0.4558
2024-01-10 21:51:37,394 - GAugM EPNet train, Epoch [136/295]: loss 0.7209, auc 0.4918, ap 0.5126
2024-01-10 21:51:37,487 - GAugM EPNet train, Epoch [137/295]: loss 0.7210, auc 0.4292, ap 0.4677
2024-01-10 21:51:37,582 - GAugM EPNet train, Epoch [138/295]: loss 0.7210, auc 0.5577, ap 0.5336
2024-01-10 21:51:37,674 - GAugM EPNet train, Epoch [139/295]: loss 0.7210, auc 0.4434, ap 0.4707
2024-01-10 21:51:37,761 - GAugM EPNet train, Epoch [140/295]: loss 0.7209, auc 0.5196, ap 0.5293
2024-01-10 21:51:37,855 - GAugM EPNet train, Epoch [141/295]: loss 0.7209, auc 0.5651, ap 0.5269
2024-01-10 21:51:37,946 - GAugM EPNet train, Epoch [142/295]: loss 0.7209, auc 0.5979, ap 0.5890
2024-01-10 21:51:38,035 - GAugM EPNet train, Epoch [143/295]: loss 0.7209, auc 0.4242, ap 0.4548
2024-01-10 21:51:38,139 - GAugM EPNet train, Epoch [144/295]: loss 0.7209, auc 0.4929, ap 0.5130
2024-01-10 21:51:38,231 - GAugM EPNet train, Epoch [145/295]: loss 0.7209, auc 0.4797, ap 0.5227
2024-01-10 21:51:38,320 - GAugM EPNet train, Epoch [146/295]: loss 0.7209, auc 0.4761, ap 0.5212
2024-01-10 21:51:38,410 - GAugM EPNet train, Epoch [147/295]: loss 0.7209, auc 0.5894, ap 0.5996
2024-01-10 21:51:38,508 - GAugM EPNet train, Epoch [148/295]: loss 0.7209, auc 0.4929, ap 0.5021
2024-01-10 21:51:38,601 - GAugM EPNet train, Epoch [149/295]: loss 0.7208, auc 0.4373, ap 0.4797
2024-01-10 21:51:38,690 - GAugM EPNet train, Epoch [150/295]: loss 0.7209, auc 0.5506, ap 0.5277
2024-01-10 21:51:38,788 - GAugM EPNet train, Epoch [151/295]: loss 0.7209, auc 0.5363, ap 0.5435
2024-01-10 21:51:38,885 - GAugM EPNet train, Epoch [152/295]: loss 0.7209, auc 0.5584, ap 0.5744
2024-01-10 21:51:38,969 - GAugM EPNet train, Epoch [153/295]: loss 0.7209, auc 0.4616, ap 0.5123
2024-01-10 21:51:39,052 - GAugM EPNet train, Epoch [154/295]: loss 0.7209, auc 0.5712, ap 0.5839
2024-01-10 21:51:39,137 - GAugM EPNet train, Epoch [155/295]: loss 0.7209, auc 0.5651, ap 0.5752
2024-01-10 21:51:39,229 - GAugM EPNet train, Epoch [156/295]: loss 0.7209, auc 0.4349, ap 0.4892
2024-01-10 21:51:39,308 - GAugM EPNet train, Epoch [157/295]: loss 0.7209, auc 0.5534, ap 0.5510
2024-01-10 21:51:39,392 - GAugM EPNet train, Epoch [158/295]: loss 0.7208, auc 0.4420, ap 0.4655
2024-01-10 21:51:39,488 - GAugM EPNet train, Epoch [159/295]: loss 0.7208, auc 0.4811, ap 0.4823
2024-01-10 21:51:39,579 - GAugM EPNet train, Epoch [160/295]: loss 0.7209, auc 0.6096, ap 0.6139
2024-01-10 21:51:39,676 - GAugM EPNet train, Epoch [161/295]: loss 0.7209, auc 0.5651, ap 0.5455
2024-01-10 21:51:39,768 - GAugM EPNet train, Epoch [162/295]: loss 0.7209, auc 0.5064, ap 0.5185
2024-01-10 21:51:39,854 - GAugM EPNet train, Epoch [163/295]: loss 0.7209, auc 0.4836, ap 0.4849
2024-01-10 21:51:39,943 - GAugM EPNet train, Epoch [164/295]: loss 0.7211, auc 0.5491, ap 0.5280
2024-01-10 21:51:40,028 - GAugM EPNet train, Epoch [165/295]: loss 0.7210, auc 0.4480, ap 0.4710
2024-01-10 21:51:40,110 - GAugM EPNet train, Epoch [166/295]: loss 0.7208, auc 0.5388, ap 0.5189
2024-01-10 21:51:40,197 - GAugM EPNet train, Epoch [167/295]: loss 0.7209, auc 0.3971, ap 0.4488
2024-01-10 21:51:40,297 - GAugM EPNet train, Epoch [168/295]: loss 0.7209, auc 0.5570, ap 0.5837
2024-01-10 21:51:40,380 - GAugM EPNet train, Epoch [169/295]: loss 0.7209, auc 0.5498, ap 0.5505
2024-01-10 21:51:40,466 - GAugM EPNet train, Epoch [170/295]: loss 0.7210, auc 0.5174, ap 0.4980
2024-01-10 21:51:40,552 - GAugM EPNet train, Epoch [171/295]: loss 0.7209, auc 0.5110, ap 0.5188
2024-01-10 21:51:40,635 - GAugM EPNet train, Epoch [172/295]: loss 0.7208, auc 0.4722, ap 0.4852
2024-01-10 21:51:40,718 - GAugM EPNet train, Epoch [173/295]: loss 0.7209, auc 0.5701, ap 0.5868
2024-01-10 21:51:40,802 - GAugM EPNet train, Epoch [174/295]: loss 0.7209, auc 0.4712, ap 0.4693
2024-01-10 21:51:40,922 - GAugM EPNet train, Epoch [175/295]: loss 0.7209, auc 0.6104, ap 0.5813
2024-01-10 21:51:41,021 - GAugM EPNet train, Epoch [176/295]: loss 0.7209, auc 0.4491, ap 0.4708
2024-01-10 21:51:41,117 - GAugM EPNet train, Epoch [177/295]: loss 0.7210, auc 0.5053, ap 0.4918
2024-01-10 21:51:41,206 - GAugM EPNet train, Epoch [178/295]: loss 0.7210, auc 0.5598, ap 0.5931
2024-01-10 21:51:41,295 - GAugM EPNet train, Epoch [179/295]: loss 0.7210, auc 0.4135, ap 0.4616
2024-01-10 21:51:41,383 - GAugM EPNet train, Epoch [180/295]: loss 0.7210, auc 0.5260, ap 0.5470
2024-01-10 21:51:41,474 - GAugM EPNet train, Epoch [181/295]: loss 0.7209, auc 0.4238, ap 0.4695
2024-01-10 21:51:41,561 - GAugM EPNet train, Epoch [182/295]: loss 0.7209, auc 0.5117, ap 0.5143
2024-01-10 21:51:41,649 - GAugM EPNet train, Epoch [183/295]: loss 0.7210, auc 0.5107, ap 0.5316
2024-01-10 21:51:41,736 - GAugM EPNet train, Epoch [184/295]: loss 0.7209, auc 0.4737, ap 0.4963
2024-01-10 21:51:41,825 - GAugM EPNet train, Epoch [185/295]: loss 0.7209, auc 0.4811, ap 0.4882
2024-01-10 21:51:41,913 - GAugM EPNet train, Epoch [186/295]: loss 0.7208, auc 0.5100, ap 0.5256
2024-01-10 21:51:42,002 - GAugM EPNet train, Epoch [187/295]: loss 0.7209, auc 0.5103, ap 0.5053
2024-01-10 21:51:42,102 - GAugM EPNet train, Epoch [188/295]: loss 0.7209, auc 0.4779, ap 0.4939
2024-01-10 21:51:42,192 - GAugM EPNet train, Epoch [189/295]: loss 0.7209, auc 0.6150, ap 0.6241
2024-01-10 21:51:42,279 - GAugM EPNet train, Epoch [190/295]: loss 0.7209, auc 0.3971, ap 0.4269
2024-01-10 21:51:42,384 - GAugM EPNet train, Epoch [191/295]: loss 0.7209, auc 0.4491, ap 0.5005
2024-01-10 21:51:42,476 - GAugM EPNet train, Epoch [192/295]: loss 0.7209, auc 0.5324, ap 0.5077
2024-01-10 21:51:42,565 - GAugM EPNet train, Epoch [193/295]: loss 0.7209, auc 0.5317, ap 0.5226
2024-01-10 21:51:42,658 - GAugM EPNet train, Epoch [194/295]: loss 0.7209, auc 0.4462, ap 0.4704
2024-01-10 21:51:42,761 - GAugM EPNet train, Epoch [195/295]: loss 0.7209, auc 0.3836, ap 0.4305
2024-01-10 21:51:42,866 - GAugM EPNet train, Epoch [196/295]: loss 0.7208, auc 0.5488, ap 0.5324
2024-01-10 21:51:42,966 - GAugM EPNet train, Epoch [197/295]: loss 0.7210, auc 0.5196, ap 0.5346
2024-01-10 21:51:43,055 - GAugM EPNet train, Epoch [198/295]: loss 0.7210, auc 0.5310, ap 0.5220
2024-01-10 21:51:43,150 - GAugM EPNet train, Epoch [199/295]: loss 0.7209, auc 0.5000, ap 0.5040
2024-01-10 21:51:43,242 - GAugM EPNet train, Epoch [200/295]: loss 0.7210, auc 0.5103, ap 0.5095
2024-01-10 21:51:43,329 - GAugM EPNet train, Epoch [201/295]: loss 0.7209, auc 0.5107, ap 0.5277
2024-01-10 21:51:43,417 - GAugM EPNet train, Epoch [202/295]: loss 0.7210, auc 0.5726, ap 0.6229
2024-01-10 21:51:43,507 - GAugM EPNet train, Epoch [203/295]: loss 0.7210, auc 0.4761, ap 0.5065
2024-01-10 21:51:43,594 - GAugM EPNet train, Epoch [204/295]: loss 0.7209, auc 0.4562, ap 0.4546
2024-01-10 21:51:43,684 - GAugM EPNet train, Epoch [205/295]: loss 0.7209, auc 0.4897, ap 0.5418
2024-01-10 21:51:43,773 - GAugM EPNet train, Epoch [206/295]: loss 0.7209, auc 0.4103, ap 0.4518
2024-01-10 21:51:43,866 - GAugM EPNet train, Epoch [207/295]: loss 0.7210, auc 0.4722, ap 0.4873
2024-01-10 21:51:43,956 - GAugM EPNet train, Epoch [208/295]: loss 0.7209, auc 0.4466, ap 0.5481
2024-01-10 21:51:44,049 - GAugM EPNet train, Epoch [209/295]: loss 0.7210, auc 0.5103, ap 0.5092
2024-01-10 21:51:44,134 - GAugM EPNet train, Epoch [210/295]: loss 0.7209, auc 0.4598, ap 0.4821
2024-01-10 21:51:44,224 - GAugM EPNet train, Epoch [211/295]: loss 0.7210, auc 0.4185, ap 0.4582
2024-01-10 21:51:44,314 - GAugM EPNet train, Epoch [212/295]: loss 0.7210, auc 0.4598, ap 0.4607
2024-01-10 21:51:44,406 - GAugM EPNet train, Epoch [213/295]: loss 0.7208, auc 0.6403, ap 0.6428
2024-01-10 21:51:44,499 - GAugM EPNet train, Epoch [214/295]: loss 0.7210, auc 0.4843, ap 0.4987
2024-01-10 21:51:44,585 - GAugM EPNet train, Epoch [215/295]: loss 0.7210, auc 0.4747, ap 0.5051
2024-01-10 21:51:44,675 - GAugM EPNet train, Epoch [216/295]: loss 0.7209, auc 0.5538, ap 0.5351
2024-01-10 21:51:44,761 - GAugM EPNet train, Epoch [217/295]: loss 0.7209, auc 0.5609, ap 0.5531
2024-01-10 21:51:44,847 - GAugM EPNet train, Epoch [218/295]: loss 0.7209, auc 0.5648, ap 0.5925
2024-01-10 21:51:44,939 - GAugM EPNet train, Epoch [219/295]: loss 0.7208, auc 0.4555, ap 0.4668
2024-01-10 21:51:45,027 - GAugM EPNet train, Epoch [220/295]: loss 0.7210, auc 0.4751, ap 0.5160
2024-01-10 21:51:45,119 - GAugM EPNet train, Epoch [221/295]: loss 0.7209, auc 0.5406, ap 0.5170
2024-01-10 21:51:45,219 - GAugM EPNet train, Epoch [222/295]: loss 0.7209, auc 0.4676, ap 0.4803
2024-01-10 21:51:45,303 - GAugM EPNet train, Epoch [223/295]: loss 0.7209, auc 0.6061, ap 0.6282
2024-01-10 21:51:45,394 - GAugM EPNet train, Epoch [224/295]: loss 0.7210, auc 0.4160, ap 0.4526
2024-01-10 21:51:45,491 - GAugM EPNet train, Epoch [225/295]: loss 0.7209, auc 0.4341, ap 0.4771
2024-01-10 21:51:45,580 - GAugM EPNet train, Epoch [226/295]: loss 0.7210, auc 0.4334, ap 0.4718
2024-01-10 21:51:45,673 - GAugM EPNet train, Epoch [227/295]: loss 0.7210, auc 0.5039, ap 0.5237
2024-01-10 21:51:45,765 - GAugM EPNet train, Epoch [228/295]: loss 0.7209, auc 0.4608, ap 0.4667
2024-01-10 21:51:45,852 - GAugM EPNet train, Epoch [229/295]: loss 0.7209, auc 0.4530, ap 0.4850
2024-01-10 21:51:45,945 - GAugM EPNet train, Epoch [230/295]: loss 0.7209, auc 0.5121, ap 0.5359
2024-01-10 21:51:46,032 - GAugM EPNet train, Epoch [231/295]: loss 0.7209, auc 0.5153, ap 0.5439
2024-01-10 21:51:46,128 - GAugM EPNet train, Epoch [232/295]: loss 0.7209, auc 0.4989, ap 0.5122
2024-01-10 21:51:46,215 - GAugM EPNet train, Epoch [233/295]: loss 0.7210, auc 0.5335, ap 0.5250
2024-01-10 21:51:46,294 - GAugM EPNet train, Epoch [234/295]: loss 0.7209, auc 0.4199, ap 0.4849
2024-01-10 21:51:46,391 - GAugM EPNet train, Epoch [235/295]: loss 0.7209, auc 0.4794, ap 0.4880
2024-01-10 21:51:46,489 - GAugM EPNet train, Epoch [236/295]: loss 0.7209, auc 0.5488, ap 0.5495
2024-01-10 21:51:46,580 - GAugM EPNet train, Epoch [237/295]: loss 0.7210, auc 0.4790, ap 0.5152
2024-01-10 21:51:46,670 - GAugM EPNet train, Epoch [238/295]: loss 0.7210, auc 0.5164, ap 0.5126
2024-01-10 21:51:46,758 - GAugM EPNet train, Epoch [239/295]: loss 0.7209, auc 0.4715, ap 0.5238
2024-01-10 21:51:46,855 - GAugM EPNet train, Epoch [240/295]: loss 0.7209, auc 0.4879, ap 0.4948
2024-01-10 21:51:46,948 - GAugM EPNet train, Epoch [241/295]: loss 0.7209, auc 0.5105, ap 0.5150
2024-01-10 21:51:47,042 - GAugM EPNet train, Epoch [242/295]: loss 0.7210, auc 0.4722, ap 0.4731
2024-01-10 21:51:47,122 - GAugM EPNet train, Epoch [243/295]: loss 0.7210, auc 0.5488, ap 0.5781
2024-01-10 21:51:47,213 - GAugM EPNet train, Epoch [244/295]: loss 0.7209, auc 0.5064, ap 0.5103
2024-01-10 21:51:47,303 - GAugM EPNet train, Epoch [245/295]: loss 0.7210, auc 0.4199, ap 0.4713
2024-01-10 21:51:47,384 - GAugM EPNet train, Epoch [246/295]: loss 0.7208, auc 0.5299, ap 0.5234
2024-01-10 21:51:47,471 - GAugM EPNet train, Epoch [247/295]: loss 0.7209, auc 0.5278, ap 0.5238
2024-01-10 21:51:47,561 - GAugM EPNet train, Epoch [248/295]: loss 0.7211, auc 0.4922, ap 0.5055
2024-01-10 21:51:47,650 - GAugM EPNet train, Epoch [249/295]: loss 0.7209, auc 0.5342, ap 0.5082
2024-01-10 21:51:47,727 - GAugM EPNet train, Epoch [250/295]: loss 0.7208, auc 0.4797, ap 0.4886
2024-01-10 21:51:47,802 - GAugM EPNet train, Epoch [251/295]: loss 0.7209, auc 0.4865, ap 0.5294
2024-01-10 21:51:47,886 - GAugM EPNet train, Epoch [252/295]: loss 0.7210, auc 0.5196, ap 0.5176
2024-01-10 21:51:47,963 - GAugM EPNet train, Epoch [253/295]: loss 0.7209, auc 0.5979, ap 0.5860
2024-01-10 21:51:48,041 - GAugM EPNet train, Epoch [254/295]: loss 0.7210, auc 0.5260, ap 0.5315
2024-01-10 21:51:48,122 - GAugM EPNet train, Epoch [255/295]: loss 0.7209, auc 0.4060, ap 0.4729
2024-01-10 21:51:48,199 - GAugM EPNet train, Epoch [256/295]: loss 0.7210, auc 0.3708, ap 0.4859
2024-01-10 21:51:48,278 - GAugM EPNet train, Epoch [257/295]: loss 0.7210, auc 0.5466, ap 0.5586
2024-01-10 21:51:48,369 - GAugM EPNet train, Epoch [258/295]: loss 0.7208, auc 0.4996, ap 0.5393
2024-01-10 21:51:48,457 - GAugM EPNet train, Epoch [259/295]: loss 0.7208, auc 0.6317, ap 0.5918
2024-01-10 21:51:48,541 - GAugM EPNet train, Epoch [260/295]: loss 0.7210, auc 0.5352, ap 0.5284
2024-01-10 21:51:48,618 - GAugM EPNet train, Epoch [261/295]: loss 0.7209, auc 0.4352, ap 0.4672
2024-01-10 21:51:48,704 - GAugM EPNet train, Epoch [262/295]: loss 0.7208, auc 0.4616, ap 0.5119
2024-01-10 21:51:48,796 - GAugM EPNet train, Epoch [263/295]: loss 0.7209, auc 0.4968, ap 0.4947
2024-01-10 21:51:48,879 - GAugM EPNet train, Epoch [264/295]: loss 0.7210, auc 0.4455, ap 0.4602
2024-01-10 21:51:48,971 - GAugM EPNet train, Epoch [265/295]: loss 0.7209, auc 0.4697, ap 0.5143
2024-01-10 21:51:49,066 - GAugM EPNet train, Epoch [266/295]: loss 0.7209, auc 0.4583, ap 0.4798
2024-01-10 21:51:49,161 - GAugM EPNet train, Epoch [267/295]: loss 0.7210, auc 0.4918, ap 0.5237
2024-01-10 21:51:49,259 - GAugM EPNet train, Epoch [268/295]: loss 0.7210, auc 0.5121, ap 0.5216
2024-01-10 21:51:49,348 - GAugM EPNet train, Epoch [269/295]: loss 0.7209, auc 0.5570, ap 0.5512
2024-01-10 21:51:49,433 - GAugM EPNet train, Epoch [270/295]: loss 0.7210, auc 0.3793, ap 0.4136
2024-01-10 21:51:49,518 - GAugM EPNet train, Epoch [271/295]: loss 0.7209, auc 0.4142, ap 0.4585
2024-01-10 21:51:49,597 - GAugM EPNet train, Epoch [272/295]: loss 0.7209, auc 0.4630, ap 0.4675
2024-01-10 21:51:49,674 - GAugM EPNet train, Epoch [273/295]: loss 0.7209, auc 0.4811, ap 0.4797
2024-01-10 21:51:49,763 - GAugM EPNet train, Epoch [274/295]: loss 0.7209, auc 0.4790, ap 0.4967
2024-01-10 21:51:49,854 - GAugM EPNet train, Epoch [275/295]: loss 0.7208, auc 0.4544, ap 0.4749
2024-01-10 21:51:49,952 - GAugM EPNet train, Epoch [276/295]: loss 0.7210, auc 0.5449, ap 0.5976
2024-01-10 21:51:50,032 - GAugM EPNet train, Epoch [277/295]: loss 0.7208, auc 0.4761, ap 0.5047
2024-01-10 21:51:50,124 - GAugM EPNet train, Epoch [278/295]: loss 0.7209, auc 0.5580, ap 0.5929
2024-01-10 21:51:50,216 - GAugM EPNet train, Epoch [279/295]: loss 0.7209, auc 0.4420, ap 0.4743
2024-01-10 21:51:50,313 - GAugM EPNet train, Epoch [280/295]: loss 0.7209, auc 0.3715, ap 0.4155
2024-01-10 21:51:50,408 - GAugM EPNet train, Epoch [281/295]: loss 0.7209, auc 0.4943, ap 0.5098
2024-01-10 21:51:50,496 - GAugM EPNet train, Epoch [282/295]: loss 0.7209, auc 0.4868, ap 0.4790
2024-01-10 21:51:50,587 - GAugM EPNet train, Epoch [283/295]: loss 0.7209, auc 0.4423, ap 0.4692
2024-01-10 21:51:50,676 - GAugM EPNet train, Epoch [284/295]: loss 0.7209, auc 0.4359, ap 0.4663
2024-01-10 21:51:50,766 - GAugM EPNet train, Epoch [285/295]: loss 0.7209, auc 0.5203, ap 0.5225
2024-01-10 21:51:50,853 - GAugM EPNet train, Epoch [286/295]: loss 0.7209, auc 0.4655, ap 0.4802
2024-01-10 21:51:50,950 - GAugM EPNet train, Epoch [287/295]: loss 0.7209, auc 0.4758, ap 0.5212
2024-01-10 21:51:51,040 - GAugM EPNet train, Epoch [288/295]: loss 0.7210, auc 0.5050, ap 0.5392
2024-01-10 21:51:51,141 - GAugM EPNet train, Epoch [289/295]: loss 0.7209, auc 0.5242, ap 0.5071
2024-01-10 21:51:51,237 - GAugM EPNet train, Epoch [290/295]: loss 0.7210, auc 0.5680, ap 0.5435
2024-01-10 21:51:51,325 - GAugM EPNet train, Epoch [291/295]: loss 0.7210, auc 0.3786, ap 0.4184
2024-01-10 21:51:51,421 - GAugM EPNet train, Epoch [292/295]: loss 0.7209, auc 0.5117, ap 0.5281
2024-01-10 21:51:51,512 - GAugM EPNet train, Epoch [293/295]: loss 0.7210, auc 0.4327, ap 0.4742
2024-01-10 21:51:51,600 - GAugM EPNet train, Epoch [294/295]: loss 0.7211, auc 0.4398, ap 0.4530
2024-01-10 21:51:51,682 - GAugM EPNet train, Epoch [295/295]: loss 0.7209, auc 0.4576, ap 0.4726
2024-01-10 21:51:51,711 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f6cea8fbf90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:51:52,457 - GAugM EPNet train, Epoch [  1/295]: loss 0.7210, auc 0.4801, ap 0.4872
2024-01-10 21:51:52,545 - GAugM EPNet train, Epoch [  2/295]: loss 0.7210, auc 0.4628, ap 0.4929
2024-01-10 21:51:52,637 - GAugM EPNet train, Epoch [  3/295]: loss 0.7209, auc 0.6184, ap 0.5989
2024-01-10 21:51:52,739 - GAugM EPNet train, Epoch [  4/295]: loss 0.7209, auc 0.5433, ap 0.5633
2024-01-10 21:51:52,828 - GAugM EPNet train, Epoch [  5/295]: loss 0.7209, auc 0.5664, ap 0.5897
2024-01-10 21:51:52,915 - GAugM EPNet train, Epoch [  6/295]: loss 0.7209, auc 0.5468, ap 0.5338
2024-01-10 21:51:53,007 - GAugM EPNet train, Epoch [  7/295]: loss 0.7209, auc 0.4279, ap 0.4376
2024-01-10 21:51:53,094 - GAugM EPNet train, Epoch [  8/295]: loss 0.7210, auc 0.4318, ap 0.4516
2024-01-10 21:51:53,194 - GAugM EPNet train, Epoch [  9/295]: loss 0.7209, auc 0.4895, ap 0.4886
2024-01-10 21:51:53,280 - GAugM EPNet train, Epoch [ 10/295]: loss 0.7208, auc 0.5379, ap 0.5557
2024-01-10 21:51:53,366 - GAugM EPNet train, Epoch [ 11/295]: loss 0.7209, auc 0.4810, ap 0.4837
2024-01-10 21:51:53,460 - GAugM EPNet train, Epoch [ 12/295]: loss 0.7210, auc 0.3795, ap 0.4292
2024-01-10 21:51:53,548 - GAugM EPNet train, Epoch [ 13/295]: loss 0.7209, auc 0.6264, ap 0.6229
2024-01-10 21:51:53,633 - GAugM EPNet train, Epoch [ 14/295]: loss 0.7209, auc 0.6369, ap 0.6267
2024-01-10 21:51:53,721 - GAugM EPNet train, Epoch [ 15/295]: loss 0.7210, auc 0.3863, ap 0.4942
2024-01-10 21:51:53,806 - GAugM EPNet train, Epoch [ 16/295]: loss 0.7209, auc 0.5635, ap 0.5768
2024-01-10 21:51:53,890 - GAugM EPNet train, Epoch [ 17/295]: loss 0.7210, auc 0.5413, ap 0.5340
2024-01-10 21:51:53,974 - GAugM EPNet train, Epoch [ 18/295]: loss 0.7210, auc 0.5740, ap 0.5636
2024-01-10 21:51:54,059 - GAugM EPNet train, Epoch [ 19/295]: loss 0.7209, auc 0.4313, ap 0.4520
2024-01-10 21:51:54,151 - GAugM EPNet train, Epoch [ 20/295]: loss 0.7210, auc 0.4256, ap 0.4522
2024-01-10 21:51:54,237 - GAugM EPNet train, Epoch [ 21/295]: loss 0.7209, auc 0.5351, ap 0.5287
2024-01-10 21:51:54,327 - GAugM EPNet train, Epoch [ 22/295]: loss 0.7210, auc 0.3752, ap 0.4399
2024-01-10 21:51:54,415 - GAugM EPNet train, Epoch [ 23/295]: loss 0.7208, auc 0.4032, ap 0.4408
2024-01-10 21:51:54,506 - GAugM EPNet train, Epoch [ 24/295]: loss 0.7209, auc 0.5258, ap 0.5235
2024-01-10 21:51:54,596 - GAugM EPNet train, Epoch [ 25/295]: loss 0.7209, auc 0.3952, ap 0.4442
2024-01-10 21:51:54,682 - GAugM EPNet train, Epoch [ 26/295]: loss 0.7210, auc 0.5543, ap 0.5688
2024-01-10 21:51:54,772 - GAugM EPNet train, Epoch [ 27/295]: loss 0.7209, auc 0.4760, ap 0.5050
2024-01-10 21:51:54,859 - GAugM EPNet train, Epoch [ 28/295]: loss 0.7209, auc 0.6107, ap 0.6213
2024-01-10 21:51:54,946 - GAugM EPNet train, Epoch [ 29/295]: loss 0.7210, auc 0.4952, ap 0.5075
2024-01-10 21:51:55,043 - GAugM EPNet train, Epoch [ 30/295]: loss 0.7209, auc 0.5269, ap 0.5531
2024-01-10 21:51:55,130 - GAugM EPNet train, Epoch [ 31/295]: loss 0.7208, auc 0.5025, ap 0.5375
2024-01-10 21:51:55,216 - GAugM EPNet train, Epoch [ 32/295]: loss 0.7210, auc 0.5126, ap 0.5087
2024-01-10 21:51:55,316 - GAugM EPNet train, Epoch [ 33/295]: loss 0.7209, auc 0.5037, ap 0.5223
2024-01-10 21:51:55,406 - GAugM EPNet train, Epoch [ 34/295]: loss 0.7209, auc 0.4155, ap 0.4503
2024-01-10 21:51:55,498 - GAugM EPNet train, Epoch [ 35/295]: loss 0.7209, auc 0.5758, ap 0.5586
2024-01-10 21:51:55,585 - GAugM EPNet train, Epoch [ 36/295]: loss 0.7209, auc 0.5728, ap 0.5818
2024-01-10 21:51:55,676 - GAugM EPNet train, Epoch [ 37/295]: loss 0.7209, auc 0.4690, ap 0.4857
2024-01-10 21:51:55,763 - GAugM EPNet train, Epoch [ 38/295]: loss 0.7209, auc 0.4528, ap 0.4797
2024-01-10 21:51:55,858 - GAugM EPNet train, Epoch [ 39/295]: loss 0.7208, auc 0.5265, ap 0.5449
2024-01-10 21:51:55,947 - GAugM EPNet train, Epoch [ 40/295]: loss 0.7210, auc 0.5858, ap 0.5519
2024-01-10 21:51:56,032 - GAugM EPNet train, Epoch [ 41/295]: loss 0.7210, auc 0.4286, ap 0.4879
2024-01-10 21:51:56,121 - GAugM EPNet train, Epoch [ 42/295]: loss 0.7209, auc 0.5511, ap 0.5817
2024-01-10 21:51:56,209 - GAugM EPNet train, Epoch [ 43/295]: loss 0.7208, auc 0.4988, ap 0.5334
2024-01-10 21:51:56,295 - GAugM EPNet train, Epoch [ 44/295]: loss 0.7208, auc 0.4543, ap 0.4877
2024-01-10 21:51:56,387 - GAugM EPNet train, Epoch [ 45/295]: loss 0.7209, auc 0.5160, ap 0.5179
2024-01-10 21:51:56,477 - GAugM EPNet train, Epoch [ 46/295]: loss 0.7209, auc 0.4867, ap 0.5050
2024-01-10 21:51:56,567 - GAugM EPNet train, Epoch [ 47/295]: loss 0.7210, auc 0.5340, ap 0.5803
2024-01-10 21:51:56,651 - GAugM EPNet train, Epoch [ 48/295]: loss 0.7210, auc 0.6342, ap 0.6339
2024-01-10 21:51:56,736 - GAugM EPNet train, Epoch [ 49/295]: loss 0.7209, auc 0.4667, ap 0.5204
2024-01-10 21:51:56,832 - GAugM EPNet train, Epoch [ 50/295]: loss 0.7210, auc 0.5304, ap 0.5295
2024-01-10 21:51:56,921 - GAugM EPNet train, Epoch [ 51/295]: loss 0.7210, auc 0.4539, ap 0.4957
2024-01-10 21:51:57,006 - GAugM EPNet train, Epoch [ 52/295]: loss 0.7209, auc 0.4756, ap 0.5235
2024-01-10 21:51:57,092 - GAugM EPNet train, Epoch [ 53/295]: loss 0.7209, auc 0.5589, ap 0.5478
2024-01-10 21:51:57,183 - GAugM EPNet train, Epoch [ 54/295]: loss 0.7211, auc 0.5689, ap 0.5659
2024-01-10 21:51:57,267 - GAugM EPNet train, Epoch [ 55/295]: loss 0.7209, auc 0.6404, ap 0.6426
2024-01-10 21:51:57,352 - GAugM EPNet train, Epoch [ 56/295]: loss 0.7208, auc 0.4409, ap 0.4661
2024-01-10 21:51:57,440 - GAugM EPNet train, Epoch [ 57/295]: loss 0.7209, auc 0.4824, ap 0.4690
2024-01-10 21:51:57,533 - GAugM EPNet train, Epoch [ 58/295]: loss 0.7210, auc 0.4616, ap 0.5383
2024-01-10 21:51:57,621 - GAugM EPNet train, Epoch [ 59/295]: loss 0.7211, auc 0.5539, ap 0.5181
2024-01-10 21:51:57,703 - GAugM EPNet train, Epoch [ 60/295]: loss 0.7210, auc 0.4728, ap 0.4963
2024-01-10 21:51:57,789 - GAugM EPNet train, Epoch [ 61/295]: loss 0.7209, auc 0.5402, ap 0.5782
2024-01-10 21:51:57,874 - GAugM EPNet train, Epoch [ 62/295]: loss 0.7210, auc 0.5621, ap 0.5830
2024-01-10 21:51:57,958 - GAugM EPNet train, Epoch [ 63/295]: loss 0.7208, auc 0.4327, ap 0.4468
2024-01-10 21:51:58,043 - GAugM EPNet train, Epoch [ 64/295]: loss 0.7208, auc 0.5443, ap 0.5682
2024-01-10 21:51:58,127 - GAugM EPNet train, Epoch [ 65/295]: loss 0.7208, auc 0.6383, ap 0.6105
2024-01-10 21:51:58,211 - GAugM EPNet train, Epoch [ 66/295]: loss 0.7209, auc 0.4669, ap 0.4976
2024-01-10 21:51:58,299 - GAugM EPNet train, Epoch [ 67/295]: loss 0.7209, auc 0.5240, ap 0.5251
2024-01-10 21:51:58,385 - GAugM EPNet train, Epoch [ 68/295]: loss 0.7210, auc 0.5918, ap 0.5998
2024-01-10 21:51:58,478 - GAugM EPNet train, Epoch [ 69/295]: loss 0.7210, auc 0.5190, ap 0.5545
2024-01-10 21:51:58,563 - GAugM EPNet train, Epoch [ 70/295]: loss 0.7210, auc 0.4560, ap 0.4978
2024-01-10 21:51:58,658 - GAugM EPNet train, Epoch [ 71/295]: loss 0.7210, auc 0.5717, ap 0.5413
2024-01-10 21:51:58,748 - GAugM EPNet train, Epoch [ 72/295]: loss 0.7210, auc 0.4448, ap 0.4591
2024-01-10 21:51:58,826 - GAugM EPNet train, Epoch [ 73/295]: loss 0.7209, auc 0.5418, ap 0.5169
2024-01-10 21:51:58,920 - GAugM EPNet train, Epoch [ 74/295]: loss 0.7209, auc 0.5367, ap 0.5520
2024-01-10 21:51:59,012 - GAugM EPNet train, Epoch [ 75/295]: loss 0.7210, auc 0.4432, ap 0.4885
2024-01-10 21:51:59,102 - GAugM EPNet train, Epoch [ 76/295]: loss 0.7209, auc 0.4276, ap 0.4783
2024-01-10 21:51:59,201 - GAugM EPNet train, Epoch [ 77/295]: loss 0.7208, auc 0.5034, ap 0.5110
2024-01-10 21:51:59,292 - GAugM EPNet train, Epoch [ 78/295]: loss 0.7209, auc 0.5336, ap 0.5478
2024-01-10 21:51:59,375 - GAugM EPNet train, Epoch [ 79/295]: loss 0.7208, auc 0.4559, ap 0.4839
2024-01-10 21:51:59,453 - GAugM EPNet train, Epoch [ 80/295]: loss 0.7209, auc 0.5774, ap 0.5475
2024-01-10 21:51:59,544 - GAugM EPNet train, Epoch [ 81/295]: loss 0.7209, auc 0.5125, ap 0.5119
2024-01-10 21:51:59,634 - GAugM EPNet train, Epoch [ 82/295]: loss 0.7210, auc 0.5564, ap 0.5661
2024-01-10 21:51:59,720 - GAugM EPNet train, Epoch [ 83/295]: loss 0.7209, auc 0.4697, ap 0.5170
2024-01-10 21:51:59,800 - GAugM EPNet train, Epoch [ 84/295]: loss 0.7209, auc 0.4220, ap 0.4791
2024-01-10 21:51:59,891 - GAugM EPNet train, Epoch [ 85/295]: loss 0.7210, auc 0.4672, ap 0.5093
2024-01-10 21:51:59,973 - GAugM EPNet train, Epoch [ 86/295]: loss 0.7208, auc 0.4596, ap 0.4713
2024-01-10 21:52:00,056 - GAugM EPNet train, Epoch [ 87/295]: loss 0.7209, auc 0.5760, ap 0.6089
2024-01-10 21:52:00,134 - GAugM EPNet train, Epoch [ 88/295]: loss 0.7210, auc 0.5018, ap 0.5344
2024-01-10 21:52:00,222 - GAugM EPNet train, Epoch [ 89/295]: loss 0.7210, auc 0.4596, ap 0.4815
2024-01-10 21:52:00,312 - GAugM EPNet train, Epoch [ 90/295]: loss 0.7209, auc 0.4907, ap 0.5246
2024-01-10 21:52:00,392 - GAugM EPNet train, Epoch [ 91/295]: loss 0.7208, auc 0.5235, ap 0.5097
2024-01-10 21:52:00,471 - GAugM EPNet train, Epoch [ 92/295]: loss 0.7209, auc 0.6675, ap 0.6504
2024-01-10 21:52:00,567 - GAugM EPNet train, Epoch [ 93/295]: loss 0.7209, auc 0.4822, ap 0.5141
2024-01-10 21:52:00,656 - GAugM EPNet train, Epoch [ 94/295]: loss 0.7210, auc 0.3788, ap 0.4226
2024-01-10 21:52:00,737 - GAugM EPNet train, Epoch [ 95/295]: loss 0.7210, auc 0.4671, ap 0.4928
2024-01-10 21:52:00,823 - GAugM EPNet train, Epoch [ 96/295]: loss 0.7209, auc 0.5692, ap 0.5732
2024-01-10 21:52:00,913 - GAugM EPNet train, Epoch [ 97/295]: loss 0.7209, auc 0.5493, ap 0.5925
2024-01-10 21:52:01,008 - GAugM EPNet train, Epoch [ 98/295]: loss 0.7209, auc 0.4656, ap 0.4796
2024-01-10 21:52:01,099 - GAugM EPNet train, Epoch [ 99/295]: loss 0.7209, auc 0.5142, ap 0.5025
2024-01-10 21:52:01,191 - GAugM EPNet train, Epoch [100/295]: loss 0.7210, auc 0.5425, ap 0.5553
2024-01-10 21:52:01,295 - GAugM EPNet train, Epoch [101/295]: loss 0.7210, auc 0.4669, ap 0.5141
2024-01-10 21:52:01,384 - GAugM EPNet train, Epoch [102/295]: loss 0.7209, auc 0.5107, ap 0.5327
2024-01-10 21:52:01,470 - GAugM EPNet train, Epoch [103/295]: loss 0.7209, auc 0.4388, ap 0.5194
2024-01-10 21:52:01,553 - GAugM EPNet train, Epoch [104/295]: loss 0.7209, auc 0.4884, ap 0.5147
2024-01-10 21:52:01,640 - GAugM EPNet train, Epoch [105/295]: loss 0.7209, auc 0.5233, ap 0.5181
2024-01-10 21:52:01,908 - GAugM EPNet train, Epoch [106/295]: loss 0.7210, auc 0.5235, ap 0.5228
2024-01-10 21:52:02,002 - GAugM EPNet train, Epoch [107/295]: loss 0.7210, auc 0.5139, ap 0.5488
2024-01-10 21:52:02,096 - GAugM EPNet train, Epoch [108/295]: loss 0.7208, auc 0.4966, ap 0.4937
2024-01-10 21:52:02,190 - GAugM EPNet train, Epoch [109/295]: loss 0.7210, auc 0.5089, ap 0.5257
2024-01-10 21:52:02,275 - GAugM EPNet train, Epoch [110/295]: loss 0.7209, auc 0.5025, ap 0.4957
2024-01-10 21:52:02,361 - GAugM EPNet train, Epoch [111/295]: loss 0.7210, auc 0.5625, ap 0.5742
2024-01-10 21:52:02,451 - GAugM EPNet train, Epoch [112/295]: loss 0.7209, auc 0.4206, ap 0.4531
2024-01-10 21:52:02,536 - GAugM EPNet train, Epoch [113/295]: loss 0.7210, auc 0.5550, ap 0.5857
2024-01-10 21:52:02,623 - GAugM EPNet train, Epoch [114/295]: loss 0.7209, auc 0.4464, ap 0.4742
2024-01-10 21:52:02,709 - GAugM EPNet train, Epoch [115/295]: loss 0.7210, auc 0.4434, ap 0.4748
2024-01-10 21:52:02,795 - GAugM EPNet train, Epoch [116/295]: loss 0.7209, auc 0.5393, ap 0.5365
2024-01-10 21:52:02,880 - GAugM EPNet train, Epoch [117/295]: loss 0.7208, auc 0.4870, ap 0.5269
2024-01-10 21:52:02,969 - GAugM EPNet train, Epoch [118/295]: loss 0.7209, auc 0.3955, ap 0.4508
2024-01-10 21:52:03,055 - GAugM EPNet train, Epoch [119/295]: loss 0.7209, auc 0.5133, ap 0.5480
2024-01-10 21:52:03,141 - GAugM EPNet train, Epoch [120/295]: loss 0.7210, auc 0.4713, ap 0.4751
2024-01-10 21:52:03,240 - GAugM EPNet train, Epoch [121/295]: loss 0.7210, auc 0.4941, ap 0.5184
2024-01-10 21:52:03,328 - GAugM EPNet train, Epoch [122/295]: loss 0.7209, auc 0.5411, ap 0.5656
2024-01-10 21:52:03,418 - GAugM EPNet train, Epoch [123/295]: loss 0.7209, auc 0.4482, ap 0.5090
2024-01-10 21:52:03,504 - GAugM EPNet train, Epoch [124/295]: loss 0.7210, auc 0.4429, ap 0.4815
2024-01-10 21:52:03,588 - GAugM EPNet train, Epoch [125/295]: loss 0.7209, auc 0.4770, ap 0.4904
2024-01-10 21:52:03,679 - GAugM EPNet train, Epoch [126/295]: loss 0.7210, auc 0.4375, ap 0.4833
2024-01-10 21:52:03,766 - GAugM EPNet train, Epoch [127/295]: loss 0.7209, auc 0.5837, ap 0.5594
2024-01-10 21:52:03,852 - GAugM EPNet train, Epoch [128/295]: loss 0.7210, auc 0.4674, ap 0.4844
2024-01-10 21:52:03,939 - GAugM EPNet train, Epoch [129/295]: loss 0.7208, auc 0.3749, ap 0.4271
2024-01-10 21:52:04,036 - GAugM EPNet train, Epoch [130/295]: loss 0.7210, auc 0.4986, ap 0.5204
2024-01-10 21:52:04,125 - GAugM EPNet train, Epoch [131/295]: loss 0.7210, auc 0.4653, ap 0.5160
2024-01-10 21:52:04,221 - GAugM EPNet train, Epoch [132/295]: loss 0.7209, auc 0.5182, ap 0.5269
2024-01-10 21:52:04,307 - GAugM EPNet train, Epoch [133/295]: loss 0.7209, auc 0.4621, ap 0.5210
2024-01-10 21:52:04,391 - GAugM EPNet train, Epoch [134/295]: loss 0.7210, auc 0.4441, ap 0.4772
2024-01-10 21:52:04,475 - GAugM EPNet train, Epoch [135/295]: loss 0.7209, auc 0.4046, ap 0.4520
2024-01-10 21:52:04,564 - GAugM EPNet train, Epoch [136/295]: loss 0.7209, auc 0.5052, ap 0.5028
2024-01-10 21:52:04,648 - GAugM EPNet train, Epoch [137/295]: loss 0.7210, auc 0.4815, ap 0.5034
2024-01-10 21:52:04,732 - GAugM EPNet train, Epoch [138/295]: loss 0.7210, auc 0.5618, ap 0.5441
2024-01-10 21:52:04,824 - GAugM EPNet train, Epoch [139/295]: loss 0.7210, auc 0.4831, ap 0.5292
2024-01-10 21:52:04,912 - GAugM EPNet train, Epoch [140/295]: loss 0.7209, auc 0.4795, ap 0.5390
2024-01-10 21:52:05,002 - GAugM EPNet train, Epoch [141/295]: loss 0.7209, auc 0.5377, ap 0.5102
2024-01-10 21:52:05,087 - GAugM EPNet train, Epoch [142/295]: loss 0.7209, auc 0.5724, ap 0.5853
2024-01-10 21:52:05,178 - GAugM EPNet train, Epoch [143/295]: loss 0.7209, auc 0.4276, ap 0.4619
2024-01-10 21:52:05,264 - GAugM EPNet train, Epoch [144/295]: loss 0.7209, auc 0.5166, ap 0.5132
2024-01-10 21:52:05,349 - GAugM EPNet train, Epoch [145/295]: loss 0.7209, auc 0.5116, ap 0.5101
2024-01-10 21:52:05,435 - GAugM EPNet train, Epoch [146/295]: loss 0.7209, auc 0.4407, ap 0.4581
2024-01-10 21:52:05,521 - GAugM EPNet train, Epoch [147/295]: loss 0.7209, auc 0.5716, ap 0.5861
2024-01-10 21:52:05,605 - GAugM EPNet train, Epoch [148/295]: loss 0.7209, auc 0.5247, ap 0.5322
2024-01-10 21:52:05,693 - GAugM EPNet train, Epoch [149/295]: loss 0.7208, auc 0.4813, ap 0.4799
2024-01-10 21:52:05,779 - GAugM EPNet train, Epoch [150/295]: loss 0.7209, auc 0.5189, ap 0.5226
2024-01-10 21:52:05,863 - GAugM EPNet train, Epoch [151/295]: loss 0.7209, auc 0.5085, ap 0.5266
2024-01-10 21:52:05,953 - GAugM EPNet train, Epoch [152/295]: loss 0.7209, auc 0.5863, ap 0.5749
2024-01-10 21:52:06,039 - GAugM EPNet train, Epoch [153/295]: loss 0.7209, auc 0.5721, ap 0.5686
2024-01-10 21:52:06,124 - GAugM EPNet train, Epoch [154/295]: loss 0.7209, auc 0.5922, ap 0.6486
2024-01-10 21:52:06,212 - GAugM EPNet train, Epoch [155/295]: loss 0.7209, auc 0.6034, ap 0.5726
2024-01-10 21:52:06,303 - GAugM EPNet train, Epoch [156/295]: loss 0.7209, auc 0.4902, ap 0.5190
2024-01-10 21:52:06,389 - GAugM EPNet train, Epoch [157/295]: loss 0.7209, auc 0.5043, ap 0.5428
2024-01-10 21:52:06,475 - GAugM EPNet train, Epoch [158/295]: loss 0.7208, auc 0.4916, ap 0.5084
2024-01-10 21:52:06,564 - GAugM EPNet train, Epoch [159/295]: loss 0.7208, auc 0.5114, ap 0.5009
2024-01-10 21:52:06,649 - GAugM EPNet train, Epoch [160/295]: loss 0.7209, auc 0.4811, ap 0.5225
2024-01-10 21:52:06,734 - GAugM EPNet train, Epoch [161/295]: loss 0.7209, auc 0.6118, ap 0.6090
2024-01-10 21:52:06,822 - GAugM EPNet train, Epoch [162/295]: loss 0.7209, auc 0.4813, ap 0.4905
2024-01-10 21:52:06,911 - GAugM EPNet train, Epoch [163/295]: loss 0.7209, auc 0.5696, ap 0.5323
2024-01-10 21:52:07,001 - GAugM EPNet train, Epoch [164/295]: loss 0.7211, auc 0.5141, ap 0.5107
2024-01-10 21:52:07,087 - GAugM EPNet train, Epoch [165/295]: loss 0.7210, auc 0.4973, ap 0.5191
2024-01-10 21:52:07,177 - GAugM EPNet train, Epoch [166/295]: loss 0.7208, auc 0.4794, ap 0.4863
2024-01-10 21:52:07,262 - GAugM EPNet train, Epoch [167/295]: loss 0.7209, auc 0.4575, ap 0.4813
2024-01-10 21:52:07,347 - GAugM EPNet train, Epoch [168/295]: loss 0.7209, auc 0.5183, ap 0.5561
2024-01-10 21:52:07,432 - GAugM EPNet train, Epoch [169/295]: loss 0.7209, auc 0.5824, ap 0.5990
2024-01-10 21:52:07,516 - GAugM EPNet train, Epoch [170/295]: loss 0.7210, auc 0.4500, ap 0.4653
2024-01-10 21:52:07,601 - GAugM EPNet train, Epoch [171/295]: loss 0.7209, auc 0.4884, ap 0.5002
2024-01-10 21:52:07,697 - GAugM EPNet train, Epoch [172/295]: loss 0.7208, auc 0.4854, ap 0.4932
2024-01-10 21:52:07,790 - GAugM EPNet train, Epoch [173/295]: loss 0.7209, auc 0.4422, ap 0.5130
2024-01-10 21:52:07,886 - GAugM EPNet train, Epoch [174/295]: loss 0.7209, auc 0.4564, ap 0.4887
2024-01-10 21:52:07,974 - GAugM EPNet train, Epoch [175/295]: loss 0.7209, auc 0.6173, ap 0.5942
2024-01-10 21:52:08,060 - GAugM EPNet train, Epoch [176/295]: loss 0.7209, auc 0.4649, ap 0.4663
2024-01-10 21:52:08,150 - GAugM EPNet train, Epoch [177/295]: loss 0.7210, auc 0.5272, ap 0.4997
2024-01-10 21:52:08,241 - GAugM EPNet train, Epoch [178/295]: loss 0.7210, auc 0.5210, ap 0.5437
2024-01-10 21:52:08,338 - GAugM EPNet train, Epoch [179/295]: loss 0.7210, auc 0.4140, ap 0.4623
2024-01-10 21:52:08,428 - GAugM EPNet train, Epoch [180/295]: loss 0.7210, auc 0.5441, ap 0.5972
2024-01-10 21:52:08,519 - GAugM EPNet train, Epoch [181/295]: loss 0.7209, auc 0.4199, ap 0.4446
2024-01-10 21:52:08,613 - GAugM EPNet train, Epoch [182/295]: loss 0.7209, auc 0.5406, ap 0.5097
2024-01-10 21:52:08,715 - GAugM EPNet train, Epoch [183/295]: loss 0.7210, auc 0.4553, ap 0.4767
2024-01-10 21:52:08,795 - GAugM EPNet train, Epoch [184/295]: loss 0.7209, auc 0.4870, ap 0.5070
2024-01-10 21:52:08,880 - GAugM EPNet train, Epoch [185/295]: loss 0.7209, auc 0.5228, ap 0.5531
2024-01-10 21:52:08,964 - GAugM EPNet train, Epoch [186/295]: loss 0.7208, auc 0.5320, ap 0.5646
2024-01-10 21:52:09,057 - GAugM EPNet train, Epoch [187/295]: loss 0.7209, auc 0.5077, ap 0.5329
2024-01-10 21:52:09,147 - GAugM EPNet train, Epoch [188/295]: loss 0.7209, auc 0.4865, ap 0.4882
2024-01-10 21:52:09,235 - GAugM EPNet train, Epoch [189/295]: loss 0.7209, auc 0.6032, ap 0.6037
2024-01-10 21:52:09,325 - GAugM EPNet train, Epoch [190/295]: loss 0.7209, auc 0.4244, ap 0.4375
2024-01-10 21:52:09,415 - GAugM EPNet train, Epoch [191/295]: loss 0.7209, auc 0.3592, ap 0.4632
2024-01-10 21:52:09,505 - GAugM EPNet train, Epoch [192/295]: loss 0.7209, auc 0.5110, ap 0.4959
2024-01-10 21:52:09,595 - GAugM EPNet train, Epoch [193/295]: loss 0.7209, auc 0.4712, ap 0.4947
2024-01-10 21:52:09,694 - GAugM EPNet train, Epoch [194/295]: loss 0.7209, auc 0.4998, ap 0.5029
2024-01-10 21:52:09,781 - GAugM EPNet train, Epoch [195/295]: loss 0.7209, auc 0.4899, ap 0.5156
2024-01-10 21:52:09,864 - GAugM EPNet train, Epoch [196/295]: loss 0.7208, auc 0.5890, ap 0.5406
2024-01-10 21:52:09,956 - GAugM EPNet train, Epoch [197/295]: loss 0.7210, auc 0.4956, ap 0.5160
2024-01-10 21:52:10,047 - GAugM EPNet train, Epoch [198/295]: loss 0.7210, auc 0.4984, ap 0.5108
2024-01-10 21:52:10,140 - GAugM EPNet train, Epoch [199/295]: loss 0.7209, auc 0.5292, ap 0.5659
2024-01-10 21:52:10,233 - GAugM EPNet train, Epoch [200/295]: loss 0.7210, auc 0.4509, ap 0.4949
2024-01-10 21:52:10,323 - GAugM EPNet train, Epoch [201/295]: loss 0.7209, auc 0.4701, ap 0.4659
2024-01-10 21:52:10,415 - GAugM EPNet train, Epoch [202/295]: loss 0.7210, auc 0.4678, ap 0.5323
2024-01-10 21:52:10,509 - GAugM EPNet train, Epoch [203/295]: loss 0.7210, auc 0.5977, ap 0.6116
2024-01-10 21:52:10,598 - GAugM EPNet train, Epoch [204/295]: loss 0.7209, auc 0.4249, ap 0.4562
2024-01-10 21:52:10,683 - GAugM EPNet train, Epoch [205/295]: loss 0.7209, auc 0.4916, ap 0.5207
2024-01-10 21:52:10,771 - GAugM EPNet train, Epoch [206/295]: loss 0.7209, auc 0.4194, ap 0.4623
2024-01-10 21:52:10,865 - GAugM EPNet train, Epoch [207/295]: loss 0.7210, auc 0.4754, ap 0.4877
2024-01-10 21:52:10,954 - GAugM EPNet train, Epoch [208/295]: loss 0.7209, auc 0.4215, ap 0.4786
2024-01-10 21:52:11,047 - GAugM EPNet train, Epoch [209/295]: loss 0.7210, auc 0.6023, ap 0.5972
2024-01-10 21:52:11,142 - GAugM EPNet train, Epoch [210/295]: loss 0.7209, auc 0.4347, ap 0.4912
2024-01-10 21:52:11,233 - GAugM EPNet train, Epoch [211/295]: loss 0.7210, auc 0.5025, ap 0.5306
2024-01-10 21:52:11,326 - GAugM EPNet train, Epoch [212/295]: loss 0.7210, auc 0.4336, ap 0.4917
2024-01-10 21:52:11,416 - GAugM EPNet train, Epoch [213/295]: loss 0.7208, auc 0.5463, ap 0.5718
2024-01-10 21:52:11,502 - GAugM EPNet train, Epoch [214/295]: loss 0.7210, auc 0.4829, ap 0.4949
2024-01-10 21:52:11,588 - GAugM EPNet train, Epoch [215/295]: loss 0.7210, auc 0.4610, ap 0.4868
2024-01-10 21:52:11,675 - GAugM EPNet train, Epoch [216/295]: loss 0.7209, auc 0.5004, ap 0.5003
2024-01-10 21:52:11,762 - GAugM EPNet train, Epoch [217/295]: loss 0.7209, auc 0.5799, ap 0.6256
2024-01-10 21:52:11,853 - GAugM EPNet train, Epoch [218/295]: loss 0.7209, auc 0.4680, ap 0.4950
2024-01-10 21:52:11,940 - GAugM EPNet train, Epoch [219/295]: loss 0.7208, auc 0.5228, ap 0.5261
2024-01-10 21:52:12,032 - GAugM EPNet train, Epoch [220/295]: loss 0.7210, auc 0.4640, ap 0.5184
2024-01-10 21:52:12,121 - GAugM EPNet train, Epoch [221/295]: loss 0.7209, auc 0.6077, ap 0.5915
2024-01-10 21:52:12,210 - GAugM EPNet train, Epoch [222/295]: loss 0.7209, auc 0.5036, ap 0.5135
2024-01-10 21:52:12,297 - GAugM EPNet train, Epoch [223/295]: loss 0.7209, auc 0.5651, ap 0.5573
2024-01-10 21:52:12,390 - GAugM EPNet train, Epoch [224/295]: loss 0.7210, auc 0.5130, ap 0.5068
2024-01-10 21:52:12,478 - GAugM EPNet train, Epoch [225/295]: loss 0.7209, auc 0.5112, ap 0.5437
2024-01-10 21:52:12,576 - GAugM EPNet train, Epoch [226/295]: loss 0.7210, auc 0.4929, ap 0.5353
2024-01-10 21:52:12,661 - GAugM EPNet train, Epoch [227/295]: loss 0.7210, auc 0.6066, ap 0.5919
2024-01-10 21:52:12,746 - GAugM EPNet train, Epoch [228/295]: loss 0.7209, auc 0.5392, ap 0.5502
2024-01-10 21:52:12,835 - GAugM EPNet train, Epoch [229/295]: loss 0.7209, auc 0.5404, ap 0.5225
2024-01-10 21:52:12,924 - GAugM EPNet train, Epoch [230/295]: loss 0.7209, auc 0.4986, ap 0.5248
2024-01-10 21:52:13,020 - GAugM EPNet train, Epoch [231/295]: loss 0.7209, auc 0.5020, ap 0.5287
2024-01-10 21:52:13,107 - GAugM EPNet train, Epoch [232/295]: loss 0.7209, auc 0.5525, ap 0.5454
2024-01-10 21:52:13,194 - GAugM EPNet train, Epoch [233/295]: loss 0.7210, auc 0.5447, ap 0.5529
2024-01-10 21:52:13,284 - GAugM EPNet train, Epoch [234/295]: loss 0.7209, auc 0.3825, ap 0.4246
2024-01-10 21:52:13,372 - GAugM EPNet train, Epoch [235/295]: loss 0.7209, auc 0.4546, ap 0.4808
2024-01-10 21:52:13,457 - GAugM EPNet train, Epoch [236/295]: loss 0.7209, auc 0.5650, ap 0.5596
2024-01-10 21:52:13,544 - GAugM EPNet train, Epoch [237/295]: loss 0.7210, auc 0.4763, ap 0.5404
2024-01-10 21:52:13,635 - GAugM EPNet train, Epoch [238/295]: loss 0.7210, auc 0.5538, ap 0.5487
2024-01-10 21:52:13,721 - GAugM EPNet train, Epoch [239/295]: loss 0.7209, auc 0.5433, ap 0.5901
2024-01-10 21:52:13,813 - GAugM EPNet train, Epoch [240/295]: loss 0.7209, auc 0.5593, ap 0.5271
2024-01-10 21:52:13,898 - GAugM EPNet train, Epoch [241/295]: loss 0.7209, auc 0.5349, ap 0.5340
2024-01-10 21:52:13,990 - GAugM EPNet train, Epoch [242/295]: loss 0.7210, auc 0.4963, ap 0.5497
2024-01-10 21:52:14,083 - GAugM EPNet train, Epoch [243/295]: loss 0.7210, auc 0.4875, ap 0.5485
2024-01-10 21:52:14,170 - GAugM EPNet train, Epoch [244/295]: loss 0.7209, auc 0.5183, ap 0.5473
2024-01-10 21:52:14,259 - GAugM EPNet train, Epoch [245/295]: loss 0.7210, auc 0.4580, ap 0.4639
2024-01-10 21:52:14,345 - GAugM EPNet train, Epoch [246/295]: loss 0.7208, auc 0.5440, ap 0.5613
2024-01-10 21:52:14,438 - GAugM EPNet train, Epoch [247/295]: loss 0.7209, auc 0.5787, ap 0.5726
2024-01-10 21:52:14,523 - GAugM EPNet train, Epoch [248/295]: loss 0.7211, auc 0.5158, ap 0.5278
2024-01-10 21:52:14,610 - GAugM EPNet train, Epoch [249/295]: loss 0.7209, auc 0.4208, ap 0.4523
2024-01-10 21:52:14,696 - GAugM EPNet train, Epoch [250/295]: loss 0.7208, auc 0.4956, ap 0.5225
2024-01-10 21:52:14,789 - GAugM EPNet train, Epoch [251/295]: loss 0.7209, auc 0.4098, ap 0.4877
2024-01-10 21:52:14,880 - GAugM EPNet train, Epoch [252/295]: loss 0.7210, auc 0.5913, ap 0.6083
2024-01-10 21:52:14,974 - GAugM EPNet train, Epoch [253/295]: loss 0.7209, auc 0.5842, ap 0.5551
2024-01-10 21:52:15,059 - GAugM EPNet train, Epoch [254/295]: loss 0.7210, auc 0.4211, ap 0.4748
2024-01-10 21:52:15,149 - GAugM EPNet train, Epoch [255/295]: loss 0.7209, auc 0.5066, ap 0.5604
2024-01-10 21:52:15,244 - GAugM EPNet train, Epoch [256/295]: loss 0.7210, auc 0.4137, ap 0.5105
2024-01-10 21:52:15,333 - GAugM EPNet train, Epoch [257/295]: loss 0.7210, auc 0.4557, ap 0.5084
2024-01-10 21:52:15,420 - GAugM EPNet train, Epoch [258/295]: loss 0.7208, auc 0.5098, ap 0.5484
2024-01-10 21:52:15,509 - GAugM EPNet train, Epoch [259/295]: loss 0.7208, auc 0.5842, ap 0.5570
2024-01-10 21:52:15,600 - GAugM EPNet train, Epoch [260/295]: loss 0.7210, auc 0.4883, ap 0.4963
2024-01-10 21:52:15,689 - GAugM EPNet train, Epoch [261/295]: loss 0.7209, auc 0.4612, ap 0.5038
2024-01-10 21:52:15,782 - GAugM EPNet train, Epoch [262/295]: loss 0.7208, auc 0.4600, ap 0.5040
2024-01-10 21:52:15,871 - GAugM EPNet train, Epoch [263/295]: loss 0.7209, auc 0.4566, ap 0.4704
2024-01-10 21:52:15,957 - GAugM EPNet train, Epoch [264/295]: loss 0.7210, auc 0.5190, ap 0.5263
2024-01-10 21:52:16,050 - GAugM EPNet train, Epoch [265/295]: loss 0.7209, auc 0.4740, ap 0.5127
2024-01-10 21:52:16,136 - GAugM EPNet train, Epoch [266/295]: loss 0.7209, auc 0.6102, ap 0.5810
2024-01-10 21:52:16,223 - GAugM EPNet train, Epoch [267/295]: loss 0.7210, auc 0.5470, ap 0.5540
2024-01-10 21:52:16,308 - GAugM EPNet train, Epoch [268/295]: loss 0.7210, auc 0.5546, ap 0.5763
2024-01-10 21:52:16,398 - GAugM EPNet train, Epoch [269/295]: loss 0.7209, auc 0.5417, ap 0.5349
2024-01-10 21:52:16,485 - GAugM EPNet train, Epoch [270/295]: loss 0.7210, auc 0.4891, ap 0.4903
2024-01-10 21:52:16,577 - GAugM EPNet train, Epoch [271/295]: loss 0.7209, auc 0.4717, ap 0.5038
2024-01-10 21:52:16,667 - GAugM EPNet train, Epoch [272/295]: loss 0.7209, auc 0.4904, ap 0.5635
2024-01-10 21:52:16,763 - GAugM EPNet train, Epoch [273/295]: loss 0.7209, auc 0.4637, ap 0.4868
2024-01-10 21:52:16,851 - GAugM EPNet train, Epoch [274/295]: loss 0.7209, auc 0.4414, ap 0.4638
2024-01-10 21:52:16,946 - GAugM EPNet train, Epoch [275/295]: loss 0.7208, auc 0.5016, ap 0.5060
2024-01-10 21:52:17,037 - GAugM EPNet train, Epoch [276/295]: loss 0.7210, auc 0.5351, ap 0.5520
2024-01-10 21:52:17,124 - GAugM EPNet train, Epoch [277/295]: loss 0.7208, auc 0.5141, ap 0.5742
2024-01-10 21:52:17,212 - GAugM EPNet train, Epoch [278/295]: loss 0.7209, auc 0.5765, ap 0.5705
2024-01-10 21:52:17,297 - GAugM EPNet train, Epoch [279/295]: loss 0.7209, auc 0.4600, ap 0.4630
2024-01-10 21:52:17,385 - GAugM EPNet train, Epoch [280/295]: loss 0.7209, auc 0.4370, ap 0.4483
2024-01-10 21:52:17,482 - GAugM EPNet train, Epoch [281/295]: loss 0.7209, auc 0.6385, ap 0.6150
2024-01-10 21:52:17,573 - GAugM EPNet train, Epoch [282/295]: loss 0.7209, auc 0.5048, ap 0.4907
2024-01-10 21:52:17,664 - GAugM EPNet train, Epoch [283/295]: loss 0.7209, auc 0.4731, ap 0.5026
2024-01-10 21:52:17,752 - GAugM EPNet train, Epoch [284/295]: loss 0.7209, auc 0.4343, ap 0.4816
2024-01-10 21:52:17,846 - GAugM EPNet train, Epoch [285/295]: loss 0.7209, auc 0.4583, ap 0.4719
2024-01-10 21:52:17,933 - GAugM EPNet train, Epoch [286/295]: loss 0.7209, auc 0.5479, ap 0.5402
2024-01-10 21:52:18,025 - GAugM EPNet train, Epoch [287/295]: loss 0.7209, auc 0.4916, ap 0.5447
2024-01-10 21:52:18,113 - GAugM EPNet train, Epoch [288/295]: loss 0.7210, auc 0.5198, ap 0.5566
2024-01-10 21:52:18,203 - GAugM EPNet train, Epoch [289/295]: loss 0.7209, auc 0.5774, ap 0.5764
2024-01-10 21:52:18,292 - GAugM EPNet train, Epoch [290/295]: loss 0.7210, auc 0.5481, ap 0.5352
2024-01-10 21:52:18,382 - GAugM EPNet train, Epoch [291/295]: loss 0.7210, auc 0.3960, ap 0.4333
2024-01-10 21:52:18,473 - GAugM EPNet train, Epoch [292/295]: loss 0.7209, auc 0.3937, ap 0.4499
2024-01-10 21:52:18,564 - GAugM EPNet train, Epoch [293/295]: loss 0.7210, auc 0.4861, ap 0.4747
2024-01-10 21:52:18,658 - GAugM EPNet train, Epoch [294/295]: loss 0.7211, auc 0.4856, ap 0.4948
2024-01-10 21:52:18,748 - GAugM EPNet train, Epoch [295/295]: loss 0.7209, auc 0.4596, ap 0.4682
2024-01-10 21:52:18,749 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f6cea83de90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:52:19,449 - GAugM EPNet train, Epoch [  1/295]: loss 0.7210, auc 0.3816, ap 0.4140
2024-01-10 21:52:19,536 - GAugM EPNet train, Epoch [  2/295]: loss 0.7210, auc 0.5061, ap 0.5077
2024-01-10 21:52:19,626 - GAugM EPNet train, Epoch [  3/295]: loss 0.7209, auc 0.5367, ap 0.5203
2024-01-10 21:52:19,719 - GAugM EPNet train, Epoch [  4/295]: loss 0.7209, auc 0.4331, ap 0.4453
2024-01-10 21:52:19,804 - GAugM EPNet train, Epoch [  5/295]: loss 0.7209, auc 0.5826, ap 0.5801
2024-01-10 21:52:19,891 - GAugM EPNet train, Epoch [  6/295]: loss 0.7209, auc 0.5696, ap 0.5202
2024-01-10 21:52:19,980 - GAugM EPNet train, Epoch [  7/295]: loss 0.7209, auc 0.3870, ap 0.4350
2024-01-10 21:52:20,076 - GAugM EPNet train, Epoch [  8/295]: loss 0.7210, auc 0.4639, ap 0.4860
2024-01-10 21:52:20,161 - GAugM EPNet train, Epoch [  9/295]: loss 0.7209, auc 0.4802, ap 0.4821
2024-01-10 21:52:20,251 - GAugM EPNet train, Epoch [ 10/295]: loss 0.7208, auc 0.5023, ap 0.4884
2024-01-10 21:52:20,338 - GAugM EPNet train, Epoch [ 11/295]: loss 0.7209, auc 0.4608, ap 0.4827
2024-01-10 21:52:20,427 - GAugM EPNet train, Epoch [ 12/295]: loss 0.7210, auc 0.4633, ap 0.4597
2024-01-10 21:52:20,513 - GAugM EPNet train, Epoch [ 13/295]: loss 0.7209, auc 0.5924, ap 0.5813
2024-01-10 21:52:20,603 - GAugM EPNet train, Epoch [ 14/295]: loss 0.7209, auc 0.4843, ap 0.4834
2024-01-10 21:52:20,692 - GAugM EPNet train, Epoch [ 15/295]: loss 0.7210, auc 0.4096, ap 0.4590
2024-01-10 21:52:20,784 - GAugM EPNet train, Epoch [ 16/295]: loss 0.7209, auc 0.5052, ap 0.4943
2024-01-10 21:52:20,869 - GAugM EPNet train, Epoch [ 17/295]: loss 0.7210, auc 0.5071, ap 0.5268
2024-01-10 21:52:20,956 - GAugM EPNet train, Epoch [ 18/295]: loss 0.7210, auc 0.5190, ap 0.5213
2024-01-10 21:52:21,046 - GAugM EPNet train, Epoch [ 19/295]: loss 0.7209, auc 0.4623, ap 0.4660
2024-01-10 21:52:21,134 - GAugM EPNet train, Epoch [ 20/295]: loss 0.7210, auc 0.4929, ap 0.5306
2024-01-10 21:52:21,221 - GAugM EPNet train, Epoch [ 21/295]: loss 0.7209, auc 0.5062, ap 0.4921
2024-01-10 21:52:21,318 - GAugM EPNet train, Epoch [ 22/295]: loss 0.7210, auc 0.3841, ap 0.4646
2024-01-10 21:52:21,408 - GAugM EPNet train, Epoch [ 23/295]: loss 0.7208, auc 0.5304, ap 0.5112
2024-01-10 21:52:21,497 - GAugM EPNet train, Epoch [ 24/295]: loss 0.7209, auc 0.4950, ap 0.4753
2024-01-10 21:52:21,583 - GAugM EPNet train, Epoch [ 25/295]: loss 0.7209, auc 0.4514, ap 0.4680
2024-01-10 21:52:21,685 - GAugM EPNet train, Epoch [ 26/295]: loss 0.7210, auc 0.5011, ap 0.5151
2024-01-10 21:52:21,773 - GAugM EPNet train, Epoch [ 27/295]: loss 0.7209, auc 0.4375, ap 0.5049
2024-01-10 21:52:21,872 - GAugM EPNet train, Epoch [ 28/295]: loss 0.7209, auc 0.5650, ap 0.5442
2024-01-10 21:52:21,962 - GAugM EPNet train, Epoch [ 29/295]: loss 0.7210, auc 0.4624, ap 0.4860
2024-01-10 21:52:22,054 - GAugM EPNet train, Epoch [ 30/295]: loss 0.7209, auc 0.5712, ap 0.5670
2024-01-10 21:52:22,133 - GAugM EPNet train, Epoch [ 31/295]: loss 0.7208, auc 0.4778, ap 0.4933
2024-01-10 21:52:22,213 - GAugM EPNet train, Epoch [ 32/295]: loss 0.7210, auc 0.5441, ap 0.5439
2024-01-10 21:52:22,286 - GAugM EPNet train, Epoch [ 33/295]: loss 0.7209, auc 0.5721, ap 0.6053
2024-01-10 21:52:22,360 - GAugM EPNet train, Epoch [ 34/295]: loss 0.7209, auc 0.4523, ap 0.4761
2024-01-10 21:52:22,431 - GAugM EPNet train, Epoch [ 35/295]: loss 0.7209, auc 0.5174, ap 0.5050
2024-01-10 21:52:22,511 - GAugM EPNet train, Epoch [ 36/295]: loss 0.7209, auc 0.5849, ap 0.5745
2024-01-10 21:52:22,588 - GAugM EPNet train, Epoch [ 37/295]: loss 0.7209, auc 0.5201, ap 0.5360
2024-01-10 21:52:22,662 - GAugM EPNet train, Epoch [ 38/295]: loss 0.7209, auc 0.5258, ap 0.4944
2024-01-10 21:52:22,738 - GAugM EPNet train, Epoch [ 39/295]: loss 0.7208, auc 0.4064, ap 0.4428
2024-01-10 21:52:22,817 - GAugM EPNet train, Epoch [ 40/295]: loss 0.7210, auc 0.5164, ap 0.5075
2024-01-10 21:52:22,889 - GAugM EPNet train, Epoch [ 41/295]: loss 0.7210, auc 0.5247, ap 0.5267
2024-01-10 21:52:22,963 - GAugM EPNet train, Epoch [ 42/295]: loss 0.7209, auc 0.5271, ap 0.5456
2024-01-10 21:52:23,063 - GAugM EPNet train, Epoch [ 43/295]: loss 0.7208, auc 0.4147, ap 0.4601
2024-01-10 21:52:23,154 - GAugM EPNet train, Epoch [ 44/295]: loss 0.7208, auc 0.3704, ap 0.4216
2024-01-10 21:52:23,230 - GAugM EPNet train, Epoch [ 45/295]: loss 0.7209, auc 0.4868, ap 0.4851
2024-01-10 21:52:23,302 - GAugM EPNet train, Epoch [ 46/295]: loss 0.7209, auc 0.4891, ap 0.5302
2024-01-10 21:52:23,378 - GAugM EPNet train, Epoch [ 47/295]: loss 0.7210, auc 0.4708, ap 0.4697
2024-01-10 21:52:23,453 - GAugM EPNet train, Epoch [ 48/295]: loss 0.7210, auc 0.5829, ap 0.5710
2024-01-10 21:52:23,531 - GAugM EPNet train, Epoch [ 49/295]: loss 0.7209, auc 0.5128, ap 0.5000
2024-01-10 21:52:23,968 - GAugM EPNet train, Epoch [ 50/295]: loss 0.7210, auc 0.4970, ap 0.5070
2024-01-10 21:52:24,057 - GAugM EPNet train, Epoch [ 51/295]: loss 0.7210, auc 0.4774, ap 0.4995
2024-01-10 21:52:24,144 - GAugM EPNet train, Epoch [ 52/295]: loss 0.7209, auc 0.4414, ap 0.4818
2024-01-10 21:52:24,235 - GAugM EPNet train, Epoch [ 53/295]: loss 0.7209, auc 0.4669, ap 0.4652
2024-01-10 21:52:24,315 - GAugM EPNet train, Epoch [ 54/295]: loss 0.7211, auc 0.5995, ap 0.5977
2024-01-10 21:52:24,397 - GAugM EPNet train, Epoch [ 55/295]: loss 0.7209, auc 0.6552, ap 0.6428
2024-01-10 21:52:24,476 - GAugM EPNet train, Epoch [ 56/295]: loss 0.7208, auc 0.4738, ap 0.4721
2024-01-10 21:52:24,560 - GAugM EPNet train, Epoch [ 57/295]: loss 0.7209, auc 0.4372, ap 0.4421
2024-01-10 21:52:24,638 - GAugM EPNet train, Epoch [ 58/295]: loss 0.7210, auc 0.4858, ap 0.5182
2024-01-10 21:52:24,721 - GAugM EPNet train, Epoch [ 59/295]: loss 0.7211, auc 0.4907, ap 0.4853
2024-01-10 21:52:24,797 - GAugM EPNet train, Epoch [ 60/295]: loss 0.7210, auc 0.5192, ap 0.5199
2024-01-10 21:52:24,872 - GAugM EPNet train, Epoch [ 61/295]: loss 0.7209, auc 0.5112, ap 0.5121
2024-01-10 21:52:24,950 - GAugM EPNet train, Epoch [ 62/295]: loss 0.7210, auc 0.5258, ap 0.5558
2024-01-10 21:52:25,026 - GAugM EPNet train, Epoch [ 63/295]: loss 0.7208, auc 0.4172, ap 0.4607
2024-01-10 21:52:25,107 - GAugM EPNet train, Epoch [ 64/295]: loss 0.7208, auc 0.4304, ap 0.4880
2024-01-10 21:52:25,183 - GAugM EPNet train, Epoch [ 65/295]: loss 0.7208, auc 0.5603, ap 0.5608
2024-01-10 21:52:25,264 - GAugM EPNet train, Epoch [ 66/295]: loss 0.7209, auc 0.5166, ap 0.5353
2024-01-10 21:52:25,349 - GAugM EPNet train, Epoch [ 67/295]: loss 0.7209, auc 0.5623, ap 0.5403
2024-01-10 21:52:25,431 - GAugM EPNet train, Epoch [ 68/295]: loss 0.7210, auc 0.4676, ap 0.4910
2024-01-10 21:52:25,509 - GAugM EPNet train, Epoch [ 69/295]: loss 0.7210, auc 0.4607, ap 0.4779
2024-01-10 21:52:25,600 - GAugM EPNet train, Epoch [ 70/295]: loss 0.7210, auc 0.4922, ap 0.4717
2024-01-10 21:52:25,677 - GAugM EPNet train, Epoch [ 71/295]: loss 0.7210, auc 0.5619, ap 0.5614
2024-01-10 21:52:25,755 - GAugM EPNet train, Epoch [ 72/295]: loss 0.7210, auc 0.4114, ap 0.4609
2024-01-10 21:52:25,840 - GAugM EPNet train, Epoch [ 73/295]: loss 0.7209, auc 0.5224, ap 0.5048
2024-01-10 21:52:25,917 - GAugM EPNet train, Epoch [ 74/295]: loss 0.7209, auc 0.5459, ap 0.5233
2024-01-10 21:52:26,003 - GAugM EPNet train, Epoch [ 75/295]: loss 0.7210, auc 0.4571, ap 0.4673
2024-01-10 21:52:26,090 - GAugM EPNet train, Epoch [ 76/295]: loss 0.7209, auc 0.4229, ap 0.4396
2024-01-10 21:52:26,177 - GAugM EPNet train, Epoch [ 77/295]: loss 0.7208, auc 0.5644, ap 0.5749
2024-01-10 21:52:26,252 - GAugM EPNet train, Epoch [ 78/295]: loss 0.7209, auc 0.4984, ap 0.5108
2024-01-10 21:52:26,327 - GAugM EPNet train, Epoch [ 79/295]: loss 0.7208, auc 0.4989, ap 0.4974
2024-01-10 21:52:26,404 - GAugM EPNet train, Epoch [ 80/295]: loss 0.7209, auc 0.5057, ap 0.5060
2024-01-10 21:52:26,485 - GAugM EPNet train, Epoch [ 81/295]: loss 0.7209, auc 0.4733, ap 0.4631
2024-01-10 21:52:26,578 - GAugM EPNet train, Epoch [ 82/295]: loss 0.7210, auc 0.5169, ap 0.5017
2024-01-10 21:52:26,675 - GAugM EPNet train, Epoch [ 83/295]: loss 0.7209, auc 0.3781, ap 0.4443
2024-01-10 21:52:26,764 - GAugM EPNet train, Epoch [ 84/295]: loss 0.7209, auc 0.4537, ap 0.4832
2024-01-10 21:52:26,856 - GAugM EPNet train, Epoch [ 85/295]: loss 0.7210, auc 0.4587, ap 0.4845
2024-01-10 21:52:26,954 - GAugM EPNet train, Epoch [ 86/295]: loss 0.7208, auc 0.4105, ap 0.4534
2024-01-10 21:52:27,044 - GAugM EPNet train, Epoch [ 87/295]: loss 0.7209, auc 0.4856, ap 0.4911
2024-01-10 21:52:27,135 - GAugM EPNet train, Epoch [ 88/295]: loss 0.7210, auc 0.5593, ap 0.5609
2024-01-10 21:52:27,226 - GAugM EPNet train, Epoch [ 89/295]: loss 0.7210, auc 0.5267, ap 0.5420
2024-01-10 21:52:27,318 - GAugM EPNet train, Epoch [ 90/295]: loss 0.7209, auc 0.3674, ap 0.4134
2024-01-10 21:52:27,406 - GAugM EPNet train, Epoch [ 91/295]: loss 0.7208, auc 0.5383, ap 0.5122
2024-01-10 21:52:27,500 - GAugM EPNet train, Epoch [ 92/295]: loss 0.7209, auc 0.5764, ap 0.5650
2024-01-10 21:52:27,601 - GAugM EPNet train, Epoch [ 93/295]: loss 0.7209, auc 0.4235, ap 0.4672
2024-01-10 21:52:27,687 - GAugM EPNet train, Epoch [ 94/295]: loss 0.7210, auc 0.4078, ap 0.4723
2024-01-10 21:52:27,771 - GAugM EPNet train, Epoch [ 95/295]: loss 0.7210, auc 0.4325, ap 0.4492
2024-01-10 21:52:27,861 - GAugM EPNet train, Epoch [ 96/295]: loss 0.7209, auc 0.5434, ap 0.5384
2024-01-10 21:52:27,947 - GAugM EPNet train, Epoch [ 97/295]: loss 0.7209, auc 0.4377, ap 0.4939
2024-01-10 21:52:28,036 - GAugM EPNet train, Epoch [ 98/295]: loss 0.7209, auc 0.4372, ap 0.4564
2024-01-10 21:52:28,125 - GAugM EPNet train, Epoch [ 99/295]: loss 0.7209, auc 0.5425, ap 0.5498
2024-01-10 21:52:28,213 - GAugM EPNet train, Epoch [100/295]: loss 0.7210, auc 0.4576, ap 0.4970
2024-01-10 21:52:28,301 - GAugM EPNet train, Epoch [101/295]: loss 0.7210, auc 0.5580, ap 0.6127
2024-01-10 21:52:28,393 - GAugM EPNet train, Epoch [102/295]: loss 0.7209, auc 0.4165, ap 0.4373
2024-01-10 21:52:28,482 - GAugM EPNet train, Epoch [103/295]: loss 0.7209, auc 0.4890, ap 0.5305
2024-01-10 21:52:28,573 - GAugM EPNet train, Epoch [104/295]: loss 0.7209, auc 0.4471, ap 0.4701
2024-01-10 21:52:28,656 - GAugM EPNet train, Epoch [105/295]: loss 0.7209, auc 0.4957, ap 0.5072
2024-01-10 21:52:28,736 - GAugM EPNet train, Epoch [106/295]: loss 0.7210, auc 0.5431, ap 0.5394
2024-01-10 21:52:28,814 - GAugM EPNet train, Epoch [107/295]: loss 0.7210, auc 0.5662, ap 0.5843
2024-01-10 21:52:28,908 - GAugM EPNet train, Epoch [108/295]: loss 0.7208, auc 0.5367, ap 0.5165
2024-01-10 21:52:29,001 - GAugM EPNet train, Epoch [109/295]: loss 0.7210, auc 0.4562, ap 0.4607
2024-01-10 21:52:29,101 - GAugM EPNet train, Epoch [110/295]: loss 0.7209, auc 0.4721, ap 0.4780
2024-01-10 21:52:29,192 - GAugM EPNet train, Epoch [111/295]: loss 0.7210, auc 0.4977, ap 0.5276
2024-01-10 21:52:29,297 - GAugM EPNet train, Epoch [112/295]: loss 0.7209, auc 0.5144, ap 0.5267
2024-01-10 21:52:29,401 - GAugM EPNet train, Epoch [113/295]: loss 0.7210, auc 0.4998, ap 0.5223
2024-01-10 21:52:29,505 - GAugM EPNet train, Epoch [114/295]: loss 0.7209, auc 0.4824, ap 0.4874
2024-01-10 21:52:29,597 - GAugM EPNet train, Epoch [115/295]: loss 0.7210, auc 0.4758, ap 0.4690
2024-01-10 21:52:29,685 - GAugM EPNet train, Epoch [116/295]: loss 0.7209, auc 0.4587, ap 0.4772
2024-01-10 21:52:29,781 - GAugM EPNet train, Epoch [117/295]: loss 0.7208, auc 0.4397, ap 0.4650
2024-01-10 21:52:29,872 - GAugM EPNet train, Epoch [118/295]: loss 0.7209, auc 0.4788, ap 0.5018
2024-01-10 21:52:29,963 - GAugM EPNet train, Epoch [119/295]: loss 0.7209, auc 0.4774, ap 0.5181
2024-01-10 21:52:30,059 - GAugM EPNet train, Epoch [120/295]: loss 0.7210, auc 0.4539, ap 0.4544
2024-01-10 21:52:30,149 - GAugM EPNet train, Epoch [121/295]: loss 0.7210, auc 0.4802, ap 0.4859
2024-01-10 21:52:30,241 - GAugM EPNet train, Epoch [122/295]: loss 0.7209, auc 0.5564, ap 0.5464
2024-01-10 21:52:30,319 - GAugM EPNet train, Epoch [123/295]: loss 0.7209, auc 0.5554, ap 0.5340
2024-01-10 21:52:30,400 - GAugM EPNet train, Epoch [124/295]: loss 0.7210, auc 0.4875, ap 0.4756
2024-01-10 21:52:30,488 - GAugM EPNet train, Epoch [125/295]: loss 0.7209, auc 0.5352, ap 0.5200
2024-01-10 21:52:30,580 - GAugM EPNet train, Epoch [126/295]: loss 0.7210, auc 0.4899, ap 0.4890
2024-01-10 21:52:30,670 - GAugM EPNet train, Epoch [127/295]: loss 0.7209, auc 0.4523, ap 0.4565
2024-01-10 21:52:30,757 - GAugM EPNet train, Epoch [128/295]: loss 0.7210, auc 0.5635, ap 0.5549
2024-01-10 21:52:30,851 - GAugM EPNet train, Epoch [129/295]: loss 0.7208, auc 0.3920, ap 0.4417
2024-01-10 21:52:30,954 - GAugM EPNet train, Epoch [130/295]: loss 0.7210, auc 0.5151, ap 0.4995
2024-01-10 21:52:31,052 - GAugM EPNet train, Epoch [131/295]: loss 0.7210, auc 0.4608, ap 0.4998
2024-01-10 21:52:31,137 - GAugM EPNet train, Epoch [132/295]: loss 0.7209, auc 0.5404, ap 0.5221
2024-01-10 21:52:31,225 - GAugM EPNet train, Epoch [133/295]: loss 0.7209, auc 0.4731, ap 0.5285
2024-01-10 21:52:31,308 - GAugM EPNet train, Epoch [134/295]: loss 0.7210, auc 0.4865, ap 0.4992
2024-01-10 21:52:31,390 - GAugM EPNet train, Epoch [135/295]: loss 0.7209, auc 0.4001, ap 0.4307
2024-01-10 21:52:31,473 - GAugM EPNet train, Epoch [136/295]: loss 0.7209, auc 0.4989, ap 0.4934
2024-01-10 21:52:31,559 - GAugM EPNet train, Epoch [137/295]: loss 0.7210, auc 0.4484, ap 0.4556
2024-01-10 21:52:31,645 - GAugM EPNet train, Epoch [138/295]: loss 0.7210, auc 0.5934, ap 0.5934
2024-01-10 21:52:31,728 - GAugM EPNet train, Epoch [139/295]: loss 0.7210, auc 0.4710, ap 0.4965
2024-01-10 21:52:31,810 - GAugM EPNet train, Epoch [140/295]: loss 0.7209, auc 0.5050, ap 0.5355
2024-01-10 21:52:31,896 - GAugM EPNet train, Epoch [141/295]: loss 0.7209, auc 0.5532, ap 0.5339
2024-01-10 21:52:31,971 - GAugM EPNet train, Epoch [142/295]: loss 0.7209, auc 0.5276, ap 0.5218
2024-01-10 21:52:32,051 - GAugM EPNet train, Epoch [143/295]: loss 0.7209, auc 0.4078, ap 0.4466
2024-01-10 21:52:32,125 - GAugM EPNet train, Epoch [144/295]: loss 0.7209, auc 0.4731, ap 0.4747
2024-01-10 21:52:32,201 - GAugM EPNet train, Epoch [145/295]: loss 0.7209, auc 0.4138, ap 0.4931
2024-01-10 21:52:32,274 - GAugM EPNet train, Epoch [146/295]: loss 0.7209, auc 0.5466, ap 0.5269
2024-01-10 21:52:32,362 - GAugM EPNet train, Epoch [147/295]: loss 0.7209, auc 0.5667, ap 0.5856
2024-01-10 21:52:32,445 - GAugM EPNet train, Epoch [148/295]: loss 0.7209, auc 0.4754, ap 0.5192
2024-01-10 21:52:32,527 - GAugM EPNet train, Epoch [149/295]: loss 0.7208, auc 0.4208, ap 0.4475
2024-01-10 21:52:32,611 - GAugM EPNet train, Epoch [150/295]: loss 0.7209, auc 0.5150, ap 0.5086
2024-01-10 21:52:32,698 - GAugM EPNet train, Epoch [151/295]: loss 0.7209, auc 0.5005, ap 0.4869
2024-01-10 21:52:32,801 - GAugM EPNet train, Epoch [152/295]: loss 0.7209, auc 0.5789, ap 0.5789
2024-01-10 21:52:32,892 - GAugM EPNet train, Epoch [153/295]: loss 0.7209, auc 0.4569, ap 0.5101
2024-01-10 21:52:32,975 - GAugM EPNet train, Epoch [154/295]: loss 0.7209, auc 0.5557, ap 0.5890
2024-01-10 21:52:33,059 - GAugM EPNet train, Epoch [155/295]: loss 0.7209, auc 0.4931, ap 0.5022
2024-01-10 21:52:33,149 - GAugM EPNet train, Epoch [156/295]: loss 0.7209, auc 0.4138, ap 0.4487
2024-01-10 21:52:33,231 - GAugM EPNet train, Epoch [157/295]: loss 0.7209, auc 0.5246, ap 0.5204
2024-01-10 21:52:33,320 - GAugM EPNet train, Epoch [158/295]: loss 0.7208, auc 0.4163, ap 0.4619
2024-01-10 21:52:33,409 - GAugM EPNet train, Epoch [159/295]: loss 0.7208, auc 0.4227, ap 0.4511
2024-01-10 21:52:33,499 - GAugM EPNet train, Epoch [160/295]: loss 0.7209, auc 0.6098, ap 0.6043
2024-01-10 21:52:33,581 - GAugM EPNet train, Epoch [161/295]: loss 0.7209, auc 0.5425, ap 0.5200
2024-01-10 21:52:33,669 - GAugM EPNet train, Epoch [162/295]: loss 0.7209, auc 0.4628, ap 0.4665
2024-01-10 21:52:33,770 - GAugM EPNet train, Epoch [163/295]: loss 0.7209, auc 0.4950, ap 0.4955
2024-01-10 21:52:33,863 - GAugM EPNet train, Epoch [164/295]: loss 0.7211, auc 0.5167, ap 0.5040
2024-01-10 21:52:33,944 - GAugM EPNet train, Epoch [165/295]: loss 0.7210, auc 0.4729, ap 0.4672
2024-01-10 21:52:34,028 - GAugM EPNet train, Epoch [166/295]: loss 0.7208, auc 0.5135, ap 0.5106
2024-01-10 21:52:34,113 - GAugM EPNet train, Epoch [167/295]: loss 0.7209, auc 0.4637, ap 0.4798
2024-01-10 21:52:34,193 - GAugM EPNet train, Epoch [168/295]: loss 0.7209, auc 0.4518, ap 0.4903
2024-01-10 21:52:34,275 - GAugM EPNet train, Epoch [169/295]: loss 0.7209, auc 0.5226, ap 0.5272
2024-01-10 21:52:34,355 - GAugM EPNet train, Epoch [170/295]: loss 0.7210, auc 0.4530, ap 0.4620
2024-01-10 21:52:34,440 - GAugM EPNet train, Epoch [171/295]: loss 0.7209, auc 0.5130, ap 0.5259
2024-01-10 21:52:34,530 - GAugM EPNet train, Epoch [172/295]: loss 0.7208, auc 0.4822, ap 0.4809
2024-01-10 21:52:34,620 - GAugM EPNet train, Epoch [173/295]: loss 0.7209, auc 0.5105, ap 0.5382
2024-01-10 21:52:34,702 - GAugM EPNet train, Epoch [174/295]: loss 0.7209, auc 0.4158, ap 0.4440
2024-01-10 21:52:34,790 - GAugM EPNet train, Epoch [175/295]: loss 0.7209, auc 0.6367, ap 0.5902
2024-01-10 21:52:34,872 - GAugM EPNet train, Epoch [176/295]: loss 0.7209, auc 0.5379, ap 0.5196
2024-01-10 21:52:34,964 - GAugM EPNet train, Epoch [177/295]: loss 0.7210, auc 0.4865, ap 0.4876
2024-01-10 21:52:35,056 - GAugM EPNet train, Epoch [178/295]: loss 0.7210, auc 0.5215, ap 0.5744
2024-01-10 21:52:35,136 - GAugM EPNet train, Epoch [179/295]: loss 0.7210, auc 0.3257, ap 0.4210
2024-01-10 21:52:35,232 - GAugM EPNet train, Epoch [180/295]: loss 0.7210, auc 0.5004, ap 0.5072
2024-01-10 21:52:35,313 - GAugM EPNet train, Epoch [181/295]: loss 0.7209, auc 0.4543, ap 0.4556
2024-01-10 21:52:35,397 - GAugM EPNet train, Epoch [182/295]: loss 0.7209, auc 0.4379, ap 0.4846
2024-01-10 21:52:35,479 - GAugM EPNet train, Epoch [183/295]: loss 0.7210, auc 0.6155, ap 0.5830
2024-01-10 21:52:35,573 - GAugM EPNet train, Epoch [184/295]: loss 0.7209, auc 0.5169, ap 0.5011
2024-01-10 21:52:35,677 - GAugM EPNet train, Epoch [185/295]: loss 0.7209, auc 0.5016, ap 0.4994
2024-01-10 21:52:35,768 - GAugM EPNet train, Epoch [186/295]: loss 0.7208, auc 0.3766, ap 0.4265
2024-01-10 21:52:35,868 - GAugM EPNet train, Epoch [187/295]: loss 0.7209, auc 0.5520, ap 0.5454
2024-01-10 21:52:35,968 - GAugM EPNet train, Epoch [188/295]: loss 0.7209, auc 0.4108, ap 0.4402
2024-01-10 21:52:36,058 - GAugM EPNet train, Epoch [189/295]: loss 0.7209, auc 0.6015, ap 0.6030
2024-01-10 21:52:36,147 - GAugM EPNet train, Epoch [190/295]: loss 0.7209, auc 0.4110, ap 0.4421
2024-01-10 21:52:36,239 - GAugM EPNet train, Epoch [191/295]: loss 0.7209, auc 0.4121, ap 0.4575
2024-01-10 21:52:36,327 - GAugM EPNet train, Epoch [192/295]: loss 0.7209, auc 0.5005, ap 0.4986
2024-01-10 21:52:36,421 - GAugM EPNet train, Epoch [193/295]: loss 0.7209, auc 0.5644, ap 0.5448
2024-01-10 21:52:36,511 - GAugM EPNet train, Epoch [194/295]: loss 0.7209, auc 0.5044, ap 0.5320
2024-01-10 21:52:36,600 - GAugM EPNet train, Epoch [195/295]: loss 0.7209, auc 0.4349, ap 0.4586
2024-01-10 21:52:36,698 - GAugM EPNet train, Epoch [196/295]: loss 0.7208, auc 0.4505, ap 0.4629
2024-01-10 21:52:36,789 - GAugM EPNet train, Epoch [197/295]: loss 0.7210, auc 0.4420, ap 0.4639
2024-01-10 21:52:36,876 - GAugM EPNet train, Epoch [198/295]: loss 0.7210, auc 0.5653, ap 0.5274
2024-01-10 21:52:36,968 - GAugM EPNet train, Epoch [199/295]: loss 0.7209, auc 0.5224, ap 0.5554
2024-01-10 21:52:37,061 - GAugM EPNet train, Epoch [200/295]: loss 0.7210, auc 0.5324, ap 0.5416
2024-01-10 21:52:37,150 - GAugM EPNet train, Epoch [201/295]: loss 0.7209, auc 0.4879, ap 0.5155
2024-01-10 21:52:37,241 - GAugM EPNet train, Epoch [202/295]: loss 0.7210, auc 0.5126, ap 0.5507
2024-01-10 21:52:37,327 - GAugM EPNet train, Epoch [203/295]: loss 0.7210, auc 0.5313, ap 0.5621
2024-01-10 21:52:37,422 - GAugM EPNet train, Epoch [204/295]: loss 0.7209, auc 0.5174, ap 0.5056
2024-01-10 21:52:37,521 - GAugM EPNet train, Epoch [205/295]: loss 0.7209, auc 0.4751, ap 0.5043
2024-01-10 21:52:37,621 - GAugM EPNet train, Epoch [206/295]: loss 0.7209, auc 0.4359, ap 0.4631
2024-01-10 21:52:37,718 - GAugM EPNet train, Epoch [207/295]: loss 0.7210, auc 0.4893, ap 0.5183
2024-01-10 21:52:37,811 - GAugM EPNet train, Epoch [208/295]: loss 0.7209, auc 0.4470, ap 0.5113
2024-01-10 21:52:37,905 - GAugM EPNet train, Epoch [209/295]: loss 0.7210, auc 0.5845, ap 0.5790
2024-01-10 21:52:38,006 - GAugM EPNet train, Epoch [210/295]: loss 0.7209, auc 0.4671, ap 0.4800
2024-01-10 21:52:38,107 - GAugM EPNet train, Epoch [211/295]: loss 0.7210, auc 0.4482, ap 0.4906
2024-01-10 21:52:38,200 - GAugM EPNet train, Epoch [212/295]: loss 0.7210, auc 0.4612, ap 0.4601
2024-01-10 21:52:38,291 - GAugM EPNet train, Epoch [213/295]: loss 0.7208, auc 0.5885, ap 0.5848
2024-01-10 21:52:38,390 - GAugM EPNet train, Epoch [214/295]: loss 0.7210, auc 0.5228, ap 0.5239
2024-01-10 21:52:38,480 - GAugM EPNet train, Epoch [215/295]: loss 0.7210, auc 0.4763, ap 0.4775
2024-01-10 21:52:38,573 - GAugM EPNet train, Epoch [216/295]: loss 0.7209, auc 0.5609, ap 0.5535
2024-01-10 21:52:38,663 - GAugM EPNet train, Epoch [217/295]: loss 0.7209, auc 0.5707, ap 0.5910
2024-01-10 21:52:38,766 - GAugM EPNet train, Epoch [218/295]: loss 0.7209, auc 0.5303, ap 0.5486
2024-01-10 21:52:38,857 - GAugM EPNet train, Epoch [219/295]: loss 0.7208, auc 0.4489, ap 0.4637
2024-01-10 21:52:38,947 - GAugM EPNet train, Epoch [220/295]: loss 0.7210, auc 0.4906, ap 0.5271
2024-01-10 21:52:39,046 - GAugM EPNet train, Epoch [221/295]: loss 0.7209, auc 0.5582, ap 0.5406
2024-01-10 21:52:39,144 - GAugM EPNet train, Epoch [222/295]: loss 0.7209, auc 0.4995, ap 0.5202
2024-01-10 21:52:39,236 - GAugM EPNet train, Epoch [223/295]: loss 0.7209, auc 0.5507, ap 0.5482
2024-01-10 21:52:39,329 - GAugM EPNet train, Epoch [224/295]: loss 0.7210, auc 0.3964, ap 0.4377
2024-01-10 21:52:39,421 - GAugM EPNet train, Epoch [225/295]: loss 0.7209, auc 0.4366, ap 0.4600
2024-01-10 21:52:39,514 - GAugM EPNet train, Epoch [226/295]: loss 0.7210, auc 0.5523, ap 0.5513
2024-01-10 21:52:39,608 - GAugM EPNet train, Epoch [227/295]: loss 0.7210, auc 0.4920, ap 0.4810
2024-01-10 21:52:39,701 - GAugM EPNet train, Epoch [228/295]: loss 0.7209, auc 0.5481, ap 0.5354
2024-01-10 21:52:39,788 - GAugM EPNet train, Epoch [229/295]: loss 0.7209, auc 0.4890, ap 0.5155
2024-01-10 21:52:39,879 - GAugM EPNet train, Epoch [230/295]: loss 0.7209, auc 0.4824, ap 0.5391
2024-01-10 21:52:39,972 - GAugM EPNet train, Epoch [231/295]: loss 0.7209, auc 0.4710, ap 0.4833
2024-01-10 21:52:40,064 - GAugM EPNet train, Epoch [232/295]: loss 0.7209, auc 0.5150, ap 0.5106
2024-01-10 21:52:40,145 - GAugM EPNet train, Epoch [233/295]: loss 0.7210, auc 0.5021, ap 0.4884
2024-01-10 21:52:40,234 - GAugM EPNet train, Epoch [234/295]: loss 0.7209, auc 0.3763, ap 0.4285
2024-01-10 21:52:40,332 - GAugM EPNet train, Epoch [235/295]: loss 0.7209, auc 0.3987, ap 0.4324
2024-01-10 21:52:40,418 - GAugM EPNet train, Epoch [236/295]: loss 0.7209, auc 0.5288, ap 0.5483
2024-01-10 21:52:40,517 - GAugM EPNet train, Epoch [237/295]: loss 0.7210, auc 0.4982, ap 0.4858
2024-01-10 21:52:40,609 - GAugM EPNet train, Epoch [238/295]: loss 0.7210, auc 0.4916, ap 0.5136
2024-01-10 21:52:40,697 - GAugM EPNet train, Epoch [239/295]: loss 0.7209, auc 0.4895, ap 0.5424
2024-01-10 21:52:40,782 - GAugM EPNet train, Epoch [240/295]: loss 0.7209, auc 0.4560, ap 0.4624
2024-01-10 21:52:40,871 - GAugM EPNet train, Epoch [241/295]: loss 0.7209, auc 0.6027, ap 0.5725
2024-01-10 21:52:40,957 - GAugM EPNet train, Epoch [242/295]: loss 0.7210, auc 0.4758, ap 0.4842
2024-01-10 21:52:41,039 - GAugM EPNet train, Epoch [243/295]: loss 0.7210, auc 0.5114, ap 0.5825
2024-01-10 21:52:41,126 - GAugM EPNet train, Epoch [244/295]: loss 0.7209, auc 0.5112, ap 0.4886
2024-01-10 21:52:41,209 - GAugM EPNet train, Epoch [245/295]: loss 0.7210, auc 0.4183, ap 0.4662
2024-01-10 21:52:41,293 - GAugM EPNet train, Epoch [246/295]: loss 0.7208, auc 0.5169, ap 0.5338
2024-01-10 21:52:41,375 - GAugM EPNet train, Epoch [247/295]: loss 0.7209, auc 0.5196, ap 0.5122
2024-01-10 21:52:41,449 - GAugM EPNet train, Epoch [248/295]: loss 0.7211, auc 0.4991, ap 0.5046
2024-01-10 21:52:41,540 - GAugM EPNet train, Epoch [249/295]: loss 0.7209, auc 0.4877, ap 0.4749
2024-01-10 21:52:41,630 - GAugM EPNet train, Epoch [250/295]: loss 0.7208, auc 0.5082, ap 0.5073
2024-01-10 21:52:41,720 - GAugM EPNet train, Epoch [251/295]: loss 0.7209, auc 0.5404, ap 0.5555
2024-01-10 21:52:41,804 - GAugM EPNet train, Epoch [252/295]: loss 0.7210, auc 0.4760, ap 0.5118
2024-01-10 21:52:41,888 - GAugM EPNet train, Epoch [253/295]: loss 0.7209, auc 0.5295, ap 0.5197
2024-01-10 21:52:41,979 - GAugM EPNet train, Epoch [254/295]: loss 0.7210, auc 0.5123, ap 0.5314
2024-01-10 21:52:42,079 - GAugM EPNet train, Epoch [255/295]: loss 0.7209, auc 0.5425, ap 0.5337
2024-01-10 21:52:42,171 - GAugM EPNet train, Epoch [256/295]: loss 0.7210, auc 0.3987, ap 0.4785
2024-01-10 21:52:42,268 - GAugM EPNet train, Epoch [257/295]: loss 0.7210, auc 0.5039, ap 0.5375
2024-01-10 21:52:42,357 - GAugM EPNet train, Epoch [258/295]: loss 0.7208, auc 0.5400, ap 0.5750
2024-01-10 21:52:42,452 - GAugM EPNet train, Epoch [259/295]: loss 0.7208, auc 0.5847, ap 0.5489
2024-01-10 21:52:42,553 - GAugM EPNet train, Epoch [260/295]: loss 0.7210, auc 0.5101, ap 0.4909
2024-01-10 21:52:42,644 - GAugM EPNet train, Epoch [261/295]: loss 0.7209, auc 0.5105, ap 0.5093
2024-01-10 21:52:42,735 - GAugM EPNet train, Epoch [262/295]: loss 0.7208, auc 0.5009, ap 0.5013
2024-01-10 21:52:42,829 - GAugM EPNet train, Epoch [263/295]: loss 0.7209, auc 0.4934, ap 0.4958
2024-01-10 21:52:42,917 - GAugM EPNet train, Epoch [264/295]: loss 0.7210, auc 0.4722, ap 0.4912
2024-01-10 21:52:43,012 - GAugM EPNet train, Epoch [265/295]: loss 0.7209, auc 0.5290, ap 0.5927
2024-01-10 21:52:43,097 - GAugM EPNet train, Epoch [266/295]: loss 0.7209, auc 0.4578, ap 0.4656
2024-01-10 21:52:43,189 - GAugM EPNet train, Epoch [267/295]: loss 0.7210, auc 0.4505, ap 0.4468
2024-01-10 21:52:43,276 - GAugM EPNet train, Epoch [268/295]: loss 0.7210, auc 0.5219, ap 0.5331
2024-01-10 21:52:43,366 - GAugM EPNet train, Epoch [269/295]: loss 0.7209, auc 0.5886, ap 0.5877
2024-01-10 21:52:43,461 - GAugM EPNet train, Epoch [270/295]: loss 0.7210, auc 0.5077, ap 0.5041
2024-01-10 21:52:43,547 - GAugM EPNet train, Epoch [271/295]: loss 0.7209, auc 0.4859, ap 0.5111
2024-01-10 21:52:43,643 - GAugM EPNet train, Epoch [272/295]: loss 0.7209, auc 0.5445, ap 0.5098
2024-01-10 21:52:43,737 - GAugM EPNet train, Epoch [273/295]: loss 0.7209, auc 0.4452, ap 0.4632
2024-01-10 21:52:43,813 - GAugM EPNet train, Epoch [274/295]: loss 0.7209, auc 0.5554, ap 0.5421
2024-01-10 21:52:43,888 - GAugM EPNet train, Epoch [275/295]: loss 0.7208, auc 0.4915, ap 0.4972
2024-01-10 21:52:43,963 - GAugM EPNet train, Epoch [276/295]: loss 0.7210, auc 0.5895, ap 0.5966
2024-01-10 21:52:44,046 - GAugM EPNet train, Epoch [277/295]: loss 0.7208, auc 0.4138, ap 0.4566
2024-01-10 21:52:44,130 - GAugM EPNet train, Epoch [278/295]: loss 0.7209, auc 0.5593, ap 0.5638
2024-01-10 21:52:44,206 - GAugM EPNet train, Epoch [279/295]: loss 0.7209, auc 0.5828, ap 0.5614
2024-01-10 21:52:44,296 - GAugM EPNet train, Epoch [280/295]: loss 0.7209, auc 0.3863, ap 0.4195
2024-01-10 21:52:44,384 - GAugM EPNet train, Epoch [281/295]: loss 0.7209, auc 0.5694, ap 0.5797
2024-01-10 21:52:44,463 - GAugM EPNet train, Epoch [282/295]: loss 0.7209, auc 0.5363, ap 0.5074
2024-01-10 21:52:44,551 - GAugM EPNet train, Epoch [283/295]: loss 0.7209, auc 0.5607, ap 0.5669
2024-01-10 21:52:44,628 - GAugM EPNet train, Epoch [284/295]: loss 0.7209, auc 0.3453, ap 0.4178
2024-01-10 21:52:44,717 - GAugM EPNet train, Epoch [285/295]: loss 0.7209, auc 0.4970, ap 0.5276
2024-01-10 21:52:44,807 - GAugM EPNet train, Epoch [286/295]: loss 0.7209, auc 0.5700, ap 0.5665
2024-01-10 21:52:44,885 - GAugM EPNet train, Epoch [287/295]: loss 0.7209, auc 0.5429, ap 0.5857
2024-01-10 21:52:44,977 - GAugM EPNet train, Epoch [288/295]: loss 0.7210, auc 0.4858, ap 0.5358
2024-01-10 21:52:45,076 - GAugM EPNet train, Epoch [289/295]: loss 0.7209, auc 0.4988, ap 0.4841
2024-01-10 21:52:45,167 - GAugM EPNet train, Epoch [290/295]: loss 0.7210, auc 0.5093, ap 0.5120
2024-01-10 21:52:45,244 - GAugM EPNet train, Epoch [291/295]: loss 0.7210, auc 0.3656, ap 0.4341
2024-01-10 21:52:45,322 - GAugM EPNet train, Epoch [292/295]: loss 0.7209, auc 0.4254, ap 0.4565
2024-01-10 21:52:45,406 - GAugM EPNet train, Epoch [293/295]: loss 0.7210, auc 0.4569, ap 0.4532
2024-01-10 21:52:45,490 - GAugM EPNet train, Epoch [294/295]: loss 0.7211, auc 0.4272, ap 0.4665
2024-01-10 21:52:45,569 - GAugM EPNet train, Epoch [295/295]: loss 0.7209, auc 0.4404, ap 0.4450
2024-01-10 21:52:45,579 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f6cea81d8d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:52:46,376 - GAugM EPNet train, Epoch [  1/295]: loss 0.7210, auc 0.4165, ap 0.4434
2024-01-10 21:52:46,469 - GAugM EPNet train, Epoch [  2/295]: loss 0.7210, auc 0.5514, ap 0.5219
2024-01-10 21:52:46,564 - GAugM EPNet train, Epoch [  3/295]: loss 0.7209, auc 0.5575, ap 0.5348
2024-01-10 21:52:46,655 - GAugM EPNet train, Epoch [  4/295]: loss 0.7209, auc 0.5372, ap 0.5541
2024-01-10 21:52:46,747 - GAugM EPNet train, Epoch [  5/295]: loss 0.7209, auc 0.6056, ap 0.6036
2024-01-10 21:52:46,843 - GAugM EPNet train, Epoch [  6/295]: loss 0.7209, auc 0.5048, ap 0.5102
2024-01-10 21:52:46,937 - GAugM EPNet train, Epoch [  7/295]: loss 0.7209, auc 0.3667, ap 0.4201
2024-01-10 21:52:47,016 - GAugM EPNet train, Epoch [  8/295]: loss 0.7210, auc 0.4881, ap 0.4894
2024-01-10 21:52:47,093 - GAugM EPNet train, Epoch [  9/295]: loss 0.7209, auc 0.5162, ap 0.4938
2024-01-10 21:52:47,174 - GAugM EPNet train, Epoch [ 10/295]: loss 0.7208, auc 0.4959, ap 0.5336
2024-01-10 21:52:47,252 - GAugM EPNet train, Epoch [ 11/295]: loss 0.7209, auc 0.4603, ap 0.4944
2024-01-10 21:52:47,330 - GAugM EPNet train, Epoch [ 12/295]: loss 0.7210, auc 0.4617, ap 0.4726
2024-01-10 21:52:47,407 - GAugM EPNet train, Epoch [ 13/295]: loss 0.7209, auc 0.5233, ap 0.5439
2024-01-10 21:52:47,491 - GAugM EPNet train, Epoch [ 14/295]: loss 0.7209, auc 0.6123, ap 0.5767
2024-01-10 21:52:47,570 - GAugM EPNet train, Epoch [ 15/295]: loss 0.7210, auc 0.4279, ap 0.4950
2024-01-10 21:52:47,648 - GAugM EPNet train, Epoch [ 16/295]: loss 0.7209, auc 0.5098, ap 0.5183
2024-01-10 21:52:47,737 - GAugM EPNet train, Epoch [ 17/295]: loss 0.7210, auc 0.5148, ap 0.5136
2024-01-10 21:52:47,823 - GAugM EPNet train, Epoch [ 18/295]: loss 0.7210, auc 0.5568, ap 0.5542
2024-01-10 21:52:47,912 - GAugM EPNet train, Epoch [ 19/295]: loss 0.7209, auc 0.5126, ap 0.5005
2024-01-10 21:52:48,006 - GAugM EPNet train, Epoch [ 20/295]: loss 0.7210, auc 0.5429, ap 0.5350
2024-01-10 21:52:48,096 - GAugM EPNet train, Epoch [ 21/295]: loss 0.7209, auc 0.5130, ap 0.5247
2024-01-10 21:52:48,185 - GAugM EPNet train, Epoch [ 22/295]: loss 0.7210, auc 0.4162, ap 0.4439
2024-01-10 21:52:48,276 - GAugM EPNet train, Epoch [ 23/295]: loss 0.7208, auc 0.4194, ap 0.4441
2024-01-10 21:52:48,369 - GAugM EPNet train, Epoch [ 24/295]: loss 0.7209, auc 0.5568, ap 0.5432
2024-01-10 21:52:48,459 - GAugM EPNet train, Epoch [ 25/295]: loss 0.7209, auc 0.3489, ap 0.4145
2024-01-10 21:52:48,559 - GAugM EPNet train, Epoch [ 26/295]: loss 0.7210, auc 0.5600, ap 0.5863
2024-01-10 21:52:48,648 - GAugM EPNet train, Epoch [ 27/295]: loss 0.7209, auc 0.4322, ap 0.5234
2024-01-10 21:52:48,747 - GAugM EPNet train, Epoch [ 28/295]: loss 0.7209, auc 0.5870, ap 0.5986
2024-01-10 21:52:48,857 - GAugM EPNet train, Epoch [ 29/295]: loss 0.7210, auc 0.4592, ap 0.4797
2024-01-10 21:52:48,956 - GAugM EPNet train, Epoch [ 30/295]: loss 0.7209, auc 0.5194, ap 0.5160
2024-01-10 21:52:49,055 - GAugM EPNet train, Epoch [ 31/295]: loss 0.7208, auc 0.4635, ap 0.4867
2024-01-10 21:52:49,163 - GAugM EPNet train, Epoch [ 32/295]: loss 0.7210, auc 0.5376, ap 0.5145
2024-01-10 21:52:49,251 - GAugM EPNet train, Epoch [ 33/295]: loss 0.7209, auc 0.4760, ap 0.4920
2024-01-10 21:52:49,335 - GAugM EPNet train, Epoch [ 34/295]: loss 0.7209, auc 0.4422, ap 0.4822
2024-01-10 21:52:49,430 - GAugM EPNet train, Epoch [ 35/295]: loss 0.7209, auc 0.5596, ap 0.5476
2024-01-10 21:52:49,519 - GAugM EPNet train, Epoch [ 36/295]: loss 0.7209, auc 0.5792, ap 0.5921
2024-01-10 21:52:49,614 - GAugM EPNet train, Epoch [ 37/295]: loss 0.7209, auc 0.5005, ap 0.5127
2024-01-10 21:52:49,703 - GAugM EPNet train, Epoch [ 38/295]: loss 0.7209, auc 0.4528, ap 0.4602
2024-01-10 21:52:49,803 - GAugM EPNet train, Epoch [ 39/295]: loss 0.7208, auc 0.4179, ap 0.4839
2024-01-10 21:52:49,887 - GAugM EPNet train, Epoch [ 40/295]: loss 0.7210, auc 0.5568, ap 0.5201
2024-01-10 21:52:49,966 - GAugM EPNet train, Epoch [ 41/295]: loss 0.7210, auc 0.4617, ap 0.4824
2024-01-10 21:52:50,043 - GAugM EPNet train, Epoch [ 42/295]: loss 0.7209, auc 0.5258, ap 0.5611
2024-01-10 21:52:50,133 - GAugM EPNet train, Epoch [ 43/295]: loss 0.7208, auc 0.4361, ap 0.4770
2024-01-10 21:52:50,211 - GAugM EPNet train, Epoch [ 44/295]: loss 0.7208, auc 0.3738, ap 0.4260
2024-01-10 21:52:50,296 - GAugM EPNet train, Epoch [ 45/295]: loss 0.7209, auc 0.4859, ap 0.5157
2024-01-10 21:52:50,393 - GAugM EPNet train, Epoch [ 46/295]: loss 0.7209, auc 0.4226, ap 0.4610
2024-01-10 21:52:50,476 - GAugM EPNet train, Epoch [ 47/295]: loss 0.7210, auc 0.4977, ap 0.5124
2024-01-10 21:52:50,551 - GAugM EPNet train, Epoch [ 48/295]: loss 0.7210, auc 0.5568, ap 0.5650
2024-01-10 21:52:50,632 - GAugM EPNet train, Epoch [ 49/295]: loss 0.7209, auc 0.5326, ap 0.5474
2024-01-10 21:52:50,707 - GAugM EPNet train, Epoch [ 50/295]: loss 0.7210, auc 0.5119, ap 0.5033
2024-01-10 21:52:50,786 - GAugM EPNet train, Epoch [ 51/295]: loss 0.7210, auc 0.4649, ap 0.4630
2024-01-10 21:52:50,859 - GAugM EPNet train, Epoch [ 52/295]: loss 0.7209, auc 0.4827, ap 0.5209
2024-01-10 21:52:50,933 - GAugM EPNet train, Epoch [ 53/295]: loss 0.7209, auc 0.5098, ap 0.5335
2024-01-10 21:52:51,015 - GAugM EPNet train, Epoch [ 54/295]: loss 0.7211, auc 0.5710, ap 0.5531
2024-01-10 21:52:51,112 - GAugM EPNet train, Epoch [ 55/295]: loss 0.7209, auc 0.5856, ap 0.6050
2024-01-10 21:52:51,198 - GAugM EPNet train, Epoch [ 56/295]: loss 0.7208, auc 0.4881, ap 0.5052
2024-01-10 21:52:51,276 - GAugM EPNet train, Epoch [ 57/295]: loss 0.7209, auc 0.4023, ap 0.4244
2024-01-10 21:52:51,372 - GAugM EPNet train, Epoch [ 58/295]: loss 0.7210, auc 0.4283, ap 0.4826
2024-01-10 21:52:51,452 - GAugM EPNet train, Epoch [ 59/295]: loss 0.7211, auc 0.4770, ap 0.4836
2024-01-10 21:52:51,528 - GAugM EPNet train, Epoch [ 60/295]: loss 0.7210, auc 0.4781, ap 0.4880
2024-01-10 21:52:51,620 - GAugM EPNet train, Epoch [ 61/295]: loss 0.7209, auc 0.5411, ap 0.5402
2024-01-10 21:52:51,703 - GAugM EPNet train, Epoch [ 62/295]: loss 0.7210, auc 0.4646, ap 0.5033
2024-01-10 21:52:51,781 - GAugM EPNet train, Epoch [ 63/295]: loss 0.7208, auc 0.3930, ap 0.4467
2024-01-10 21:52:51,866 - GAugM EPNet train, Epoch [ 64/295]: loss 0.7208, auc 0.5080, ap 0.5253
2024-01-10 21:52:51,945 - GAugM EPNet train, Epoch [ 65/295]: loss 0.7208, auc 0.5497, ap 0.5500
2024-01-10 21:52:52,028 - GAugM EPNet train, Epoch [ 66/295]: loss 0.7209, auc 0.4920, ap 0.5154
2024-01-10 21:52:52,108 - GAugM EPNet train, Epoch [ 67/295]: loss 0.7209, auc 0.5141, ap 0.4964
2024-01-10 21:52:52,185 - GAugM EPNet train, Epoch [ 68/295]: loss 0.7210, auc 0.5311, ap 0.5364
2024-01-10 21:52:52,267 - GAugM EPNet train, Epoch [ 69/295]: loss 0.7210, auc 0.5123, ap 0.5677
2024-01-10 21:52:52,350 - GAugM EPNet train, Epoch [ 70/295]: loss 0.7210, auc 0.4642, ap 0.4619
2024-01-10 21:52:52,427 - GAugM EPNet train, Epoch [ 71/295]: loss 0.7210, auc 0.6212, ap 0.5783
2024-01-10 21:52:52,518 - GAugM EPNet train, Epoch [ 72/295]: loss 0.7210, auc 0.4731, ap 0.4770
2024-01-10 21:52:52,597 - GAugM EPNet train, Epoch [ 73/295]: loss 0.7209, auc 0.5151, ap 0.4830
2024-01-10 21:52:52,675 - GAugM EPNet train, Epoch [ 74/295]: loss 0.7209, auc 0.4770, ap 0.4904
2024-01-10 21:52:52,749 - GAugM EPNet train, Epoch [ 75/295]: loss 0.7210, auc 0.4592, ap 0.4915
2024-01-10 21:52:52,827 - GAugM EPNet train, Epoch [ 76/295]: loss 0.7209, auc 0.3685, ap 0.4163
2024-01-10 21:52:52,904 - GAugM EPNet train, Epoch [ 77/295]: loss 0.7208, auc 0.5721, ap 0.5955
2024-01-10 21:52:52,987 - GAugM EPNet train, Epoch [ 78/295]: loss 0.7209, auc 0.4806, ap 0.5108
2024-01-10 21:52:53,063 - GAugM EPNet train, Epoch [ 79/295]: loss 0.7208, auc 0.5130, ap 0.5231
2024-01-10 21:52:53,136 - GAugM EPNet train, Epoch [ 80/295]: loss 0.7209, auc 0.5098, ap 0.5080
2024-01-10 21:52:53,218 - GAugM EPNet train, Epoch [ 81/295]: loss 0.7209, auc 0.4521, ap 0.4698
2024-01-10 21:52:53,303 - GAugM EPNet train, Epoch [ 82/295]: loss 0.7210, auc 0.5728, ap 0.5576
2024-01-10 21:52:53,384 - GAugM EPNet train, Epoch [ 83/295]: loss 0.7209, auc 0.4539, ap 0.4922
2024-01-10 21:52:53,463 - GAugM EPNet train, Epoch [ 84/295]: loss 0.7209, auc 0.4155, ap 0.4294
2024-01-10 21:52:53,538 - GAugM EPNet train, Epoch [ 85/295]: loss 0.7210, auc 0.4496, ap 0.4677
2024-01-10 21:52:53,619 - GAugM EPNet train, Epoch [ 86/295]: loss 0.7208, auc 0.5187, ap 0.5398
2024-01-10 21:52:53,698 - GAugM EPNet train, Epoch [ 87/295]: loss 0.7209, auc 0.5902, ap 0.5466
2024-01-10 21:52:53,784 - GAugM EPNet train, Epoch [ 88/295]: loss 0.7210, auc 0.5272, ap 0.5885
2024-01-10 21:52:53,860 - GAugM EPNet train, Epoch [ 89/295]: loss 0.7210, auc 0.5180, ap 0.5204
2024-01-10 21:52:53,938 - GAugM EPNet train, Epoch [ 90/295]: loss 0.7209, auc 0.4756, ap 0.5061
2024-01-10 21:52:54,022 - GAugM EPNet train, Epoch [ 91/295]: loss 0.7208, auc 0.5440, ap 0.5110
2024-01-10 21:52:54,099 - GAugM EPNet train, Epoch [ 92/295]: loss 0.7209, auc 0.6141, ap 0.5912
2024-01-10 21:52:54,175 - GAugM EPNet train, Epoch [ 93/295]: loss 0.7209, auc 0.3742, ap 0.4303
2024-01-10 21:52:54,260 - GAugM EPNet train, Epoch [ 94/295]: loss 0.7210, auc 0.4518, ap 0.4793
2024-01-10 21:52:54,341 - GAugM EPNet train, Epoch [ 95/295]: loss 0.7210, auc 0.4774, ap 0.4756
2024-01-10 21:52:54,419 - GAugM EPNet train, Epoch [ 96/295]: loss 0.7209, auc 0.5856, ap 0.5801
2024-01-10 21:52:54,503 - GAugM EPNet train, Epoch [ 97/295]: loss 0.7209, auc 0.4354, ap 0.4691
2024-01-10 21:52:54,580 - GAugM EPNet train, Epoch [ 98/295]: loss 0.7209, auc 0.4222, ap 0.4475
2024-01-10 21:52:54,657 - GAugM EPNet train, Epoch [ 99/295]: loss 0.7209, auc 0.4724, ap 0.5105
2024-01-10 21:52:54,737 - GAugM EPNet train, Epoch [100/295]: loss 0.7210, auc 0.5262, ap 0.5458
2024-01-10 21:52:54,814 - GAugM EPNet train, Epoch [101/295]: loss 0.7210, auc 0.5258, ap 0.5630
2024-01-10 21:52:54,892 - GAugM EPNet train, Epoch [102/295]: loss 0.7209, auc 0.5315, ap 0.5182
2024-01-10 21:52:54,969 - GAugM EPNet train, Epoch [103/295]: loss 0.7209, auc 0.5578, ap 0.5884
2024-01-10 21:52:55,046 - GAugM EPNet train, Epoch [104/295]: loss 0.7209, auc 0.4226, ap 0.4638
2024-01-10 21:52:55,128 - GAugM EPNet train, Epoch [105/295]: loss 0.7209, auc 0.4753, ap 0.4814
2024-01-10 21:52:55,215 - GAugM EPNet train, Epoch [106/295]: loss 0.7210, auc 0.4699, ap 0.5007
2024-01-10 21:52:55,295 - GAugM EPNet train, Epoch [107/295]: loss 0.7210, auc 0.4756, ap 0.5134
2024-01-10 21:52:55,370 - GAugM EPNet train, Epoch [108/295]: loss 0.7208, auc 0.5692, ap 0.5675
2024-01-10 21:52:55,452 - GAugM EPNet train, Epoch [109/295]: loss 0.7210, auc 0.4066, ap 0.4245
2024-01-10 21:52:55,533 - GAugM EPNet train, Epoch [110/295]: loss 0.7209, auc 0.4204, ap 0.4513
2024-01-10 21:52:55,613 - GAugM EPNet train, Epoch [111/295]: loss 0.7210, auc 0.5148, ap 0.5510
2024-01-10 21:52:55,688 - GAugM EPNet train, Epoch [112/295]: loss 0.7209, auc 0.4906, ap 0.4998
2024-01-10 21:52:55,767 - GAugM EPNet train, Epoch [113/295]: loss 0.7210, auc 0.4653, ap 0.4928
2024-01-10 21:52:55,856 - GAugM EPNet train, Epoch [114/295]: loss 0.7209, auc 0.5294, ap 0.5152
2024-01-10 21:52:55,935 - GAugM EPNet train, Epoch [115/295]: loss 0.7210, auc 0.5657, ap 0.5249
2024-01-10 21:52:56,038 - GAugM EPNet train, Epoch [116/295]: loss 0.7209, auc 0.5764, ap 0.5521
2024-01-10 21:52:56,133 - GAugM EPNet train, Epoch [117/295]: loss 0.7208, auc 0.4293, ap 0.4544
2024-01-10 21:52:56,210 - GAugM EPNet train, Epoch [118/295]: loss 0.7209, auc 0.5105, ap 0.5140
2024-01-10 21:52:56,294 - GAugM EPNet train, Epoch [119/295]: loss 0.7209, auc 0.5219, ap 0.5306
2024-01-10 21:52:56,372 - GAugM EPNet train, Epoch [120/295]: loss 0.7210, auc 0.4721, ap 0.4635
2024-01-10 21:52:56,455 - GAugM EPNet train, Epoch [121/295]: loss 0.7210, auc 0.5240, ap 0.5253
2024-01-10 21:52:56,531 - GAugM EPNet train, Epoch [122/295]: loss 0.7209, auc 0.5059, ap 0.5177
2024-01-10 21:52:56,613 - GAugM EPNet train, Epoch [123/295]: loss 0.7209, auc 0.4457, ap 0.4779
2024-01-10 21:52:56,689 - GAugM EPNet train, Epoch [124/295]: loss 0.7210, auc 0.4959, ap 0.4968
2024-01-10 21:52:56,767 - GAugM EPNet train, Epoch [125/295]: loss 0.7209, auc 0.4735, ap 0.4947
2024-01-10 21:52:56,843 - GAugM EPNet train, Epoch [126/295]: loss 0.7210, auc 0.5967, ap 0.5777
2024-01-10 21:52:56,921 - GAugM EPNet train, Epoch [127/295]: loss 0.7209, auc 0.5265, ap 0.5071
2024-01-10 21:52:56,998 - GAugM EPNet train, Epoch [128/295]: loss 0.7210, auc 0.5155, ap 0.4916
2024-01-10 21:52:57,076 - GAugM EPNet train, Epoch [129/295]: loss 0.7208, auc 0.4094, ap 0.4365
2024-01-10 21:52:57,152 - GAugM EPNet train, Epoch [130/295]: loss 0.7210, auc 0.5169, ap 0.5304
2024-01-10 21:52:57,242 - GAugM EPNet train, Epoch [131/295]: loss 0.7210, auc 0.5301, ap 0.5604
2024-01-10 21:52:57,322 - GAugM EPNet train, Epoch [132/295]: loss 0.7209, auc 0.4685, ap 0.4795
2024-01-10 21:52:57,398 - GAugM EPNet train, Epoch [133/295]: loss 0.7209, auc 0.4831, ap 0.5222
2024-01-10 21:52:57,485 - GAugM EPNet train, Epoch [134/295]: loss 0.7210, auc 0.5493, ap 0.5442
2024-01-10 21:52:57,563 - GAugM EPNet train, Epoch [135/295]: loss 0.7209, auc 0.4689, ap 0.4866
2024-01-10 21:52:57,641 - GAugM EPNet train, Epoch [136/295]: loss 0.7209, auc 0.5934, ap 0.5696
2024-01-10 21:52:57,726 - GAugM EPNet train, Epoch [137/295]: loss 0.7210, auc 0.5109, ap 0.5191
2024-01-10 21:52:57,808 - GAugM EPNet train, Epoch [138/295]: loss 0.7210, auc 0.4724, ap 0.4980
2024-01-10 21:52:57,888 - GAugM EPNet train, Epoch [139/295]: loss 0.7210, auc 0.4667, ap 0.4965
2024-01-10 21:52:57,965 - GAugM EPNet train, Epoch [140/295]: loss 0.7209, auc 0.4966, ap 0.5178
2024-01-10 21:52:58,048 - GAugM EPNet train, Epoch [141/295]: loss 0.7209, auc 0.5564, ap 0.5469
2024-01-10 21:52:58,126 - GAugM EPNet train, Epoch [142/295]: loss 0.7209, auc 0.5080, ap 0.5215
2024-01-10 21:52:58,217 - GAugM EPNet train, Epoch [143/295]: loss 0.7209, auc 0.3969, ap 0.4390
2024-01-10 21:52:58,298 - GAugM EPNet train, Epoch [144/295]: loss 0.7209, auc 0.4575, ap 0.4693
2024-01-10 21:52:58,379 - GAugM EPNet train, Epoch [145/295]: loss 0.7209, auc 0.4607, ap 0.5030
2024-01-10 21:52:58,458 - GAugM EPNet train, Epoch [146/295]: loss 0.7209, auc 0.4788, ap 0.5341
2024-01-10 21:52:58,539 - GAugM EPNet train, Epoch [147/295]: loss 0.7209, auc 0.6508, ap 0.6595
2024-01-10 21:52:58,616 - GAugM EPNet train, Epoch [148/295]: loss 0.7209, auc 0.4585, ap 0.4775
2024-01-10 21:52:58,696 - GAugM EPNet train, Epoch [149/295]: loss 0.7208, auc 0.4838, ap 0.4870
2024-01-10 21:52:58,775 - GAugM EPNet train, Epoch [150/295]: loss 0.7209, auc 0.4977, ap 0.4968
2024-01-10 21:52:58,862 - GAugM EPNet train, Epoch [151/295]: loss 0.7209, auc 0.4902, ap 0.4721
2024-01-10 21:52:58,942 - GAugM EPNet train, Epoch [152/295]: loss 0.7209, auc 0.5995, ap 0.5603
2024-01-10 21:52:59,026 - GAugM EPNet train, Epoch [153/295]: loss 0.7209, auc 0.4575, ap 0.5016
2024-01-10 21:52:59,106 - GAugM EPNet train, Epoch [154/295]: loss 0.7209, auc 0.4770, ap 0.4859
2024-01-10 21:52:59,185 - GAugM EPNet train, Epoch [155/295]: loss 0.7209, auc 0.4956, ap 0.4995
2024-01-10 21:52:59,262 - GAugM EPNet train, Epoch [156/295]: loss 0.7209, auc 0.4386, ap 0.4583
2024-01-10 21:52:59,342 - GAugM EPNet train, Epoch [157/295]: loss 0.7209, auc 0.5198, ap 0.5150
2024-01-10 21:52:59,419 - GAugM EPNet train, Epoch [158/295]: loss 0.7208, auc 0.4425, ap 0.4614
2024-01-10 21:52:59,497 - GAugM EPNet train, Epoch [159/295]: loss 0.7208, auc 0.4535, ap 0.4634
2024-01-10 21:52:59,577 - GAugM EPNet train, Epoch [160/295]: loss 0.7209, auc 0.6223, ap 0.6297
2024-01-10 21:52:59,673 - GAugM EPNet train, Epoch [161/295]: loss 0.7209, auc 0.6034, ap 0.5838
2024-01-10 21:52:59,752 - GAugM EPNet train, Epoch [162/295]: loss 0.7209, auc 0.4667, ap 0.4726
2024-01-10 21:52:59,832 - GAugM EPNet train, Epoch [163/295]: loss 0.7209, auc 0.4802, ap 0.4847
2024-01-10 21:52:59,909 - GAugM EPNet train, Epoch [164/295]: loss 0.7211, auc 0.5568, ap 0.5301
2024-01-10 21:52:59,992 - GAugM EPNet train, Epoch [165/295]: loss 0.7210, auc 0.3781, ap 0.4190
2024-01-10 21:53:00,073 - GAugM EPNet train, Epoch [166/295]: loss 0.7208, auc 0.5717, ap 0.5773
2024-01-10 21:53:00,161 - GAugM EPNet train, Epoch [167/295]: loss 0.7209, auc 0.4795, ap 0.4912
2024-01-10 21:53:00,240 - GAugM EPNet train, Epoch [168/295]: loss 0.7209, auc 0.5119, ap 0.5502
2024-01-10 21:53:00,319 - GAugM EPNet train, Epoch [169/295]: loss 0.7209, auc 0.5707, ap 0.5583
2024-01-10 21:53:00,401 - GAugM EPNet train, Epoch [170/295]: loss 0.7210, auc 0.3934, ap 0.4319
2024-01-10 21:53:00,480 - GAugM EPNet train, Epoch [171/295]: loss 0.7209, auc 0.4592, ap 0.4685
2024-01-10 21:53:00,560 - GAugM EPNet train, Epoch [172/295]: loss 0.7208, auc 0.4535, ap 0.4693
2024-01-10 21:53:00,644 - GAugM EPNet train, Epoch [173/295]: loss 0.7209, auc 0.4817, ap 0.4876
2024-01-10 21:53:00,722 - GAugM EPNet train, Epoch [174/295]: loss 0.7209, auc 0.4756, ap 0.4713
2024-01-10 21:53:00,805 - GAugM EPNet train, Epoch [175/295]: loss 0.7209, auc 0.6273, ap 0.5892
2024-01-10 21:53:00,895 - GAugM EPNet train, Epoch [176/295]: loss 0.7209, auc 0.4236, ap 0.4481
2024-01-10 21:53:00,980 - GAugM EPNet train, Epoch [177/295]: loss 0.7210, auc 0.5219, ap 0.4998
2024-01-10 21:53:01,059 - GAugM EPNet train, Epoch [178/295]: loss 0.7210, auc 0.5322, ap 0.5390
2024-01-10 21:53:01,136 - GAugM EPNet train, Epoch [179/295]: loss 0.7210, auc 0.3834, ap 0.4321
2024-01-10 21:53:01,218 - GAugM EPNet train, Epoch [180/295]: loss 0.7210, auc 0.5255, ap 0.5385
2024-01-10 21:53:01,305 - GAugM EPNet train, Epoch [181/295]: loss 0.7209, auc 0.3859, ap 0.4409
2024-01-10 21:53:01,389 - GAugM EPNet train, Epoch [182/295]: loss 0.7209, auc 0.4899, ap 0.5159
2024-01-10 21:53:01,470 - GAugM EPNet train, Epoch [183/295]: loss 0.7210, auc 0.5393, ap 0.5302
2024-01-10 21:53:01,552 - GAugM EPNet train, Epoch [184/295]: loss 0.7209, auc 0.4101, ap 0.4645
2024-01-10 21:53:01,631 - GAugM EPNet train, Epoch [185/295]: loss 0.7209, auc 0.4948, ap 0.5200
2024-01-10 21:53:01,706 - GAugM EPNet train, Epoch [186/295]: loss 0.7208, auc 0.4831, ap 0.5183
2024-01-10 21:53:01,788 - GAugM EPNet train, Epoch [187/295]: loss 0.7209, auc 0.5667, ap 0.5606
2024-01-10 21:53:01,869 - GAugM EPNet train, Epoch [188/295]: loss 0.7209, auc 0.4197, ap 0.4481
2024-01-10 21:53:01,948 - GAugM EPNet train, Epoch [189/295]: loss 0.7209, auc 0.5393, ap 0.5913
2024-01-10 21:53:02,029 - GAugM EPNet train, Epoch [190/295]: loss 0.7209, auc 0.4461, ap 0.4747
2024-01-10 21:53:02,112 - GAugM EPNet train, Epoch [191/295]: loss 0.7209, auc 0.3389, ap 0.4319
2024-01-10 21:53:02,188 - GAugM EPNet train, Epoch [192/295]: loss 0.7209, auc 0.5044, ap 0.4796
2024-01-10 21:53:02,266 - GAugM EPNet train, Epoch [193/295]: loss 0.7209, auc 0.5190, ap 0.5117
2024-01-10 21:53:02,352 - GAugM EPNet train, Epoch [194/295]: loss 0.7209, auc 0.5589, ap 0.5410
2024-01-10 21:53:02,433 - GAugM EPNet train, Epoch [195/295]: loss 0.7209, auc 0.4090, ap 0.4458
2024-01-10 21:53:02,511 - GAugM EPNet train, Epoch [196/295]: loss 0.7208, auc 0.5297, ap 0.5109
2024-01-10 21:53:02,588 - GAugM EPNet train, Epoch [197/295]: loss 0.7210, auc 0.5315, ap 0.5284
2024-01-10 21:53:02,673 - GAugM EPNet train, Epoch [198/295]: loss 0.7210, auc 0.5276, ap 0.5316
2024-01-10 21:53:02,772 - GAugM EPNet train, Epoch [199/295]: loss 0.7209, auc 0.4671, ap 0.4890
2024-01-10 21:53:02,877 - GAugM EPNet train, Epoch [200/295]: loss 0.7210, auc 0.5479, ap 0.5293
2024-01-10 21:53:02,980 - GAugM EPNet train, Epoch [201/295]: loss 0.7209, auc 0.4546, ap 0.4590
2024-01-10 21:53:03,072 - GAugM EPNet train, Epoch [202/295]: loss 0.7210, auc 0.5511, ap 0.5680
2024-01-10 21:53:03,165 - GAugM EPNet train, Epoch [203/295]: loss 0.7210, auc 0.5347, ap 0.5271
2024-01-10 21:53:03,259 - GAugM EPNet train, Epoch [204/295]: loss 0.7209, auc 0.4407, ap 0.4765
2024-01-10 21:53:03,342 - GAugM EPNet train, Epoch [205/295]: loss 0.7209, auc 0.4991, ap 0.5437
2024-01-10 21:53:03,433 - GAugM EPNet train, Epoch [206/295]: loss 0.7209, auc 0.4528, ap 0.4950
2024-01-10 21:53:03,543 - GAugM EPNet train, Epoch [207/295]: loss 0.7210, auc 0.4122, ap 0.4396
2024-01-10 21:53:03,638 - GAugM EPNet train, Epoch [208/295]: loss 0.7209, auc 0.4343, ap 0.5093
2024-01-10 21:53:03,727 - GAugM EPNet train, Epoch [209/295]: loss 0.7210, auc 0.5753, ap 0.5952
2024-01-10 21:53:03,813 - GAugM EPNet train, Epoch [210/295]: loss 0.7209, auc 0.4397, ap 0.4666
2024-01-10 21:53:03,908 - GAugM EPNet train, Epoch [211/295]: loss 0.7210, auc 0.4571, ap 0.4930
2024-01-10 21:53:04,004 - GAugM EPNet train, Epoch [212/295]: loss 0.7210, auc 0.5030, ap 0.4994
2024-01-10 21:53:04,103 - GAugM EPNet train, Epoch [213/295]: loss 0.7208, auc 0.6433, ap 0.6336
2024-01-10 21:53:04,199 - GAugM EPNet train, Epoch [214/295]: loss 0.7210, auc 0.5169, ap 0.5179
2024-01-10 21:53:04,291 - GAugM EPNet train, Epoch [215/295]: loss 0.7210, auc 0.4603, ap 0.4827
2024-01-10 21:53:04,388 - GAugM EPNet train, Epoch [216/295]: loss 0.7209, auc 0.5739, ap 0.5407
2024-01-10 21:53:04,487 - GAugM EPNet train, Epoch [217/295]: loss 0.7209, auc 0.5878, ap 0.6282
2024-01-10 21:53:04,584 - GAugM EPNet train, Epoch [218/295]: loss 0.7209, auc 0.5753, ap 0.6199
2024-01-10 21:53:04,688 - GAugM EPNet train, Epoch [219/295]: loss 0.7208, auc 0.5771, ap 0.5584
2024-01-10 21:53:04,786 - GAugM EPNet train, Epoch [220/295]: loss 0.7210, auc 0.4671, ap 0.5213
2024-01-10 21:53:04,881 - GAugM EPNet train, Epoch [221/295]: loss 0.7209, auc 0.5710, ap 0.5683
2024-01-10 21:53:04,982 - GAugM EPNet train, Epoch [222/295]: loss 0.7209, auc 0.4400, ap 0.4591
2024-01-10 21:53:05,079 - GAugM EPNet train, Epoch [223/295]: loss 0.7209, auc 0.5589, ap 0.5817
2024-01-10 21:53:05,173 - GAugM EPNet train, Epoch [224/295]: loss 0.7210, auc 0.4635, ap 0.4540
2024-01-10 21:53:05,264 - GAugM EPNet train, Epoch [225/295]: loss 0.7209, auc 0.4454, ap 0.5084
2024-01-10 21:53:05,360 - GAugM EPNet train, Epoch [226/295]: loss 0.7210, auc 0.5493, ap 0.5469
2024-01-10 21:53:05,456 - GAugM EPNet train, Epoch [227/295]: loss 0.7210, auc 0.5621, ap 0.5750
2024-01-10 21:53:05,565 - GAugM EPNet train, Epoch [228/295]: loss 0.7209, auc 0.5187, ap 0.5474
2024-01-10 21:53:05,659 - GAugM EPNet train, Epoch [229/295]: loss 0.7209, auc 0.4689, ap 0.4713
2024-01-10 21:53:05,752 - GAugM EPNet train, Epoch [230/295]: loss 0.7209, auc 0.4343, ap 0.4941
2024-01-10 21:53:05,845 - GAugM EPNet train, Epoch [231/295]: loss 0.7209, auc 0.4877, ap 0.4983
2024-01-10 21:53:05,939 - GAugM EPNet train, Epoch [232/295]: loss 0.7209, auc 0.5493, ap 0.5610
2024-01-10 21:53:06,030 - GAugM EPNet train, Epoch [233/295]: loss 0.7210, auc 0.5130, ap 0.5322
2024-01-10 21:53:06,124 - GAugM EPNet train, Epoch [234/295]: loss 0.7209, auc 0.4222, ap 0.4706
2024-01-10 21:53:06,215 - GAugM EPNet train, Epoch [235/295]: loss 0.7209, auc 0.4500, ap 0.4582
2024-01-10 21:53:06,306 - GAugM EPNet train, Epoch [236/295]: loss 0.7209, auc 0.4422, ap 0.4981
2024-01-10 21:53:06,402 - GAugM EPNet train, Epoch [237/295]: loss 0.7210, auc 0.5383, ap 0.5689
2024-01-10 21:53:06,498 - GAugM EPNet train, Epoch [238/295]: loss 0.7210, auc 0.5279, ap 0.5476
2024-01-10 21:53:06,588 - GAugM EPNet train, Epoch [239/295]: loss 0.7209, auc 0.4966, ap 0.5294
2024-01-10 21:53:06,690 - GAugM EPNet train, Epoch [240/295]: loss 0.7209, auc 0.5016, ap 0.4899
2024-01-10 21:53:06,778 - GAugM EPNet train, Epoch [241/295]: loss 0.7209, auc 0.5771, ap 0.5785
2024-01-10 21:53:06,874 - GAugM EPNet train, Epoch [242/295]: loss 0.7210, auc 0.4831, ap 0.4951
2024-01-10 21:53:06,964 - GAugM EPNet train, Epoch [243/295]: loss 0.7210, auc 0.4852, ap 0.5479
2024-01-10 21:53:07,054 - GAugM EPNet train, Epoch [244/295]: loss 0.7209, auc 0.5251, ap 0.4904
2024-01-10 21:53:07,141 - GAugM EPNet train, Epoch [245/295]: loss 0.7210, auc 0.5098, ap 0.5248
2024-01-10 21:53:07,231 - GAugM EPNet train, Epoch [246/295]: loss 0.7208, auc 0.4781, ap 0.4896
2024-01-10 21:53:07,318 - GAugM EPNet train, Epoch [247/295]: loss 0.7209, auc 0.4681, ap 0.4781
2024-01-10 21:53:07,406 - GAugM EPNet train, Epoch [248/295]: loss 0.7211, auc 0.5497, ap 0.5519
2024-01-10 21:53:07,500 - GAugM EPNet train, Epoch [249/295]: loss 0.7209, auc 0.5012, ap 0.4787
2024-01-10 21:53:07,586 - GAugM EPNet train, Epoch [250/295]: loss 0.7208, auc 0.4817, ap 0.4993
2024-01-10 21:53:07,672 - GAugM EPNet train, Epoch [251/295]: loss 0.7209, auc 0.4375, ap 0.5083
2024-01-10 21:53:07,762 - GAugM EPNet train, Epoch [252/295]: loss 0.7210, auc 0.5287, ap 0.5377
2024-01-10 21:53:07,853 - GAugM EPNet train, Epoch [253/295]: loss 0.7209, auc 0.5749, ap 0.5464
2024-01-10 21:53:07,939 - GAugM EPNet train, Epoch [254/295]: loss 0.7210, auc 0.4899, ap 0.5054
2024-01-10 21:53:08,029 - GAugM EPNet train, Epoch [255/295]: loss 0.7209, auc 0.4407, ap 0.4966
2024-01-10 21:53:08,114 - GAugM EPNet train, Epoch [256/295]: loss 0.7210, auc 0.4179, ap 0.5022
2024-01-10 21:53:08,206 - GAugM EPNet train, Epoch [257/295]: loss 0.7210, auc 0.4639, ap 0.4744
2024-01-10 21:53:08,297 - GAugM EPNet train, Epoch [258/295]: loss 0.7208, auc 0.5440, ap 0.5779
2024-01-10 21:53:08,394 - GAugM EPNet train, Epoch [259/295]: loss 0.7208, auc 0.6347, ap 0.5732
2024-01-10 21:53:08,483 - GAugM EPNet train, Epoch [260/295]: loss 0.7210, auc 0.5618, ap 0.5674
2024-01-10 21:53:08,571 - GAugM EPNet train, Epoch [261/295]: loss 0.7209, auc 0.4948, ap 0.5192
2024-01-10 21:53:08,658 - GAugM EPNet train, Epoch [262/295]: loss 0.7208, auc 0.4906, ap 0.5258
2024-01-10 21:53:08,745 - GAugM EPNet train, Epoch [263/295]: loss 0.7209, auc 0.4703, ap 0.4910
2024-01-10 21:53:08,830 - GAugM EPNet train, Epoch [264/295]: loss 0.7210, auc 0.4539, ap 0.4787
2024-01-10 21:53:08,916 - GAugM EPNet train, Epoch [265/295]: loss 0.7209, auc 0.5233, ap 0.5585
2024-01-10 21:53:08,994 - GAugM EPNet train, Epoch [266/295]: loss 0.7209, auc 0.4503, ap 0.4576
2024-01-10 21:53:09,092 - GAugM EPNet train, Epoch [267/295]: loss 0.7210, auc 0.5002, ap 0.5167
2024-01-10 21:53:09,189 - GAugM EPNet train, Epoch [268/295]: loss 0.7210, auc 0.4411, ap 0.4790
2024-01-10 21:53:09,278 - GAugM EPNet train, Epoch [269/295]: loss 0.7209, auc 0.4781, ap 0.5284
2024-01-10 21:53:09,368 - GAugM EPNet train, Epoch [270/295]: loss 0.7210, auc 0.4037, ap 0.4396
2024-01-10 21:53:09,459 - GAugM EPNet train, Epoch [271/295]: loss 0.7209, auc 0.4980, ap 0.5235
2024-01-10 21:53:09,546 - GAugM EPNet train, Epoch [272/295]: loss 0.7209, auc 0.5294, ap 0.5138
2024-01-10 21:53:09,630 - GAugM EPNet train, Epoch [273/295]: loss 0.7209, auc 0.5497, ap 0.5424
2024-01-10 21:53:09,714 - GAugM EPNet train, Epoch [274/295]: loss 0.7209, auc 0.5336, ap 0.5252
2024-01-10 21:53:09,800 - GAugM EPNet train, Epoch [275/295]: loss 0.7208, auc 0.5425, ap 0.5165
2024-01-10 21:53:09,886 - GAugM EPNet train, Epoch [276/295]: loss 0.7210, auc 0.5717, ap 0.6021
2024-01-10 21:53:09,971 - GAugM EPNet train, Epoch [277/295]: loss 0.7208, auc 0.4290, ap 0.4906
2024-01-10 21:53:10,049 - GAugM EPNet train, Epoch [278/295]: loss 0.7209, auc 0.5774, ap 0.6125
2024-01-10 21:53:10,127 - GAugM EPNet train, Epoch [279/295]: loss 0.7209, auc 0.4770, ap 0.5043
2024-01-10 21:53:10,229 - GAugM EPNet train, Epoch [280/295]: loss 0.7209, auc 0.4215, ap 0.4511
2024-01-10 21:53:10,324 - GAugM EPNet train, Epoch [281/295]: loss 0.7209, auc 0.5340, ap 0.5205
2024-01-10 21:53:10,420 - GAugM EPNet train, Epoch [282/295]: loss 0.7209, auc 0.4560, ap 0.4622
2024-01-10 21:53:10,514 - GAugM EPNet train, Epoch [283/295]: loss 0.7209, auc 0.5027, ap 0.5096
2024-01-10 21:53:10,612 - GAugM EPNet train, Epoch [284/295]: loss 0.7209, auc 0.4051, ap 0.4498
2024-01-10 21:53:10,706 - GAugM EPNet train, Epoch [285/295]: loss 0.7209, auc 0.5158, ap 0.5267
2024-01-10 21:53:10,805 - GAugM EPNet train, Epoch [286/295]: loss 0.7209, auc 0.5400, ap 0.5294
2024-01-10 21:53:10,898 - GAugM EPNet train, Epoch [287/295]: loss 0.7209, auc 0.5383, ap 0.5260
2024-01-10 21:53:10,987 - GAugM EPNet train, Epoch [288/295]: loss 0.7210, auc 0.5482, ap 0.5689
2024-01-10 21:53:11,079 - GAugM EPNet train, Epoch [289/295]: loss 0.7209, auc 0.4934, ap 0.4994
2024-01-10 21:53:11,168 - GAugM EPNet train, Epoch [290/295]: loss 0.7210, auc 0.5618, ap 0.5255
2024-01-10 21:53:11,262 - GAugM EPNet train, Epoch [291/295]: loss 0.7210, auc 0.4400, ap 0.4572
2024-01-10 21:53:11,358 - GAugM EPNet train, Epoch [292/295]: loss 0.7209, auc 0.4834, ap 0.4972
2024-01-10 21:53:11,450 - GAugM EPNet train, Epoch [293/295]: loss 0.7210, auc 0.4496, ap 0.4571
2024-01-10 21:53:11,540 - GAugM EPNet train, Epoch [294/295]: loss 0.7211, auc 0.4653, ap 0.5005
2024-01-10 21:53:11,630 - GAugM EPNet train, Epoch [295/295]: loss 0.7209, auc 0.3863, ap 0.4265
2024-01-10 21:53:11,635 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f6e0dba5a10>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:53:12,354 - GAugM EPNet train, Epoch [  1/295]: loss 0.7210, auc 0.4792, ap 0.4895
2024-01-10 21:53:12,446 - GAugM EPNet train, Epoch [  2/295]: loss 0.7210, auc 0.5635, ap 0.5319
2024-01-10 21:53:12,530 - GAugM EPNet train, Epoch [  3/295]: loss 0.7209, auc 0.5578, ap 0.5579
2024-01-10 21:53:12,622 - GAugM EPNet train, Epoch [  4/295]: loss 0.7209, auc 0.5101, ap 0.5102
2024-01-10 21:53:12,712 - GAugM EPNet train, Epoch [  5/295]: loss 0.7209, auc 0.5692, ap 0.5634
2024-01-10 21:53:12,803 - GAugM EPNet train, Epoch [  6/295]: loss 0.7209, auc 0.5180, ap 0.5394
2024-01-10 21:53:12,909 - GAugM EPNet train, Epoch [  7/295]: loss 0.7209, auc 0.4927, ap 0.4754
2024-01-10 21:53:13,047 - GAugM EPNet train, Epoch [  8/295]: loss 0.7210, auc 0.4624, ap 0.5147
2024-01-10 21:53:13,144 - GAugM EPNet train, Epoch [  9/295]: loss 0.7209, auc 0.4881, ap 0.4917
2024-01-10 21:53:13,249 - GAugM EPNet train, Epoch [ 10/295]: loss 0.7208, auc 0.4842, ap 0.5039
2024-01-10 21:53:13,341 - GAugM EPNet train, Epoch [ 11/295]: loss 0.7209, auc 0.4970, ap 0.5093
2024-01-10 21:53:13,434 - GAugM EPNet train, Epoch [ 12/295]: loss 0.7210, auc 0.4756, ap 0.5084
2024-01-10 21:53:13,528 - GAugM EPNet train, Epoch [ 13/295]: loss 0.7209, auc 0.5514, ap 0.5577
2024-01-10 21:53:13,627 - GAugM EPNet train, Epoch [ 14/295]: loss 0.7209, auc 0.5379, ap 0.5148
2024-01-10 21:53:13,724 - GAugM EPNet train, Epoch [ 15/295]: loss 0.7210, auc 0.3920, ap 0.4606
2024-01-10 21:53:13,812 - GAugM EPNet train, Epoch [ 16/295]: loss 0.7209, auc 0.5344, ap 0.5362
2024-01-10 21:53:13,894 - GAugM EPNet train, Epoch [ 17/295]: loss 0.7210, auc 0.5294, ap 0.5293
2024-01-10 21:53:13,979 - GAugM EPNet train, Epoch [ 18/295]: loss 0.7210, auc 0.5344, ap 0.5311
2024-01-10 21:53:14,061 - GAugM EPNet train, Epoch [ 19/295]: loss 0.7209, auc 0.4984, ap 0.4847
2024-01-10 21:53:14,140 - GAugM EPNet train, Epoch [ 20/295]: loss 0.7210, auc 0.5336, ap 0.5199
2024-01-10 21:53:14,224 - GAugM EPNet train, Epoch [ 21/295]: loss 0.7209, auc 0.4799, ap 0.4950
2024-01-10 21:53:14,303 - GAugM EPNet train, Epoch [ 22/295]: loss 0.7210, auc 0.4155, ap 0.4376
2024-01-10 21:53:14,381 - GAugM EPNet train, Epoch [ 23/295]: loss 0.7208, auc 0.5397, ap 0.5335
2024-01-10 21:53:14,464 - GAugM EPNet train, Epoch [ 24/295]: loss 0.7209, auc 0.5255, ap 0.4954
2024-01-10 21:53:14,546 - GAugM EPNet train, Epoch [ 25/295]: loss 0.7209, auc 0.4108, ap 0.4516
2024-01-10 21:53:14,624 - GAugM EPNet train, Epoch [ 26/295]: loss 0.7210, auc 0.5778, ap 0.5883
2024-01-10 21:53:14,717 - GAugM EPNet train, Epoch [ 27/295]: loss 0.7209, auc 0.3877, ap 0.4378
2024-01-10 21:53:14,799 - GAugM EPNet train, Epoch [ 28/295]: loss 0.7209, auc 0.5682, ap 0.5913
2024-01-10 21:53:14,890 - GAugM EPNet train, Epoch [ 29/295]: loss 0.7210, auc 0.5109, ap 0.5171
2024-01-10 21:53:14,964 - GAugM EPNet train, Epoch [ 30/295]: loss 0.7209, auc 0.4767, ap 0.5050
2024-01-10 21:53:15,044 - GAugM EPNet train, Epoch [ 31/295]: loss 0.7208, auc 0.4909, ap 0.5000
2024-01-10 21:53:15,130 - GAugM EPNet train, Epoch [ 32/295]: loss 0.7210, auc 0.5514, ap 0.5392
2024-01-10 21:53:15,222 - GAugM EPNet train, Epoch [ 33/295]: loss 0.7209, auc 0.5611, ap 0.5850
2024-01-10 21:53:15,312 - GAugM EPNet train, Epoch [ 34/295]: loss 0.7209, auc 0.3688, ap 0.4167
2024-01-10 21:53:15,394 - GAugM EPNet train, Epoch [ 35/295]: loss 0.7209, auc 0.5101, ap 0.4903
2024-01-10 21:53:15,472 - GAugM EPNet train, Epoch [ 36/295]: loss 0.7209, auc 0.5856, ap 0.6091
2024-01-10 21:53:15,557 - GAugM EPNet train, Epoch [ 37/295]: loss 0.7209, auc 0.4870, ap 0.4997
2024-01-10 21:53:15,632 - GAugM EPNet train, Epoch [ 38/295]: loss 0.7209, auc 0.4667, ap 0.4743
2024-01-10 21:53:15,709 - GAugM EPNet train, Epoch [ 39/295]: loss 0.7208, auc 0.3998, ap 0.4537
2024-01-10 21:53:15,782 - GAugM EPNet train, Epoch [ 40/295]: loss 0.7210, auc 0.5860, ap 0.5411
2024-01-10 21:53:15,863 - GAugM EPNet train, Epoch [ 41/295]: loss 0.7210, auc 0.4916, ap 0.5387
2024-01-10 21:53:15,937 - GAugM EPNet train, Epoch [ 42/295]: loss 0.7209, auc 0.5600, ap 0.5741
2024-01-10 21:53:16,012 - GAugM EPNet train, Epoch [ 43/295]: loss 0.7208, auc 0.5055, ap 0.5078
2024-01-10 21:53:16,087 - GAugM EPNet train, Epoch [ 44/295]: loss 0.7208, auc 0.5272, ap 0.5442
2024-01-10 21:53:16,168 - GAugM EPNet train, Epoch [ 45/295]: loss 0.7209, auc 0.6098, ap 0.6323
2024-01-10 21:53:16,245 - GAugM EPNet train, Epoch [ 46/295]: loss 0.7209, auc 0.4941, ap 0.5213
2024-01-10 21:53:16,322 - GAugM EPNet train, Epoch [ 47/295]: loss 0.7210, auc 0.4108, ap 0.4287
2024-01-10 21:53:16,420 - GAugM EPNet train, Epoch [ 48/295]: loss 0.7210, auc 0.5977, ap 0.6127
2024-01-10 21:53:16,516 - GAugM EPNet train, Epoch [ 49/295]: loss 0.7209, auc 0.5408, ap 0.5814
2024-01-10 21:53:16,614 - GAugM EPNet train, Epoch [ 50/295]: loss 0.7210, auc 0.4980, ap 0.4985
2024-01-10 21:53:16,705 - GAugM EPNet train, Epoch [ 51/295]: loss 0.7210, auc 0.4817, ap 0.5051
2024-01-10 21:53:16,790 - GAugM EPNet train, Epoch [ 52/295]: loss 0.7209, auc 0.5094, ap 0.5589
2024-01-10 21:53:16,885 - GAugM EPNet train, Epoch [ 53/295]: loss 0.7209, auc 0.5091, ap 0.5654
2024-01-10 21:53:16,978 - GAugM EPNet train, Epoch [ 54/295]: loss 0.7211, auc 0.5945, ap 0.5640
2024-01-10 21:53:17,075 - GAugM EPNet train, Epoch [ 55/295]: loss 0.7209, auc 0.6451, ap 0.6292
2024-01-10 21:53:17,169 - GAugM EPNet train, Epoch [ 56/295]: loss 0.7208, auc 0.5486, ap 0.5468
2024-01-10 21:53:17,257 - GAugM EPNet train, Epoch [ 57/295]: loss 0.7209, auc 0.4311, ap 0.4509
2024-01-10 21:53:17,335 - GAugM EPNet train, Epoch [ 58/295]: loss 0.7210, auc 0.4745, ap 0.5122
2024-01-10 21:53:17,431 - GAugM EPNet train, Epoch [ 59/295]: loss 0.7211, auc 0.5450, ap 0.5134
2024-01-10 21:53:17,517 - GAugM EPNet train, Epoch [ 60/295]: loss 0.7210, auc 0.5119, ap 0.5164
2024-01-10 21:53:17,609 - GAugM EPNet train, Epoch [ 61/295]: loss 0.7209, auc 0.5247, ap 0.5397
2024-01-10 21:53:17,699 - GAugM EPNet train, Epoch [ 62/295]: loss 0.7210, auc 0.5678, ap 0.5592
2024-01-10 21:53:17,789 - GAugM EPNet train, Epoch [ 63/295]: loss 0.7208, auc 0.4340, ap 0.4531
2024-01-10 21:53:17,875 - GAugM EPNet train, Epoch [ 64/295]: loss 0.7208, auc 0.4738, ap 0.4857
2024-01-10 21:53:17,957 - GAugM EPNet train, Epoch [ 65/295]: loss 0.7208, auc 0.5486, ap 0.5727
2024-01-10 21:53:18,048 - GAugM EPNet train, Epoch [ 66/295]: loss 0.7209, auc 0.4365, ap 0.4668
2024-01-10 21:53:18,140 - GAugM EPNet train, Epoch [ 67/295]: loss 0.7209, auc 0.4575, ap 0.4705
2024-01-10 21:53:18,237 - GAugM EPNet train, Epoch [ 68/295]: loss 0.7210, auc 0.4279, ap 0.4854
2024-01-10 21:53:18,326 - GAugM EPNet train, Epoch [ 69/295]: loss 0.7210, auc 0.4582, ap 0.4962
2024-01-10 21:53:18,414 - GAugM EPNet train, Epoch [ 70/295]: loss 0.7210, auc 0.4831, ap 0.4893
2024-01-10 21:53:18,511 - GAugM EPNet train, Epoch [ 71/295]: loss 0.7210, auc 0.6027, ap 0.5772
2024-01-10 21:53:18,605 - GAugM EPNet train, Epoch [ 72/295]: loss 0.7210, auc 0.4585, ap 0.5142
2024-01-10 21:53:18,698 - GAugM EPNet train, Epoch [ 73/295]: loss 0.7209, auc 0.5386, ap 0.5148
2024-01-10 21:53:18,790 - GAugM EPNet train, Epoch [ 74/295]: loss 0.7209, auc 0.5297, ap 0.5235
2024-01-10 21:53:18,880 - GAugM EPNet train, Epoch [ 75/295]: loss 0.7210, auc 0.4596, ap 0.4916
2024-01-10 21:53:18,967 - GAugM EPNet train, Epoch [ 76/295]: loss 0.7209, auc 0.3952, ap 0.4375
2024-01-10 21:53:19,052 - GAugM EPNet train, Epoch [ 77/295]: loss 0.7208, auc 0.6045, ap 0.6050
2024-01-10 21:53:19,140 - GAugM EPNet train, Epoch [ 78/295]: loss 0.7209, auc 0.5361, ap 0.5259
2024-01-10 21:53:19,231 - GAugM EPNet train, Epoch [ 79/295]: loss 0.7208, auc 0.5522, ap 0.5470
2024-01-10 21:53:19,318 - GAugM EPNet train, Epoch [ 80/295]: loss 0.7209, auc 0.5077, ap 0.5307
2024-01-10 21:53:19,408 - GAugM EPNet train, Epoch [ 81/295]: loss 0.7209, auc 0.4963, ap 0.4820
2024-01-10 21:53:19,495 - GAugM EPNet train, Epoch [ 82/295]: loss 0.7210, auc 0.5141, ap 0.5093
2024-01-10 21:53:19,581 - GAugM EPNet train, Epoch [ 83/295]: loss 0.7209, auc 0.4738, ap 0.5005
2024-01-10 21:53:19,669 - GAugM EPNet train, Epoch [ 84/295]: loss 0.7209, auc 0.3460, ap 0.4264
2024-01-10 21:53:19,754 - GAugM EPNet train, Epoch [ 85/295]: loss 0.7210, auc 0.4286, ap 0.5016
2024-01-10 21:53:19,848 - GAugM EPNet train, Epoch [ 86/295]: loss 0.7208, auc 0.5133, ap 0.5386
2024-01-10 21:53:19,936 - GAugM EPNet train, Epoch [ 87/295]: loss 0.7209, auc 0.5810, ap 0.5468
2024-01-10 21:53:20,028 - GAugM EPNet train, Epoch [ 88/295]: loss 0.7210, auc 0.5230, ap 0.5542
2024-01-10 21:53:20,130 - GAugM EPNet train, Epoch [ 89/295]: loss 0.7210, auc 0.4496, ap 0.4962
2024-01-10 21:53:20,223 - GAugM EPNet train, Epoch [ 90/295]: loss 0.7209, auc 0.4486, ap 0.4871
2024-01-10 21:53:20,318 - GAugM EPNet train, Epoch [ 91/295]: loss 0.7208, auc 0.5376, ap 0.5272
2024-01-10 21:53:20,405 - GAugM EPNet train, Epoch [ 92/295]: loss 0.7209, auc 0.6137, ap 0.5924
2024-01-10 21:53:20,502 - GAugM EPNet train, Epoch [ 93/295]: loss 0.7209, auc 0.3998, ap 0.4554
2024-01-10 21:53:20,599 - GAugM EPNet train, Epoch [ 94/295]: loss 0.7210, auc 0.4304, ap 0.4872
2024-01-10 21:53:20,691 - GAugM EPNet train, Epoch [ 95/295]: loss 0.7210, auc 0.5319, ap 0.5126
2024-01-10 21:53:20,780 - GAugM EPNet train, Epoch [ 96/295]: loss 0.7209, auc 0.4774, ap 0.5027
2024-01-10 21:53:20,877 - GAugM EPNet train, Epoch [ 97/295]: loss 0.7209, auc 0.4582, ap 0.4812
2024-01-10 21:53:20,967 - GAugM EPNet train, Epoch [ 98/295]: loss 0.7209, auc 0.4361, ap 0.4627
2024-01-10 21:53:21,054 - GAugM EPNet train, Epoch [ 99/295]: loss 0.7209, auc 0.4422, ap 0.4931
2024-01-10 21:53:21,144 - GAugM EPNet train, Epoch [100/295]: loss 0.7210, auc 0.4884, ap 0.4691
2024-01-10 21:53:21,238 - GAugM EPNet train, Epoch [101/295]: loss 0.7210, auc 0.4952, ap 0.5580
2024-01-10 21:53:21,334 - GAugM EPNet train, Epoch [102/295]: loss 0.7209, auc 0.5258, ap 0.5024
2024-01-10 21:53:21,433 - GAugM EPNet train, Epoch [103/295]: loss 0.7209, auc 0.4375, ap 0.4994
2024-01-10 21:53:21,524 - GAugM EPNet train, Epoch [104/295]: loss 0.7209, auc 0.4411, ap 0.4698
2024-01-10 21:53:21,614 - GAugM EPNet train, Epoch [105/295]: loss 0.7209, auc 0.4603, ap 0.4861
2024-01-10 21:53:21,704 - GAugM EPNet train, Epoch [106/295]: loss 0.7210, auc 0.4888, ap 0.4969
2024-01-10 21:53:21,796 - GAugM EPNet train, Epoch [107/295]: loss 0.7210, auc 0.4090, ap 0.4637
2024-01-10 21:53:21,888 - GAugM EPNet train, Epoch [108/295]: loss 0.7208, auc 0.5279, ap 0.5274
2024-01-10 21:53:21,986 - GAugM EPNet train, Epoch [109/295]: loss 0.7210, auc 0.4856, ap 0.4914
2024-01-10 21:53:22,071 - GAugM EPNet train, Epoch [110/295]: loss 0.7209, auc 0.5023, ap 0.5284
2024-01-10 21:53:22,175 - GAugM EPNet train, Epoch [111/295]: loss 0.7210, auc 0.5447, ap 0.5482
2024-01-10 21:53:22,269 - GAugM EPNet train, Epoch [112/295]: loss 0.7209, auc 0.4486, ap 0.4754
2024-01-10 21:53:22,363 - GAugM EPNet train, Epoch [113/295]: loss 0.7210, auc 0.4187, ap 0.4674
2024-01-10 21:53:22,453 - GAugM EPNet train, Epoch [114/295]: loss 0.7209, auc 0.4578, ap 0.4589
2024-01-10 21:53:22,547 - GAugM EPNet train, Epoch [115/295]: loss 0.7210, auc 0.5347, ap 0.5159
2024-01-10 21:53:22,636 - GAugM EPNet train, Epoch [116/295]: loss 0.7209, auc 0.4902, ap 0.5336
2024-01-10 21:53:22,728 - GAugM EPNet train, Epoch [117/295]: loss 0.7208, auc 0.4350, ap 0.4590
2024-01-10 21:53:22,819 - GAugM EPNet train, Epoch [118/295]: loss 0.7209, auc 0.4187, ap 0.4546
2024-01-10 21:53:22,911 - GAugM EPNet train, Epoch [119/295]: loss 0.7209, auc 0.5621, ap 0.5859
2024-01-10 21:53:23,010 - GAugM EPNet train, Epoch [120/295]: loss 0.7210, auc 0.4639, ap 0.4523
2024-01-10 21:53:23,099 - GAugM EPNet train, Epoch [121/295]: loss 0.7210, auc 0.4543, ap 0.4543
2024-01-10 21:53:23,188 - GAugM EPNet train, Epoch [122/295]: loss 0.7209, auc 0.4585, ap 0.4926
2024-01-10 21:53:23,282 - GAugM EPNet train, Epoch [123/295]: loss 0.7209, auc 0.5002, ap 0.5433
2024-01-10 21:53:23,370 - GAugM EPNet train, Epoch [124/295]: loss 0.7210, auc 0.4053, ap 0.4309
2024-01-10 21:53:23,468 - GAugM EPNet train, Epoch [125/295]: loss 0.7209, auc 0.5326, ap 0.5326
2024-01-10 21:53:23,559 - GAugM EPNet train, Epoch [126/295]: loss 0.7210, auc 0.5539, ap 0.5296
2024-01-10 21:53:23,660 - GAugM EPNet train, Epoch [127/295]: loss 0.7209, auc 0.4379, ap 0.4544
2024-01-10 21:53:23,757 - GAugM EPNet train, Epoch [128/295]: loss 0.7210, auc 0.4998, ap 0.4983
2024-01-10 21:53:23,859 - GAugM EPNet train, Epoch [129/295]: loss 0.7208, auc 0.3596, ap 0.4256
2024-01-10 21:53:23,953 - GAugM EPNet train, Epoch [130/295]: loss 0.7210, auc 0.4745, ap 0.5034
2024-01-10 21:53:24,050 - GAugM EPNet train, Epoch [131/295]: loss 0.7210, auc 0.4970, ap 0.5102
2024-01-10 21:53:24,151 - GAugM EPNet train, Epoch [132/295]: loss 0.7209, auc 0.6009, ap 0.5637
2024-01-10 21:53:24,239 - GAugM EPNet train, Epoch [133/295]: loss 0.7209, auc 0.4600, ap 0.5009
2024-01-10 21:53:24,319 - GAugM EPNet train, Epoch [134/295]: loss 0.7210, auc 0.5340, ap 0.5687
2024-01-10 21:53:24,412 - GAugM EPNet train, Epoch [135/295]: loss 0.7209, auc 0.4066, ap 0.4563
2024-01-10 21:53:24,508 - GAugM EPNet train, Epoch [136/295]: loss 0.7209, auc 0.4194, ap 0.4444
2024-01-10 21:53:24,599 - GAugM EPNet train, Epoch [137/295]: loss 0.7210, auc 0.5230, ap 0.5435
2024-01-10 21:53:24,687 - GAugM EPNet train, Epoch [138/295]: loss 0.7210, auc 0.5198, ap 0.5021
2024-01-10 21:53:24,766 - GAugM EPNet train, Epoch [139/295]: loss 0.7210, auc 0.4187, ap 0.4422
2024-01-10 21:53:24,851 - GAugM EPNet train, Epoch [140/295]: loss 0.7209, auc 0.4884, ap 0.5339
2024-01-10 21:53:24,946 - GAugM EPNet train, Epoch [141/295]: loss 0.7209, auc 0.5600, ap 0.5562
2024-01-10 21:53:25,030 - GAugM EPNet train, Epoch [142/295]: loss 0.7209, auc 0.5020, ap 0.5214
2024-01-10 21:53:25,110 - GAugM EPNet train, Epoch [143/295]: loss 0.7209, auc 0.4229, ap 0.4524
2024-01-10 21:53:25,196 - GAugM EPNet train, Epoch [144/295]: loss 0.7209, auc 0.4678, ap 0.4834
2024-01-10 21:53:25,276 - GAugM EPNet train, Epoch [145/295]: loss 0.7209, auc 0.5176, ap 0.5432
2024-01-10 21:53:25,355 - GAugM EPNet train, Epoch [146/295]: loss 0.7209, auc 0.5443, ap 0.5459
2024-01-10 21:53:25,435 - GAugM EPNet train, Epoch [147/295]: loss 0.7209, auc 0.6362, ap 0.6474
2024-01-10 21:53:25,528 - GAugM EPNet train, Epoch [148/295]: loss 0.7209, auc 0.5739, ap 0.6017
2024-01-10 21:53:25,621 - GAugM EPNet train, Epoch [149/295]: loss 0.7208, auc 0.4888, ap 0.5273
2024-01-10 21:53:25,705 - GAugM EPNet train, Epoch [150/295]: loss 0.7209, auc 0.4998, ap 0.5185
2024-01-10 21:53:25,787 - GAugM EPNet train, Epoch [151/295]: loss 0.7209, auc 0.5230, ap 0.5346
2024-01-10 21:53:25,867 - GAugM EPNet train, Epoch [152/295]: loss 0.7209, auc 0.5710, ap 0.5734
2024-01-10 21:53:25,955 - GAugM EPNet train, Epoch [153/295]: loss 0.7209, auc 0.4931, ap 0.4977
2024-01-10 21:53:26,047 - GAugM EPNet train, Epoch [154/295]: loss 0.7209, auc 0.5650, ap 0.6033
2024-01-10 21:53:26,140 - GAugM EPNet train, Epoch [155/295]: loss 0.7209, auc 0.4585, ap 0.5039
2024-01-10 21:53:26,233 - GAugM EPNet train, Epoch [156/295]: loss 0.7209, auc 0.3920, ap 0.4464
2024-01-10 21:53:26,328 - GAugM EPNet train, Epoch [157/295]: loss 0.7209, auc 0.5422, ap 0.5249
2024-01-10 21:53:26,421 - GAugM EPNet train, Epoch [158/295]: loss 0.7208, auc 0.4333, ap 0.4539
2024-01-10 21:53:26,523 - GAugM EPNet train, Epoch [159/295]: loss 0.7208, auc 0.4706, ap 0.4891
2024-01-10 21:53:26,609 - GAugM EPNet train, Epoch [160/295]: loss 0.7209, auc 0.6358, ap 0.6294
2024-01-10 21:53:26,688 - GAugM EPNet train, Epoch [161/295]: loss 0.7209, auc 0.4664, ap 0.4783
2024-01-10 21:53:26,771 - GAugM EPNet train, Epoch [162/295]: loss 0.7209, auc 0.4233, ap 0.4476
2024-01-10 21:53:26,845 - GAugM EPNet train, Epoch [163/295]: loss 0.7209, auc 0.4393, ap 0.4622
2024-01-10 21:53:26,924 - GAugM EPNet train, Epoch [164/295]: loss 0.7211, auc 0.5351, ap 0.5072
2024-01-10 21:53:27,011 - GAugM EPNet train, Epoch [165/295]: loss 0.7210, auc 0.4457, ap 0.4743
2024-01-10 21:53:27,089 - GAugM EPNet train, Epoch [166/295]: loss 0.7208, auc 0.4849, ap 0.4974
2024-01-10 21:53:27,188 - GAugM EPNet train, Epoch [167/295]: loss 0.7209, auc 0.4834, ap 0.4978
2024-01-10 21:53:27,269 - GAugM EPNet train, Epoch [168/295]: loss 0.7209, auc 0.4233, ap 0.5053
2024-01-10 21:53:27,355 - GAugM EPNet train, Epoch [169/295]: loss 0.7209, auc 0.5639, ap 0.5985
2024-01-10 21:53:27,448 - GAugM EPNet train, Epoch [170/295]: loss 0.7210, auc 0.4357, ap 0.4633
2024-01-10 21:53:27,538 - GAugM EPNet train, Epoch [171/295]: loss 0.7209, auc 0.4325, ap 0.4541
2024-01-10 21:53:27,634 - GAugM EPNet train, Epoch [172/295]: loss 0.7208, auc 0.4422, ap 0.4791
2024-01-10 21:53:27,718 - GAugM EPNet train, Epoch [173/295]: loss 0.7209, auc 0.5002, ap 0.5221
2024-01-10 21:53:27,795 - GAugM EPNet train, Epoch [174/295]: loss 0.7209, auc 0.5358, ap 0.5205
2024-01-10 21:53:27,876 - GAugM EPNet train, Epoch [175/295]: loss 0.7209, auc 0.5621, ap 0.5540
2024-01-10 21:53:27,962 - GAugM EPNet train, Epoch [176/295]: loss 0.7209, auc 0.4980, ap 0.5098
2024-01-10 21:53:28,044 - GAugM EPNet train, Epoch [177/295]: loss 0.7210, auc 0.5899, ap 0.5517
2024-01-10 21:53:28,145 - GAugM EPNet train, Epoch [178/295]: loss 0.7210, auc 0.5347, ap 0.5404
2024-01-10 21:53:28,237 - GAugM EPNet train, Epoch [179/295]: loss 0.7210, auc 0.4567, ap 0.4947
2024-01-10 21:53:28,328 - GAugM EPNet train, Epoch [180/295]: loss 0.7210, auc 0.5536, ap 0.5985
2024-01-10 21:53:28,423 - GAugM EPNet train, Epoch [181/295]: loss 0.7209, auc 0.4407, ap 0.4899
2024-01-10 21:53:28,514 - GAugM EPNet train, Epoch [182/295]: loss 0.7209, auc 0.4482, ap 0.5059
2024-01-10 21:53:28,605 - GAugM EPNet train, Epoch [183/295]: loss 0.7210, auc 0.5329, ap 0.5091
2024-01-10 21:53:28,698 - GAugM EPNet train, Epoch [184/295]: loss 0.7209, auc 0.4781, ap 0.4960
2024-01-10 21:53:28,782 - GAugM EPNet train, Epoch [185/295]: loss 0.7209, auc 0.4464, ap 0.4696
2024-01-10 21:53:28,869 - GAugM EPNet train, Epoch [186/295]: loss 0.7208, auc 0.5187, ap 0.5544
2024-01-10 21:53:28,961 - GAugM EPNet train, Epoch [187/295]: loss 0.7209, auc 0.5116, ap 0.5237
2024-01-10 21:53:29,047 - GAugM EPNet train, Epoch [188/295]: loss 0.7209, auc 0.4770, ap 0.4776
2024-01-10 21:53:29,130 - GAugM EPNet train, Epoch [189/295]: loss 0.7209, auc 0.5600, ap 0.5728
2024-01-10 21:53:29,210 - GAugM EPNet train, Epoch [190/295]: loss 0.7209, auc 0.4471, ap 0.4551
2024-01-10 21:53:29,289 - GAugM EPNet train, Epoch [191/295]: loss 0.7209, auc 0.4763, ap 0.5322
2024-01-10 21:53:29,372 - GAugM EPNet train, Epoch [192/295]: loss 0.7209, auc 0.5571, ap 0.5424
2024-01-10 21:53:29,453 - GAugM EPNet train, Epoch [193/295]: loss 0.7209, auc 0.5379, ap 0.5069
2024-01-10 21:53:29,534 - GAugM EPNet train, Epoch [194/295]: loss 0.7209, auc 0.4681, ap 0.4820
2024-01-10 21:53:29,611 - GAugM EPNet train, Epoch [195/295]: loss 0.7209, auc 0.4525, ap 0.4704
2024-01-10 21:53:29,702 - GAugM EPNet train, Epoch [196/295]: loss 0.7208, auc 0.5878, ap 0.5612
2024-01-10 21:53:29,785 - GAugM EPNet train, Epoch [197/295]: loss 0.7210, auc 0.5037, ap 0.5037
2024-01-10 21:53:29,866 - GAugM EPNet train, Epoch [198/295]: loss 0.7210, auc 0.4977, ap 0.5132
2024-01-10 21:53:29,960 - GAugM EPNet train, Epoch [199/295]: loss 0.7209, auc 0.5023, ap 0.5132
2024-01-10 21:53:30,055 - GAugM EPNet train, Epoch [200/295]: loss 0.7210, auc 0.3895, ap 0.4329
2024-01-10 21:53:30,162 - GAugM EPNet train, Epoch [201/295]: loss 0.7209, auc 0.4788, ap 0.4674
2024-01-10 21:53:30,257 - GAugM EPNet train, Epoch [202/295]: loss 0.7210, auc 0.5237, ap 0.5627
2024-01-10 21:53:30,345 - GAugM EPNet train, Epoch [203/295]: loss 0.7210, auc 0.5853, ap 0.6013
2024-01-10 21:53:30,437 - GAugM EPNet train, Epoch [204/295]: loss 0.7209, auc 0.3905, ap 0.4294
2024-01-10 21:53:30,533 - GAugM EPNet train, Epoch [205/295]: loss 0.7209, auc 0.4956, ap 0.5030
2024-01-10 21:53:30,622 - GAugM EPNet train, Epoch [206/295]: loss 0.7209, auc 0.3734, ap 0.4345
2024-01-10 21:53:30,715 - GAugM EPNet train, Epoch [207/295]: loss 0.7210, auc 0.4115, ap 0.4456
2024-01-10 21:53:30,810 - GAugM EPNet train, Epoch [208/295]: loss 0.7209, auc 0.5276, ap 0.5618
2024-01-10 21:53:30,901 - GAugM EPNet train, Epoch [209/295]: loss 0.7210, auc 0.6105, ap 0.5844
2024-01-10 21:53:30,991 - GAugM EPNet train, Epoch [210/295]: loss 0.7209, auc 0.4567, ap 0.4865
2024-01-10 21:53:31,079 - GAugM EPNet train, Epoch [211/295]: loss 0.7210, auc 0.5272, ap 0.5296
2024-01-10 21:53:31,171 - GAugM EPNet train, Epoch [212/295]: loss 0.7210, auc 0.5094, ap 0.5191
2024-01-10 21:53:31,268 - GAugM EPNet train, Epoch [213/295]: loss 0.7208, auc 0.6924, ap 0.6936
2024-01-10 21:53:31,364 - GAugM EPNet train, Epoch [214/295]: loss 0.7210, auc 0.4717, ap 0.4978
2024-01-10 21:53:31,457 - GAugM EPNet train, Epoch [215/295]: loss 0.7210, auc 0.4877, ap 0.4914
2024-01-10 21:53:31,552 - GAugM EPNet train, Epoch [216/295]: loss 0.7209, auc 0.5315, ap 0.5368
2024-01-10 21:53:31,643 - GAugM EPNet train, Epoch [217/295]: loss 0.7209, auc 0.5767, ap 0.6180
2024-01-10 21:53:31,735 - GAugM EPNet train, Epoch [218/295]: loss 0.7209, auc 0.5180, ap 0.5646
2024-01-10 21:53:31,827 - GAugM EPNet train, Epoch [219/295]: loss 0.7208, auc 0.5233, ap 0.5323
2024-01-10 21:53:31,932 - GAugM EPNet train, Epoch [220/295]: loss 0.7210, auc 0.4642, ap 0.4701
2024-01-10 21:53:32,023 - GAugM EPNet train, Epoch [221/295]: loss 0.7209, auc 0.5742, ap 0.5479
2024-01-10 21:53:32,114 - GAugM EPNet train, Epoch [222/295]: loss 0.7209, auc 0.4667, ap 0.4759
2024-01-10 21:53:32,207 - GAugM EPNet train, Epoch [223/295]: loss 0.7209, auc 0.6251, ap 0.6343
2024-01-10 21:53:32,294 - GAugM EPNet train, Epoch [224/295]: loss 0.7210, auc 0.4464, ap 0.4786
2024-01-10 21:53:32,383 - GAugM EPNet train, Epoch [225/295]: loss 0.7209, auc 0.4582, ap 0.4520
2024-01-10 21:53:32,480 - GAugM EPNet train, Epoch [226/295]: loss 0.7210, auc 0.4931, ap 0.5167
2024-01-10 21:53:32,569 - GAugM EPNet train, Epoch [227/295]: loss 0.7210, auc 0.5785, ap 0.5659
2024-01-10 21:53:32,664 - GAugM EPNet train, Epoch [228/295]: loss 0.7209, auc 0.4813, ap 0.4962
2024-01-10 21:53:32,762 - GAugM EPNet train, Epoch [229/295]: loss 0.7209, auc 0.4557, ap 0.4577
2024-01-10 21:53:32,858 - GAugM EPNet train, Epoch [230/295]: loss 0.7209, auc 0.4913, ap 0.5092
2024-01-10 21:53:32,944 - GAugM EPNet train, Epoch [231/295]: loss 0.7209, auc 0.4842, ap 0.4992
2024-01-10 21:53:33,040 - GAugM EPNet train, Epoch [232/295]: loss 0.7209, auc 0.5030, ap 0.4953
2024-01-10 21:53:33,136 - GAugM EPNet train, Epoch [233/295]: loss 0.7210, auc 0.4817, ap 0.5005
2024-01-10 21:53:33,223 - GAugM EPNet train, Epoch [234/295]: loss 0.7209, auc 0.4386, ap 0.4813
2024-01-10 21:53:33,308 - GAugM EPNet train, Epoch [235/295]: loss 0.7209, auc 0.4731, ap 0.4799
2024-01-10 21:53:33,405 - GAugM EPNet train, Epoch [236/295]: loss 0.7209, auc 0.5304, ap 0.5279
2024-01-10 21:53:33,493 - GAugM EPNet train, Epoch [237/295]: loss 0.7210, auc 0.5308, ap 0.5447
2024-01-10 21:53:33,591 - GAugM EPNet train, Epoch [238/295]: loss 0.7210, auc 0.5465, ap 0.5695
2024-01-10 21:53:33,682 - GAugM EPNet train, Epoch [239/295]: loss 0.7209, auc 0.4546, ap 0.5292
2024-01-10 21:53:33,771 - GAugM EPNet train, Epoch [240/295]: loss 0.7209, auc 0.5386, ap 0.5255
2024-01-10 21:53:33,851 - GAugM EPNet train, Epoch [241/295]: loss 0.7209, auc 0.5817, ap 0.5818
2024-01-10 21:53:33,930 - GAugM EPNet train, Epoch [242/295]: loss 0.7210, auc 0.4653, ap 0.5069
2024-01-10 21:53:34,029 - GAugM EPNet train, Epoch [243/295]: loss 0.7210, auc 0.4429, ap 0.4887
2024-01-10 21:53:34,122 - GAugM EPNet train, Epoch [244/295]: loss 0.7209, auc 0.5561, ap 0.5786
2024-01-10 21:53:34,218 - GAugM EPNet train, Epoch [245/295]: loss 0.7210, auc 0.4607, ap 0.5029
2024-01-10 21:53:34,316 - GAugM EPNet train, Epoch [246/295]: loss 0.7208, auc 0.4884, ap 0.5137
2024-01-10 21:53:34,411 - GAugM EPNet train, Epoch [247/295]: loss 0.7209, auc 0.4397, ap 0.4810
2024-01-10 21:53:34,509 - GAugM EPNet train, Epoch [248/295]: loss 0.7211, auc 0.4995, ap 0.5070
2024-01-10 21:53:34,608 - GAugM EPNet train, Epoch [249/295]: loss 0.7209, auc 0.4938, ap 0.4737
2024-01-10 21:53:34,699 - GAugM EPNet train, Epoch [250/295]: loss 0.7208, auc 0.4863, ap 0.4898
2024-01-10 21:53:34,784 - GAugM EPNet train, Epoch [251/295]: loss 0.7209, auc 0.4543, ap 0.4890
2024-01-10 21:53:34,881 - GAugM EPNet train, Epoch [252/295]: loss 0.7210, auc 0.4564, ap 0.5002
2024-01-10 21:53:34,976 - GAugM EPNet train, Epoch [253/295]: loss 0.7209, auc 0.5660, ap 0.5329
2024-01-10 21:53:35,070 - GAugM EPNet train, Epoch [254/295]: loss 0.7210, auc 0.5055, ap 0.5153
2024-01-10 21:53:35,171 - GAugM EPNet train, Epoch [255/295]: loss 0.7209, auc 0.5258, ap 0.5754
2024-01-10 21:53:35,263 - GAugM EPNet train, Epoch [256/295]: loss 0.7210, auc 0.3297, ap 0.3977
2024-01-10 21:53:35,361 - GAugM EPNet train, Epoch [257/295]: loss 0.7210, auc 0.4934, ap 0.5256
2024-01-10 21:53:35,465 - GAugM EPNet train, Epoch [258/295]: loss 0.7208, auc 0.4931, ap 0.5265
2024-01-10 21:53:35,557 - GAugM EPNet train, Epoch [259/295]: loss 0.7208, auc 0.5297, ap 0.5316
2024-01-10 21:53:35,657 - GAugM EPNet train, Epoch [260/295]: loss 0.7210, auc 0.5393, ap 0.5420
2024-01-10 21:53:35,748 - GAugM EPNet train, Epoch [261/295]: loss 0.7209, auc 0.4614, ap 0.4954
2024-01-10 21:53:35,841 - GAugM EPNet train, Epoch [262/295]: loss 0.7208, auc 0.4945, ap 0.5061
2024-01-10 21:53:35,938 - GAugM EPNet train, Epoch [263/295]: loss 0.7209, auc 0.4592, ap 0.4704
2024-01-10 21:53:36,039 - GAugM EPNet train, Epoch [264/295]: loss 0.7210, auc 0.5700, ap 0.5374
2024-01-10 21:53:36,130 - GAugM EPNet train, Epoch [265/295]: loss 0.7209, auc 0.4681, ap 0.5512
2024-01-10 21:53:36,226 - GAugM EPNet train, Epoch [266/295]: loss 0.7209, auc 0.5383, ap 0.5277
2024-01-10 21:53:36,324 - GAugM EPNet train, Epoch [267/295]: loss 0.7210, auc 0.4998, ap 0.5177
2024-01-10 21:53:36,424 - GAugM EPNet train, Epoch [268/295]: loss 0.7210, auc 0.5643, ap 0.5613
2024-01-10 21:53:36,513 - GAugM EPNet train, Epoch [269/295]: loss 0.7209, auc 0.5048, ap 0.5145
2024-01-10 21:53:36,598 - GAugM EPNet train, Epoch [270/295]: loss 0.7210, auc 0.4667, ap 0.5121
2024-01-10 21:53:36,687 - GAugM EPNet train, Epoch [271/295]: loss 0.7209, auc 0.4350, ap 0.4684
2024-01-10 21:53:36,780 - GAugM EPNet train, Epoch [272/295]: loss 0.7209, auc 0.4482, ap 0.4668
2024-01-10 21:53:36,869 - GAugM EPNet train, Epoch [273/295]: loss 0.7209, auc 0.4617, ap 0.5009
2024-01-10 21:53:36,963 - GAugM EPNet train, Epoch [274/295]: loss 0.7209, auc 0.5290, ap 0.5448
2024-01-10 21:53:37,056 - GAugM EPNet train, Epoch [275/295]: loss 0.7208, auc 0.4717, ap 0.5094
2024-01-10 21:53:37,149 - GAugM EPNet train, Epoch [276/295]: loss 0.7210, auc 0.6372, ap 0.6570
2024-01-10 21:53:37,239 - GAugM EPNet train, Epoch [277/295]: loss 0.7208, auc 0.5201, ap 0.5700
2024-01-10 21:53:37,334 - GAugM EPNet train, Epoch [278/295]: loss 0.7209, auc 0.5618, ap 0.5677
2024-01-10 21:53:37,421 - GAugM EPNet train, Epoch [279/295]: loss 0.7209, auc 0.5094, ap 0.5299
2024-01-10 21:53:37,510 - GAugM EPNet train, Epoch [280/295]: loss 0.7209, auc 0.4001, ap 0.4285
2024-01-10 21:53:37,606 - GAugM EPNet train, Epoch [281/295]: loss 0.7209, auc 0.5589, ap 0.5492
2024-01-10 21:53:37,691 - GAugM EPNet train, Epoch [282/295]: loss 0.7209, auc 0.5037, ap 0.5130
2024-01-10 21:53:37,778 - GAugM EPNet train, Epoch [283/295]: loss 0.7209, auc 0.4126, ap 0.4387
2024-01-10 21:53:37,863 - GAugM EPNet train, Epoch [284/295]: loss 0.7209, auc 0.3674, ap 0.4160
2024-01-10 21:53:37,964 - GAugM EPNet train, Epoch [285/295]: loss 0.7209, auc 0.4877, ap 0.5114
2024-01-10 21:53:38,052 - GAugM EPNet train, Epoch [286/295]: loss 0.7209, auc 0.5344, ap 0.5333
2024-01-10 21:53:38,140 - GAugM EPNet train, Epoch [287/295]: loss 0.7209, auc 0.5340, ap 0.5290
2024-01-10 21:53:38,228 - GAugM EPNet train, Epoch [288/295]: loss 0.7210, auc 0.5020, ap 0.5284
2024-01-10 21:53:38,324 - GAugM EPNet train, Epoch [289/295]: loss 0.7209, auc 0.4589, ap 0.4867
2024-01-10 21:53:38,413 - GAugM EPNet train, Epoch [290/295]: loss 0.7210, auc 0.4656, ap 0.4772
2024-01-10 21:53:38,500 - GAugM EPNet train, Epoch [291/295]: loss 0.7210, auc 0.4144, ap 0.4511
2024-01-10 21:53:38,589 - GAugM EPNet train, Epoch [292/295]: loss 0.7209, auc 0.4236, ap 0.4525
2024-01-10 21:53:38,677 - GAugM EPNet train, Epoch [293/295]: loss 0.7210, auc 0.4806, ap 0.4821
2024-01-10 21:53:38,768 - GAugM EPNet train, Epoch [294/295]: loss 0.7211, auc 0.4471, ap 0.4541
2024-01-10 21:53:38,856 - GAugM EPNet train, Epoch [295/295]: loss 0.7209, auc 0.4493, ap 0.4588
2024-01-10 21:53:38,857 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f6ced4ed350>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:53:39,673 - GAugM EPNet train, Epoch [  1/295]: loss 0.7210, auc 0.4655, ap 0.4563
2024-01-10 21:53:39,764 - GAugM EPNet train, Epoch [  2/295]: loss 0.7210, auc 0.4427, ap 0.4556
2024-01-10 21:53:39,857 - GAugM EPNet train, Epoch [  3/295]: loss 0.7209, auc 0.5673, ap 0.5456
2024-01-10 21:53:39,945 - GAugM EPNet train, Epoch [  4/295]: loss 0.7209, auc 0.4747, ap 0.4894
2024-01-10 21:53:40,035 - GAugM EPNet train, Epoch [  5/295]: loss 0.7209, auc 0.5570, ap 0.5450
2024-01-10 21:53:40,124 - GAugM EPNet train, Epoch [  6/295]: loss 0.7209, auc 0.5313, ap 0.5030
2024-01-10 21:53:40,216 - GAugM EPNet train, Epoch [  7/295]: loss 0.7209, auc 0.4534, ap 0.4479
2024-01-10 21:53:40,307 - GAugM EPNet train, Epoch [  8/295]: loss 0.7210, auc 0.4861, ap 0.4786
2024-01-10 21:53:40,402 - GAugM EPNet train, Epoch [  9/295]: loss 0.7209, auc 0.4502, ap 0.4561
2024-01-10 21:53:40,495 - GAugM EPNet train, Epoch [ 10/295]: loss 0.7208, auc 0.5121, ap 0.5024
2024-01-10 21:53:40,585 - GAugM EPNet train, Epoch [ 11/295]: loss 0.7209, auc 0.5295, ap 0.5396
2024-01-10 21:53:40,679 - GAugM EPNet train, Epoch [ 12/295]: loss 0.7210, auc 0.4502, ap 0.4604
2024-01-10 21:53:40,769 - GAugM EPNet train, Epoch [ 13/295]: loss 0.7209, auc 0.5662, ap 0.5511
2024-01-10 21:53:40,861 - GAugM EPNet train, Epoch [ 14/295]: loss 0.7209, auc 0.5488, ap 0.5178
2024-01-10 21:53:40,944 - GAugM EPNet train, Epoch [ 15/295]: loss 0.7210, auc 0.4324, ap 0.4608
2024-01-10 21:53:41,029 - GAugM EPNet train, Epoch [ 16/295]: loss 0.7209, auc 0.5655, ap 0.5775
2024-01-10 21:53:41,109 - GAugM EPNet train, Epoch [ 17/295]: loss 0.7210, auc 0.6193, ap 0.5615
2024-01-10 21:53:41,191 - GAugM EPNet train, Epoch [ 18/295]: loss 0.7210, auc 0.5637, ap 0.5478
2024-01-10 21:53:41,284 - GAugM EPNet train, Epoch [ 19/295]: loss 0.7209, auc 0.5107, ap 0.4986
2024-01-10 21:53:41,368 - GAugM EPNet train, Epoch [ 20/295]: loss 0.7210, auc 0.4733, ap 0.4847
2024-01-10 21:53:41,445 - GAugM EPNet train, Epoch [ 21/295]: loss 0.7209, auc 0.5071, ap 0.4915
2024-01-10 21:53:41,533 - GAugM EPNet train, Epoch [ 22/295]: loss 0.7210, auc 0.3377, ap 0.4290
2024-01-10 21:53:41,610 - GAugM EPNet train, Epoch [ 23/295]: loss 0.7208, auc 0.4826, ap 0.5023
2024-01-10 21:53:41,691 - GAugM EPNet train, Epoch [ 24/295]: loss 0.7209, auc 0.5246, ap 0.4951
2024-01-10 21:53:41,770 - GAugM EPNet train, Epoch [ 25/295]: loss 0.7209, auc 0.4541, ap 0.4562
2024-01-10 21:53:41,853 - GAugM EPNet train, Epoch [ 26/295]: loss 0.7210, auc 0.5267, ap 0.5075
2024-01-10 21:53:41,929 - GAugM EPNet train, Epoch [ 27/295]: loss 0.7209, auc 0.4648, ap 0.4663
2024-01-10 21:53:42,011 - GAugM EPNet train, Epoch [ 28/295]: loss 0.7209, auc 0.5595, ap 0.5459
2024-01-10 21:53:42,093 - GAugM EPNet train, Epoch [ 29/295]: loss 0.7210, auc 0.4943, ap 0.4987
2024-01-10 21:53:42,170 - GAugM EPNet train, Epoch [ 30/295]: loss 0.7209, auc 0.5206, ap 0.5282
2024-01-10 21:53:42,251 - GAugM EPNet train, Epoch [ 31/295]: loss 0.7208, auc 0.4954, ap 0.5091
2024-01-10 21:53:42,333 - GAugM EPNet train, Epoch [ 32/295]: loss 0.7210, auc 0.6018, ap 0.5536
2024-01-10 21:53:42,419 - GAugM EPNet train, Epoch [ 33/295]: loss 0.7209, auc 0.4776, ap 0.5145
2024-01-10 21:53:42,502 - GAugM EPNet train, Epoch [ 34/295]: loss 0.7209, auc 0.4648, ap 0.4562
2024-01-10 21:53:42,578 - GAugM EPNet train, Epoch [ 35/295]: loss 0.7209, auc 0.5335, ap 0.5352
2024-01-10 21:53:42,656 - GAugM EPNet train, Epoch [ 36/295]: loss 0.7209, auc 0.5477, ap 0.5213
2024-01-10 21:53:42,736 - GAugM EPNet train, Epoch [ 37/295]: loss 0.7209, auc 0.4235, ap 0.4341
2024-01-10 21:53:42,815 - GAugM EPNet train, Epoch [ 38/295]: loss 0.7209, auc 0.4758, ap 0.4659
2024-01-10 21:53:42,891 - GAugM EPNet train, Epoch [ 39/295]: loss 0.7208, auc 0.4680, ap 0.4858
2024-01-10 21:53:42,967 - GAugM EPNet train, Epoch [ 40/295]: loss 0.7210, auc 0.5801, ap 0.5432
2024-01-10 21:53:43,043 - GAugM EPNet train, Epoch [ 41/295]: loss 0.7210, auc 0.4619, ap 0.5076
2024-01-10 21:53:43,133 - GAugM EPNet train, Epoch [ 42/295]: loss 0.7209, auc 0.5199, ap 0.5355
2024-01-10 21:53:43,225 - GAugM EPNet train, Epoch [ 43/295]: loss 0.7208, auc 0.4594, ap 0.5049
2024-01-10 21:53:43,316 - GAugM EPNet train, Epoch [ 44/295]: loss 0.7208, auc 0.4302, ap 0.4526
2024-01-10 21:53:43,415 - GAugM EPNet train, Epoch [ 45/295]: loss 0.7209, auc 0.5701, ap 0.5551
2024-01-10 21:53:43,520 - GAugM EPNet train, Epoch [ 46/295]: loss 0.7209, auc 0.4007, ap 0.4460
2024-01-10 21:53:43,606 - GAugM EPNet train, Epoch [ 47/295]: loss 0.7210, auc 0.4587, ap 0.4579
2024-01-10 21:53:43,698 - GAugM EPNet train, Epoch [ 48/295]: loss 0.7210, auc 0.6146, ap 0.6229
2024-01-10 21:53:43,776 - GAugM EPNet train, Epoch [ 49/295]: loss 0.7209, auc 0.5128, ap 0.5149
2024-01-10 21:53:43,857 - GAugM EPNet train, Epoch [ 50/295]: loss 0.7210, auc 0.5630, ap 0.5453
2024-01-10 21:53:43,937 - GAugM EPNet train, Epoch [ 51/295]: loss 0.7210, auc 0.4986, ap 0.4730
2024-01-10 21:53:44,020 - GAugM EPNet train, Epoch [ 52/295]: loss 0.7209, auc 0.4651, ap 0.4949
2024-01-10 21:53:44,099 - GAugM EPNet train, Epoch [ 53/295]: loss 0.7209, auc 0.4776, ap 0.4841
2024-01-10 21:53:44,184 - GAugM EPNet train, Epoch [ 54/295]: loss 0.7211, auc 0.4772, ap 0.4871
2024-01-10 21:53:44,261 - GAugM EPNet train, Epoch [ 55/295]: loss 0.7209, auc 0.5644, ap 0.5389
2024-01-10 21:53:44,336 - GAugM EPNet train, Epoch [ 56/295]: loss 0.7208, auc 0.4986, ap 0.5056
2024-01-10 21:53:44,420 - GAugM EPNet train, Epoch [ 57/295]: loss 0.7209, auc 0.4598, ap 0.4546
2024-01-10 21:53:44,499 - GAugM EPNet train, Epoch [ 58/295]: loss 0.7210, auc 0.4484, ap 0.4992
2024-01-10 21:53:44,582 - GAugM EPNet train, Epoch [ 59/295]: loss 0.7211, auc 0.5498, ap 0.5360
2024-01-10 21:53:44,659 - GAugM EPNet train, Epoch [ 60/295]: loss 0.7210, auc 0.5755, ap 0.5400
2024-01-10 21:53:44,736 - GAugM EPNet train, Epoch [ 61/295]: loss 0.7209, auc 0.4833, ap 0.4963
2024-01-10 21:53:44,818 - GAugM EPNet train, Epoch [ 62/295]: loss 0.7210, auc 0.4943, ap 0.5118
2024-01-10 21:53:44,895 - GAugM EPNet train, Epoch [ 63/295]: loss 0.7208, auc 0.4366, ap 0.4595
2024-01-10 21:53:44,971 - GAugM EPNet train, Epoch [ 64/295]: loss 0.7208, auc 0.4779, ap 0.5064
2024-01-10 21:53:45,049 - GAugM EPNet train, Epoch [ 65/295]: loss 0.7208, auc 0.5708, ap 0.5532
2024-01-10 21:53:45,129 - GAugM EPNet train, Epoch [ 66/295]: loss 0.7209, auc 0.3829, ap 0.4326
2024-01-10 21:53:45,204 - GAugM EPNet train, Epoch [ 67/295]: loss 0.7209, auc 0.5313, ap 0.5131
2024-01-10 21:53:45,281 - GAugM EPNet train, Epoch [ 68/295]: loss 0.7210, auc 0.5206, ap 0.5181
2024-01-10 21:53:45,358 - GAugM EPNet train, Epoch [ 69/295]: loss 0.7210, auc 0.4829, ap 0.5311
2024-01-10 21:53:45,432 - GAugM EPNet train, Epoch [ 70/295]: loss 0.7210, auc 0.4761, ap 0.4668
2024-01-10 21:53:45,519 - GAugM EPNet train, Epoch [ 71/295]: loss 0.7210, auc 0.5523, ap 0.5067
2024-01-10 21:53:45,593 - GAugM EPNet train, Epoch [ 72/295]: loss 0.7210, auc 0.5192, ap 0.5044
2024-01-10 21:53:45,671 - GAugM EPNet train, Epoch [ 73/295]: loss 0.7209, auc 0.4911, ap 0.4847
2024-01-10 21:53:45,745 - GAugM EPNet train, Epoch [ 74/295]: loss 0.7209, auc 0.4833, ap 0.4933
2024-01-10 21:53:45,827 - GAugM EPNet train, Epoch [ 75/295]: loss 0.7210, auc 0.4359, ap 0.4765
2024-01-10 21:53:45,903 - GAugM EPNet train, Epoch [ 76/295]: loss 0.7209, auc 0.4149, ap 0.4505
2024-01-10 21:53:45,979 - GAugM EPNet train, Epoch [ 77/295]: loss 0.7208, auc 0.5566, ap 0.5432
2024-01-10 21:53:46,053 - GAugM EPNet train, Epoch [ 78/295]: loss 0.7209, auc 0.5260, ap 0.5154
2024-01-10 21:53:46,130 - GAugM EPNet train, Epoch [ 79/295]: loss 0.7208, auc 0.5263, ap 0.5179
2024-01-10 21:53:46,212 - GAugM EPNet train, Epoch [ 80/295]: loss 0.7209, auc 0.5527, ap 0.5339
2024-01-10 21:53:46,288 - GAugM EPNet train, Epoch [ 81/295]: loss 0.7209, auc 0.4779, ap 0.4722
2024-01-10 21:53:46,368 - GAugM EPNet train, Epoch [ 82/295]: loss 0.7210, auc 0.5933, ap 0.5625
2024-01-10 21:53:46,446 - GAugM EPNet train, Epoch [ 83/295]: loss 0.7209, auc 0.4886, ap 0.5009
2024-01-10 21:53:46,530 - GAugM EPNet train, Epoch [ 84/295]: loss 0.7209, auc 0.4420, ap 0.4575
2024-01-10 21:53:46,613 - GAugM EPNet train, Epoch [ 85/295]: loss 0.7210, auc 0.4345, ap 0.4476
2024-01-10 21:53:46,688 - GAugM EPNet train, Epoch [ 86/295]: loss 0.7208, auc 0.4719, ap 0.4909
2024-01-10 21:53:46,767 - GAugM EPNet train, Epoch [ 87/295]: loss 0.7209, auc 0.5046, ap 0.4840
2024-01-10 21:53:46,846 - GAugM EPNet train, Epoch [ 88/295]: loss 0.7210, auc 0.4769, ap 0.4930
2024-01-10 21:53:46,924 - GAugM EPNet train, Epoch [ 89/295]: loss 0.7210, auc 0.4662, ap 0.4894
2024-01-10 21:53:47,009 - GAugM EPNet train, Epoch [ 90/295]: loss 0.7209, auc 0.4021, ap 0.4468
2024-01-10 21:53:47,089 - GAugM EPNet train, Epoch [ 91/295]: loss 0.7208, auc 0.5637, ap 0.5315
2024-01-10 21:53:47,170 - GAugM EPNet train, Epoch [ 92/295]: loss 0.7209, auc 0.5434, ap 0.5415
2024-01-10 21:53:47,251 - GAugM EPNet train, Epoch [ 93/295]: loss 0.7209, auc 0.4046, ap 0.4421
2024-01-10 21:53:47,326 - GAugM EPNet train, Epoch [ 94/295]: loss 0.7210, auc 0.4947, ap 0.5248
2024-01-10 21:53:47,406 - GAugM EPNet train, Epoch [ 95/295]: loss 0.7210, auc 0.5210, ap 0.5042
2024-01-10 21:53:47,481 - GAugM EPNet train, Epoch [ 96/295]: loss 0.7209, auc 0.5520, ap 0.5626
2024-01-10 21:53:47,562 - GAugM EPNet train, Epoch [ 97/295]: loss 0.7209, auc 0.4324, ap 0.4547
2024-01-10 21:53:47,638 - GAugM EPNet train, Epoch [ 98/295]: loss 0.7209, auc 0.4427, ap 0.4571
2024-01-10 21:53:47,724 - GAugM EPNet train, Epoch [ 99/295]: loss 0.7209, auc 0.4377, ap 0.4934
2024-01-10 21:53:47,799 - GAugM EPNet train, Epoch [100/295]: loss 0.7210, auc 0.5310, ap 0.5396
2024-01-10 21:53:47,877 - GAugM EPNet train, Epoch [101/295]: loss 0.7210, auc 0.4989, ap 0.5423
2024-01-10 21:53:47,961 - GAugM EPNet train, Epoch [102/295]: loss 0.7209, auc 0.4712, ap 0.4811
2024-01-10 21:53:48,037 - GAugM EPNet train, Epoch [103/295]: loss 0.7209, auc 0.5107, ap 0.5112
2024-01-10 21:53:48,130 - GAugM EPNet train, Epoch [104/295]: loss 0.7209, auc 0.4530, ap 0.4858
2024-01-10 21:53:48,208 - GAugM EPNet train, Epoch [105/295]: loss 0.7209, auc 0.4416, ap 0.4472
2024-01-10 21:53:48,283 - GAugM EPNet train, Epoch [106/295]: loss 0.7210, auc 0.5417, ap 0.5145
2024-01-10 21:53:48,362 - GAugM EPNet train, Epoch [107/295]: loss 0.7210, auc 0.4427, ap 0.4796
2024-01-10 21:53:48,440 - GAugM EPNet train, Epoch [108/295]: loss 0.7208, auc 0.4922, ap 0.4791
2024-01-10 21:53:48,514 - GAugM EPNet train, Epoch [109/295]: loss 0.7210, auc 0.4989, ap 0.4917
2024-01-10 21:53:48,591 - GAugM EPNet train, Epoch [110/295]: loss 0.7209, auc 0.4473, ap 0.4708
2024-01-10 21:53:48,672 - GAugM EPNet train, Epoch [111/295]: loss 0.7210, auc 0.5737, ap 0.5396
2024-01-10 21:53:48,756 - GAugM EPNet train, Epoch [112/295]: loss 0.7209, auc 0.4213, ap 0.4491
2024-01-10 21:53:48,835 - GAugM EPNet train, Epoch [113/295]: loss 0.7210, auc 0.4459, ap 0.4881
2024-01-10 21:53:48,914 - GAugM EPNet train, Epoch [114/295]: loss 0.7209, auc 0.4783, ap 0.4810
2024-01-10 21:53:48,990 - GAugM EPNet train, Epoch [115/295]: loss 0.7210, auc 0.5470, ap 0.5360
2024-01-10 21:53:49,068 - GAugM EPNet train, Epoch [116/295]: loss 0.7209, auc 0.5178, ap 0.4883
2024-01-10 21:53:49,143 - GAugM EPNet train, Epoch [117/295]: loss 0.7208, auc 0.4794, ap 0.4990
2024-01-10 21:53:49,225 - GAugM EPNet train, Epoch [118/295]: loss 0.7209, auc 0.5246, ap 0.5305
2024-01-10 21:53:49,300 - GAugM EPNet train, Epoch [119/295]: loss 0.7209, auc 0.5196, ap 0.5508
2024-01-10 21:53:49,375 - GAugM EPNet train, Epoch [120/295]: loss 0.7210, auc 0.4655, ap 0.4754
2024-01-10 21:53:49,449 - GAugM EPNet train, Epoch [121/295]: loss 0.7210, auc 0.4242, ap 0.4585
2024-01-10 21:53:49,535 - GAugM EPNet train, Epoch [122/295]: loss 0.7209, auc 0.4872, ap 0.4742
2024-01-10 21:53:49,613 - GAugM EPNet train, Epoch [123/295]: loss 0.7209, auc 0.5199, ap 0.5137
2024-01-10 21:53:49,693 - GAugM EPNet train, Epoch [124/295]: loss 0.7210, auc 0.5093, ap 0.5193
2024-01-10 21:53:49,772 - GAugM EPNet train, Epoch [125/295]: loss 0.7209, auc 0.4576, ap 0.4698
2024-01-10 21:53:49,854 - GAugM EPNet train, Epoch [126/295]: loss 0.7210, auc 0.5032, ap 0.5166
2024-01-10 21:53:49,928 - GAugM EPNet train, Epoch [127/295]: loss 0.7209, auc 0.5363, ap 0.5127
2024-01-10 21:53:50,000 - GAugM EPNet train, Epoch [128/295]: loss 0.7210, auc 0.5356, ap 0.5290
2024-01-10 21:53:50,076 - GAugM EPNet train, Epoch [129/295]: loss 0.7208, auc 0.4434, ap 0.4714
2024-01-10 21:53:50,151 - GAugM EPNet train, Epoch [130/295]: loss 0.7210, auc 0.5000, ap 0.5171
2024-01-10 21:53:50,232 - GAugM EPNet train, Epoch [131/295]: loss 0.7210, auc 0.5025, ap 0.5358
2024-01-10 21:53:50,319 - GAugM EPNet train, Epoch [132/295]: loss 0.7209, auc 0.4865, ap 0.4881
2024-01-10 21:53:50,395 - GAugM EPNet train, Epoch [133/295]: loss 0.7209, auc 0.5043, ap 0.5162
2024-01-10 21:53:50,470 - GAugM EPNet train, Epoch [134/295]: loss 0.7210, auc 0.5299, ap 0.5492
2024-01-10 21:53:50,553 - GAugM EPNet train, Epoch [135/295]: loss 0.7209, auc 0.4366, ap 0.4631
2024-01-10 21:53:50,640 - GAugM EPNet train, Epoch [136/295]: loss 0.7209, auc 0.5142, ap 0.5051
2024-01-10 21:53:50,714 - GAugM EPNet train, Epoch [137/295]: loss 0.7210, auc 0.4954, ap 0.5064
2024-01-10 21:53:50,789 - GAugM EPNet train, Epoch [138/295]: loss 0.7210, auc 0.5185, ap 0.5143
2024-01-10 21:53:50,868 - GAugM EPNet train, Epoch [139/295]: loss 0.7210, auc 0.5173, ap 0.5433
2024-01-10 21:53:50,944 - GAugM EPNet train, Epoch [140/295]: loss 0.7209, auc 0.5292, ap 0.5322
2024-01-10 21:53:51,020 - GAugM EPNet train, Epoch [141/295]: loss 0.7209, auc 0.5862, ap 0.5532
2024-01-10 21:53:51,095 - GAugM EPNet train, Epoch [142/295]: loss 0.7209, auc 0.4327, ap 0.4495
2024-01-10 21:53:51,176 - GAugM EPNet train, Epoch [143/295]: loss 0.7209, auc 0.5061, ap 0.5066
2024-01-10 21:53:51,259 - GAugM EPNet train, Epoch [144/295]: loss 0.7209, auc 0.4648, ap 0.4632
2024-01-10 21:53:51,335 - GAugM EPNet train, Epoch [145/295]: loss 0.7209, auc 0.4769, ap 0.5248
2024-01-10 21:53:51,419 - GAugM EPNet train, Epoch [146/295]: loss 0.7209, auc 0.4591, ap 0.4896
2024-01-10 21:53:51,498 - GAugM EPNet train, Epoch [147/295]: loss 0.7209, auc 0.5584, ap 0.5739
2024-01-10 21:53:51,573 - GAugM EPNet train, Epoch [148/295]: loss 0.7209, auc 0.4918, ap 0.5323
2024-01-10 21:53:51,651 - GAugM EPNet train, Epoch [149/295]: loss 0.7208, auc 0.5260, ap 0.5145
2024-01-10 21:53:51,725 - GAugM EPNet train, Epoch [150/295]: loss 0.7209, auc 0.5288, ap 0.5092
2024-01-10 21:53:51,804 - GAugM EPNet train, Epoch [151/295]: loss 0.7209, auc 0.5755, ap 0.5650
2024-01-10 21:53:51,880 - GAugM EPNet train, Epoch [152/295]: loss 0.7209, auc 0.5388, ap 0.5447
2024-01-10 21:53:51,968 - GAugM EPNet train, Epoch [153/295]: loss 0.7209, auc 0.4672, ap 0.5181
2024-01-10 21:53:52,047 - GAugM EPNet train, Epoch [154/295]: loss 0.7209, auc 0.6225, ap 0.6270
2024-01-10 21:53:52,127 - GAugM EPNet train, Epoch [155/295]: loss 0.7209, auc 0.5267, ap 0.5381
2024-01-10 21:53:52,203 - GAugM EPNet train, Epoch [156/295]: loss 0.7209, auc 0.4334, ap 0.4762
2024-01-10 21:53:52,281 - GAugM EPNet train, Epoch [157/295]: loss 0.7209, auc 0.5399, ap 0.5249
2024-01-10 21:53:52,356 - GAugM EPNet train, Epoch [158/295]: loss 0.7208, auc 0.4106, ap 0.4344
2024-01-10 21:53:52,430 - GAugM EPNet train, Epoch [159/295]: loss 0.7208, auc 0.4733, ap 0.4906
2024-01-10 21:53:52,518 - GAugM EPNet train, Epoch [160/295]: loss 0.7209, auc 0.5402, ap 0.5755
2024-01-10 21:53:52,594 - GAugM EPNet train, Epoch [161/295]: loss 0.7209, auc 0.5345, ap 0.5396
2024-01-10 21:53:52,667 - GAugM EPNet train, Epoch [162/295]: loss 0.7209, auc 0.5110, ap 0.4915
2024-01-10 21:53:52,741 - GAugM EPNet train, Epoch [163/295]: loss 0.7209, auc 0.4883, ap 0.4777
2024-01-10 21:53:52,820 - GAugM EPNet train, Epoch [164/295]: loss 0.7211, auc 0.5078, ap 0.4943
2024-01-10 21:53:52,894 - GAugM EPNet train, Epoch [165/295]: loss 0.7210, auc 0.4840, ap 0.5090
2024-01-10 21:53:52,968 - GAugM EPNet train, Epoch [166/295]: loss 0.7208, auc 0.5424, ap 0.5182
2024-01-10 21:53:53,043 - GAugM EPNet train, Epoch [167/295]: loss 0.7209, auc 0.4544, ap 0.4697
2024-01-10 21:53:53,126 - GAugM EPNet train, Epoch [168/295]: loss 0.7209, auc 0.5424, ap 0.5398
2024-01-10 21:53:53,199 - GAugM EPNet train, Epoch [169/295]: loss 0.7209, auc 0.5381, ap 0.5490
2024-01-10 21:53:53,278 - GAugM EPNet train, Epoch [170/295]: loss 0.7210, auc 0.4648, ap 0.4746
2024-01-10 21:53:53,353 - GAugM EPNet train, Epoch [171/295]: loss 0.7209, auc 0.3996, ap 0.4452
2024-01-10 21:53:53,441 - GAugM EPNet train, Epoch [172/295]: loss 0.7208, auc 0.4003, ap 0.4328
2024-01-10 21:53:53,517 - GAugM EPNet train, Epoch [173/295]: loss 0.7209, auc 0.4886, ap 0.5140
2024-01-10 21:53:53,595 - GAugM EPNet train, Epoch [174/295]: loss 0.7209, auc 0.4562, ap 0.4635
2024-01-10 21:53:53,670 - GAugM EPNet train, Epoch [175/295]: loss 0.7209, auc 0.6613, ap 0.6152
2024-01-10 21:53:53,753 - GAugM EPNet train, Epoch [176/295]: loss 0.7209, auc 0.5068, ap 0.4952
2024-01-10 21:53:53,837 - GAugM EPNet train, Epoch [177/295]: loss 0.7210, auc 0.4576, ap 0.4563
2024-01-10 21:53:53,919 - GAugM EPNet train, Epoch [178/295]: loss 0.7210, auc 0.5530, ap 0.5470
2024-01-10 21:53:54,008 - GAugM EPNet train, Epoch [179/295]: loss 0.7210, auc 0.4089, ap 0.4436
2024-01-10 21:53:54,101 - GAugM EPNet train, Epoch [180/295]: loss 0.7210, auc 0.5523, ap 0.5547
2024-01-10 21:53:54,189 - GAugM EPNet train, Epoch [181/295]: loss 0.7209, auc 0.4274, ap 0.4411
2024-01-10 21:53:54,283 - GAugM EPNet train, Epoch [182/295]: loss 0.7209, auc 0.4238, ap 0.4784
2024-01-10 21:53:54,370 - GAugM EPNet train, Epoch [183/295]: loss 0.7210, auc 0.5324, ap 0.5081
2024-01-10 21:53:54,456 - GAugM EPNet train, Epoch [184/295]: loss 0.7209, auc 0.4758, ap 0.5005
2024-01-10 21:53:54,546 - GAugM EPNet train, Epoch [185/295]: loss 0.7209, auc 0.5157, ap 0.5178
2024-01-10 21:53:54,632 - GAugM EPNet train, Epoch [186/295]: loss 0.7208, auc 0.4413, ap 0.4825
2024-01-10 21:53:54,725 - GAugM EPNet train, Epoch [187/295]: loss 0.7209, auc 0.5230, ap 0.5300
2024-01-10 21:53:54,816 - GAugM EPNet train, Epoch [188/295]: loss 0.7209, auc 0.4712, ap 0.4536
2024-01-10 21:53:54,905 - GAugM EPNet train, Epoch [189/295]: loss 0.7209, auc 0.5876, ap 0.5886
2024-01-10 21:53:54,998 - GAugM EPNet train, Epoch [190/295]: loss 0.7209, auc 0.4445, ap 0.4711
2024-01-10 21:53:55,086 - GAugM EPNet train, Epoch [191/295]: loss 0.7209, auc 0.4616, ap 0.4912
2024-01-10 21:53:55,180 - GAugM EPNet train, Epoch [192/295]: loss 0.7209, auc 0.5384, ap 0.4909
2024-01-10 21:53:55,268 - GAugM EPNet train, Epoch [193/295]: loss 0.7209, auc 0.5463, ap 0.5234
2024-01-10 21:53:55,361 - GAugM EPNet train, Epoch [194/295]: loss 0.7209, auc 0.5498, ap 0.5299
2024-01-10 21:53:55,460 - GAugM EPNet train, Epoch [195/295]: loss 0.7209, auc 0.4124, ap 0.4381
2024-01-10 21:53:55,558 - GAugM EPNet train, Epoch [196/295]: loss 0.7208, auc 0.5527, ap 0.5265
2024-01-10 21:53:55,655 - GAugM EPNet train, Epoch [197/295]: loss 0.7210, auc 0.4623, ap 0.4698
2024-01-10 21:53:55,746 - GAugM EPNet train, Epoch [198/295]: loss 0.7210, auc 0.5527, ap 0.5350
2024-01-10 21:53:55,835 - GAugM EPNet train, Epoch [199/295]: loss 0.7209, auc 0.4701, ap 0.5123
2024-01-10 21:53:55,928 - GAugM EPNet train, Epoch [200/295]: loss 0.7210, auc 0.4900, ap 0.4947
2024-01-10 21:53:56,020 - GAugM EPNet train, Epoch [201/295]: loss 0.7209, auc 0.5121, ap 0.4999
2024-01-10 21:53:56,114 - GAugM EPNet train, Epoch [202/295]: loss 0.7210, auc 0.4843, ap 0.5227
2024-01-10 21:53:56,206 - GAugM EPNet train, Epoch [203/295]: loss 0.7210, auc 0.4761, ap 0.4922
2024-01-10 21:53:56,300 - GAugM EPNet train, Epoch [204/295]: loss 0.7209, auc 0.4815, ap 0.5069
2024-01-10 21:53:56,388 - GAugM EPNet train, Epoch [205/295]: loss 0.7209, auc 0.4961, ap 0.4757
2024-01-10 21:53:56,476 - GAugM EPNet train, Epoch [206/295]: loss 0.7209, auc 0.4420, ap 0.4683
2024-01-10 21:53:56,570 - GAugM EPNet train, Epoch [207/295]: loss 0.7210, auc 0.4576, ap 0.4774
2024-01-10 21:53:56,657 - GAugM EPNet train, Epoch [208/295]: loss 0.7209, auc 0.4441, ap 0.4567
2024-01-10 21:53:56,747 - GAugM EPNet train, Epoch [209/295]: loss 0.7210, auc 0.6132, ap 0.5703
2024-01-10 21:53:56,836 - GAugM EPNet train, Epoch [210/295]: loss 0.7209, auc 0.4338, ap 0.4626
2024-01-10 21:53:56,926 - GAugM EPNet train, Epoch [211/295]: loss 0.7210, auc 0.5488, ap 0.5470
2024-01-10 21:53:57,011 - GAugM EPNet train, Epoch [212/295]: loss 0.7210, auc 0.3658, ap 0.4151
2024-01-10 21:53:57,095 - GAugM EPNet train, Epoch [213/295]: loss 0.7208, auc 0.6324, ap 0.6411
2024-01-10 21:53:57,183 - GAugM EPNet train, Epoch [214/295]: loss 0.7210, auc 0.5605, ap 0.5601
2024-01-10 21:53:57,276 - GAugM EPNet train, Epoch [215/295]: loss 0.7210, auc 0.5021, ap 0.4819
2024-01-10 21:53:57,372 - GAugM EPNet train, Epoch [216/295]: loss 0.7209, auc 0.5093, ap 0.4857
2024-01-10 21:53:57,472 - GAugM EPNet train, Epoch [217/295]: loss 0.7209, auc 0.5926, ap 0.5930
2024-01-10 21:53:57,563 - GAugM EPNet train, Epoch [218/295]: loss 0.7209, auc 0.5392, ap 0.5638
2024-01-10 21:53:57,660 - GAugM EPNet train, Epoch [219/295]: loss 0.7208, auc 0.5028, ap 0.4934
2024-01-10 21:53:57,751 - GAugM EPNet train, Epoch [220/295]: loss 0.7210, auc 0.4644, ap 0.5192
2024-01-10 21:53:57,845 - GAugM EPNet train, Epoch [221/295]: loss 0.7209, auc 0.5477, ap 0.5183
2024-01-10 21:53:57,928 - GAugM EPNet train, Epoch [222/295]: loss 0.7209, auc 0.4441, ap 0.4659
2024-01-10 21:53:58,022 - GAugM EPNet train, Epoch [223/295]: loss 0.7209, auc 0.5616, ap 0.5660
2024-01-10 21:53:58,114 - GAugM EPNet train, Epoch [224/295]: loss 0.7210, auc 0.4907, ap 0.5069
2024-01-10 21:53:58,208 - GAugM EPNet train, Epoch [225/295]: loss 0.7209, auc 0.5085, ap 0.5084
2024-01-10 21:53:58,301 - GAugM EPNet train, Epoch [226/295]: loss 0.7210, auc 0.4576, ap 0.4765
2024-01-10 21:53:58,393 - GAugM EPNet train, Epoch [227/295]: loss 0.7210, auc 0.5573, ap 0.5542
2024-01-10 21:53:58,476 - GAugM EPNet train, Epoch [228/295]: loss 0.7209, auc 0.4850, ap 0.4930
2024-01-10 21:53:58,554 - GAugM EPNet train, Epoch [229/295]: loss 0.7209, auc 0.5427, ap 0.5235
2024-01-10 21:53:58,643 - GAugM EPNet train, Epoch [230/295]: loss 0.7209, auc 0.4416, ap 0.4805
2024-01-10 21:53:58,740 - GAugM EPNet train, Epoch [231/295]: loss 0.7209, auc 0.5239, ap 0.5405
2024-01-10 21:53:58,833 - GAugM EPNet train, Epoch [232/295]: loss 0.7209, auc 0.5103, ap 0.5172
2024-01-10 21:53:58,928 - GAugM EPNet train, Epoch [233/295]: loss 0.7210, auc 0.4779, ap 0.5076
2024-01-10 21:53:59,025 - GAugM EPNet train, Epoch [234/295]: loss 0.7209, auc 0.4003, ap 0.4377
2024-01-10 21:53:59,124 - GAugM EPNet train, Epoch [235/295]: loss 0.7209, auc 0.5050, ap 0.4785
2024-01-10 21:53:59,216 - GAugM EPNet train, Epoch [236/295]: loss 0.7209, auc 0.5085, ap 0.5145
2024-01-10 21:53:59,310 - GAugM EPNet train, Epoch [237/295]: loss 0.7210, auc 0.4740, ap 0.4995
2024-01-10 21:53:59,407 - GAugM EPNet train, Epoch [238/295]: loss 0.7210, auc 0.4267, ap 0.4416
2024-01-10 21:53:59,503 - GAugM EPNet train, Epoch [239/295]: loss 0.7209, auc 0.5239, ap 0.5590
2024-01-10 21:53:59,596 - GAugM EPNet train, Epoch [240/295]: loss 0.7209, auc 0.5263, ap 0.4942
2024-01-10 21:53:59,694 - GAugM EPNet train, Epoch [241/295]: loss 0.7209, auc 0.5840, ap 0.5952
2024-01-10 21:53:59,785 - GAugM EPNet train, Epoch [242/295]: loss 0.7210, auc 0.4957, ap 0.5264
2024-01-10 21:53:59,878 - GAugM EPNet train, Epoch [243/295]: loss 0.7210, auc 0.5089, ap 0.5300
2024-01-10 21:53:59,973 - GAugM EPNet train, Epoch [244/295]: loss 0.7209, auc 0.5021, ap 0.5127
2024-01-10 21:54:00,073 - GAugM EPNet train, Epoch [245/295]: loss 0.7210, auc 0.4548, ap 0.4943
2024-01-10 21:54:00,174 - GAugM EPNet train, Epoch [246/295]: loss 0.7208, auc 0.5292, ap 0.5155
2024-01-10 21:54:00,273 - GAugM EPNet train, Epoch [247/295]: loss 0.7209, auc 0.5530, ap 0.5415
2024-01-10 21:54:00,365 - GAugM EPNet train, Epoch [248/295]: loss 0.7211, auc 0.5420, ap 0.5263
2024-01-10 21:54:00,474 - GAugM EPNet train, Epoch [249/295]: loss 0.7209, auc 0.5110, ap 0.5094
2024-01-10 21:54:00,568 - GAugM EPNet train, Epoch [250/295]: loss 0.7208, auc 0.5260, ap 0.5311
2024-01-10 21:54:00,662 - GAugM EPNet train, Epoch [251/295]: loss 0.7209, auc 0.5299, ap 0.5286
2024-01-10 21:54:00,763 - GAugM EPNet train, Epoch [252/295]: loss 0.7210, auc 0.6153, ap 0.5921
2024-01-10 21:54:00,854 - GAugM EPNet train, Epoch [253/295]: loss 0.7209, auc 0.6032, ap 0.5625
2024-01-10 21:54:00,943 - GAugM EPNet train, Epoch [254/295]: loss 0.7210, auc 0.4381, ap 0.4582
2024-01-10 21:54:01,030 - GAugM EPNet train, Epoch [255/295]: loss 0.7209, auc 0.5071, ap 0.5143
2024-01-10 21:54:01,121 - GAugM EPNet train, Epoch [256/295]: loss 0.7210, auc 0.3836, ap 0.4773
2024-01-10 21:54:01,212 - GAugM EPNet train, Epoch [257/295]: loss 0.7210, auc 0.5142, ap 0.5143
2024-01-10 21:54:01,301 - GAugM EPNet train, Epoch [258/295]: loss 0.7208, auc 0.4769, ap 0.4926
2024-01-10 21:54:01,399 - GAugM EPNet train, Epoch [259/295]: loss 0.7208, auc 0.5438, ap 0.5114
2024-01-10 21:54:01,486 - GAugM EPNet train, Epoch [260/295]: loss 0.7210, auc 0.5498, ap 0.5380
2024-01-10 21:54:01,576 - GAugM EPNet train, Epoch [261/295]: loss 0.7209, auc 0.4747, ap 0.4840
2024-01-10 21:54:01,662 - GAugM EPNet train, Epoch [262/295]: loss 0.7208, auc 0.4712, ap 0.4865
2024-01-10 21:54:01,757 - GAugM EPNet train, Epoch [263/295]: loss 0.7209, auc 0.3918, ap 0.4235
2024-01-10 21:54:01,845 - GAugM EPNet train, Epoch [264/295]: loss 0.7210, auc 0.5349, ap 0.5152
2024-01-10 21:54:01,939 - GAugM EPNet train, Epoch [265/295]: loss 0.7209, auc 0.5061, ap 0.5172
2024-01-10 21:54:02,018 - GAugM EPNet train, Epoch [266/295]: loss 0.7209, auc 0.5530, ap 0.5359
2024-01-10 21:54:02,100 - GAugM EPNet train, Epoch [267/295]: loss 0.7210, auc 0.5370, ap 0.5234
2024-01-10 21:54:02,182 - GAugM EPNet train, Epoch [268/295]: loss 0.7210, auc 0.4865, ap 0.5031
2024-01-10 21:54:02,270 - GAugM EPNet train, Epoch [269/295]: loss 0.7209, auc 0.5299, ap 0.5251
2024-01-10 21:54:02,363 - GAugM EPNet train, Epoch [270/295]: loss 0.7210, auc 0.4302, ap 0.4538
2024-01-10 21:54:02,457 - GAugM EPNet train, Epoch [271/295]: loss 0.7209, auc 0.4929, ap 0.4977
2024-01-10 21:54:02,547 - GAugM EPNet train, Epoch [272/295]: loss 0.7209, auc 0.5623, ap 0.5806
2024-01-10 21:54:02,649 - GAugM EPNet train, Epoch [273/295]: loss 0.7209, auc 0.4758, ap 0.4776
2024-01-10 21:54:02,737 - GAugM EPNet train, Epoch [274/295]: loss 0.7209, auc 0.4167, ap 0.4530
2024-01-10 21:54:02,819 - GAugM EPNet train, Epoch [275/295]: loss 0.7208, auc 0.4217, ap 0.4454
2024-01-10 21:54:02,907 - GAugM EPNet train, Epoch [276/295]: loss 0.7210, auc 0.5011, ap 0.5128
2024-01-10 21:54:02,984 - GAugM EPNet train, Epoch [277/295]: loss 0.7208, auc 0.4986, ap 0.4955
2024-01-10 21:54:03,065 - GAugM EPNet train, Epoch [278/295]: loss 0.7209, auc 0.6143, ap 0.6288
2024-01-10 21:54:03,147 - GAugM EPNet train, Epoch [279/295]: loss 0.7209, auc 0.5135, ap 0.5319
2024-01-10 21:54:03,225 - GAugM EPNet train, Epoch [280/295]: loss 0.7209, auc 0.4046, ap 0.4229
2024-01-10 21:54:03,307 - GAugM EPNet train, Epoch [281/295]: loss 0.7209, auc 0.5595, ap 0.5489
2024-01-10 21:54:03,395 - GAugM EPNet train, Epoch [282/295]: loss 0.7209, auc 0.5121, ap 0.4927
2024-01-10 21:54:03,492 - GAugM EPNet train, Epoch [283/295]: loss 0.7209, auc 0.4174, ap 0.4340
2024-01-10 21:54:03,584 - GAugM EPNet train, Epoch [284/295]: loss 0.7209, auc 0.4149, ap 0.4353
2024-01-10 21:54:03,683 - GAugM EPNet train, Epoch [285/295]: loss 0.7209, auc 0.4893, ap 0.4758
2024-01-10 21:54:03,772 - GAugM EPNet train, Epoch [286/295]: loss 0.7209, auc 0.4566, ap 0.4711
2024-01-10 21:54:03,859 - GAugM EPNet train, Epoch [287/295]: loss 0.7209, auc 0.5046, ap 0.5430
2024-01-10 21:54:03,953 - GAugM EPNet train, Epoch [288/295]: loss 0.7210, auc 0.4288, ap 0.4717
2024-01-10 21:54:04,038 - GAugM EPNet train, Epoch [289/295]: loss 0.7209, auc 0.5167, ap 0.5048
2024-01-10 21:54:04,117 - GAugM EPNet train, Epoch [290/295]: loss 0.7210, auc 0.5630, ap 0.5203
2024-01-10 21:54:04,196 - GAugM EPNet train, Epoch [291/295]: loss 0.7210, auc 0.4448, ap 0.4934
2024-01-10 21:54:04,285 - GAugM EPNet train, Epoch [292/295]: loss 0.7209, auc 0.4384, ap 0.4497
2024-01-10 21:54:04,376 - GAugM EPNet train, Epoch [293/295]: loss 0.7210, auc 0.4769, ap 0.4564
2024-01-10 21:54:04,474 - GAugM EPNet train, Epoch [294/295]: loss 0.7211, auc 0.5004, ap 0.4919
2024-01-10 21:54:04,564 - GAugM EPNet train, Epoch [295/295]: loss 0.7209, auc 0.4487, ap 0.4523
2024-01-10 21:55:03,949 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d0377b610>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:55:04,703 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4539, ap 0.4556
2024-01-10 21:55:04,790 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5098, ap 0.5044
2024-01-10 21:55:04,871 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5634, ap 0.5441
2024-01-10 21:55:04,952 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.5203, ap 0.5294
2024-01-10 21:55:05,033 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5789, ap 0.5718
2024-01-10 21:55:05,107 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.4945, ap 0.4821
2024-01-10 21:55:05,180 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4724, ap 0.4777
2024-01-10 21:55:05,249 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.4932, ap 0.5393
2024-01-10 21:55:05,312 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4776, ap 0.4770
2024-01-10 21:55:05,372 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4995, ap 0.5189
2024-01-10 21:55:05,443 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4904, ap 0.5306
2024-01-10 21:55:05,505 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4745, ap 0.4891
2024-01-10 21:55:05,566 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5393, ap 0.5449
2024-01-10 21:55:05,632 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5301, ap 0.5099
2024-01-10 21:55:05,715 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4535, ap 0.4885
2024-01-10 21:55:05,800 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5667, ap 0.5566
2024-01-10 21:55:05,876 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5522, ap 0.5420
2024-01-10 21:55:05,956 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.6082, ap 0.6144
2024-01-10 21:55:06,026 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5199, ap 0.5070
2024-01-10 21:55:06,090 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.4333, ap 0.4694
2024-01-10 21:55:06,167 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4738, ap 0.4973
2024-01-10 21:55:06,230 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.3695, ap 0.4269
2024-01-10 21:55:06,294 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5023, ap 0.5035
2024-01-10 21:55:06,357 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5623, ap 0.5608
2024-01-10 21:55:06,418 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4066, ap 0.4527
2024-01-10 21:55:06,478 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5872, ap 0.5987
2024-01-10 21:55:06,544 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.3647, ap 0.4296
2024-01-10 21:55:06,604 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5995, ap 0.5915
2024-01-10 21:55:06,668 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.4813, ap 0.4921
2024-01-10 21:55:06,740 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5587, ap 0.5471
2024-01-10 21:55:06,824 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.5354, ap 0.5270
2024-01-10 21:55:06,905 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.6120, ap 0.6027
2024-01-10 21:55:06,985 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.4744, ap 0.4963
2024-01-10 21:55:07,070 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.5048, ap 0.5014
2024-01-10 21:55:07,150 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5311, ap 0.5241
2024-01-10 21:55:07,235 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5491, ap 0.5746
2024-01-10 21:55:07,315 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4614, ap 0.4939
2024-01-10 21:55:07,395 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.5840, ap 0.5418
2024-01-10 21:55:07,473 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4325, ap 0.4836
2024-01-10 21:55:07,558 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5639, ap 0.5404
2024-01-10 21:55:07,637 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.5550, ap 0.5859
2024-01-10 21:55:07,717 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5335, ap 0.5861
2024-01-10 21:55:07,797 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4464, ap 0.4926
2024-01-10 21:55:07,879 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4172, ap 0.4594
2024-01-10 21:55:07,962 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5628, ap 0.5701
2024-01-10 21:55:08,040 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4689, ap 0.5088
2024-01-10 21:55:08,127 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4340, ap 0.4705
2024-01-10 21:55:08,211 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.6753, ap 0.6625
2024-01-10 21:55:08,291 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.4719, ap 0.4882
2024-01-10 21:55:08,376 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5708, ap 0.5540
2024-01-10 21:55:08,454 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4895, ap 0.5357
2024-01-10 21:55:08,531 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4934, ap 0.5289
2024-01-10 21:55:08,609 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5062, ap 0.5241
2024-01-10 21:55:08,689 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5415, ap 0.5348
2024-01-10 21:55:08,767 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.6248, ap 0.6002
2024-01-10 21:55:08,863 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4863, ap 0.4973
2024-01-10 21:55:08,951 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.5226, ap 0.4950
2024-01-10 21:55:09,036 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.5230, ap 0.5850
2024-01-10 21:55:09,117 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4881, ap 0.4741
2024-01-10 21:55:09,198 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.6040, ap 0.5781
2024-01-10 21:55:09,283 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5308, ap 0.5419
2024-01-10 21:55:09,362 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5954, ap 0.5937
2024-01-10 21:55:09,442 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4151, ap 0.4491
2024-01-10 21:55:09,523 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.5100, ap 0.5177
2024-01-10 21:55:09,604 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5285, ap 0.5437
2024-01-10 21:55:09,683 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4518, ap 0.4723
2024-01-10 21:55:09,763 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5235, ap 0.5137
2024-01-10 21:55:09,848 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.4790, ap 0.5196
2024-01-10 21:55:09,927 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.5466, ap 0.5356
2024-01-10 21:55:10,013 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4436, ap 0.4817
2024-01-10 21:55:10,099 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5965, ap 0.5643
2024-01-10 21:55:10,185 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4514, ap 0.5004
2024-01-10 21:55:10,269 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5036, ap 0.5112
2024-01-10 21:55:10,353 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.4450, ap 0.4632
2024-01-10 21:55:10,439 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.3943, ap 0.4344
2024-01-10 21:55:10,519 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4149, ap 0.4622
2024-01-10 21:55:10,602 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5539, ap 0.5908
2024-01-10 21:55:10,685 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5294, ap 0.5355
2024-01-10 21:55:10,770 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5062, ap 0.5164
2024-01-10 21:55:10,877 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.4847, ap 0.4961
2024-01-10 21:55:10,970 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5662, ap 0.5332
2024-01-10 21:55:11,058 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5078, ap 0.5204
2024-01-10 21:55:11,144 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4774, ap 0.5116
2024-01-10 21:55:11,237 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4391, ap 0.4664
2024-01-10 21:55:11,327 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4697, ap 0.5139
2024-01-10 21:55:11,417 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4847, ap 0.5313
2024-01-10 21:55:11,502 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.4820, ap 0.4852
2024-01-10 21:55:11,588 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.5429, ap 0.5960
2024-01-10 21:55:11,683 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4393, ap 0.4805
2024-01-10 21:55:11,768 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4459, ap 0.4853
2024-01-10 21:55:11,775 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d036f1a50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:55:12,491 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4683, ap 0.4697
2024-01-10 21:55:12,584 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.4427, ap 0.4514
2024-01-10 21:55:12,672 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.4811, ap 0.4790
2024-01-10 21:55:12,759 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4416, ap 0.4851
2024-01-10 21:55:12,846 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.6552, ap 0.6259
2024-01-10 21:55:12,936 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.5402, ap 0.5181
2024-01-10 21:55:13,022 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4450, ap 0.4508
2024-01-10 21:55:13,111 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5545, ap 0.5655
2024-01-10 21:55:13,196 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4489, ap 0.4678
2024-01-10 21:55:13,286 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.5009, ap 0.4964
2024-01-10 21:55:13,372 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4719, ap 0.4639
2024-01-10 21:55:13,459 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.5578, ap 0.5230
2024-01-10 21:55:13,545 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5707, ap 0.5402
2024-01-10 21:55:13,631 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5107, ap 0.4948
2024-01-10 21:55:13,724 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.3861, ap 0.4363
2024-01-10 21:55:13,811 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.4786, ap 0.4801
2024-01-10 21:55:13,900 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.6023, ap 0.5671
2024-01-10 21:55:13,987 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.6606, ap 0.6145
2024-01-10 21:55:14,073 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5253, ap 0.5104
2024-01-10 21:55:14,162 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5425, ap 0.5373
2024-01-10 21:55:14,251 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.5465, ap 0.5033
2024-01-10 21:55:14,336 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.4142, ap 0.4411
2024-01-10 21:55:14,422 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.4751, ap 0.4787
2024-01-10 21:55:14,510 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5408, ap 0.5539
2024-01-10 21:55:14,595 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4365, ap 0.4589
2024-01-10 21:55:14,680 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5393, ap 0.5220
2024-01-10 21:55:14,773 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4147, ap 0.4589
2024-01-10 21:55:14,860 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5951, ap 0.6151
2024-01-10 21:55:14,945 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5046, ap 0.5123
2024-01-10 21:55:15,035 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5356, ap 0.5430
2024-01-10 21:55:15,134 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.4810, ap 0.4980
2024-01-10 21:55:15,223 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5465, ap 0.5122
2024-01-10 21:55:15,309 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5418, ap 0.5451
2024-01-10 21:55:15,399 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4728, ap 0.4743
2024-01-10 21:55:15,485 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5281, ap 0.5154
2024-01-10 21:55:15,577 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5997, ap 0.5613
2024-01-10 21:55:15,661 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4667, ap 0.4672
2024-01-10 21:55:15,747 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.4911, ap 0.4859
2024-01-10 21:55:15,831 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.5386, ap 0.5504
2024-01-10 21:55:15,916 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5943, ap 0.5409
2024-01-10 21:55:16,000 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.5109, ap 0.5458
2024-01-10 21:55:16,089 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5228, ap 0.5586
2024-01-10 21:55:16,177 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4943, ap 0.5233
2024-01-10 21:55:16,260 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.3968, ap 0.4473
2024-01-10 21:55:16,348 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5481, ap 0.5452
2024-01-10 21:55:16,433 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4468, ap 0.4740
2024-01-10 21:55:16,517 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4957, ap 0.5100
2024-01-10 21:55:16,607 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5555, ap 0.5750
2024-01-10 21:55:16,703 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5653, ap 0.5429
2024-01-10 21:55:16,797 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5445, ap 0.5423
2024-01-10 21:55:16,890 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4915, ap 0.5255
2024-01-10 21:55:16,981 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4596, ap 0.4985
2024-01-10 21:55:17,069 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.4493, ap 0.4674
2024-01-10 21:55:17,157 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5358, ap 0.5194
2024-01-10 21:55:17,245 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5479, ap 0.5715
2024-01-10 21:55:17,366 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.5719, ap 0.5797
2024-01-10 21:55:17,463 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.5381, ap 0.5192
2024-01-10 21:55:17,558 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4514, ap 0.5231
2024-01-10 21:55:17,651 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4929, ap 0.4982
2024-01-10 21:55:17,746 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5287, ap 0.5334
2024-01-10 21:55:17,841 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5198, ap 0.5022
2024-01-10 21:55:17,934 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5125, ap 0.5248
2024-01-10 21:55:18,031 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.5198, ap 0.4977
2024-01-10 21:55:18,123 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4137, ap 0.4854
2024-01-10 21:55:18,218 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5591, ap 0.5754
2024-01-10 21:55:18,312 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4881, ap 0.5286
2024-01-10 21:55:18,404 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5509, ap 0.5630
2024-01-10 21:55:18,498 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5313, ap 0.5359
2024-01-10 21:55:18,591 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.5263, ap 0.4945
2024-01-10 21:55:18,683 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4498, ap 0.4498
2024-01-10 21:55:18,778 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5352, ap 0.5359
2024-01-10 21:55:18,868 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4381, ap 0.4664
2024-01-10 21:55:18,960 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.4658, ap 0.4688
2024-01-10 21:55:19,051 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5285, ap 0.5126
2024-01-10 21:55:19,143 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4852, ap 0.5233
2024-01-10 21:55:19,232 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.5082, ap 0.5072
2024-01-10 21:55:19,320 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5680, ap 0.5534
2024-01-10 21:55:19,409 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5288, ap 0.5129
2024-01-10 21:55:19,502 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.4478, ap 0.4609
2024-01-10 21:55:19,591 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.4929, ap 0.5014
2024-01-10 21:55:19,680 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5623, ap 0.5319
2024-01-10 21:55:19,772 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5101, ap 0.5172
2024-01-10 21:55:19,861 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.5495, ap 0.5845
2024-01-10 21:55:19,951 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4098, ap 0.4536
2024-01-10 21:55:20,039 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4439, ap 0.4533
2024-01-10 21:55:20,128 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4772, ap 0.4915
2024-01-10 21:55:20,217 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5392, ap 0.5221
2024-01-10 21:55:20,309 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4167, ap 0.4512
2024-01-10 21:55:20,399 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.5030, ap 0.5159
2024-01-10 21:55:20,488 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4603, ap 0.4844
2024-01-10 21:55:20,504 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035b4090>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:55:21,342 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.5068, ap 0.5095
2024-01-10 21:55:21,436 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5080, ap 0.5040
2024-01-10 21:55:21,542 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5109, ap 0.5037
2024-01-10 21:55:21,639 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4514, ap 0.4734
2024-01-10 21:55:21,723 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.6547, ap 0.6716
2024-01-10 21:55:21,809 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.5050, ap 0.4928
2024-01-10 21:55:21,891 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4589, ap 0.4606
2024-01-10 21:55:21,974 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5055, ap 0.5003
2024-01-10 21:55:22,086 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4315, ap 0.4698
2024-01-10 21:55:22,180 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4612, ap 0.4901
2024-01-10 21:55:22,274 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.5281, ap 0.5380
2024-01-10 21:55:22,391 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4865, ap 0.4783
2024-01-10 21:55:22,484 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5806, ap 0.5675
2024-01-10 21:55:22,573 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5783, ap 0.5711
2024-01-10 21:55:22,666 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4941, ap 0.5251
2024-01-10 21:55:22,753 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.4607, ap 0.4927
2024-01-10 21:55:22,841 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5397, ap 0.5282
2024-01-10 21:55:22,929 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5837, ap 0.5658
2024-01-10 21:55:23,014 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5219, ap 0.5346
2024-01-10 21:55:23,106 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.4947, ap 0.5438
2024-01-10 21:55:23,193 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4938, ap 0.5002
2024-01-10 21:55:23,279 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.3923, ap 0.4283
2024-01-10 21:55:23,365 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5945, ap 0.5646
2024-01-10 21:55:23,452 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5176, ap 0.5092
2024-01-10 21:55:23,536 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4681, ap 0.4901
2024-01-10 21:55:23,621 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5189, ap 0.5208
2024-01-10 21:55:23,714 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4567, ap 0.5078
2024-01-10 21:55:23,802 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5911, ap 0.6061
2024-01-10 21:55:23,886 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5349, ap 0.5492
2024-01-10 21:55:23,977 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5573, ap 0.5744
2024-01-10 21:55:24,083 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.5454, ap 0.5522
2024-01-10 21:55:24,165 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5345, ap 0.5446
2024-01-10 21:55:24,247 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5513, ap 0.5408
2024-01-10 21:55:24,331 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4745, ap 0.4979
2024-01-10 21:55:24,421 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5518, ap 0.5256
2024-01-10 21:55:24,517 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.6064, ap 0.6151
2024-01-10 21:55:24,605 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4744, ap 0.5103
2024-01-10 21:55:24,702 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.5112, ap 0.5047
2024-01-10 21:55:24,844 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4879, ap 0.4930
2024-01-10 21:55:24,942 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5383, ap 0.5218
2024-01-10 21:55:25,042 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.5048, ap 0.5047
2024-01-10 21:55:25,131 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5523, ap 0.5946
2024-01-10 21:55:25,227 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4660, ap 0.5186
2024-01-10 21:55:25,316 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.3088, ap 0.3985
2024-01-10 21:55:25,411 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5224, ap 0.5457
2024-01-10 21:55:25,505 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4820, ap 0.5066
2024-01-10 21:55:25,591 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4683, ap 0.5131
2024-01-10 21:55:25,681 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5044, ap 0.5557
2024-01-10 21:55:25,774 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5146, ap 0.5109
2024-01-10 21:55:25,866 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.4644, ap 0.4863
2024-01-10 21:55:25,955 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4662, ap 0.4846
2024-01-10 21:55:26,044 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4553, ap 0.5039
2024-01-10 21:55:26,139 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5523, ap 0.5753
2024-01-10 21:55:26,228 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5894, ap 0.5834
2024-01-10 21:55:26,319 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.6611, ap 0.6573
2024-01-10 21:55:26,409 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.5069, ap 0.4989
2024-01-10 21:55:26,495 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.5164, ap 0.5097
2024-01-10 21:55:26,584 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.5379, ap 0.5961
2024-01-10 21:55:26,676 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.5550, ap 0.5374
2024-01-10 21:55:26,765 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5634, ap 0.5616
2024-01-10 21:55:26,851 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.4911, ap 0.5096
2024-01-10 21:55:26,939 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.4662, ap 0.5065
2024-01-10 21:55:27,028 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4340, ap 0.4491
2024-01-10 21:55:27,119 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.5345, ap 0.5333
2024-01-10 21:55:27,210 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5881, ap 0.5892
2024-01-10 21:55:27,303 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4701, ap 0.4899
2024-01-10 21:55:27,393 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.4537, ap 0.4740
2024-01-10 21:55:27,494 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5498, ap 0.5721
2024-01-10 21:55:27,586 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.5130, ap 0.5124
2024-01-10 21:55:27,676 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4438, ap 0.4647
2024-01-10 21:55:27,762 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5454, ap 0.5272
2024-01-10 21:55:27,851 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4957, ap 0.5088
2024-01-10 21:55:27,948 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5133, ap 0.4985
2024-01-10 21:55:28,046 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.4980, ap 0.5206
2024-01-10 21:55:28,138 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.5169, ap 0.5141
2024-01-10 21:55:28,228 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4486, ap 0.4805
2024-01-10 21:55:28,318 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5205, ap 0.5388
2024-01-10 21:55:28,413 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.4500, ap 0.4590
2024-01-10 21:55:28,506 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.4640, ap 0.5067
2024-01-10 21:55:28,596 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5176, ap 0.5195
2024-01-10 21:55:28,684 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5018, ap 0.5087
2024-01-10 21:55:28,775 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5182, ap 0.5164
2024-01-10 21:55:28,861 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4039, ap 0.4597
2024-01-10 21:55:28,951 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4550, ap 0.4909
2024-01-10 21:55:29,046 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4194, ap 0.4569
2024-01-10 21:55:29,139 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.5062, ap 0.5264
2024-01-10 21:55:29,237 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.6175, ap 0.5758
2024-01-10 21:55:29,328 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.5005, ap 0.5535
2024-01-10 21:55:29,412 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4715, ap 0.5365
2024-01-10 21:55:29,501 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.3731, ap 0.4178
2024-01-10 21:55:29,502 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0dd5a56c90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:55:30,269 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4386, ap 0.4489
2024-01-10 21:55:30,356 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5625, ap 0.5524
2024-01-10 21:55:30,442 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5981, ap 0.5827
2024-01-10 21:55:30,528 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4689, ap 0.5240
2024-01-10 21:55:30,615 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5368, ap 0.5207
2024-01-10 21:55:30,701 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.4863, ap 0.4983
2024-01-10 21:55:30,791 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4664, ap 0.4817
2024-01-10 21:55:30,874 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.4386, ap 0.4607
2024-01-10 21:55:30,962 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4393, ap 0.4730
2024-01-10 21:55:31,045 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.5126, ap 0.5223
2024-01-10 21:55:31,131 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4617, ap 0.5046
2024-01-10 21:55:31,216 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.5052, ap 0.5039
2024-01-10 21:55:31,304 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5742, ap 0.5953
2024-01-10 21:55:31,389 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5137, ap 0.5298
2024-01-10 21:55:31,473 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4169, ap 0.4670
2024-01-10 21:55:31,559 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5080, ap 0.5397
2024-01-10 21:55:31,663 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5408, ap 0.5223
2024-01-10 21:55:31,750 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.6319, ap 0.6075
2024-01-10 21:55:31,848 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5315, ap 0.5261
2024-01-10 21:55:31,936 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5044, ap 0.5386
2024-01-10 21:55:32,036 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.5137, ap 0.5222
2024-01-10 21:55:32,132 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.3713, ap 0.4344
2024-01-10 21:55:32,225 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5571, ap 0.5515
2024-01-10 21:55:32,315 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5372, ap 0.4988
2024-01-10 21:55:32,404 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4738, ap 0.5035
2024-01-10 21:55:32,495 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.6105, ap 0.5882
2024-01-10 21:55:32,584 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4745, ap 0.5039
2024-01-10 21:55:32,679 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5429, ap 0.5716
2024-01-10 21:55:32,768 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5347, ap 0.5483
2024-01-10 21:55:32,861 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5311, ap 0.5437
2024-01-10 21:55:32,955 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.5244, ap 0.5464
2024-01-10 21:55:33,043 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5789, ap 0.5773
2024-01-10 21:55:33,133 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5205, ap 0.5560
2024-01-10 21:55:33,231 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4169, ap 0.4479
2024-01-10 21:55:33,320 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.4948, ap 0.5112
2024-01-10 21:55:33,413 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5821, ap 0.6028
2024-01-10 21:55:33,503 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4621, ap 0.4721
2024-01-10 21:55:33,590 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.5069, ap 0.5029
2024-01-10 21:55:33,686 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4699, ap 0.5088
2024-01-10 21:55:33,775 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5422, ap 0.5307
2024-01-10 21:55:33,860 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.3937, ap 0.4519
2024-01-10 21:55:33,947 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.4564, ap 0.5017
2024-01-10 21:55:34,032 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4087, ap 0.4604
2024-01-10 21:55:34,121 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4098, ap 0.4445
2024-01-10 21:55:34,208 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5080, ap 0.5101
2024-01-10 21:55:34,294 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4279, ap 0.5090
2024-01-10 21:55:34,380 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.5247, ap 0.5226
2024-01-10 21:55:34,468 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.6205, ap 0.6359
2024-01-10 21:55:34,556 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5005, ap 0.5425
2024-01-10 21:55:34,641 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5034, ap 0.5184
2024-01-10 21:55:34,728 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.5511, ap 0.6093
2024-01-10 21:55:34,812 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.5425, ap 0.5736
2024-01-10 21:55:34,898 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.4931, ap 0.4939
2024-01-10 21:55:34,985 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.4899, ap 0.4917
2024-01-10 21:55:35,072 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5180, ap 0.5334
2024-01-10 21:55:35,160 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.5304, ap 0.5476
2024-01-10 21:55:35,250 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4468, ap 0.4557
2024-01-10 21:55:35,339 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4208, ap 0.5165
2024-01-10 21:55:35,433 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.5041, ap 0.5295
2024-01-10 21:55:35,521 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.4824, ap 0.5055
2024-01-10 21:55:35,608 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5287, ap 0.5348
2024-01-10 21:55:35,699 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.4966, ap 0.5097
2024-01-10 21:55:35,787 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4696, ap 0.4655
2024-01-10 21:55:35,874 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4105, ap 0.4494
2024-01-10 21:55:35,966 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5397, ap 0.5796
2024-01-10 21:55:36,055 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4998, ap 0.5160
2024-01-10 21:55:36,144 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.4952, ap 0.5074
2024-01-10 21:55:36,233 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.4795, ap 0.5121
2024-01-10 21:55:36,326 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.5468, ap 0.5864
2024-01-10 21:55:36,415 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4845, ap 0.4863
2024-01-10 21:55:36,508 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5639, ap 0.5462
2024-01-10 21:55:36,594 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.5222, ap 0.5348
2024-01-10 21:55:36,684 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5586, ap 0.5524
2024-01-10 21:55:36,773 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5607, ap 0.5665
2024-01-10 21:55:36,860 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.5176, ap 0.5492
2024-01-10 21:55:36,947 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4190, ap 0.4545
2024-01-10 21:55:37,035 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5322, ap 0.5809
2024-01-10 21:55:37,124 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5878, ap 0.5807
2024-01-10 21:55:37,213 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5546, ap 0.5675
2024-01-10 21:55:37,305 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5265, ap 0.5242
2024-01-10 21:55:37,393 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.4891, ap 0.4804
2024-01-10 21:55:37,482 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5493, ap 0.5355
2024-01-10 21:55:37,569 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4233, ap 0.4787
2024-01-10 21:55:37,659 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4261, ap 0.4838
2024-01-10 21:55:37,745 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.3884, ap 0.4474
2024-01-10 21:55:37,834 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4977, ap 0.5225
2024-01-10 21:55:37,925 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5012, ap 0.4937
2024-01-10 21:55:38,015 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.5247, ap 0.5654
2024-01-10 21:55:38,101 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4656, ap 0.5072
2024-01-10 21:55:38,189 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4906, ap 0.5263
2024-01-10 21:55:38,194 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d0377b610>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:55:38,925 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4386, ap 0.4503
2024-01-10 21:55:39,018 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5222, ap 0.5209
2024-01-10 21:55:39,112 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5461, ap 0.5351
2024-01-10 21:55:39,207 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4786, ap 0.5202
2024-01-10 21:55:39,298 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5826, ap 0.6095
2024-01-10 21:55:39,391 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.4608, ap 0.4568
2024-01-10 21:55:39,477 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4842, ap 0.4775
2024-01-10 21:55:39,572 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5142, ap 0.5244
2024-01-10 21:55:39,669 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4927, ap 0.5067
2024-01-10 21:55:39,759 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4868, ap 0.4884
2024-01-10 21:55:39,848 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4836, ap 0.5094
2024-01-10 21:55:39,940 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4518, ap 0.4540
2024-01-10 21:55:40,026 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5867, ap 0.5852
2024-01-10 21:55:40,116 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5176, ap 0.5144
2024-01-10 21:55:40,209 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.3768, ap 0.4469
2024-01-10 21:55:40,311 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.4797, ap 0.5312
2024-01-10 21:55:40,403 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.6068, ap 0.5605
2024-01-10 21:55:40,496 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5571, ap 0.5637
2024-01-10 21:55:40,583 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5018, ap 0.4818
2024-01-10 21:55:40,670 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.4854, ap 0.5027
2024-01-10 21:55:40,769 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4859, ap 0.5018
2024-01-10 21:55:40,861 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.4436, ap 0.4824
2024-01-10 21:55:40,965 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.4995, ap 0.4929
2024-01-10 21:55:41,056 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5383, ap 0.5308
2024-01-10 21:55:41,145 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4858, ap 0.4989
2024-01-10 21:55:41,242 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5459, ap 0.5538
2024-01-10 21:55:41,335 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4799, ap 0.5167
2024-01-10 21:55:41,422 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5507, ap 0.5667
2024-01-10 21:55:41,515 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.4861, ap 0.5024
2024-01-10 21:55:41,599 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5344, ap 0.5566
2024-01-10 21:55:41,686 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.4735, ap 0.5034
2024-01-10 21:55:41,787 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.6209, ap 0.5887
2024-01-10 21:55:41,877 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5299, ap 0.5206
2024-01-10 21:55:41,964 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4498, ap 0.4839
2024-01-10 21:55:42,063 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5059, ap 0.5005
2024-01-10 21:55:42,151 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5988, ap 0.5844
2024-01-10 21:55:42,242 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4562, ap 0.4635
2024-01-10 21:55:42,329 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.5043, ap 0.4825
2024-01-10 21:55:42,414 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4281, ap 0.4804
2024-01-10 21:55:42,504 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5367, ap 0.5093
2024-01-10 21:55:42,590 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.4683, ap 0.4923
2024-01-10 21:55:42,694 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5477, ap 0.5983
2024-01-10 21:55:42,779 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4425, ap 0.4873
2024-01-10 21:55:42,857 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.3690, ap 0.4110
2024-01-10 21:55:42,942 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5522, ap 0.5181
2024-01-10 21:55:43,027 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.5041, ap 0.5260
2024-01-10 21:55:43,100 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4792, ap 0.5191
2024-01-10 21:55:43,180 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.6146, ap 0.6203
2024-01-10 21:55:43,276 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5856, ap 0.5631
2024-01-10 21:55:43,374 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5502, ap 0.5326
2024-01-10 21:55:43,461 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4156, ap 0.4447
2024-01-10 21:55:43,557 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.5004, ap 0.5013
2024-01-10 21:55:43,648 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5573, ap 0.5695
2024-01-10 21:55:43,738 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5776, ap 0.5485
2024-01-10 21:55:43,828 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5529, ap 0.5540
2024-01-10 21:55:43,923 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4699, ap 0.4706
2024-01-10 21:55:44,009 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4706, ap 0.4659
2024-01-10 21:55:44,096 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4927, ap 0.5487
2024-01-10 21:55:44,181 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.5018, ap 0.5018
2024-01-10 21:55:44,273 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.4690, ap 0.4619
2024-01-10 21:55:44,362 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.4662, ap 0.4778
2024-01-10 21:55:44,450 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5538, ap 0.5992
2024-01-10 21:55:44,535 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4044, ap 0.4283
2024-01-10 21:55:44,637 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4697, ap 0.5098
2024-01-10 21:55:44,731 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.6000, ap 0.6204
2024-01-10 21:55:44,828 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.5121, ap 0.5110
2024-01-10 21:55:44,919 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5621, ap 0.5303
2024-01-10 21:55:45,012 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.4911, ap 0.4947
2024-01-10 21:55:45,106 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4961, ap 0.5438
2024-01-10 21:55:45,209 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4733, ap 0.4705
2024-01-10 21:55:45,298 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5797, ap 0.5773
2024-01-10 21:55:45,386 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4082, ap 0.4288
2024-01-10 21:55:45,478 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5514, ap 0.5212
2024-01-10 21:55:45,567 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5335, ap 0.5443
2024-01-10 21:55:45,661 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4801, ap 0.5024
2024-01-10 21:55:45,761 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4386, ap 0.4737
2024-01-10 21:55:45,854 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5733, ap 0.5948
2024-01-10 21:55:45,954 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5915, ap 0.5577
2024-01-10 21:55:46,050 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.4614, ap 0.4691
2024-01-10 21:55:46,141 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5625, ap 0.5459
2024-01-10 21:55:46,238 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5144, ap 0.5121
2024-01-10 21:55:46,332 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.4610, ap 0.4685
2024-01-10 21:55:46,419 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4649, ap 0.4791
2024-01-10 21:55:46,510 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4302, ap 0.4357
2024-01-10 21:55:46,600 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4616, ap 0.4934
2024-01-10 21:55:46,691 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.5411, ap 0.5498
2024-01-10 21:55:46,784 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5285, ap 0.5264
2024-01-10 21:55:46,880 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4309, ap 0.5006
2024-01-10 21:55:46,970 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.5039, ap 0.5395
2024-01-10 21:55:47,055 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4103, ap 0.4567
2024-01-10 21:55:47,073 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0dd5a56c90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:55:47,816 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4349, ap 0.4520
2024-01-10 21:55:47,909 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5438, ap 0.5116
2024-01-10 21:55:47,995 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.6015, ap 0.5790
2024-01-10 21:55:48,100 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4747, ap 0.5496
2024-01-10 21:55:48,195 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5445, ap 0.5414
2024-01-10 21:55:48,281 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.4450, ap 0.4525
2024-01-10 21:55:48,384 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.5246, ap 0.4980
2024-01-10 21:55:48,487 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5513, ap 0.5079
2024-01-10 21:55:48,579 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4947, ap 0.5009
2024-01-10 21:55:48,679 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4920, ap 0.4860
2024-01-10 21:55:48,781 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4432, ap 0.4803
2024-01-10 21:55:48,874 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4706, ap 0.5036
2024-01-10 21:55:48,970 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5173, ap 0.5163
2024-01-10 21:55:49,061 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.4845, ap 0.4936
2024-01-10 21:55:49,161 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.3163, ap 0.4357
2024-01-10 21:55:49,254 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.4779, ap 0.5034
2024-01-10 21:55:49,346 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5842, ap 0.5545
2024-01-10 21:55:49,438 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5424, ap 0.5403
2024-01-10 21:55:49,527 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5069, ap 0.4939
2024-01-10 21:55:49,613 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.4502, ap 0.4707
2024-01-10 21:55:49,711 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4694, ap 0.4804
2024-01-10 21:55:49,811 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.4042, ap 0.4661
2024-01-10 21:55:49,910 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.4446, ap 0.4745
2024-01-10 21:55:49,999 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.4954, ap 0.4765
2024-01-10 21:55:50,091 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4915, ap 0.4978
2024-01-10 21:55:50,183 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.4792, ap 0.5035
2024-01-10 21:55:50,276 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4420, ap 0.4737
2024-01-10 21:55:50,367 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5441, ap 0.5534
2024-01-10 21:55:50,458 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5116, ap 0.5033
2024-01-10 21:55:50,551 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5226, ap 0.5194
2024-01-10 21:55:50,639 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.5237, ap 0.5102
2024-01-10 21:55:50,742 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5810, ap 0.5490
2024-01-10 21:55:50,833 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5376, ap 0.5698
2024-01-10 21:55:50,928 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.3946, ap 0.4371
2024-01-10 21:55:51,018 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.4425, ap 0.4543
2024-01-10 21:55:51,112 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5863, ap 0.5984
2024-01-10 21:55:51,220 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4427, ap 0.4736
2024-01-10 21:55:51,313 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.4327, ap 0.4490
2024-01-10 21:55:51,406 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4454, ap 0.4861
2024-01-10 21:55:51,498 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5664, ap 0.5424
2024-01-10 21:55:51,596 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.4726, ap 0.5103
2024-01-10 21:55:51,694 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5087, ap 0.5285
2024-01-10 21:55:51,786 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4359, ap 0.4445
2024-01-10 21:55:51,877 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4685, ap 0.4993
2024-01-10 21:55:51,966 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5420, ap 0.5264
2024-01-10 21:55:52,055 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4192, ap 0.4569
2024-01-10 21:55:52,144 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.5262, ap 0.5328
2024-01-10 21:55:52,248 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.6137, ap 0.6219
2024-01-10 21:55:52,351 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5279, ap 0.5201
2024-01-10 21:55:52,446 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.4920, ap 0.4939
2024-01-10 21:55:52,542 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4603, ap 0.4851
2024-01-10 21:55:52,639 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4527, ap 0.4919
2024-01-10 21:55:52,729 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5472, ap 0.5096
2024-01-10 21:55:52,821 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5732, ap 0.5451
2024-01-10 21:55:52,904 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5694, ap 0.5921
2024-01-10 21:55:52,991 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.5258, ap 0.5497
2024-01-10 21:55:53,078 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4507, ap 0.4593
2024-01-10 21:55:53,172 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4026, ap 0.4934
2024-01-10 21:55:53,264 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4505, ap 0.4463
2024-01-10 21:55:53,356 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5329, ap 0.5228
2024-01-10 21:55:53,455 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5249, ap 0.5238
2024-01-10 21:55:53,557 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5454, ap 0.5345
2024-01-10 21:55:53,651 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4603, ap 0.4630
2024-01-10 21:55:53,740 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4717, ap 0.4891
2024-01-10 21:55:53,832 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5691, ap 0.5722
2024-01-10 21:55:53,924 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4900, ap 0.5268
2024-01-10 21:55:54,023 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5504, ap 0.5330
2024-01-10 21:55:54,129 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.4865, ap 0.4982
2024-01-10 21:55:54,216 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4897, ap 0.4864
2024-01-10 21:55:54,305 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.5041, ap 0.4925
2024-01-10 21:55:54,394 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5776, ap 0.5645
2024-01-10 21:55:54,481 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4512, ap 0.4736
2024-01-10 21:55:54,565 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.4694, ap 0.4584
2024-01-10 21:55:54,662 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5529, ap 0.5230
2024-01-10 21:55:54,750 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.5082, ap 0.5178
2024-01-10 21:55:54,836 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.5103, ap 0.5235
2024-01-10 21:55:54,924 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5659, ap 0.5799
2024-01-10 21:55:55,018 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.4918, ap 0.4959
2024-01-10 21:55:55,106 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.4594, ap 0.4716
2024-01-10 21:55:55,193 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.6047, ap 0.5660
2024-01-10 21:55:55,284 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.4616, ap 0.4635
2024-01-10 21:55:55,371 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.4920, ap 0.4953
2024-01-10 21:55:55,463 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.3993, ap 0.4486
2024-01-10 21:55:55,548 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4514, ap 0.4665
2024-01-10 21:55:55,637 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.3937, ap 0.4458
2024-01-10 21:55:55,724 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4669, ap 0.4967
2024-01-10 21:55:55,807 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5963, ap 0.5679
2024-01-10 21:55:55,897 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4888, ap 0.5307
2024-01-10 21:55:55,993 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4315, ap 0.4837
2024-01-10 21:55:56,092 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4361, ap 0.4904
2024-01-10 21:55:56,097 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03546bd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:55:56,937 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4600, ap 0.4804
2024-01-10 21:55:57,042 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5085, ap 0.5194
2024-01-10 21:55:57,137 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5386, ap 0.5245
2024-01-10 21:55:57,246 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.5150, ap 0.5549
2024-01-10 21:55:57,331 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5393, ap 0.5586
2024-01-10 21:55:57,422 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.5233, ap 0.5324
2024-01-10 21:55:57,512 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4916, ap 0.4931
2024-01-10 21:55:57,603 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5413, ap 0.5590
2024-01-10 21:55:57,686 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4550, ap 0.4680
2024-01-10 21:55:57,775 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4528, ap 0.4877
2024-01-10 21:55:57,873 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.5283, ap 0.5425
2024-01-10 21:55:57,966 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4943, ap 0.5040
2024-01-10 21:55:58,052 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5376, ap 0.5324
2024-01-10 21:55:58,147 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5502, ap 0.5424
2024-01-10 21:55:58,233 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4272, ap 0.4867
2024-01-10 21:55:58,333 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5637, ap 0.5620
2024-01-10 21:55:58,435 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.4539, ap 0.4900
2024-01-10 21:55:58,518 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.6408, ap 0.6337
2024-01-10 21:55:58,604 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.6075, ap 0.5657
2024-01-10 21:55:58,695 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5354, ap 0.5701
2024-01-10 21:55:58,779 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4938, ap 0.5102
2024-01-10 21:55:58,869 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.4098, ap 0.4349
2024-01-10 21:55:58,953 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5518, ap 0.5323
2024-01-10 21:55:59,043 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5694, ap 0.5397
2024-01-10 21:55:59,131 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4511, ap 0.4708
2024-01-10 21:55:59,219 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5388, ap 0.5681
2024-01-10 21:55:59,301 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4778, ap 0.5123
2024-01-10 21:55:59,383 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5951, ap 0.5873
2024-01-10 21:55:59,470 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5425, ap 0.5554
2024-01-10 21:55:59,565 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5075, ap 0.5275
2024-01-10 21:55:59,652 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.5153, ap 0.5134
2024-01-10 21:55:59,734 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5822, ap 0.5706
2024-01-10 21:55:59,839 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.4710, ap 0.5186
2024-01-10 21:55:59,932 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.3507, ap 0.4215
2024-01-10 21:56:00,027 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5014, ap 0.5088
2024-01-10 21:56:00,117 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.6137, ap 0.6528
2024-01-10 21:56:00,204 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4016, ap 0.4546
2024-01-10 21:56:00,291 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.4646, ap 0.4680
2024-01-10 21:56:00,377 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4794, ap 0.5265
2024-01-10 21:56:00,465 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5917, ap 0.5483
2024-01-10 21:56:00,555 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.4696, ap 0.4959
2024-01-10 21:56:00,639 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.6098, ap 0.6432
2024-01-10 21:56:00,728 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4283, ap 0.4464
2024-01-10 21:56:00,810 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4322, ap 0.4618
2024-01-10 21:56:00,904 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5758, ap 0.6068
2024-01-10 21:56:00,990 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.5249, ap 0.5286
2024-01-10 21:56:01,081 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4813, ap 0.4970
2024-01-10 21:56:01,167 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.6371, ap 0.6237
2024-01-10 21:56:01,255 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5717, ap 0.5848
2024-01-10 21:56:01,341 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5500, ap 0.5354
2024-01-10 21:56:01,442 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4872, ap 0.5790
2024-01-10 21:56:01,529 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.5335, ap 0.5857
2024-01-10 21:56:01,615 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5041, ap 0.5559
2024-01-10 21:56:01,703 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5244, ap 0.5123
2024-01-10 21:56:01,797 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5146, ap 0.5305
2024-01-10 21:56:01,891 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4569, ap 0.4719
2024-01-10 21:56:01,975 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4322, ap 0.4439
2024-01-10 21:56:02,062 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4530, ap 0.5318
2024-01-10 21:56:02,153 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.5303, ap 0.5511
2024-01-10 21:56:02,237 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5498, ap 0.5598
2024-01-10 21:56:02,327 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5429, ap 0.5194
2024-01-10 21:56:02,411 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5621, ap 0.5746
2024-01-10 21:56:02,504 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.3672, ap 0.4310
2024-01-10 21:56:02,590 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4400, ap 0.4709
2024-01-10 21:56:02,678 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5457, ap 0.5604
2024-01-10 21:56:02,761 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.3895, ap 0.4368
2024-01-10 21:56:02,854 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5406, ap 0.5439
2024-01-10 21:56:02,942 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.4628, ap 0.5084
2024-01-10 21:56:03,028 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4884, ap 0.5231
2024-01-10 21:56:03,122 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4767, ap 0.4764
2024-01-10 21:56:03,216 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5824, ap 0.5378
2024-01-10 21:56:03,314 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.5107, ap 0.5571
2024-01-10 21:56:03,400 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5340, ap 0.5370
2024-01-10 21:56:03,493 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5568, ap 0.5825
2024-01-10 21:56:03,581 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.3784, ap 0.4296
2024-01-10 21:56:03,676 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4211, ap 0.4539
2024-01-10 21:56:03,764 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5543, ap 0.5879
2024-01-10 21:56:03,847 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.4395, ap 0.4767
2024-01-10 21:56:03,933 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5733, ap 0.5589
2024-01-10 21:56:04,024 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5482, ap 0.5433
2024-01-10 21:56:04,116 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5167, ap 0.4987
2024-01-10 21:56:04,208 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5377, ap 0.5323
2024-01-10 21:56:04,295 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4867, ap 0.5040
2024-01-10 21:56:04,392 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.3386, ap 0.4232
2024-01-10 21:56:04,487 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4199, ap 0.4390
2024-01-10 21:56:04,580 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.5500, ap 0.5662
2024-01-10 21:56:04,673 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5778, ap 0.5949
2024-01-10 21:56:04,763 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4778, ap 0.5206
2024-01-10 21:56:04,851 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4080, ap 0.4659
2024-01-10 21:56:04,938 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4877, ap 0.5525
2024-01-10 21:56:04,947 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0dd5a56c90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:05,725 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4932, ap 0.4730
2024-01-10 21:56:05,816 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5411, ap 0.5288
2024-01-10 21:56:05,918 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5586, ap 0.5412
2024-01-10 21:56:06,004 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4778, ap 0.5163
2024-01-10 21:56:06,090 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5525, ap 0.5475
2024-01-10 21:56:06,173 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.5675, ap 0.5391
2024-01-10 21:56:06,269 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4308, ap 0.4503
2024-01-10 21:56:06,357 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.4956, ap 0.5008
2024-01-10 21:56:06,448 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4626, ap 0.4698
2024-01-10 21:56:06,539 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4797, ap 0.4906
2024-01-10 21:56:06,632 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.5377, ap 0.5784
2024-01-10 21:56:06,730 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4616, ap 0.4685
2024-01-10 21:56:06,816 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5726, ap 0.5839
2024-01-10 21:56:06,909 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5046, ap 0.4988
2024-01-10 21:56:06,999 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.5514, ap 0.5595
2024-01-10 21:56:07,094 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5331, ap 0.5606
2024-01-10 21:56:07,189 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5112, ap 0.5163
2024-01-10 21:56:07,280 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5539, ap 0.5505
2024-01-10 21:56:07,369 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5128, ap 0.5194
2024-01-10 21:56:07,461 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5347, ap 0.5519
2024-01-10 21:56:07,552 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4900, ap 0.5073
2024-01-10 21:56:07,644 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.4338, ap 0.5034
2024-01-10 21:56:07,744 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5068, ap 0.5313
2024-01-10 21:56:07,836 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5466, ap 0.5294
2024-01-10 21:56:07,932 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.3914, ap 0.4400
2024-01-10 21:56:08,022 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5790, ap 0.5796
2024-01-10 21:56:08,118 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.3914, ap 0.4589
2024-01-10 21:56:08,207 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5358, ap 0.5526
2024-01-10 21:56:08,309 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5178, ap 0.5324
2024-01-10 21:56:08,403 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5174, ap 0.5667
2024-01-10 21:56:08,493 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.4318, ap 0.4647
2024-01-10 21:56:08,594 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5696, ap 0.5875
2024-01-10 21:56:08,693 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.6018, ap 0.6125
2024-01-10 21:56:08,785 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.5182, ap 0.4969
2024-01-10 21:56:08,883 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5842, ap 0.5629
2024-01-10 21:56:08,981 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.6396, ap 0.6566
2024-01-10 21:56:09,078 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.5130, ap 0.5256
2024-01-10 21:56:09,174 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.4879, ap 0.4930
2024-01-10 21:56:09,272 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.5265, ap 0.5539
2024-01-10 21:56:09,365 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5703, ap 0.5510
2024-01-10 21:56:09,455 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.4000, ap 0.4533
2024-01-10 21:56:09,557 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.4939, ap 0.5092
2024-01-10 21:56:09,654 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4466, ap 0.4951
2024-01-10 21:56:09,744 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4267, ap 0.4621
2024-01-10 21:56:09,834 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5297, ap 0.5632
2024-01-10 21:56:09,927 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.5055, ap 0.5473
2024-01-10 21:56:10,020 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4669, ap 0.5026
2024-01-10 21:56:10,111 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5578, ap 0.5725
2024-01-10 21:56:10,216 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5559, ap 0.5522
2024-01-10 21:56:10,308 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5541, ap 0.5430
2024-01-10 21:56:10,399 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4279, ap 0.4566
2024-01-10 21:56:10,487 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4957, ap 0.5312
2024-01-10 21:56:10,577 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5262, ap 0.5042
2024-01-10 21:56:10,668 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5523, ap 0.5720
2024-01-10 21:56:10,758 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.6468, ap 0.6745
2024-01-10 21:56:10,851 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4455, ap 0.4583
2024-01-10 21:56:10,939 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4516, ap 0.4546
2024-01-10 21:56:11,027 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.3823, ap 0.4558
2024-01-10 21:56:11,119 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.5641, ap 0.5373
2024-01-10 21:56:11,212 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5436, ap 0.5273
2024-01-10 21:56:11,301 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5367, ap 0.5587
2024-01-10 21:56:11,398 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5482, ap 0.5775
2024-01-10 21:56:11,487 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.5187, ap 0.4982
2024-01-10 21:56:11,579 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4226, ap 0.4697
2024-01-10 21:56:11,666 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.6018, ap 0.6143
2024-01-10 21:56:11,763 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4858, ap 0.4966
2024-01-10 21:56:11,854 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.4865, ap 0.4923
2024-01-10 21:56:11,946 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5491, ap 0.5913
2024-01-10 21:56:12,038 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4872, ap 0.4832
2024-01-10 21:56:12,130 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.5762, ap 0.5450
2024-01-10 21:56:12,219 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5739, ap 0.5424
2024-01-10 21:56:12,314 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4535, ap 0.4684
2024-01-10 21:56:12,405 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5351, ap 0.5315
2024-01-10 21:56:12,491 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.4858, ap 0.5024
2024-01-10 21:56:12,594 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4826, ap 0.5003
2024-01-10 21:56:12,684 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4617, ap 0.5144
2024-01-10 21:56:12,775 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5936, ap 0.6023
2024-01-10 21:56:12,870 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5182, ap 0.5233
2024-01-10 21:56:12,960 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.4703, ap 0.4904
2024-01-10 21:56:13,051 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5879, ap 0.5667
2024-01-10 21:56:13,147 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.4893, ap 0.4795
2024-01-10 21:56:13,242 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5457, ap 0.5354
2024-01-10 21:56:13,330 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4713, ap 0.4956
2024-01-10 21:56:13,420 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.3836, ap 0.4435
2024-01-10 21:56:13,511 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4883, ap 0.5203
2024-01-10 21:56:13,595 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4842, ap 0.5259
2024-01-10 21:56:13,680 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5251, ap 0.5094
2024-01-10 21:56:13,774 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4605, ap 0.5402
2024-01-10 21:56:13,865 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4934, ap 0.5111
2024-01-10 21:56:13,952 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.3809, ap 0.4195
2024-01-10 21:56:13,962 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03805b50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:14,687 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4592, ap 0.4594
2024-01-10 21:56:14,781 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.4843, ap 0.4811
2024-01-10 21:56:14,871 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5132, ap 0.5045
2024-01-10 21:56:14,960 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4833, ap 0.5333
2024-01-10 21:56:15,056 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5139, ap 0.5455
2024-01-10 21:56:15,145 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.4982, ap 0.4825
2024-01-10 21:56:15,238 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4605, ap 0.4561
2024-01-10 21:56:15,328 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5249, ap 0.5244
2024-01-10 21:56:15,417 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4859, ap 0.4941
2024-01-10 21:56:15,509 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.5137, ap 0.5198
2024-01-10 21:56:15,599 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.5141, ap 0.5423
2024-01-10 21:56:15,687 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4244, ap 0.4506
2024-01-10 21:56:15,776 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5539, ap 0.5365
2024-01-10 21:56:15,867 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5109, ap 0.4942
2024-01-10 21:56:15,954 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4281, ap 0.4824
2024-01-10 21:56:16,052 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.4621, ap 0.4977
2024-01-10 21:56:16,142 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5445, ap 0.5330
2024-01-10 21:56:16,233 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.6445, ap 0.6262
2024-01-10 21:56:16,325 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.4884, ap 0.4847
2024-01-10 21:56:16,420 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5203, ap 0.5788
2024-01-10 21:56:16,512 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4649, ap 0.4971
2024-01-10 21:56:16,603 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.3838, ap 0.4356
2024-01-10 21:56:16,697 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.4991, ap 0.5030
2024-01-10 21:56:16,787 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.4165, ap 0.4332
2024-01-10 21:56:16,884 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4283, ap 0.4493
2024-01-10 21:56:16,974 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5568, ap 0.5422
2024-01-10 21:56:17,063 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4842, ap 0.5136
2024-01-10 21:56:17,151 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5470, ap 0.5656
2024-01-10 21:56:17,236 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5810, ap 0.5775
2024-01-10 21:56:17,333 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.4603, ap 0.4739
2024-01-10 21:56:17,431 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.4576, ap 0.4820
2024-01-10 21:56:17,521 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5548, ap 0.5258
2024-01-10 21:56:17,612 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.4799, ap 0.5023
2024-01-10 21:56:17,704 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.3977, ap 0.4346
2024-01-10 21:56:17,800 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5559, ap 0.5349
2024-01-10 21:56:17,890 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.6582, ap 0.6315
2024-01-10 21:56:17,979 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4555, ap 0.4802
2024-01-10 21:56:18,073 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.5094, ap 0.4863
2024-01-10 21:56:18,175 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4608, ap 0.4924
2024-01-10 21:56:18,266 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5484, ap 0.5158
2024-01-10 21:56:18,359 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.5002, ap 0.5044
2024-01-10 21:56:18,451 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5660, ap 0.5934
2024-01-10 21:56:18,545 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4642, ap 0.4739
2024-01-10 21:56:18,642 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4340, ap 0.4810
2024-01-10 21:56:18,735 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5203, ap 0.4977
2024-01-10 21:56:18,828 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4672, ap 0.5127
2024-01-10 21:56:18,918 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4621, ap 0.4675
2024-01-10 21:56:19,004 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5602, ap 0.5765
2024-01-10 21:56:19,094 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5336, ap 0.5393
2024-01-10 21:56:19,190 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5700, ap 0.5619
2024-01-10 21:56:19,281 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.5050, ap 0.5472
2024-01-10 21:56:19,368 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4397, ap 0.4563
2024-01-10 21:56:19,457 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.6207, ap 0.5880
2024-01-10 21:56:19,546 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5155, ap 0.5246
2024-01-10 21:56:19,642 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5377, ap 0.5446
2024-01-10 21:56:19,734 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4913, ap 0.5059
2024-01-10 21:56:19,830 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4685, ap 0.4546
2024-01-10 21:56:19,920 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.5068, ap 0.5347
2024-01-10 21:56:20,015 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.5158, ap 0.5208
2024-01-10 21:56:20,109 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.4441, ap 0.4725
2024-01-10 21:56:20,204 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.4703, ap 0.4877
2024-01-10 21:56:20,310 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.4680, ap 0.4849
2024-01-10 21:56:20,407 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.3953, ap 0.4324
2024-01-10 21:56:20,504 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.5538, ap 0.5732
2024-01-10 21:56:20,599 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5767, ap 0.5570
2024-01-10 21:56:20,698 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4194, ap 0.4539
2024-01-10 21:56:20,791 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5518, ap 0.5533
2024-01-10 21:56:20,885 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.4774, ap 0.4989
2024-01-10 21:56:20,979 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4863, ap 0.5143
2024-01-10 21:56:21,073 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4190, ap 0.4312
2024-01-10 21:56:21,166 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5295, ap 0.5371
2024-01-10 21:56:21,268 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4334, ap 0.4707
2024-01-10 21:56:21,361 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5559, ap 0.5142
2024-01-10 21:56:21,455 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.4977, ap 0.4912
2024-01-10 21:56:21,549 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4286, ap 0.4656
2024-01-10 21:56:21,646 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4178, ap 0.4553
2024-01-10 21:56:21,740 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5044, ap 0.5121
2024-01-10 21:56:21,828 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5472, ap 0.5392
2024-01-10 21:56:21,922 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5399, ap 0.5446
2024-01-10 21:56:22,013 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5664, ap 0.5392
2024-01-10 21:56:22,107 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.4834, ap 0.4852
2024-01-10 21:56:22,201 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5117, ap 0.5069
2024-01-10 21:56:22,294 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.5182, ap 0.5591
2024-01-10 21:56:22,386 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4468, ap 0.4672
2024-01-10 21:56:22,479 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.5198, ap 0.5446
2024-01-10 21:56:22,569 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4457, ap 0.4900
2024-01-10 21:56:22,659 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5534, ap 0.5297
2024-01-10 21:56:22,757 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4977, ap 0.5456
2024-01-10 21:56:22,861 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4769, ap 0.4958
2024-01-10 21:56:22,957 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4324, ap 0.4576
2024-01-10 21:56:22,962 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d037a1b90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:23,716 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4737, ap 0.4926
2024-01-10 21:56:23,809 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5449, ap 0.5520
2024-01-10 21:56:23,897 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5719, ap 0.5531
2024-01-10 21:56:23,985 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.5253, ap 0.5356
2024-01-10 21:56:24,078 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5609, ap 0.5508
2024-01-10 21:56:24,167 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.5068, ap 0.5074
2024-01-10 21:56:24,261 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4576, ap 0.4637
2024-01-10 21:56:24,353 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5253, ap 0.5221
2024-01-10 21:56:24,444 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4505, ap 0.4653
2024-01-10 21:56:24,537 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4705, ap 0.4809
2024-01-10 21:56:24,630 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4815, ap 0.4934
2024-01-10 21:56:24,724 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.5271, ap 0.5035
2024-01-10 21:56:24,821 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5160, ap 0.5318
2024-01-10 21:56:24,914 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5260, ap 0.5227
2024-01-10 21:56:25,006 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4430, ap 0.4751
2024-01-10 21:56:25,090 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5064, ap 0.5167
2024-01-10 21:56:25,171 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5228, ap 0.5269
2024-01-10 21:56:25,252 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5733, ap 0.5729
2024-01-10 21:56:25,351 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.4868, ap 0.4829
2024-01-10 21:56:25,446 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5021, ap 0.5577
2024-01-10 21:56:25,544 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4776, ap 0.5142
2024-01-10 21:56:25,638 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.3839, ap 0.4365
2024-01-10 21:56:25,732 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.4872, ap 0.5085
2024-01-10 21:56:25,816 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.4623, ap 0.4965
2024-01-10 21:56:25,897 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4423, ap 0.4592
2024-01-10 21:56:25,991 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5057, ap 0.5122
2024-01-10 21:56:26,084 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4708, ap 0.5351
2024-01-10 21:56:26,178 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5335, ap 0.5303
2024-01-10 21:56:26,275 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5595, ap 0.5503
2024-01-10 21:56:26,373 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5328, ap 0.5164
2024-01-10 21:56:26,475 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.5342, ap 0.5330
2024-01-10 21:56:26,569 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5541, ap 0.5384
2024-01-10 21:56:26,668 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.4121, ap 0.4392
2024-01-10 21:56:26,764 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.3953, ap 0.4292
2024-01-10 21:56:26,861 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5655, ap 0.5412
2024-01-10 21:56:26,956 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5844, ap 0.5677
2024-01-10 21:56:27,050 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.5068, ap 0.5163
2024-01-10 21:56:27,137 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.4373, ap 0.4461
2024-01-10 21:56:27,220 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.5142, ap 0.5388
2024-01-10 21:56:27,314 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5488, ap 0.5392
2024-01-10 21:56:27,411 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.4861, ap 0.5226
2024-01-10 21:56:27,506 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.4961, ap 0.5415
2024-01-10 21:56:27,596 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4836, ap 0.5066
2024-01-10 21:56:27,693 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4302, ap 0.4665
2024-01-10 21:56:27,789 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5488, ap 0.5390
2024-01-10 21:56:27,882 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4569, ap 0.5075
2024-01-10 21:56:27,980 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4754, ap 0.4765
2024-01-10 21:56:28,087 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5929, ap 0.5951
2024-01-10 21:56:28,180 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5292, ap 0.5212
2024-01-10 21:56:28,269 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5189, ap 0.5196
2024-01-10 21:56:28,372 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4594, ap 0.4827
2024-01-10 21:56:28,455 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.3936, ap 0.4473
2024-01-10 21:56:28,555 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.4954, ap 0.5107
2024-01-10 21:56:28,650 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5278, ap 0.5241
2024-01-10 21:56:28,734 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5477, ap 0.5568
2024-01-10 21:56:28,824 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.5182, ap 0.5316
2024-01-10 21:56:28,919 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4726, ap 0.4632
2024-01-10 21:56:29,008 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.5239, ap 0.5551
2024-01-10 21:56:29,107 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4569, ap 0.4739
2024-01-10 21:56:29,202 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.4153, ap 0.4439
2024-01-10 21:56:29,299 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5463, ap 0.5581
2024-01-10 21:56:29,388 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5164, ap 0.5057
2024-01-10 21:56:29,476 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4648, ap 0.4651
2024-01-10 21:56:29,570 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4427, ap 0.4737
2024-01-10 21:56:29,661 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5797, ap 0.5963
2024-01-10 21:56:29,748 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4893, ap 0.5314
2024-01-10 21:56:29,836 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5580, ap 0.5352
2024-01-10 21:56:29,928 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5324, ap 0.5237
2024-01-10 21:56:30,015 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.5221, ap 0.5248
2024-01-10 21:56:30,110 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.5182, ap 0.4938
2024-01-10 21:56:30,200 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5360, ap 0.5292
2024-01-10 21:56:30,291 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4227, ap 0.4769
2024-01-10 21:56:30,383 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5217, ap 0.5099
2024-01-10 21:56:30,474 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5687, ap 0.5493
2024-01-10 21:56:30,561 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4886, ap 0.5158
2024-01-10 21:56:30,645 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4573, ap 0.4952
2024-01-10 21:56:30,741 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5477, ap 0.5368
2024-01-10 21:56:30,831 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5488, ap 0.5245
2024-01-10 21:56:30,918 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5135, ap 0.5468
2024-01-10 21:56:31,005 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5502, ap 0.5370
2024-01-10 21:56:31,092 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5338, ap 0.5265
2024-01-10 21:56:31,180 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5117, ap 0.5329
2024-01-10 21:56:31,266 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4737, ap 0.5114
2024-01-10 21:56:31,358 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.3975, ap 0.4484
2024-01-10 21:56:31,453 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4527, ap 0.4664
2024-01-10 21:56:31,542 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4786, ap 0.5110
2024-01-10 21:56:31,631 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.4936, ap 0.5066
2024-01-10 21:56:31,723 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4747, ap 0.5024
2024-01-10 21:56:31,814 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4491, ap 0.4868
2024-01-10 21:56:31,906 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4498, ap 0.5223
2024-01-10 21:56:31,924 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa02d8d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:32,642 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4724, ap 0.5021
2024-01-10 21:56:32,735 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.4893, ap 0.5047
2024-01-10 21:56:32,826 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5801, ap 0.5696
2024-01-10 21:56:32,913 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4811, ap 0.4975
2024-01-10 21:56:33,005 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.4943, ap 0.5160
2024-01-10 21:56:33,092 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.5253, ap 0.5387
2024-01-10 21:56:33,179 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4786, ap 0.4814
2024-01-10 21:56:33,268 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4961, ap 0.4924
2024-01-10 21:56:33,354 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.5719, ap 0.5512
2024-01-10 21:56:33,440 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4106, ap 0.4429
2024-01-10 21:56:33,527 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4694, ap 0.5085
2024-01-10 21:56:33,611 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4445, ap 0.4803
2024-01-10 21:56:33,706 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5130, ap 0.4957
2024-01-10 21:56:33,794 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.4559, ap 0.4790
2024-01-10 21:56:33,881 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3629, ap 0.4308
2024-01-10 21:56:33,966 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.6200, ap 0.5913
2024-01-10 21:56:34,056 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5789, ap 0.5580
2024-01-10 21:56:34,142 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.6269, ap 0.6191
2024-01-10 21:56:34,234 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5383, ap 0.5060
2024-01-10 21:56:34,320 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.5230, ap 0.5857
2024-01-10 21:56:34,408 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5605, ap 0.5348
2024-01-10 21:56:34,496 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4402, ap 0.4513
2024-01-10 21:56:34,582 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5465, ap 0.5544
2024-01-10 21:56:34,668 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5819, ap 0.5613
2024-01-10 21:56:34,756 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4722, ap 0.4922
2024-01-10 21:56:34,845 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5441, ap 0.5741
2024-01-10 21:56:34,937 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4847, ap 0.5339
2024-01-10 21:56:35,030 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5326, ap 0.5881
2024-01-10 21:56:35,118 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4818, ap 0.4899
2024-01-10 21:56:35,204 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.4801, ap 0.4989
2024-01-10 21:56:35,226 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03573fd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:35,892 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.5053, ap 0.5012
2024-01-10 21:56:35,991 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5068, ap 0.4982
2024-01-10 21:56:36,079 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5644, ap 0.5475
2024-01-10 21:56:36,171 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.5132, ap 0.5621
2024-01-10 21:56:36,258 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5616, ap 0.5839
2024-01-10 21:56:36,360 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4541, ap 0.4841
2024-01-10 21:56:36,447 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.5036, ap 0.4902
2024-01-10 21:56:36,536 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4274, ap 0.4649
2024-01-10 21:56:36,618 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4082, ap 0.4526
2024-01-10 21:56:36,696 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4391, ap 0.4572
2024-01-10 21:56:36,778 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4744, ap 0.4914
2024-01-10 21:56:36,866 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4395, ap 0.4507
2024-01-10 21:56:36,946 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5285, ap 0.5273
2024-01-10 21:56:37,023 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.6004, ap 0.5726
2024-01-10 21:56:37,102 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4103, ap 0.4863
2024-01-10 21:56:37,181 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4808, ap 0.4924
2024-01-10 21:56:37,260 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5538, ap 0.5519
2024-01-10 21:56:37,344 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.6047, ap 0.5962
2024-01-10 21:56:37,432 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.4989, ap 0.5037
2024-01-10 21:56:37,521 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.5260, ap 0.5625
2024-01-10 21:56:37,623 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5135, ap 0.5386
2024-01-10 21:56:37,712 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3950, ap 0.4524
2024-01-10 21:56:37,803 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.4925, ap 0.4966
2024-01-10 21:56:37,895 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5231, ap 0.5103
2024-01-10 21:56:37,987 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4142, ap 0.4468
2024-01-10 21:56:38,076 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5376, ap 0.5546
2024-01-10 21:56:38,165 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.5057, ap 0.5384
2024-01-10 21:56:38,257 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5651, ap 0.5801
2024-01-10 21:56:38,345 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4961, ap 0.5182
2024-01-10 21:56:38,435 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5306, ap 0.5500
2024-01-10 21:56:38,451 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d0353f210>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:39,217 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.5279, ap 0.5146
2024-01-10 21:56:39,308 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5390, ap 0.5211
2024-01-10 21:56:39,389 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5251, ap 0.5249
2024-01-10 21:56:39,467 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4881, ap 0.4964
2024-01-10 21:56:39,551 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5269, ap 0.5576
2024-01-10 21:56:39,636 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4801, ap 0.4903
2024-01-10 21:56:39,726 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4539, ap 0.4613
2024-01-10 21:56:39,809 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4090, ap 0.4581
2024-01-10 21:56:39,900 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4920, ap 0.4996
2024-01-10 21:56:39,989 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4964, ap 0.4996
2024-01-10 21:56:40,081 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4680, ap 0.4822
2024-01-10 21:56:40,179 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4726, ap 0.4982
2024-01-10 21:56:40,261 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5687, ap 0.5393
2024-01-10 21:56:40,339 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5826, ap 0.5537
2024-01-10 21:56:40,428 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4354, ap 0.4798
2024-01-10 21:56:40,519 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5344, ap 0.5374
2024-01-10 21:56:40,610 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5043, ap 0.5093
2024-01-10 21:56:40,707 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5728, ap 0.5834
2024-01-10 21:56:40,800 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5011, ap 0.4954
2024-01-10 21:56:40,877 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.5525, ap 0.5787
2024-01-10 21:56:40,955 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5625, ap 0.5709
2024-01-10 21:56:41,052 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3774, ap 0.4315
2024-01-10 21:56:41,142 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5139, ap 0.5281
2024-01-10 21:56:41,236 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.4884, ap 0.4868
2024-01-10 21:56:41,329 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4507, ap 0.4752
2024-01-10 21:56:41,415 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5085, ap 0.5510
2024-01-10 21:56:41,504 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4126, ap 0.4915
2024-01-10 21:56:41,585 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5529, ap 0.5860
2024-01-10 21:56:41,661 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4804, ap 0.4933
2024-01-10 21:56:41,755 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5452, ap 0.5600
2024-01-10 21:56:41,774 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035b7dd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:42,465 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4571, ap 0.4790
2024-01-10 21:56:42,551 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5183, ap 0.5101
2024-01-10 21:56:42,635 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5635, ap 0.5733
2024-01-10 21:56:42,731 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4637, ap 0.4767
2024-01-10 21:56:42,816 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.6096, ap 0.6386
2024-01-10 21:56:42,904 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4740, ap 0.4682
2024-01-10 21:56:42,988 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4826, ap 0.4814
2024-01-10 21:56:43,074 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5210, ap 0.5197
2024-01-10 21:56:43,164 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4340, ap 0.4409
2024-01-10 21:56:43,250 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.5274, ap 0.5261
2024-01-10 21:56:43,334 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4728, ap 0.5158
2024-01-10 21:56:43,422 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4496, ap 0.4681
2024-01-10 21:56:43,513 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5961, ap 0.5979
2024-01-10 21:56:43,598 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5263, ap 0.5367
2024-01-10 21:56:43,681 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3928, ap 0.4409
2024-01-10 21:56:43,756 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4801, ap 0.4846
2024-01-10 21:56:43,833 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.6319, ap 0.6094
2024-01-10 21:56:43,909 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.6369, ap 0.6110
2024-01-10 21:56:43,985 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5849, ap 0.5580
2024-01-10 21:56:44,067 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.3811, ap 0.4317
2024-01-10 21:56:44,152 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5666, ap 0.5457
2024-01-10 21:56:44,232 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3649, ap 0.4438
2024-01-10 21:56:44,326 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.4653, ap 0.4893
2024-01-10 21:56:44,406 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5080, ap 0.4874
2024-01-10 21:56:44,484 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4384, ap 0.4541
2024-01-10 21:56:44,563 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5753, ap 0.5799
2024-01-10 21:56:44,645 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4834, ap 0.5243
2024-01-10 21:56:44,733 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5356, ap 0.5352
2024-01-10 21:56:44,812 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.5231, ap 0.5348
2024-01-10 21:56:44,890 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5657, ap 0.5617
2024-01-10 21:56:44,900 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d039d9dd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:45,650 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4690, ap 0.4626
2024-01-10 21:56:45,747 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.4738, ap 0.4735
2024-01-10 21:56:45,835 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5160, ap 0.5086
2024-01-10 21:56:45,923 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.5178, ap 0.5583
2024-01-10 21:56:46,007 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5157, ap 0.4886
2024-01-10 21:56:46,088 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.5345, ap 0.5067
2024-01-10 21:56:46,163 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4398, ap 0.4443
2024-01-10 21:56:46,247 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5139, ap 0.4950
2024-01-10 21:56:46,323 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4270, ap 0.4439
2024-01-10 21:56:46,404 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4945, ap 0.5119
2024-01-10 21:56:46,481 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.5043, ap 0.5230
2024-01-10 21:56:46,557 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4804, ap 0.4826
2024-01-10 21:56:46,635 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5071, ap 0.5153
2024-01-10 21:56:46,712 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.4996, ap 0.4845
2024-01-10 21:56:46,787 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4058, ap 0.4446
2024-01-10 21:56:46,877 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4680, ap 0.4872
2024-01-10 21:56:46,955 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5367, ap 0.5208
2024-01-10 21:56:47,036 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5466, ap 0.5455
2024-01-10 21:56:47,110 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5650, ap 0.5237
2024-01-10 21:56:47,191 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4477, ap 0.4690
2024-01-10 21:56:47,267 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.4530, ap 0.4776
2024-01-10 21:56:47,356 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4032, ap 0.4309
2024-01-10 21:56:47,435 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5390, ap 0.5177
2024-01-10 21:56:47,520 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5641, ap 0.5630
2024-01-10 21:56:47,595 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4594, ap 0.4670
2024-01-10 21:56:47,681 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5666, ap 0.5457
2024-01-10 21:56:47,756 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4377, ap 0.4686
2024-01-10 21:56:47,831 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.4751, ap 0.5055
2024-01-10 21:56:47,910 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4548, ap 0.4718
2024-01-10 21:56:47,999 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5114, ap 0.5244
2024-01-10 21:56:48,010 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035e2290>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:48,746 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4178, ap 0.4560
2024-01-10 21:56:48,841 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5374, ap 0.5230
2024-01-10 21:56:48,931 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5028, ap 0.5010
2024-01-10 21:56:49,016 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4818, ap 0.5186
2024-01-10 21:56:49,094 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5915, ap 0.6089
2024-01-10 21:56:49,181 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.5203, ap 0.5027
2024-01-10 21:56:49,259 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4473, ap 0.4672
2024-01-10 21:56:49,336 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5028, ap 0.4998
2024-01-10 21:56:49,416 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4939, ap 0.5038
2024-01-10 21:56:49,491 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4413, ap 0.4762
2024-01-10 21:56:49,566 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.5021, ap 0.5456
2024-01-10 21:56:49,641 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4822, ap 0.4938
2024-01-10 21:56:49,729 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.6324, ap 0.5974
2024-01-10 21:56:49,806 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5320, ap 0.5319
2024-01-10 21:56:49,882 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3957, ap 0.4598
2024-01-10 21:56:49,958 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5609, ap 0.5640
2024-01-10 21:56:50,041 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5246, ap 0.5331
2024-01-10 21:56:50,117 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5595, ap 0.5657
2024-01-10 21:56:50,198 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5584, ap 0.5381
2024-01-10 21:56:50,275 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.5153, ap 0.5099
2024-01-10 21:56:50,353 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.4747, ap 0.5008
2024-01-10 21:56:50,429 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3900, ap 0.4285
2024-01-10 21:56:50,512 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.4868, ap 0.4979
2024-01-10 21:56:50,597 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5043, ap 0.5199
2024-01-10 21:56:50,674 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.5231, ap 0.5194
2024-01-10 21:56:50,751 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.4473, ap 0.4682
2024-01-10 21:56:50,836 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4640, ap 0.5216
2024-01-10 21:56:50,918 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.4961, ap 0.5273
2024-01-10 21:56:50,996 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.5908, ap 0.5873
2024-01-10 21:56:51,078 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5082, ap 0.5116
2024-01-10 21:56:51,088 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035ef390>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:51,807 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4804, ap 0.4797
2024-01-10 21:56:51,902 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5043, ap 0.5017
2024-01-10 21:56:51,994 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.6207, ap 0.6191
2024-01-10 21:56:52,077 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4729, ap 0.5181
2024-01-10 21:56:52,162 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5666, ap 0.5706
2024-01-10 21:56:52,239 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4306, ap 0.4529
2024-01-10 21:56:52,328 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4473, ap 0.4642
2024-01-10 21:56:52,404 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5189, ap 0.5206
2024-01-10 21:56:52,478 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4555, ap 0.4742
2024-01-10 21:56:52,562 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4238, ap 0.4506
2024-01-10 21:56:52,641 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4448, ap 0.4537
2024-01-10 21:56:52,730 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.5128, ap 0.5372
2024-01-10 21:56:52,809 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5680, ap 0.5535
2024-01-10 21:56:52,885 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.6047, ap 0.5832
2024-01-10 21:56:52,963 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3533, ap 0.4277
2024-01-10 21:56:53,040 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4783, ap 0.5167
2024-01-10 21:56:53,129 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5587, ap 0.5462
2024-01-10 21:56:53,206 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.6025, ap 0.6225
2024-01-10 21:56:53,289 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5132, ap 0.5091
2024-01-10 21:56:53,371 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4448, ap 0.5124
2024-01-10 21:56:53,458 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.5110, ap 0.5230
2024-01-10 21:56:53,547 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3416, ap 0.4203
2024-01-10 21:56:53,628 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5128, ap 0.5243
2024-01-10 21:56:53,706 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5117, ap 0.5080
2024-01-10 21:56:53,793 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4292, ap 0.4602
2024-01-10 21:56:53,870 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.4915, ap 0.5126
2024-01-10 21:56:53,944 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4708, ap 0.5026
2024-01-10 21:56:54,021 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5452, ap 0.5695
2024-01-10 21:56:54,098 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4996, ap 0.5047
2024-01-10 21:56:54,178 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5078, ap 0.5612
2024-01-10 21:56:54,192 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa00e150>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:54,933 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4617, ap 0.4613
2024-01-10 21:56:55,024 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.4671, ap 0.4741
2024-01-10 21:56:55,113 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.6223, ap 0.6084
2024-01-10 21:56:55,200 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.5283, ap 0.5140
2024-01-10 21:56:55,280 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5899, ap 0.5906
2024-01-10 21:56:55,353 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.5368, ap 0.5165
2024-01-10 21:56:55,430 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4995, ap 0.4819
2024-01-10 21:56:55,505 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5447, ap 0.5197
2024-01-10 21:56:55,585 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4607, ap 0.4763
2024-01-10 21:56:55,661 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4810, ap 0.4984
2024-01-10 21:56:55,739 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4639, ap 0.5097
2024-01-10 21:56:55,815 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4678, ap 0.4697
2024-01-10 21:56:55,894 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5376, ap 0.5347
2024-01-10 21:56:55,973 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.5205, ap 0.4942
2024-01-10 21:56:56,051 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3870, ap 0.4851
2024-01-10 21:56:56,125 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.4881, ap 0.4912
2024-01-10 21:56:56,208 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5707, ap 0.5482
2024-01-10 21:56:56,289 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5066, ap 0.5073
2024-01-10 21:56:56,373 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5173, ap 0.5041
2024-01-10 21:56:56,452 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4867, ap 0.5025
2024-01-10 21:56:56,537 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.4980, ap 0.4915
2024-01-10 21:56:56,613 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.3777, ap 0.4245
2024-01-10 21:56:56,695 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.4877, ap 0.5112
2024-01-10 21:56:56,773 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5080, ap 0.4944
2024-01-10 21:56:56,857 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.3863, ap 0.4213
2024-01-10 21:56:56,937 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5429, ap 0.5327
2024-01-10 21:56:57,015 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4578, ap 0.5004
2024-01-10 21:56:57,095 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.6173, ap 0.5819
2024-01-10 21:56:57,172 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4656, ap 0.4838
2024-01-10 21:56:57,250 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5504, ap 0.5719
2024-01-10 21:56:57,263 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d039d9910>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:56:57,977 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4705, ap 0.4651
2024-01-10 21:56:58,068 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.5077, ap 0.5122
2024-01-10 21:56:58,153 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5806, ap 0.5603
2024-01-10 21:56:58,236 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4799, ap 0.5012
2024-01-10 21:56:58,311 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.4925, ap 0.4937
2024-01-10 21:56:58,389 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.5506, ap 0.5439
2024-01-10 21:56:58,465 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4300, ap 0.4621
2024-01-10 21:56:58,550 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.4918, ap 0.4774
2024-01-10 21:56:58,624 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.5180, ap 0.5198
2024-01-10 21:56:58,700 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.4600, ap 0.4631
2024-01-10 21:56:58,775 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4881, ap 0.5017
2024-01-10 21:56:58,851 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.4589, ap 0.4621
2024-01-10 21:56:58,927 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5084, ap 0.5227
2024-01-10 21:56:59,009 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.4553, ap 0.4681
2024-01-10 21:56:59,087 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.4055, ap 0.4485
2024-01-10 21:56:59,163 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5942, ap 0.5563
2024-01-10 21:56:59,241 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.5632, ap 0.5385
2024-01-10 21:56:59,317 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.6109, ap 0.5923
2024-01-10 21:56:59,391 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5098, ap 0.4932
2024-01-10 21:56:59,472 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.5603, ap 0.5425
2024-01-10 21:56:59,549 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.4998, ap 0.5185
2024-01-10 21:56:59,629 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4074, ap 0.4370
2024-01-10 21:56:59,712 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5689, ap 0.5431
2024-01-10 21:56:59,787 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.5237, ap 0.4924
2024-01-10 21:56:59,863 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4567, ap 0.4739
2024-01-10 21:56:59,946 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.5525, ap 0.5451
2024-01-10 21:57:00,022 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.4001, ap 0.4345
2024-01-10 21:57:00,098 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5472, ap 0.5530
2024-01-10 21:57:00,172 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4806, ap 0.5051
2024-01-10 21:57:00,249 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5023, ap 0.4807
2024-01-10 21:57:00,249 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03594c90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:57:00,981 - GAugM EPNet train, Epoch [  1/30]: loss 0.7210, auc 0.4649, ap 0.4746
2024-01-10 21:57:01,075 - GAugM EPNet train, Epoch [  2/30]: loss 0.7210, auc 0.4891, ap 0.4977
2024-01-10 21:57:01,152 - GAugM EPNet train, Epoch [  3/30]: loss 0.7209, auc 0.5756, ap 0.5643
2024-01-10 21:57:01,226 - GAugM EPNet train, Epoch [  4/30]: loss 0.7209, auc 0.4721, ap 0.5107
2024-01-10 21:57:01,308 - GAugM EPNet train, Epoch [  5/30]: loss 0.7209, auc 0.5059, ap 0.4920
2024-01-10 21:57:01,384 - GAugM EPNet train, Epoch [  6/30]: loss 0.7209, auc 0.4756, ap 0.4926
2024-01-10 21:57:01,461 - GAugM EPNet train, Epoch [  7/30]: loss 0.7209, auc 0.4105, ap 0.4326
2024-01-10 21:57:01,536 - GAugM EPNet train, Epoch [  8/30]: loss 0.7210, auc 0.5486, ap 0.5306
2024-01-10 21:57:01,615 - GAugM EPNet train, Epoch [  9/30]: loss 0.7209, auc 0.4571, ap 0.4888
2024-01-10 21:57:01,698 - GAugM EPNet train, Epoch [ 10/30]: loss 0.7208, auc 0.5461, ap 0.5433
2024-01-10 21:57:01,780 - GAugM EPNet train, Epoch [ 11/30]: loss 0.7209, auc 0.4742, ap 0.4705
2024-01-10 21:57:01,858 - GAugM EPNet train, Epoch [ 12/30]: loss 0.7210, auc 0.5101, ap 0.5211
2024-01-10 21:57:01,935 - GAugM EPNet train, Epoch [ 13/30]: loss 0.7209, auc 0.5984, ap 0.5802
2024-01-10 21:57:02,016 - GAugM EPNet train, Epoch [ 14/30]: loss 0.7209, auc 0.4696, ap 0.4852
2024-01-10 21:57:02,094 - GAugM EPNet train, Epoch [ 15/30]: loss 0.7210, auc 0.3628, ap 0.4452
2024-01-10 21:57:02,180 - GAugM EPNet train, Epoch [ 16/30]: loss 0.7209, auc 0.5358, ap 0.5290
2024-01-10 21:57:02,265 - GAugM EPNet train, Epoch [ 17/30]: loss 0.7210, auc 0.4938, ap 0.5056
2024-01-10 21:57:02,342 - GAugM EPNet train, Epoch [ 18/30]: loss 0.7210, auc 0.5611, ap 0.5554
2024-01-10 21:57:02,425 - GAugM EPNet train, Epoch [ 19/30]: loss 0.7209, auc 0.5564, ap 0.5291
2024-01-10 21:57:02,502 - GAugM EPNet train, Epoch [ 20/30]: loss 0.7210, auc 0.4600, ap 0.5206
2024-01-10 21:57:02,582 - GAugM EPNet train, Epoch [ 21/30]: loss 0.7209, auc 0.4834, ap 0.5078
2024-01-10 21:57:02,665 - GAugM EPNet train, Epoch [ 22/30]: loss 0.7210, auc 0.4325, ap 0.4659
2024-01-10 21:57:02,749 - GAugM EPNet train, Epoch [ 23/30]: loss 0.7208, auc 0.5180, ap 0.5077
2024-01-10 21:57:02,834 - GAugM EPNet train, Epoch [ 24/30]: loss 0.7209, auc 0.4948, ap 0.4720
2024-01-10 21:57:02,910 - GAugM EPNet train, Epoch [ 25/30]: loss 0.7209, auc 0.4909, ap 0.5029
2024-01-10 21:57:02,990 - GAugM EPNet train, Epoch [ 26/30]: loss 0.7210, auc 0.4877, ap 0.5099
2024-01-10 21:57:03,065 - GAugM EPNet train, Epoch [ 27/30]: loss 0.7209, auc 0.3603, ap 0.4414
2024-01-10 21:57:03,142 - GAugM EPNet train, Epoch [ 28/30]: loss 0.7209, auc 0.5358, ap 0.5608
2024-01-10 21:57:03,220 - GAugM EPNet train, Epoch [ 29/30]: loss 0.7210, auc 0.4436, ap 0.4694
2024-01-10 21:57:03,300 - GAugM EPNet train, Epoch [ 30/30]: loss 0.7209, auc 0.5493, ap 0.5650
2024-01-10 21:57:03,318 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9e5a6d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:57:04,051 - GAugM EPNet train, Epoch [  1/285]: loss 0.7210, auc 0.4450, ap 0.4561
2024-01-10 21:57:04,139 - GAugM EPNet train, Epoch [  2/285]: loss 0.7210, auc 0.4692, ap 0.4811
2024-01-10 21:57:04,227 - GAugM EPNet train, Epoch [  3/285]: loss 0.7209, auc 0.6255, ap 0.5760
2024-01-10 21:57:04,313 - GAugM EPNet train, Epoch [  4/285]: loss 0.7209, auc 0.5554, ap 0.5872
2024-01-10 21:57:04,392 - GAugM EPNet train, Epoch [  5/285]: loss 0.7209, auc 0.4756, ap 0.4654
2024-01-10 21:57:04,466 - GAugM EPNet train, Epoch [  6/285]: loss 0.7209, auc 0.4920, ap 0.4955
2024-01-10 21:57:04,545 - GAugM EPNet train, Epoch [  7/285]: loss 0.7209, auc 0.4943, ap 0.4686
2024-01-10 21:57:04,619 - GAugM EPNet train, Epoch [  8/285]: loss 0.7210, auc 0.4009, ap 0.4369
2024-01-10 21:57:04,694 - GAugM EPNet train, Epoch [  9/285]: loss 0.7209, auc 0.5119, ap 0.4977
2024-01-10 21:57:04,768 - GAugM EPNet train, Epoch [ 10/285]: loss 0.7208, auc 0.4567, ap 0.4793
2024-01-10 21:57:04,844 - GAugM EPNet train, Epoch [ 11/285]: loss 0.7209, auc 0.5546, ap 0.5474
2024-01-10 21:57:04,918 - GAugM EPNet train, Epoch [ 12/285]: loss 0.7210, auc 0.4628, ap 0.4601
2024-01-10 21:57:04,997 - GAugM EPNet train, Epoch [ 13/285]: loss 0.7209, auc 0.6273, ap 0.6042
2024-01-10 21:57:05,072 - GAugM EPNet train, Epoch [ 14/285]: loss 0.7209, auc 0.5376, ap 0.5087
2024-01-10 21:57:05,146 - GAugM EPNet train, Epoch [ 15/285]: loss 0.7210, auc 0.3941, ap 0.4260
2024-01-10 21:57:05,225 - GAugM EPNet train, Epoch [ 16/285]: loss 0.7209, auc 0.6066, ap 0.5941
2024-01-10 21:57:05,301 - GAugM EPNet train, Epoch [ 17/285]: loss 0.7210, auc 0.5486, ap 0.5345
2024-01-10 21:57:05,380 - GAugM EPNet train, Epoch [ 18/285]: loss 0.7210, auc 0.5044, ap 0.5122
2024-01-10 21:57:05,453 - GAugM EPNet train, Epoch [ 19/285]: loss 0.7209, auc 0.4856, ap 0.4783
2024-01-10 21:57:05,527 - GAugM EPNet train, Epoch [ 20/285]: loss 0.7210, auc 0.5005, ap 0.5200
2024-01-10 21:57:05,602 - GAugM EPNet train, Epoch [ 21/285]: loss 0.7209, auc 0.5173, ap 0.5320
2024-01-10 21:57:05,677 - GAugM EPNet train, Epoch [ 22/285]: loss 0.7210, auc 0.4012, ap 0.4558
2024-01-10 21:57:05,753 - GAugM EPNet train, Epoch [ 23/285]: loss 0.7208, auc 0.4692, ap 0.4868
2024-01-10 21:57:05,831 - GAugM EPNet train, Epoch [ 24/285]: loss 0.7209, auc 0.5333, ap 0.5035
2024-01-10 21:57:05,907 - GAugM EPNet train, Epoch [ 25/285]: loss 0.7209, auc 0.4272, ap 0.4543
2024-01-10 21:57:05,981 - GAugM EPNet train, Epoch [ 26/285]: loss 0.7210, auc 0.5230, ap 0.5225
2024-01-10 21:57:06,056 - GAugM EPNet train, Epoch [ 27/285]: loss 0.7209, auc 0.4251, ap 0.4698
2024-01-10 21:57:06,130 - GAugM EPNet train, Epoch [ 28/285]: loss 0.7209, auc 0.5600, ap 0.5406
2024-01-10 21:57:06,205 - GAugM EPNet train, Epoch [ 29/285]: loss 0.7210, auc 0.4785, ap 0.4847
2024-01-10 21:57:06,278 - GAugM EPNet train, Epoch [ 30/285]: loss 0.7209, auc 0.4678, ap 0.4642
2024-01-10 21:57:06,352 - GAugM EPNet train, Epoch [ 31/285]: loss 0.7208, auc 0.4813, ap 0.5001
2024-01-10 21:57:06,425 - GAugM EPNet train, Epoch [ 32/285]: loss 0.7210, auc 0.5838, ap 0.5636
2024-01-10 21:57:06,498 - GAugM EPNet train, Epoch [ 33/285]: loss 0.7209, auc 0.5628, ap 0.6072
2024-01-10 21:57:06,571 - GAugM EPNet train, Epoch [ 34/285]: loss 0.7209, auc 0.4094, ap 0.4279
2024-01-10 21:57:06,645 - GAugM EPNet train, Epoch [ 35/285]: loss 0.7209, auc 0.5625, ap 0.5585
2024-01-10 21:57:06,720 - GAugM EPNet train, Epoch [ 36/285]: loss 0.7209, auc 0.4995, ap 0.5234
2024-01-10 21:57:06,794 - GAugM EPNet train, Epoch [ 37/285]: loss 0.7209, auc 0.4475, ap 0.4824
2024-01-10 21:57:06,873 - GAugM EPNet train, Epoch [ 38/285]: loss 0.7209, auc 0.4464, ap 0.4733
2024-01-10 21:57:06,949 - GAugM EPNet train, Epoch [ 39/285]: loss 0.7208, auc 0.5112, ap 0.5271
2024-01-10 21:57:07,022 - GAugM EPNet train, Epoch [ 40/285]: loss 0.7210, auc 0.5326, ap 0.5248
2024-01-10 21:57:07,095 - GAugM EPNet train, Epoch [ 41/285]: loss 0.7210, auc 0.5084, ap 0.5524
2024-01-10 21:57:07,170 - GAugM EPNet train, Epoch [ 42/285]: loss 0.7209, auc 0.5101, ap 0.5391
2024-01-10 21:57:07,242 - GAugM EPNet train, Epoch [ 43/285]: loss 0.7208, auc 0.4080, ap 0.4776
2024-01-10 21:57:07,317 - GAugM EPNet train, Epoch [ 44/285]: loss 0.7208, auc 0.4414, ap 0.4876
2024-01-10 21:57:07,394 - GAugM EPNet train, Epoch [ 45/285]: loss 0.7209, auc 0.4582, ap 0.4569
2024-01-10 21:57:07,471 - GAugM EPNet train, Epoch [ 46/285]: loss 0.7209, auc 0.4265, ap 0.4744
2024-01-10 21:57:07,554 - GAugM EPNet train, Epoch [ 47/285]: loss 0.7210, auc 0.5262, ap 0.5269
2024-01-10 21:57:07,632 - GAugM EPNet train, Epoch [ 48/285]: loss 0.7210, auc 0.5810, ap 0.5688
2024-01-10 21:57:07,706 - GAugM EPNet train, Epoch [ 49/285]: loss 0.7209, auc 0.4834, ap 0.5012
2024-01-10 21:57:07,781 - GAugM EPNet train, Epoch [ 50/285]: loss 0.7210, auc 0.5351, ap 0.5254
2024-01-10 21:57:07,857 - GAugM EPNet train, Epoch [ 51/285]: loss 0.7210, auc 0.4322, ap 0.4844
2024-01-10 21:57:07,935 - GAugM EPNet train, Epoch [ 52/285]: loss 0.7209, auc 0.5091, ap 0.4881
2024-01-10 21:57:08,010 - GAugM EPNet train, Epoch [ 53/285]: loss 0.7209, auc 0.4778, ap 0.5128
2024-01-10 21:57:08,086 - GAugM EPNet train, Epoch [ 54/285]: loss 0.7211, auc 0.5974, ap 0.5592
2024-01-10 21:57:08,162 - GAugM EPNet train, Epoch [ 55/285]: loss 0.7209, auc 0.6362, ap 0.6586
2024-01-10 21:57:08,240 - GAugM EPNet train, Epoch [ 56/285]: loss 0.7208, auc 0.5144, ap 0.5367
2024-01-10 21:57:08,315 - GAugM EPNet train, Epoch [ 57/285]: loss 0.7209, auc 0.4468, ap 0.4542
2024-01-10 21:57:08,388 - GAugM EPNet train, Epoch [ 58/285]: loss 0.7210, auc 0.5326, ap 0.5841
2024-01-10 21:57:08,463 - GAugM EPNet train, Epoch [ 59/285]: loss 0.7211, auc 0.5878, ap 0.5708
2024-01-10 21:57:08,538 - GAugM EPNet train, Epoch [ 60/285]: loss 0.7210, auc 0.5522, ap 0.5685
2024-01-10 21:57:08,619 - GAugM EPNet train, Epoch [ 61/285]: loss 0.7209, auc 0.5700, ap 0.5769
2024-01-10 21:57:08,699 - GAugM EPNet train, Epoch [ 62/285]: loss 0.7210, auc 0.5667, ap 0.5877
2024-01-10 21:57:08,777 - GAugM EPNet train, Epoch [ 63/285]: loss 0.7208, auc 0.4389, ap 0.4718
2024-01-10 21:57:08,852 - GAugM EPNet train, Epoch [ 64/285]: loss 0.7208, auc 0.4496, ap 0.4856
2024-01-10 21:57:08,925 - GAugM EPNet train, Epoch [ 65/285]: loss 0.7208, auc 0.6447, ap 0.6171
2024-01-10 21:57:09,002 - GAugM EPNet train, Epoch [ 66/285]: loss 0.7209, auc 0.4389, ap 0.5052
2024-01-10 21:57:09,075 - GAugM EPNet train, Epoch [ 67/285]: loss 0.7209, auc 0.5963, ap 0.5833
2024-01-10 21:57:09,151 - GAugM EPNet train, Epoch [ 68/285]: loss 0.7210, auc 0.5144, ap 0.5647
2024-01-10 21:57:09,225 - GAugM EPNet train, Epoch [ 69/285]: loss 0.7210, auc 0.4582, ap 0.5026
2024-01-10 21:57:09,298 - GAugM EPNet train, Epoch [ 70/285]: loss 0.7210, auc 0.5372, ap 0.5102
2024-01-10 21:57:09,372 - GAugM EPNet train, Epoch [ 71/285]: loss 0.7210, auc 0.5678, ap 0.5415
2024-01-10 21:57:09,445 - GAugM EPNet train, Epoch [ 72/285]: loss 0.7210, auc 0.5005, ap 0.5574
2024-01-10 21:57:09,517 - GAugM EPNet train, Epoch [ 73/285]: loss 0.7209, auc 0.5411, ap 0.5238
2024-01-10 21:57:09,590 - GAugM EPNet train, Epoch [ 74/285]: loss 0.7209, auc 0.5141, ap 0.5159
2024-01-10 21:57:09,666 - GAugM EPNet train, Epoch [ 75/285]: loss 0.7210, auc 0.4471, ap 0.4710
2024-01-10 21:57:09,741 - GAugM EPNet train, Epoch [ 76/285]: loss 0.7209, auc 0.4454, ap 0.4652
2024-01-10 21:57:09,820 - GAugM EPNet train, Epoch [ 77/285]: loss 0.7208, auc 0.5198, ap 0.5425
2024-01-10 21:57:09,895 - GAugM EPNet train, Epoch [ 78/285]: loss 0.7209, auc 0.5201, ap 0.5266
2024-01-10 21:57:09,971 - GAugM EPNet train, Epoch [ 79/285]: loss 0.7208, auc 0.5404, ap 0.5295
2024-01-10 21:57:10,047 - GAugM EPNet train, Epoch [ 80/285]: loss 0.7209, auc 0.5678, ap 0.5695
2024-01-10 21:57:10,124 - GAugM EPNet train, Epoch [ 81/285]: loss 0.7209, auc 0.4998, ap 0.5065
2024-01-10 21:57:10,198 - GAugM EPNet train, Epoch [ 82/285]: loss 0.7210, auc 0.5133, ap 0.5113
2024-01-10 21:57:10,271 - GAugM EPNet train, Epoch [ 83/285]: loss 0.7209, auc 0.5440, ap 0.5578
2024-01-10 21:57:10,349 - GAugM EPNet train, Epoch [ 84/285]: loss 0.7209, auc 0.4080, ap 0.4852
2024-01-10 21:57:10,433 - GAugM EPNet train, Epoch [ 85/285]: loss 0.7210, auc 0.4169, ap 0.4665
2024-01-10 21:57:10,510 - GAugM EPNet train, Epoch [ 86/285]: loss 0.7208, auc 0.4478, ap 0.4782
2024-01-10 21:57:10,585 - GAugM EPNet train, Epoch [ 87/285]: loss 0.7209, auc 0.4795, ap 0.4946
2024-01-10 21:57:10,659 - GAugM EPNet train, Epoch [ 88/285]: loss 0.7210, auc 0.4810, ap 0.5371
2024-01-10 21:57:10,733 - GAugM EPNet train, Epoch [ 89/285]: loss 0.7210, auc 0.4614, ap 0.4917
2024-01-10 21:57:10,806 - GAugM EPNet train, Epoch [ 90/285]: loss 0.7209, auc 0.4179, ap 0.4893
2024-01-10 21:57:10,881 - GAugM EPNet train, Epoch [ 91/285]: loss 0.7208, auc 0.5297, ap 0.5076
2024-01-10 21:57:10,960 - GAugM EPNet train, Epoch [ 92/285]: loss 0.7209, auc 0.5714, ap 0.5765
2024-01-10 21:57:11,037 - GAugM EPNet train, Epoch [ 93/285]: loss 0.7209, auc 0.3966, ap 0.4660
2024-01-10 21:57:11,120 - GAugM EPNet train, Epoch [ 94/285]: loss 0.7210, auc 0.4126, ap 0.4755
2024-01-10 21:57:11,198 - GAugM EPNet train, Epoch [ 95/285]: loss 0.7210, auc 0.5308, ap 0.5490
2024-01-10 21:57:11,274 - GAugM EPNet train, Epoch [ 96/285]: loss 0.7209, auc 0.5518, ap 0.5447
2024-01-10 21:57:11,349 - GAugM EPNet train, Epoch [ 97/285]: loss 0.7209, auc 0.5066, ap 0.5447
2024-01-10 21:57:11,425 - GAugM EPNet train, Epoch [ 98/285]: loss 0.7209, auc 0.4051, ap 0.4483
2024-01-10 21:57:11,501 - GAugM EPNet train, Epoch [ 99/285]: loss 0.7209, auc 0.5344, ap 0.5328
2024-01-10 21:57:11,575 - GAugM EPNet train, Epoch [100/285]: loss 0.7210, auc 0.4895, ap 0.4829
2024-01-10 21:57:11,654 - GAugM EPNet train, Epoch [101/285]: loss 0.7210, auc 0.5255, ap 0.5896
2024-01-10 21:57:11,730 - GAugM EPNet train, Epoch [102/285]: loss 0.7209, auc 0.4756, ap 0.4849
2024-01-10 21:57:11,804 - GAugM EPNet train, Epoch [103/285]: loss 0.7209, auc 0.5272, ap 0.5609
2024-01-10 21:57:11,886 - GAugM EPNet train, Epoch [104/285]: loss 0.7209, auc 0.4717, ap 0.4990
2024-01-10 21:57:11,961 - GAugM EPNet train, Epoch [105/285]: loss 0.7209, auc 0.4436, ap 0.4763
2024-01-10 21:57:12,037 - GAugM EPNet train, Epoch [106/285]: loss 0.7210, auc 0.5069, ap 0.5124
2024-01-10 21:57:12,113 - GAugM EPNet train, Epoch [107/285]: loss 0.7210, auc 0.5237, ap 0.5614
2024-01-10 21:57:12,188 - GAugM EPNet train, Epoch [108/285]: loss 0.7208, auc 0.4966, ap 0.4843
2024-01-10 21:57:12,265 - GAugM EPNet train, Epoch [109/285]: loss 0.7210, auc 0.5133, ap 0.5191
2024-01-10 21:57:12,340 - GAugM EPNet train, Epoch [110/285]: loss 0.7209, auc 0.4090, ap 0.4493
2024-01-10 21:57:12,422 - GAugM EPNet train, Epoch [111/285]: loss 0.7210, auc 0.5361, ap 0.5514
2024-01-10 21:57:12,497 - GAugM EPNet train, Epoch [112/285]: loss 0.7209, auc 0.4689, ap 0.5113
2024-01-10 21:57:12,571 - GAugM EPNet train, Epoch [113/285]: loss 0.7210, auc 0.4696, ap 0.5238
2024-01-10 21:57:12,645 - GAugM EPNet train, Epoch [114/285]: loss 0.7209, auc 0.4881, ap 0.4874
2024-01-10 21:57:12,719 - GAugM EPNet train, Epoch [115/285]: loss 0.7210, auc 0.5340, ap 0.5104
2024-01-10 21:57:12,797 - GAugM EPNet train, Epoch [116/285]: loss 0.7209, auc 0.5461, ap 0.5589
2024-01-10 21:57:12,878 - GAugM EPNet train, Epoch [117/285]: loss 0.7208, auc 0.4308, ap 0.4558
2024-01-10 21:57:12,955 - GAugM EPNet train, Epoch [118/285]: loss 0.7209, auc 0.4311, ap 0.4823
2024-01-10 21:57:13,032 - GAugM EPNet train, Epoch [119/285]: loss 0.7209, auc 0.5283, ap 0.5587
2024-01-10 21:57:13,106 - GAugM EPNet train, Epoch [120/285]: loss 0.7210, auc 0.4628, ap 0.4747
2024-01-10 21:57:13,180 - GAugM EPNet train, Epoch [121/285]: loss 0.7210, auc 0.5294, ap 0.5490
2024-01-10 21:57:13,254 - GAugM EPNet train, Epoch [122/285]: loss 0.7209, auc 0.5062, ap 0.5280
2024-01-10 21:57:13,336 - GAugM EPNet train, Epoch [123/285]: loss 0.7209, auc 0.5041, ap 0.5487
2024-01-10 21:57:13,409 - GAugM EPNet train, Epoch [124/285]: loss 0.7210, auc 0.4500, ap 0.4490
2024-01-10 21:57:13,484 - GAugM EPNet train, Epoch [125/285]: loss 0.7209, auc 0.4226, ap 0.4667
2024-01-10 21:57:13,558 - GAugM EPNet train, Epoch [126/285]: loss 0.7210, auc 0.5016, ap 0.5185
2024-01-10 21:57:13,632 - GAugM EPNet train, Epoch [127/285]: loss 0.7209, auc 0.5201, ap 0.5161
2024-01-10 21:57:13,710 - GAugM EPNet train, Epoch [128/285]: loss 0.7210, auc 0.5361, ap 0.5069
2024-01-10 21:57:13,790 - GAugM EPNet train, Epoch [129/285]: loss 0.7208, auc 0.4023, ap 0.4455
2024-01-10 21:57:13,870 - GAugM EPNet train, Epoch [130/285]: loss 0.7210, auc 0.5012, ap 0.5210
2024-01-10 21:57:13,947 - GAugM EPNet train, Epoch [131/285]: loss 0.7210, auc 0.5052, ap 0.5331
2024-01-10 21:57:14,021 - GAugM EPNet train, Epoch [132/285]: loss 0.7209, auc 0.5190, ap 0.5206
2024-01-10 21:57:14,101 - GAugM EPNet train, Epoch [133/285]: loss 0.7209, auc 0.4760, ap 0.5258
2024-01-10 21:57:14,174 - GAugM EPNet train, Epoch [134/285]: loss 0.7210, auc 0.5155, ap 0.5438
2024-01-10 21:57:14,247 - GAugM EPNet train, Epoch [135/285]: loss 0.7209, auc 0.3588, ap 0.4266
2024-01-10 21:57:14,328 - GAugM EPNet train, Epoch [136/285]: loss 0.7209, auc 0.4923, ap 0.4885
2024-01-10 21:57:14,405 - GAugM EPNet train, Epoch [137/285]: loss 0.7210, auc 0.5073, ap 0.5222
2024-01-10 21:57:14,481 - GAugM EPNet train, Epoch [138/285]: loss 0.7210, auc 0.5611, ap 0.5654
2024-01-10 21:57:14,554 - GAugM EPNet train, Epoch [139/285]: loss 0.7210, auc 0.4664, ap 0.4902
2024-01-10 21:57:14,627 - GAugM EPNet train, Epoch [140/285]: loss 0.7209, auc 0.5059, ap 0.5236
2024-01-10 21:57:14,703 - GAugM EPNet train, Epoch [141/285]: loss 0.7209, auc 0.6048, ap 0.5874
2024-01-10 21:57:14,778 - GAugM EPNet train, Epoch [142/285]: loss 0.7209, auc 0.4888, ap 0.5314
2024-01-10 21:57:14,866 - GAugM EPNet train, Epoch [143/285]: loss 0.7209, auc 0.4211, ap 0.4450
2024-01-10 21:57:14,944 - GAugM EPNet train, Epoch [144/285]: loss 0.7209, auc 0.5101, ap 0.5037
2024-01-10 21:57:15,019 - GAugM EPNet train, Epoch [145/285]: loss 0.7209, auc 0.5077, ap 0.5748
2024-01-10 21:57:15,093 - GAugM EPNet train, Epoch [146/285]: loss 0.7209, auc 0.5158, ap 0.5308
2024-01-10 21:57:15,175 - GAugM EPNet train, Epoch [147/285]: loss 0.7209, auc 0.5853, ap 0.5984
2024-01-10 21:57:15,255 - GAugM EPNet train, Epoch [148/285]: loss 0.7209, auc 0.4788, ap 0.4884
2024-01-10 21:57:15,332 - GAugM EPNet train, Epoch [149/285]: loss 0.7208, auc 0.5162, ap 0.5359
2024-01-10 21:57:15,406 - GAugM EPNet train, Epoch [150/285]: loss 0.7209, auc 0.5180, ap 0.5280
2024-01-10 21:57:15,480 - GAugM EPNet train, Epoch [151/285]: loss 0.7209, auc 0.4963, ap 0.5334
2024-01-10 21:57:15,556 - GAugM EPNet train, Epoch [152/285]: loss 0.7209, auc 0.6080, ap 0.6142
2024-01-10 21:57:15,633 - GAugM EPNet train, Epoch [153/285]: loss 0.7209, auc 0.4973, ap 0.5145
2024-01-10 21:57:15,706 - GAugM EPNet train, Epoch [154/285]: loss 0.7209, auc 0.5724, ap 0.5931
2024-01-10 21:57:15,784 - GAugM EPNet train, Epoch [155/285]: loss 0.7209, auc 0.5069, ap 0.5027
2024-01-10 21:57:15,864 - GAugM EPNet train, Epoch [156/285]: loss 0.7209, auc 0.4382, ap 0.4845
2024-01-10 21:57:15,943 - GAugM EPNet train, Epoch [157/285]: loss 0.7209, auc 0.4521, ap 0.4799
2024-01-10 21:57:16,033 - GAugM EPNet train, Epoch [158/285]: loss 0.7208, auc 0.4486, ap 0.4836
2024-01-10 21:57:16,117 - GAugM EPNet train, Epoch [159/285]: loss 0.7208, auc 0.4247, ap 0.4489
2024-01-10 21:57:16,199 - GAugM EPNet train, Epoch [160/285]: loss 0.7209, auc 0.5162, ap 0.5374
2024-01-10 21:57:16,274 - GAugM EPNet train, Epoch [161/285]: loss 0.7209, auc 0.5429, ap 0.5438
2024-01-10 21:57:16,350 - GAugM EPNet train, Epoch [162/285]: loss 0.7209, auc 0.4585, ap 0.4684
2024-01-10 21:57:16,424 - GAugM EPNet train, Epoch [163/285]: loss 0.7209, auc 0.5465, ap 0.5272
2024-01-10 21:57:16,502 - GAugM EPNet train, Epoch [164/285]: loss 0.7211, auc 0.4913, ap 0.5113
2024-01-10 21:57:16,578 - GAugM EPNet train, Epoch [165/285]: loss 0.7210, auc 0.4233, ap 0.4814
2024-01-10 21:57:16,652 - GAugM EPNet train, Epoch [166/285]: loss 0.7208, auc 0.5497, ap 0.5318
2024-01-10 21:57:16,727 - GAugM EPNet train, Epoch [167/285]: loss 0.7209, auc 0.4916, ap 0.5101
2024-01-10 21:57:16,811 - GAugM EPNet train, Epoch [168/285]: loss 0.7209, auc 0.4920, ap 0.5141
2024-01-10 21:57:16,886 - GAugM EPNet train, Epoch [169/285]: loss 0.7209, auc 0.5582, ap 0.5669
2024-01-10 21:57:16,959 - GAugM EPNet train, Epoch [170/285]: loss 0.7210, auc 0.4404, ap 0.4635
2024-01-10 21:57:17,039 - GAugM EPNet train, Epoch [171/285]: loss 0.7209, auc 0.4414, ap 0.4575
2024-01-10 21:57:17,119 - GAugM EPNet train, Epoch [172/285]: loss 0.7208, auc 0.4763, ap 0.4698
2024-01-10 21:57:17,193 - GAugM EPNet train, Epoch [173/285]: loss 0.7209, auc 0.5319, ap 0.5277
2024-01-10 21:57:17,266 - GAugM EPNet train, Epoch [174/285]: loss 0.7209, auc 0.4646, ap 0.4663
2024-01-10 21:57:17,341 - GAugM EPNet train, Epoch [175/285]: loss 0.7209, auc 0.5824, ap 0.5630
2024-01-10 21:57:17,419 - GAugM EPNet train, Epoch [176/285]: loss 0.7209, auc 0.5094, ap 0.5208
2024-01-10 21:57:17,500 - GAugM EPNet train, Epoch [177/285]: loss 0.7210, auc 0.4874, ap 0.4973
2024-01-10 21:57:17,577 - GAugM EPNet train, Epoch [178/285]: loss 0.7210, auc 0.5368, ap 0.5934
2024-01-10 21:57:17,653 - GAugM EPNet train, Epoch [179/285]: loss 0.7210, auc 0.4357, ap 0.4865
2024-01-10 21:57:17,736 - GAugM EPNet train, Epoch [180/285]: loss 0.7210, auc 0.4770, ap 0.5205
2024-01-10 21:57:17,811 - GAugM EPNet train, Epoch [181/285]: loss 0.7209, auc 0.4457, ap 0.4903
2024-01-10 21:57:17,895 - GAugM EPNet train, Epoch [182/285]: loss 0.7209, auc 0.5180, ap 0.5423
2024-01-10 21:57:17,971 - GAugM EPNet train, Epoch [183/285]: loss 0.7210, auc 0.5507, ap 0.5628
2024-01-10 21:57:18,044 - GAugM EPNet train, Epoch [184/285]: loss 0.7209, auc 0.4945, ap 0.5132
2024-01-10 21:57:18,121 - GAugM EPNet train, Epoch [185/285]: loss 0.7209, auc 0.4681, ap 0.5050
2024-01-10 21:57:18,196 - GAugM EPNet train, Epoch [186/285]: loss 0.7208, auc 0.4304, ap 0.4825
2024-01-10 21:57:18,274 - GAugM EPNet train, Epoch [187/285]: loss 0.7209, auc 0.4867, ap 0.5055
2024-01-10 21:57:18,349 - GAugM EPNet train, Epoch [188/285]: loss 0.7209, auc 0.4422, ap 0.4669
2024-01-10 21:57:18,426 - GAugM EPNet train, Epoch [189/285]: loss 0.7209, auc 0.5539, ap 0.5622
2024-01-10 21:57:18,500 - GAugM EPNet train, Epoch [190/285]: loss 0.7209, auc 0.3873, ap 0.4229
2024-01-10 21:57:18,574 - GAugM EPNet train, Epoch [191/285]: loss 0.7209, auc 0.4457, ap 0.4883
2024-01-10 21:57:18,647 - GAugM EPNet train, Epoch [192/285]: loss 0.7209, auc 0.4966, ap 0.4793
2024-01-10 21:57:18,724 - GAugM EPNet train, Epoch [193/285]: loss 0.7209, auc 0.5187, ap 0.5380
2024-01-10 21:57:18,797 - GAugM EPNet train, Epoch [194/285]: loss 0.7209, auc 0.5183, ap 0.5194
2024-01-10 21:57:18,870 - GAugM EPNet train, Epoch [195/285]: loss 0.7209, auc 0.4863, ap 0.5167
2024-01-10 21:57:18,943 - GAugM EPNet train, Epoch [196/285]: loss 0.7208, auc 0.5041, ap 0.4976
2024-01-10 21:57:19,016 - GAugM EPNet train, Epoch [197/285]: loss 0.7210, auc 0.5041, ap 0.5045
2024-01-10 21:57:19,095 - GAugM EPNet train, Epoch [198/285]: loss 0.7210, auc 0.5372, ap 0.5313
2024-01-10 21:57:19,169 - GAugM EPNet train, Epoch [199/285]: loss 0.7209, auc 0.5155, ap 0.5369
2024-01-10 21:57:19,248 - GAugM EPNet train, Epoch [200/285]: loss 0.7210, auc 0.4571, ap 0.4663
2024-01-10 21:57:19,329 - GAugM EPNet train, Epoch [201/285]: loss 0.7209, auc 0.5489, ap 0.5235
2024-01-10 21:57:19,405 - GAugM EPNet train, Epoch [202/285]: loss 0.7210, auc 0.5835, ap 0.6205
2024-01-10 21:57:19,483 - GAugM EPNet train, Epoch [203/285]: loss 0.7210, auc 0.5578, ap 0.5794
2024-01-10 21:57:19,564 - GAugM EPNet train, Epoch [204/285]: loss 0.7209, auc 0.4827, ap 0.4961
2024-01-10 21:57:19,640 - GAugM EPNet train, Epoch [205/285]: loss 0.7209, auc 0.5255, ap 0.5554
2024-01-10 21:57:19,714 - GAugM EPNet train, Epoch [206/285]: loss 0.7209, auc 0.4069, ap 0.4631
2024-01-10 21:57:19,789 - GAugM EPNet train, Epoch [207/285]: loss 0.7210, auc 0.3766, ap 0.4344
2024-01-10 21:57:19,864 - GAugM EPNet train, Epoch [208/285]: loss 0.7209, auc 0.4738, ap 0.5389
2024-01-10 21:57:19,937 - GAugM EPNet train, Epoch [209/285]: loss 0.7210, auc 0.5789, ap 0.5882
2024-01-10 21:57:20,011 - GAugM EPNet train, Epoch [210/285]: loss 0.7209, auc 0.5030, ap 0.5123
2024-01-10 21:57:20,085 - GAugM EPNet train, Epoch [211/285]: loss 0.7210, auc 0.5308, ap 0.5429
2024-01-10 21:57:20,157 - GAugM EPNet train, Epoch [212/285]: loss 0.7210, auc 0.5180, ap 0.4958
2024-01-10 21:57:20,234 - GAugM EPNet train, Epoch [213/285]: loss 0.7208, auc 0.6009, ap 0.6279
2024-01-10 21:57:20,321 - GAugM EPNet train, Epoch [214/285]: loss 0.7210, auc 0.5404, ap 0.5281
2024-01-10 21:57:20,398 - GAugM EPNet train, Epoch [215/285]: loss 0.7210, auc 0.4571, ap 0.4664
2024-01-10 21:57:20,471 - GAugM EPNet train, Epoch [216/285]: loss 0.7209, auc 0.5162, ap 0.5060
2024-01-10 21:57:20,555 - GAugM EPNet train, Epoch [217/285]: loss 0.7209, auc 0.5635, ap 0.5915
2024-01-10 21:57:20,635 - GAugM EPNet train, Epoch [218/285]: loss 0.7209, auc 0.4931, ap 0.5571
2024-01-10 21:57:20,709 - GAugM EPNet train, Epoch [219/285]: loss 0.7208, auc 0.5536, ap 0.5495
2024-01-10 21:57:20,789 - GAugM EPNet train, Epoch [220/285]: loss 0.7210, auc 0.4642, ap 0.4938
2024-01-10 21:57:20,864 - GAugM EPNet train, Epoch [221/285]: loss 0.7209, auc 0.6255, ap 0.5984
2024-01-10 21:57:20,940 - GAugM EPNet train, Epoch [222/285]: loss 0.7209, auc 0.4770, ap 0.5010
2024-01-10 21:57:21,018 - GAugM EPNet train, Epoch [223/285]: loss 0.7209, auc 0.5020, ap 0.5222
2024-01-10 21:57:21,090 - GAugM EPNet train, Epoch [224/285]: loss 0.7210, auc 0.4778, ap 0.4650
2024-01-10 21:57:21,172 - GAugM EPNet train, Epoch [225/285]: loss 0.7209, auc 0.4863, ap 0.5096
2024-01-10 21:57:21,254 - GAugM EPNet train, Epoch [226/285]: loss 0.7210, auc 0.5148, ap 0.5282
2024-01-10 21:57:21,328 - GAugM EPNet train, Epoch [227/285]: loss 0.7210, auc 0.5646, ap 0.5660
2024-01-10 21:57:21,406 - GAugM EPNet train, Epoch [228/285]: loss 0.7209, auc 0.5016, ap 0.5268
2024-01-10 21:57:21,480 - GAugM EPNet train, Epoch [229/285]: loss 0.7209, auc 0.4959, ap 0.4978
2024-01-10 21:57:21,554 - GAugM EPNet train, Epoch [230/285]: loss 0.7209, auc 0.4560, ap 0.4881
2024-01-10 21:57:21,636 - GAugM EPNet train, Epoch [231/285]: loss 0.7209, auc 0.4884, ap 0.4932
2024-01-10 21:57:21,715 - GAugM EPNet train, Epoch [232/285]: loss 0.7209, auc 0.6084, ap 0.5846
2024-01-10 21:57:21,795 - GAugM EPNet train, Epoch [233/285]: loss 0.7210, auc 0.4970, ap 0.4840
2024-01-10 21:57:21,870 - GAugM EPNet train, Epoch [234/285]: loss 0.7209, auc 0.3660, ap 0.4351
2024-01-10 21:57:21,946 - GAugM EPNet train, Epoch [235/285]: loss 0.7209, auc 0.4190, ap 0.4565
2024-01-10 21:57:22,023 - GAugM EPNet train, Epoch [236/285]: loss 0.7209, auc 0.5497, ap 0.5647
2024-01-10 21:57:22,108 - GAugM EPNet train, Epoch [237/285]: loss 0.7210, auc 0.5372, ap 0.5513
2024-01-10 21:57:22,186 - GAugM EPNet train, Epoch [238/285]: loss 0.7210, auc 0.4585, ap 0.4749
2024-01-10 21:57:22,262 - GAugM EPNet train, Epoch [239/285]: loss 0.7209, auc 0.4831, ap 0.5191
2024-01-10 21:57:22,343 - GAugM EPNet train, Epoch [240/285]: loss 0.7209, auc 0.4400, ap 0.4573
2024-01-10 21:57:22,419 - GAugM EPNet train, Epoch [241/285]: loss 0.7209, auc 0.5073, ap 0.5174
2024-01-10 21:57:22,493 - GAugM EPNet train, Epoch [242/285]: loss 0.7210, auc 0.4888, ap 0.5334
2024-01-10 21:57:22,569 - GAugM EPNet train, Epoch [243/285]: loss 0.7210, auc 0.4041, ap 0.4502
2024-01-10 21:57:22,648 - GAugM EPNet train, Epoch [244/285]: loss 0.7209, auc 0.4557, ap 0.4841
2024-01-10 21:57:22,722 - GAugM EPNet train, Epoch [245/285]: loss 0.7210, auc 0.4233, ap 0.4655
2024-01-10 21:57:22,801 - GAugM EPNet train, Epoch [246/285]: loss 0.7208, auc 0.4649, ap 0.5140
2024-01-10 21:57:22,877 - GAugM EPNet train, Epoch [247/285]: loss 0.7209, auc 0.4888, ap 0.4884
2024-01-10 21:57:22,953 - GAugM EPNet train, Epoch [248/285]: loss 0.7211, auc 0.5297, ap 0.5442
2024-01-10 21:57:23,028 - GAugM EPNet train, Epoch [249/285]: loss 0.7209, auc 0.4824, ap 0.4763
2024-01-10 21:57:23,107 - GAugM EPNet train, Epoch [250/285]: loss 0.7208, auc 0.5600, ap 0.5553
2024-01-10 21:57:23,185 - GAugM EPNet train, Epoch [251/285]: loss 0.7209, auc 0.4731, ap 0.5135
2024-01-10 21:57:23,260 - GAugM EPNet train, Epoch [252/285]: loss 0.7210, auc 0.5237, ap 0.5510
2024-01-10 21:57:23,337 - GAugM EPNet train, Epoch [253/285]: loss 0.7209, auc 0.5981, ap 0.5633
2024-01-10 21:57:23,419 - GAugM EPNet train, Epoch [254/285]: loss 0.7210, auc 0.4916, ap 0.5279
2024-01-10 21:57:23,492 - GAugM EPNet train, Epoch [255/285]: loss 0.7209, auc 0.4852, ap 0.5361
2024-01-10 21:57:23,565 - GAugM EPNet train, Epoch [256/285]: loss 0.7210, auc 0.3386, ap 0.4236
2024-01-10 21:57:23,649 - GAugM EPNet train, Epoch [257/285]: loss 0.7210, auc 0.4909, ap 0.5360
2024-01-10 21:57:23,729 - GAugM EPNet train, Epoch [258/285]: loss 0.7208, auc 0.5247, ap 0.5692
2024-01-10 21:57:23,806 - GAugM EPNet train, Epoch [259/285]: loss 0.7208, auc 0.6127, ap 0.5946
2024-01-10 21:57:23,881 - GAugM EPNet train, Epoch [260/285]: loss 0.7210, auc 0.5796, ap 0.5516
2024-01-10 21:57:23,956 - GAugM EPNet train, Epoch [261/285]: loss 0.7209, auc 0.4041, ap 0.4361
2024-01-10 21:57:24,038 - GAugM EPNet train, Epoch [262/285]: loss 0.7208, auc 0.4557, ap 0.4778
2024-01-10 21:57:24,116 - GAugM EPNet train, Epoch [263/285]: loss 0.7209, auc 0.4632, ap 0.4898
2024-01-10 21:57:24,190 - GAugM EPNet train, Epoch [264/285]: loss 0.7210, auc 0.4664, ap 0.4770
2024-01-10 21:57:24,278 - GAugM EPNet train, Epoch [265/285]: loss 0.7209, auc 0.4984, ap 0.5178
2024-01-10 21:57:24,356 - GAugM EPNet train, Epoch [266/285]: loss 0.7209, auc 0.5425, ap 0.5108
2024-01-10 21:57:24,437 - GAugM EPNet train, Epoch [267/285]: loss 0.7210, auc 0.5660, ap 0.5658
2024-01-10 21:57:24,515 - GAugM EPNet train, Epoch [268/285]: loss 0.7210, auc 0.4603, ap 0.5029
2024-01-10 21:57:24,592 - GAugM EPNet train, Epoch [269/285]: loss 0.7209, auc 0.5287, ap 0.5674
2024-01-10 21:57:24,667 - GAugM EPNet train, Epoch [270/285]: loss 0.7210, auc 0.5141, ap 0.5239
2024-01-10 21:57:24,743 - GAugM EPNet train, Epoch [271/285]: loss 0.7209, auc 0.5514, ap 0.5475
2024-01-10 21:57:24,826 - GAugM EPNet train, Epoch [272/285]: loss 0.7209, auc 0.5105, ap 0.5347
2024-01-10 21:57:24,899 - GAugM EPNet train, Epoch [273/285]: loss 0.7209, auc 0.4126, ap 0.4462
2024-01-10 21:57:24,974 - GAugM EPNet train, Epoch [274/285]: loss 0.7209, auc 0.4215, ap 0.4423
2024-01-10 21:57:25,048 - GAugM EPNet train, Epoch [275/285]: loss 0.7208, auc 0.4457, ap 0.4723
2024-01-10 21:57:25,127 - GAugM EPNet train, Epoch [276/285]: loss 0.7210, auc 0.5546, ap 0.5850
2024-01-10 21:57:25,202 - GAugM EPNet train, Epoch [277/285]: loss 0.7208, auc 0.5023, ap 0.5901
2024-01-10 21:57:25,276 - GAugM EPNet train, Epoch [278/285]: loss 0.7209, auc 0.5643, ap 0.5691
2024-01-10 21:57:25,351 - GAugM EPNet train, Epoch [279/285]: loss 0.7209, auc 0.4934, ap 0.5231
2024-01-10 21:57:25,425 - GAugM EPNet train, Epoch [280/285]: loss 0.7209, auc 0.3592, ap 0.4144
2024-01-10 21:57:25,499 - GAugM EPNet train, Epoch [281/285]: loss 0.7209, auc 0.5920, ap 0.5729
2024-01-10 21:57:25,573 - GAugM EPNet train, Epoch [282/285]: loss 0.7209, auc 0.4988, ap 0.5024
2024-01-10 21:57:25,651 - GAugM EPNet train, Epoch [283/285]: loss 0.7209, auc 0.4340, ap 0.4679
2024-01-10 21:57:25,726 - GAugM EPNet train, Epoch [284/285]: loss 0.7209, auc 0.4300, ap 0.4654
2024-01-10 21:57:25,801 - GAugM EPNet train, Epoch [285/285]: loss 0.7209, auc 0.4909, ap 0.5137
2024-01-10 21:57:25,810 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa0b0bd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:57:26,554 - GAugM EPNet train, Epoch [  1/285]: loss 0.7210, auc 0.4676, ap 0.4862
2024-01-10 21:57:26,649 - GAugM EPNet train, Epoch [  2/285]: loss 0.7210, auc 0.4470, ap 0.4666
2024-01-10 21:57:26,733 - GAugM EPNet train, Epoch [  3/285]: loss 0.7209, auc 0.5103, ap 0.5233
2024-01-10 21:57:26,822 - GAugM EPNet train, Epoch [  4/285]: loss 0.7209, auc 0.5279, ap 0.5726
2024-01-10 21:57:26,911 - GAugM EPNet train, Epoch [  5/285]: loss 0.7209, auc 0.5655, ap 0.5757
2024-01-10 21:57:26,999 - GAugM EPNet train, Epoch [  6/285]: loss 0.7209, auc 0.4968, ap 0.4946
2024-01-10 21:57:27,084 - GAugM EPNet train, Epoch [  7/285]: loss 0.7209, auc 0.4642, ap 0.4687
2024-01-10 21:57:27,163 - GAugM EPNet train, Epoch [  8/285]: loss 0.7210, auc 0.4881, ap 0.5165
2024-01-10 21:57:27,241 - GAugM EPNet train, Epoch [  9/285]: loss 0.7209, auc 0.5116, ap 0.5137
2024-01-10 21:57:27,319 - GAugM EPNet train, Epoch [ 10/285]: loss 0.7208, auc 0.4916, ap 0.5014
2024-01-10 21:57:27,397 - GAugM EPNet train, Epoch [ 11/285]: loss 0.7209, auc 0.4760, ap 0.5195
2024-01-10 21:57:27,474 - GAugM EPNet train, Epoch [ 12/285]: loss 0.7210, auc 0.5020, ap 0.5007
2024-01-10 21:57:27,546 - GAugM EPNet train, Epoch [ 13/285]: loss 0.7209, auc 0.5813, ap 0.6047
2024-01-10 21:57:27,622 - GAugM EPNet train, Epoch [ 14/285]: loss 0.7209, auc 0.4941, ap 0.5070
2024-01-10 21:57:27,696 - GAugM EPNet train, Epoch [ 15/285]: loss 0.7210, auc 0.4021, ap 0.4870
2024-01-10 21:57:27,780 - GAugM EPNet train, Epoch [ 16/285]: loss 0.7209, auc 0.5256, ap 0.5435
2024-01-10 21:57:27,855 - GAugM EPNet train, Epoch [ 17/285]: loss 0.7210, auc 0.5660, ap 0.5450
2024-01-10 21:57:27,933 - GAugM EPNet train, Epoch [ 18/285]: loss 0.7210, auc 0.5570, ap 0.5422
2024-01-10 21:57:28,008 - GAugM EPNet train, Epoch [ 19/285]: loss 0.7209, auc 0.5150, ap 0.5079
2024-01-10 21:57:28,082 - GAugM EPNet train, Epoch [ 20/285]: loss 0.7210, auc 0.4671, ap 0.5042
2024-01-10 21:57:28,157 - GAugM EPNet train, Epoch [ 21/285]: loss 0.7209, auc 0.4939, ap 0.4878
2024-01-10 21:57:28,235 - GAugM EPNet train, Epoch [ 22/285]: loss 0.7210, auc 0.3686, ap 0.4223
2024-01-10 21:57:28,311 - GAugM EPNet train, Epoch [ 23/285]: loss 0.7208, auc 0.4366, ap 0.4624
2024-01-10 21:57:28,390 - GAugM EPNet train, Epoch [ 24/285]: loss 0.7209, auc 0.5708, ap 0.5826
2024-01-10 21:57:28,473 - GAugM EPNet train, Epoch [ 25/285]: loss 0.7209, auc 0.5132, ap 0.5142
2024-01-10 21:57:28,548 - GAugM EPNet train, Epoch [ 26/285]: loss 0.7210, auc 0.5320, ap 0.5771
2024-01-10 21:57:28,622 - GAugM EPNet train, Epoch [ 27/285]: loss 0.7209, auc 0.4580, ap 0.5247
2024-01-10 21:57:28,703 - GAugM EPNet train, Epoch [ 28/285]: loss 0.7209, auc 0.5603, ap 0.6111
2024-01-10 21:57:28,779 - GAugM EPNet train, Epoch [ 29/285]: loss 0.7210, auc 0.4179, ap 0.4890
2024-01-10 21:57:28,853 - GAugM EPNet train, Epoch [ 30/285]: loss 0.7209, auc 0.5189, ap 0.5102
2024-01-10 21:57:28,927 - GAugM EPNet train, Epoch [ 31/285]: loss 0.7208, auc 0.4897, ap 0.5108
2024-01-10 21:57:29,008 - GAugM EPNet train, Epoch [ 32/285]: loss 0.7210, auc 0.5429, ap 0.5302
2024-01-10 21:57:29,083 - GAugM EPNet train, Epoch [ 33/285]: loss 0.7209, auc 0.5262, ap 0.5400
2024-01-10 21:57:29,157 - GAugM EPNet train, Epoch [ 34/285]: loss 0.7209, auc 0.4601, ap 0.4667
2024-01-10 21:57:29,232 - GAugM EPNet train, Epoch [ 35/285]: loss 0.7209, auc 0.5545, ap 0.5638
2024-01-10 21:57:29,304 - GAugM EPNet train, Epoch [ 36/285]: loss 0.7209, auc 0.5481, ap 0.5961
2024-01-10 21:57:29,382 - GAugM EPNet train, Epoch [ 37/285]: loss 0.7209, auc 0.4500, ap 0.5045
2024-01-10 21:57:29,458 - GAugM EPNet train, Epoch [ 38/285]: loss 0.7209, auc 0.5009, ap 0.4822
2024-01-10 21:57:29,532 - GAugM EPNet train, Epoch [ 39/285]: loss 0.7208, auc 0.4461, ap 0.4862
2024-01-10 21:57:29,608 - GAugM EPNet train, Epoch [ 40/285]: loss 0.7210, auc 0.5052, ap 0.4957
2024-01-10 21:57:29,686 - GAugM EPNet train, Epoch [ 41/285]: loss 0.7210, auc 0.5240, ap 0.5454
2024-01-10 21:57:29,762 - GAugM EPNet train, Epoch [ 42/285]: loss 0.7209, auc 0.5105, ap 0.5336
2024-01-10 21:57:29,838 - GAugM EPNet train, Epoch [ 43/285]: loss 0.7208, auc 0.4564, ap 0.4962
2024-01-10 21:57:29,917 - GAugM EPNet train, Epoch [ 44/285]: loss 0.7208, auc 0.3147, ap 0.4003
2024-01-10 21:57:29,989 - GAugM EPNet train, Epoch [ 45/285]: loss 0.7209, auc 0.5249, ap 0.5569
2024-01-10 21:57:30,064 - GAugM EPNet train, Epoch [ 46/285]: loss 0.7209, auc 0.4667, ap 0.5058
2024-01-10 21:57:30,137 - GAugM EPNet train, Epoch [ 47/285]: loss 0.7210, auc 0.5621, ap 0.5691
2024-01-10 21:57:30,214 - GAugM EPNet train, Epoch [ 48/285]: loss 0.7210, auc 0.6050, ap 0.6232
2024-01-10 21:57:30,289 - GAugM EPNet train, Epoch [ 49/285]: loss 0.7209, auc 0.5582, ap 0.5523
2024-01-10 21:57:30,374 - GAugM EPNet train, Epoch [ 50/285]: loss 0.7210, auc 0.5845, ap 0.5834
2024-01-10 21:57:30,449 - GAugM EPNet train, Epoch [ 51/285]: loss 0.7210, auc 0.5368, ap 0.5471
2024-01-10 21:57:30,526 - GAugM EPNet train, Epoch [ 52/285]: loss 0.7209, auc 0.4925, ap 0.4940
2024-01-10 21:57:30,603 - GAugM EPNet train, Epoch [ 53/285]: loss 0.7209, auc 0.5392, ap 0.5437
2024-01-10 21:57:30,680 - GAugM EPNet train, Epoch [ 54/285]: loss 0.7211, auc 0.5142, ap 0.5146
2024-01-10 21:57:30,761 - GAugM EPNet train, Epoch [ 55/285]: loss 0.7209, auc 0.6429, ap 0.6379
2024-01-10 21:57:30,842 - GAugM EPNet train, Epoch [ 56/285]: loss 0.7208, auc 0.5319, ap 0.5398
2024-01-10 21:57:30,917 - GAugM EPNet train, Epoch [ 57/285]: loss 0.7209, auc 0.4429, ap 0.4635
2024-01-10 21:57:30,998 - GAugM EPNet train, Epoch [ 58/285]: loss 0.7210, auc 0.4899, ap 0.5590
2024-01-10 21:57:31,077 - GAugM EPNet train, Epoch [ 59/285]: loss 0.7211, auc 0.5233, ap 0.5089
2024-01-10 21:57:31,152 - GAugM EPNet train, Epoch [ 60/285]: loss 0.7210, auc 0.4827, ap 0.4866
2024-01-10 21:57:31,226 - GAugM EPNet train, Epoch [ 61/285]: loss 0.7209, auc 0.5233, ap 0.5285
2024-01-10 21:57:31,300 - GAugM EPNet train, Epoch [ 62/285]: loss 0.7210, auc 0.5384, ap 0.5475
2024-01-10 21:57:31,379 - GAugM EPNet train, Epoch [ 63/285]: loss 0.7208, auc 0.4907, ap 0.4836
2024-01-10 21:57:31,453 - GAugM EPNet train, Epoch [ 64/285]: loss 0.7208, auc 0.5196, ap 0.5413
2024-01-10 21:57:31,528 - GAugM EPNet train, Epoch [ 65/285]: loss 0.7208, auc 0.5212, ap 0.5452
2024-01-10 21:57:31,602 - GAugM EPNet train, Epoch [ 66/285]: loss 0.7209, auc 0.4742, ap 0.5301
2024-01-10 21:57:31,687 - GAugM EPNet train, Epoch [ 67/285]: loss 0.7209, auc 0.4744, ap 0.4949
2024-01-10 21:57:31,766 - GAugM EPNet train, Epoch [ 68/285]: loss 0.7210, auc 0.4658, ap 0.5123
2024-01-10 21:57:31,847 - GAugM EPNet train, Epoch [ 69/285]: loss 0.7210, auc 0.5689, ap 0.5842
2024-01-10 21:57:31,921 - GAugM EPNet train, Epoch [ 70/285]: loss 0.7210, auc 0.4956, ap 0.5171
2024-01-10 21:57:31,996 - GAugM EPNet train, Epoch [ 71/285]: loss 0.7210, auc 0.5554, ap 0.5401
2024-01-10 21:57:32,071 - GAugM EPNet train, Epoch [ 72/285]: loss 0.7210, auc 0.4341, ap 0.4505
2024-01-10 21:57:32,156 - GAugM EPNet train, Epoch [ 73/285]: loss 0.7209, auc 0.4763, ap 0.4820
2024-01-10 21:57:32,235 - GAugM EPNet train, Epoch [ 74/285]: loss 0.7209, auc 0.3889, ap 0.4777
2024-01-10 21:57:32,308 - GAugM EPNet train, Epoch [ 75/285]: loss 0.7210, auc 0.4503, ap 0.4736
2024-01-10 21:57:32,385 - GAugM EPNet train, Epoch [ 76/285]: loss 0.7209, auc 0.4496, ap 0.4706
2024-01-10 21:57:32,462 - GAugM EPNet train, Epoch [ 77/285]: loss 0.7208, auc 0.6007, ap 0.5943
2024-01-10 21:57:32,540 - GAugM EPNet train, Epoch [ 78/285]: loss 0.7209, auc 0.5335, ap 0.5322
2024-01-10 21:57:32,618 - GAugM EPNet train, Epoch [ 79/285]: loss 0.7208, auc 0.4861, ap 0.4870
2024-01-10 21:57:32,700 - GAugM EPNet train, Epoch [ 80/285]: loss 0.7209, auc 0.5408, ap 0.5340
2024-01-10 21:57:32,775 - GAugM EPNet train, Epoch [ 81/285]: loss 0.7209, auc 0.4938, ap 0.4969
2024-01-10 21:57:32,851 - GAugM EPNet train, Epoch [ 82/285]: loss 0.7210, auc 0.4681, ap 0.4878
2024-01-10 21:57:32,927 - GAugM EPNet train, Epoch [ 83/285]: loss 0.7209, auc 0.4662, ap 0.5114
2024-01-10 21:57:33,006 - GAugM EPNet train, Epoch [ 84/285]: loss 0.7209, auc 0.3953, ap 0.4506
2024-01-10 21:57:33,083 - GAugM EPNet train, Epoch [ 85/285]: loss 0.7210, auc 0.3868, ap 0.4587
2024-01-10 21:57:33,162 - GAugM EPNet train, Epoch [ 86/285]: loss 0.7208, auc 0.5541, ap 0.5532
2024-01-10 21:57:33,235 - GAugM EPNet train, Epoch [ 87/285]: loss 0.7209, auc 0.4897, ap 0.5050
2024-01-10 21:57:33,310 - GAugM EPNet train, Epoch [ 88/285]: loss 0.7210, auc 0.4546, ap 0.4832
2024-01-10 21:57:33,388 - GAugM EPNet train, Epoch [ 89/285]: loss 0.7210, auc 0.5205, ap 0.5622
2024-01-10 21:57:33,467 - GAugM EPNet train, Epoch [ 90/285]: loss 0.7209, auc 0.4518, ap 0.4864
2024-01-10 21:57:33,542 - GAugM EPNet train, Epoch [ 91/285]: loss 0.7208, auc 0.6137, ap 0.5777
2024-01-10 21:57:33,617 - GAugM EPNet train, Epoch [ 92/285]: loss 0.7209, auc 0.5895, ap 0.5917
2024-01-10 21:57:33,690 - GAugM EPNet train, Epoch [ 93/285]: loss 0.7209, auc 0.3993, ap 0.4759
2024-01-10 21:57:33,763 - GAugM EPNet train, Epoch [ 94/285]: loss 0.7210, auc 0.4423, ap 0.5233
2024-01-10 21:57:33,843 - GAugM EPNet train, Epoch [ 95/285]: loss 0.7210, auc 0.4977, ap 0.5183
2024-01-10 21:57:33,915 - GAugM EPNet train, Epoch [ 96/285]: loss 0.7209, auc 0.4874, ap 0.5142
2024-01-10 21:57:33,991 - GAugM EPNet train, Epoch [ 97/285]: loss 0.7209, auc 0.4749, ap 0.5088
2024-01-10 21:57:34,068 - GAugM EPNet train, Epoch [ 98/285]: loss 0.7209, auc 0.4923, ap 0.5003
2024-01-10 21:57:34,146 - GAugM EPNet train, Epoch [ 99/285]: loss 0.7209, auc 0.4729, ap 0.5245
2024-01-10 21:57:34,224 - GAugM EPNet train, Epoch [100/285]: loss 0.7210, auc 0.4749, ap 0.4953
2024-01-10 21:57:34,304 - GAugM EPNet train, Epoch [101/285]: loss 0.7210, auc 0.4213, ap 0.4951
2024-01-10 21:57:34,384 - GAugM EPNet train, Epoch [102/285]: loss 0.7209, auc 0.4753, ap 0.4856
2024-01-10 21:57:34,461 - GAugM EPNet train, Epoch [103/285]: loss 0.7209, auc 0.5543, ap 0.5694
2024-01-10 21:57:34,538 - GAugM EPNet train, Epoch [104/285]: loss 0.7209, auc 0.4724, ap 0.4863
2024-01-10 21:57:34,614 - GAugM EPNet train, Epoch [105/285]: loss 0.7209, auc 0.4138, ap 0.4758
2024-01-10 21:57:34,691 - GAugM EPNet train, Epoch [106/285]: loss 0.7210, auc 0.4571, ap 0.4677
2024-01-10 21:57:34,767 - GAugM EPNet train, Epoch [107/285]: loss 0.7210, auc 0.4114, ap 0.4435
2024-01-10 21:57:34,843 - GAugM EPNet train, Epoch [108/285]: loss 0.7208, auc 0.4721, ap 0.4754
2024-01-10 21:57:34,920 - GAugM EPNet train, Epoch [109/285]: loss 0.7210, auc 0.4393, ap 0.4791
2024-01-10 21:57:34,994 - GAugM EPNet train, Epoch [110/285]: loss 0.7209, auc 0.3978, ap 0.4808
2024-01-10 21:57:35,087 - GAugM EPNet train, Epoch [111/285]: loss 0.7210, auc 0.5077, ap 0.5045
2024-01-10 21:57:35,165 - GAugM EPNet train, Epoch [112/285]: loss 0.7209, auc 0.4432, ap 0.4859
2024-01-10 21:57:35,249 - GAugM EPNet train, Epoch [113/285]: loss 0.7210, auc 0.5089, ap 0.5420
2024-01-10 21:57:35,325 - GAugM EPNet train, Epoch [114/285]: loss 0.7209, auc 0.4080, ap 0.4495
2024-01-10 21:57:35,401 - GAugM EPNet train, Epoch [115/285]: loss 0.7210, auc 0.4462, ap 0.4869
2024-01-10 21:57:35,477 - GAugM EPNet train, Epoch [116/285]: loss 0.7209, auc 0.5457, ap 0.5921
2024-01-10 21:57:35,559 - GAugM EPNet train, Epoch [117/285]: loss 0.7208, auc 0.4745, ap 0.5049
2024-01-10 21:57:35,635 - GAugM EPNet train, Epoch [118/285]: loss 0.7209, auc 0.4555, ap 0.4952
2024-01-10 21:57:35,706 - GAugM EPNet train, Epoch [119/285]: loss 0.7209, auc 0.5052, ap 0.5607
2024-01-10 21:57:35,792 - GAugM EPNet train, Epoch [120/285]: loss 0.7210, auc 0.4527, ap 0.4944
2024-01-10 21:57:35,869 - GAugM EPNet train, Epoch [121/285]: loss 0.7210, auc 0.4455, ap 0.4831
2024-01-10 21:57:35,960 - GAugM EPNet train, Epoch [122/285]: loss 0.7209, auc 0.4069, ap 0.4507
2024-01-10 21:57:36,038 - GAugM EPNet train, Epoch [123/285]: loss 0.7209, auc 0.5773, ap 0.5799
2024-01-10 21:57:36,113 - GAugM EPNet train, Epoch [124/285]: loss 0.7210, auc 0.4560, ap 0.4900
2024-01-10 21:57:36,188 - GAugM EPNet train, Epoch [125/285]: loss 0.7209, auc 0.6084, ap 0.5681
2024-01-10 21:57:36,263 - GAugM EPNet train, Epoch [126/285]: loss 0.7210, auc 0.4934, ap 0.4973
2024-01-10 21:57:36,338 - GAugM EPNet train, Epoch [127/285]: loss 0.7209, auc 0.5358, ap 0.5323
2024-01-10 21:57:36,411 - GAugM EPNet train, Epoch [128/285]: loss 0.7210, auc 0.5646, ap 0.5312
2024-01-10 21:57:36,485 - GAugM EPNet train, Epoch [129/285]: loss 0.7208, auc 0.3895, ap 0.4577
2024-01-10 21:57:36,558 - GAugM EPNet train, Epoch [130/285]: loss 0.7210, auc 0.5048, ap 0.5328
2024-01-10 21:57:36,639 - GAugM EPNet train, Epoch [131/285]: loss 0.7210, auc 0.4995, ap 0.6018
2024-01-10 21:57:36,722 - GAugM EPNet train, Epoch [132/285]: loss 0.7209, auc 0.6040, ap 0.5820
2024-01-10 21:57:36,802 - GAugM EPNet train, Epoch [133/285]: loss 0.7209, auc 0.4699, ap 0.5269
2024-01-10 21:57:36,882 - GAugM EPNet train, Epoch [134/285]: loss 0.7210, auc 0.4637, ap 0.4867
2024-01-10 21:57:36,965 - GAugM EPNet train, Epoch [135/285]: loss 0.7209, auc 0.4279, ap 0.4718
2024-01-10 21:57:37,041 - GAugM EPNet train, Epoch [136/285]: loss 0.7209, auc 0.4724, ap 0.4780
2024-01-10 21:57:37,117 - GAugM EPNet train, Epoch [137/285]: loss 0.7210, auc 0.4475, ap 0.4833
2024-01-10 21:57:37,193 - GAugM EPNet train, Epoch [138/285]: loss 0.7210, auc 0.4785, ap 0.4795
2024-01-10 21:57:37,268 - GAugM EPNet train, Epoch [139/285]: loss 0.7210, auc 0.5566, ap 0.5569
2024-01-10 21:57:37,346 - GAugM EPNet train, Epoch [140/285]: loss 0.7209, auc 0.5036, ap 0.5622
2024-01-10 21:57:37,423 - GAugM EPNet train, Epoch [141/285]: loss 0.7209, auc 0.5618, ap 0.5404
2024-01-10 21:57:37,499 - GAugM EPNet train, Epoch [142/285]: loss 0.7209, auc 0.5564, ap 0.5801
2024-01-10 21:57:37,578 - GAugM EPNet train, Epoch [143/285]: loss 0.7209, auc 0.4178, ap 0.4603
2024-01-10 21:57:37,654 - GAugM EPNet train, Epoch [144/285]: loss 0.7209, auc 0.3718, ap 0.4212
2024-01-10 21:57:37,730 - GAugM EPNet train, Epoch [145/285]: loss 0.7209, auc 0.5616, ap 0.5788
2024-01-10 21:57:37,804 - GAugM EPNet train, Epoch [146/285]: loss 0.7209, auc 0.5174, ap 0.5447
2024-01-10 21:57:37,880 - GAugM EPNet train, Epoch [147/285]: loss 0.7209, auc 0.6397, ap 0.6543
2024-01-10 21:57:37,955 - GAugM EPNet train, Epoch [148/285]: loss 0.7209, auc 0.3960, ap 0.4534
2024-01-10 21:57:38,034 - GAugM EPNet train, Epoch [149/285]: loss 0.7208, auc 0.4489, ap 0.4712
2024-01-10 21:57:38,107 - GAugM EPNet train, Epoch [150/285]: loss 0.7209, auc 0.5344, ap 0.5575
2024-01-10 21:57:38,181 - GAugM EPNet train, Epoch [151/285]: loss 0.7209, auc 0.5133, ap 0.5345
2024-01-10 21:57:38,259 - GAugM EPNet train, Epoch [152/285]: loss 0.7209, auc 0.5427, ap 0.5248
2024-01-10 21:57:38,339 - GAugM EPNet train, Epoch [153/285]: loss 0.7209, auc 0.4685, ap 0.4815
2024-01-10 21:57:38,415 - GAugM EPNet train, Epoch [154/285]: loss 0.7209, auc 0.6173, ap 0.6772
2024-01-10 21:57:38,488 - GAugM EPNet train, Epoch [155/285]: loss 0.7209, auc 0.5288, ap 0.5548
2024-01-10 21:57:38,561 - GAugM EPNet train, Epoch [156/285]: loss 0.7209, auc 0.4258, ap 0.4452
2024-01-10 21:57:38,637 - GAugM EPNet train, Epoch [157/285]: loss 0.7209, auc 0.5041, ap 0.4948
2024-01-10 21:57:38,713 - GAugM EPNet train, Epoch [158/285]: loss 0.7208, auc 0.4735, ap 0.4950
2024-01-10 21:57:38,788 - GAugM EPNet train, Epoch [159/285]: loss 0.7208, auc 0.4612, ap 0.4755
2024-01-10 21:57:38,872 - GAugM EPNet train, Epoch [160/285]: loss 0.7209, auc 0.5906, ap 0.6003
2024-01-10 21:57:38,948 - GAugM EPNet train, Epoch [161/285]: loss 0.7209, auc 0.5395, ap 0.5651
2024-01-10 21:57:39,024 - GAugM EPNet train, Epoch [162/285]: loss 0.7209, auc 0.4765, ap 0.4899
2024-01-10 21:57:39,104 - GAugM EPNet train, Epoch [163/285]: loss 0.7209, auc 0.4817, ap 0.4980
2024-01-10 21:57:39,178 - GAugM EPNet train, Epoch [164/285]: loss 0.7211, auc 0.5171, ap 0.4983
2024-01-10 21:57:39,256 - GAugM EPNet train, Epoch [165/285]: loss 0.7210, auc 0.4710, ap 0.5091
2024-01-10 21:57:39,335 - GAugM EPNet train, Epoch [166/285]: loss 0.7208, auc 0.5584, ap 0.5432
2024-01-10 21:57:39,412 - GAugM EPNet train, Epoch [167/285]: loss 0.7209, auc 0.4632, ap 0.4957
2024-01-10 21:57:39,496 - GAugM EPNet train, Epoch [168/285]: loss 0.7209, auc 0.4639, ap 0.5172
2024-01-10 21:57:39,573 - GAugM EPNet train, Epoch [169/285]: loss 0.7209, auc 0.4993, ap 0.5256
2024-01-10 21:57:39,649 - GAugM EPNet train, Epoch [170/285]: loss 0.7210, auc 0.4956, ap 0.4895
2024-01-10 21:57:39,725 - GAugM EPNet train, Epoch [171/285]: loss 0.7209, auc 0.4160, ap 0.4586
2024-01-10 21:57:39,801 - GAugM EPNet train, Epoch [172/285]: loss 0.7208, auc 0.4432, ap 0.4628
2024-01-10 21:57:39,875 - GAugM EPNet train, Epoch [173/285]: loss 0.7209, auc 0.4950, ap 0.5404
2024-01-10 21:57:39,958 - GAugM EPNet train, Epoch [174/285]: loss 0.7209, auc 0.4886, ap 0.4920
2024-01-10 21:57:40,032 - GAugM EPNet train, Epoch [175/285]: loss 0.7209, auc 0.5671, ap 0.5512
2024-01-10 21:57:40,110 - GAugM EPNet train, Epoch [176/285]: loss 0.7209, auc 0.4648, ap 0.4838
2024-01-10 21:57:40,188 - GAugM EPNet train, Epoch [177/285]: loss 0.7210, auc 0.5044, ap 0.5018
2024-01-10 21:57:40,274 - GAugM EPNet train, Epoch [178/285]: loss 0.7210, auc 0.5477, ap 0.5612
2024-01-10 21:57:40,351 - GAugM EPNet train, Epoch [179/285]: loss 0.7210, auc 0.4423, ap 0.5016
2024-01-10 21:57:40,428 - GAugM EPNet train, Epoch [180/285]: loss 0.7210, auc 0.5368, ap 0.5695
2024-01-10 21:57:40,516 - GAugM EPNet train, Epoch [181/285]: loss 0.7209, auc 0.4632, ap 0.4810
2024-01-10 21:57:40,594 - GAugM EPNet train, Epoch [182/285]: loss 0.7209, auc 0.4578, ap 0.4938
2024-01-10 21:57:40,684 - GAugM EPNet train, Epoch [183/285]: loss 0.7210, auc 0.5910, ap 0.5970
2024-01-10 21:57:40,761 - GAugM EPNet train, Epoch [184/285]: loss 0.7209, auc 0.5128, ap 0.5108
2024-01-10 21:57:40,838 - GAugM EPNet train, Epoch [185/285]: loss 0.7209, auc 0.5032, ap 0.5190
2024-01-10 21:57:40,914 - GAugM EPNet train, Epoch [186/285]: loss 0.7208, auc 0.4744, ap 0.5444
2024-01-10 21:57:40,995 - GAugM EPNet train, Epoch [187/285]: loss 0.7209, auc 0.4963, ap 0.5124
2024-01-10 21:57:41,073 - GAugM EPNet train, Epoch [188/285]: loss 0.7209, auc 0.4988, ap 0.4818
2024-01-10 21:57:41,155 - GAugM EPNet train, Epoch [189/285]: loss 0.7209, auc 0.5182, ap 0.5553
2024-01-10 21:57:41,233 - GAugM EPNet train, Epoch [190/285]: loss 0.7209, auc 0.4573, ap 0.4646
2024-01-10 21:57:41,319 - GAugM EPNet train, Epoch [191/285]: loss 0.7209, auc 0.4283, ap 0.5198
2024-01-10 21:57:41,395 - GAugM EPNet train, Epoch [192/285]: loss 0.7209, auc 0.4776, ap 0.4688
2024-01-10 21:57:41,473 - GAugM EPNet train, Epoch [193/285]: loss 0.7209, auc 0.5265, ap 0.5236
2024-01-10 21:57:41,553 - GAugM EPNet train, Epoch [194/285]: loss 0.7209, auc 0.4717, ap 0.5021
2024-01-10 21:57:41,633 - GAugM EPNet train, Epoch [195/285]: loss 0.7209, auc 0.4448, ap 0.5101
2024-01-10 21:57:41,709 - GAugM EPNet train, Epoch [196/285]: loss 0.7208, auc 0.5554, ap 0.5349
2024-01-10 21:57:41,785 - GAugM EPNet train, Epoch [197/285]: loss 0.7210, auc 0.4439, ap 0.4697
2024-01-10 21:57:41,857 - GAugM EPNet train, Epoch [198/285]: loss 0.7210, auc 0.5274, ap 0.5354
2024-01-10 21:57:41,933 - GAugM EPNet train, Epoch [199/285]: loss 0.7209, auc 0.4801, ap 0.5081
2024-01-10 21:57:42,012 - GAugM EPNet train, Epoch [200/285]: loss 0.7210, auc 0.5023, ap 0.4968
2024-01-10 21:57:42,087 - GAugM EPNet train, Epoch [201/285]: loss 0.7209, auc 0.5205, ap 0.5327
2024-01-10 21:57:42,170 - GAugM EPNet train, Epoch [202/285]: loss 0.7210, auc 0.5646, ap 0.5923
2024-01-10 21:57:42,245 - GAugM EPNet train, Epoch [203/285]: loss 0.7210, auc 0.5085, ap 0.5331
2024-01-10 21:57:42,336 - GAugM EPNet train, Epoch [204/285]: loss 0.7209, auc 0.4567, ap 0.4659
2024-01-10 21:57:42,428 - GAugM EPNet train, Epoch [205/285]: loss 0.7209, auc 0.5319, ap 0.5337
2024-01-10 21:57:42,509 - GAugM EPNet train, Epoch [206/285]: loss 0.7209, auc 0.4325, ap 0.4552
2024-01-10 21:57:42,585 - GAugM EPNet train, Epoch [207/285]: loss 0.7210, auc 0.5057, ap 0.5094
2024-01-10 21:57:42,668 - GAugM EPNet train, Epoch [208/285]: loss 0.7209, auc 0.4863, ap 0.5306
2024-01-10 21:57:42,756 - GAugM EPNet train, Epoch [209/285]: loss 0.7210, auc 0.6193, ap 0.5813
2024-01-10 21:57:42,849 - GAugM EPNet train, Epoch [210/285]: loss 0.7209, auc 0.4754, ap 0.4832
2024-01-10 21:57:42,945 - GAugM EPNet train, Epoch [211/285]: loss 0.7210, auc 0.5586, ap 0.5961
2024-01-10 21:57:43,031 - GAugM EPNet train, Epoch [212/285]: loss 0.7210, auc 0.4883, ap 0.5065
2024-01-10 21:57:43,122 - GAugM EPNet train, Epoch [213/285]: loss 0.7208, auc 0.6477, ap 0.6641
2024-01-10 21:57:43,212 - GAugM EPNet train, Epoch [214/285]: loss 0.7210, auc 0.4834, ap 0.5124
2024-01-10 21:57:43,298 - GAugM EPNet train, Epoch [215/285]: loss 0.7210, auc 0.4726, ap 0.4858
2024-01-10 21:57:43,388 - GAugM EPNet train, Epoch [216/285]: loss 0.7209, auc 0.5105, ap 0.5176
2024-01-10 21:57:43,474 - GAugM EPNet train, Epoch [217/285]: loss 0.7209, auc 0.5497, ap 0.5798
2024-01-10 21:57:43,565 - GAugM EPNet train, Epoch [218/285]: loss 0.7209, auc 0.5329, ap 0.5559
2024-01-10 21:57:43,654 - GAugM EPNet train, Epoch [219/285]: loss 0.7208, auc 0.4651, ap 0.4863
2024-01-10 21:57:43,740 - GAugM EPNet train, Epoch [220/285]: loss 0.7210, auc 0.4954, ap 0.5415
2024-01-10 21:57:43,835 - GAugM EPNet train, Epoch [221/285]: loss 0.7209, auc 0.6096, ap 0.5905
2024-01-10 21:57:43,923 - GAugM EPNet train, Epoch [222/285]: loss 0.7209, auc 0.4470, ap 0.4948
2024-01-10 21:57:44,012 - GAugM EPNet train, Epoch [223/285]: loss 0.7209, auc 0.5926, ap 0.6214
2024-01-10 21:57:44,097 - GAugM EPNet train, Epoch [224/285]: loss 0.7210, auc 0.4121, ap 0.4320
2024-01-10 21:57:44,183 - GAugM EPNet train, Epoch [225/285]: loss 0.7209, auc 0.5230, ap 0.5377
2024-01-10 21:57:44,268 - GAugM EPNet train, Epoch [226/285]: loss 0.7210, auc 0.4939, ap 0.5289
2024-01-10 21:57:44,357 - GAugM EPNet train, Epoch [227/285]: loss 0.7210, auc 0.5319, ap 0.5403
2024-01-10 21:57:44,443 - GAugM EPNet train, Epoch [228/285]: loss 0.7209, auc 0.4758, ap 0.4764
2024-01-10 21:57:44,528 - GAugM EPNet train, Epoch [229/285]: loss 0.7209, auc 0.5235, ap 0.5448
2024-01-10 21:57:44,611 - GAugM EPNet train, Epoch [230/285]: loss 0.7209, auc 0.4523, ap 0.4724
2024-01-10 21:57:44,698 - GAugM EPNet train, Epoch [231/285]: loss 0.7209, auc 0.4838, ap 0.5091
2024-01-10 21:57:44,794 - GAugM EPNet train, Epoch [232/285]: loss 0.7209, auc 0.5486, ap 0.5345
2024-01-10 21:57:44,880 - GAugM EPNet train, Epoch [233/285]: loss 0.7210, auc 0.5080, ap 0.5549
2024-01-10 21:57:44,966 - GAugM EPNet train, Epoch [234/285]: loss 0.7209, auc 0.3998, ap 0.4483
2024-01-10 21:57:45,051 - GAugM EPNet train, Epoch [235/285]: loss 0.7209, auc 0.5342, ap 0.5373
2024-01-10 21:57:45,135 - GAugM EPNet train, Epoch [236/285]: loss 0.7209, auc 0.5112, ap 0.5417
2024-01-10 21:57:45,221 - GAugM EPNet train, Epoch [237/285]: loss 0.7210, auc 0.5025, ap 0.5293
2024-01-10 21:57:45,307 - GAugM EPNet train, Epoch [238/285]: loss 0.7210, auc 0.4712, ap 0.4893
2024-01-10 21:57:45,392 - GAugM EPNet train, Epoch [239/285]: loss 0.7209, auc 0.5740, ap 0.6251
2024-01-10 21:57:45,478 - GAugM EPNet train, Epoch [240/285]: loss 0.7209, auc 0.5408, ap 0.5229
2024-01-10 21:57:45,575 - GAugM EPNet train, Epoch [241/285]: loss 0.7209, auc 0.5336, ap 0.5533
2024-01-10 21:57:45,662 - GAugM EPNet train, Epoch [242/285]: loss 0.7210, auc 0.4875, ap 0.5261
2024-01-10 21:57:45,750 - GAugM EPNet train, Epoch [243/285]: loss 0.7210, auc 0.5349, ap 0.5927
2024-01-10 21:57:45,836 - GAugM EPNet train, Epoch [244/285]: loss 0.7209, auc 0.4956, ap 0.4990
2024-01-10 21:57:45,921 - GAugM EPNet train, Epoch [245/285]: loss 0.7210, auc 0.4528, ap 0.4805
2024-01-10 21:57:46,006 - GAugM EPNet train, Epoch [246/285]: loss 0.7208, auc 0.4521, ap 0.4841
2024-01-10 21:57:46,090 - GAugM EPNet train, Epoch [247/285]: loss 0.7209, auc 0.5244, ap 0.5534
2024-01-10 21:57:46,174 - GAugM EPNet train, Epoch [248/285]: loss 0.7211, auc 0.5386, ap 0.5459
2024-01-10 21:57:46,259 - GAugM EPNet train, Epoch [249/285]: loss 0.7209, auc 0.4215, ap 0.4615
2024-01-10 21:57:46,353 - GAugM EPNet train, Epoch [250/285]: loss 0.7208, auc 0.4959, ap 0.5165
2024-01-10 21:57:46,438 - GAugM EPNet train, Epoch [251/285]: loss 0.7209, auc 0.4277, ap 0.4628
2024-01-10 21:57:46,524 - GAugM EPNet train, Epoch [252/285]: loss 0.7210, auc 0.5123, ap 0.5727
2024-01-10 21:57:46,608 - GAugM EPNet train, Epoch [253/285]: loss 0.7209, auc 0.5546, ap 0.5421
2024-01-10 21:57:46,693 - GAugM EPNet train, Epoch [254/285]: loss 0.7210, auc 0.5137, ap 0.5198
2024-01-10 21:57:46,779 - GAugM EPNet train, Epoch [255/285]: loss 0.7209, auc 0.4934, ap 0.5536
2024-01-10 21:57:46,864 - GAugM EPNet train, Epoch [256/285]: loss 0.7210, auc 0.4411, ap 0.5188
2024-01-10 21:57:46,949 - GAugM EPNet train, Epoch [257/285]: loss 0.7210, auc 0.5773, ap 0.5787
2024-01-10 21:57:47,038 - GAugM EPNet train, Epoch [258/285]: loss 0.7208, auc 0.4669, ap 0.5044
2024-01-10 21:57:47,123 - GAugM EPNet train, Epoch [259/285]: loss 0.7208, auc 0.6080, ap 0.6136
2024-01-10 21:57:47,209 - GAugM EPNet train, Epoch [260/285]: loss 0.7210, auc 0.4877, ap 0.5181
2024-01-10 21:57:47,294 - GAugM EPNet train, Epoch [261/285]: loss 0.7209, auc 0.3688, ap 0.4322
2024-01-10 21:57:47,384 - GAugM EPNet train, Epoch [262/285]: loss 0.7208, auc 0.5044, ap 0.5163
2024-01-10 21:57:47,469 - GAugM EPNet train, Epoch [263/285]: loss 0.7209, auc 0.5114, ap 0.5168
2024-01-10 21:57:47,555 - GAugM EPNet train, Epoch [264/285]: loss 0.7210, auc 0.4891, ap 0.4989
2024-01-10 21:57:47,641 - GAugM EPNet train, Epoch [265/285]: loss 0.7209, auc 0.5342, ap 0.5939
2024-01-10 21:57:47,734 - GAugM EPNet train, Epoch [266/285]: loss 0.7209, auc 0.4911, ap 0.4990
2024-01-10 21:57:47,837 - GAugM EPNet train, Epoch [267/285]: loss 0.7210, auc 0.4311, ap 0.4694
2024-01-10 21:57:47,931 - GAugM EPNet train, Epoch [268/285]: loss 0.7210, auc 0.4854, ap 0.5257
2024-01-10 21:57:48,023 - GAugM EPNet train, Epoch [269/285]: loss 0.7209, auc 0.5684, ap 0.5840
2024-01-10 21:57:48,119 - GAugM EPNet train, Epoch [270/285]: loss 0.7210, auc 0.4662, ap 0.5089
2024-01-10 21:57:48,208 - GAugM EPNet train, Epoch [271/285]: loss 0.7209, auc 0.4772, ap 0.5106
2024-01-10 21:57:48,296 - GAugM EPNet train, Epoch [272/285]: loss 0.7209, auc 0.4781, ap 0.5103
2024-01-10 21:57:48,385 - GAugM EPNet train, Epoch [273/285]: loss 0.7209, auc 0.4514, ap 0.4842
2024-01-10 21:57:48,475 - GAugM EPNet train, Epoch [274/285]: loss 0.7209, auc 0.4229, ap 0.4500
2024-01-10 21:57:48,562 - GAugM EPNet train, Epoch [275/285]: loss 0.7208, auc 0.4701, ap 0.4945
2024-01-10 21:57:48,650 - GAugM EPNet train, Epoch [276/285]: loss 0.7210, auc 0.5272, ap 0.5623
2024-01-10 21:57:48,743 - GAugM EPNet train, Epoch [277/285]: loss 0.7208, auc 0.4215, ap 0.4601
2024-01-10 21:57:48,834 - GAugM EPNet train, Epoch [278/285]: loss 0.7209, auc 0.5607, ap 0.5951
2024-01-10 21:57:48,921 - GAugM EPNet train, Epoch [279/285]: loss 0.7209, auc 0.4356, ap 0.4954
2024-01-10 21:57:49,009 - GAugM EPNet train, Epoch [280/285]: loss 0.7209, auc 0.4735, ap 0.4698
2024-01-10 21:57:49,098 - GAugM EPNet train, Epoch [281/285]: loss 0.7209, auc 0.5853, ap 0.5728
2024-01-10 21:57:49,187 - GAugM EPNet train, Epoch [282/285]: loss 0.7209, auc 0.5311, ap 0.5075
2024-01-10 21:57:49,275 - GAugM EPNet train, Epoch [283/285]: loss 0.7209, auc 0.4674, ap 0.4859
2024-01-10 21:57:49,360 - GAugM EPNet train, Epoch [284/285]: loss 0.7209, auc 0.4719, ap 0.4841
2024-01-10 21:57:49,456 - GAugM EPNet train, Epoch [285/285]: loss 0.7209, auc 0.4858, ap 0.4820
2024-01-10 21:57:49,457 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9e0c190>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:57:50,257 - GAugM EPNet train, Epoch [  1/285]: loss 0.7210, auc 0.4781, ap 0.4636
2024-01-10 21:57:50,354 - GAugM EPNet train, Epoch [  2/285]: loss 0.7210, auc 0.5101, ap 0.4928
2024-01-10 21:57:50,458 - GAugM EPNet train, Epoch [  3/285]: loss 0.7209, auc 0.5427, ap 0.5248
2024-01-10 21:57:50,555 - GAugM EPNet train, Epoch [  4/285]: loss 0.7209, auc 0.5237, ap 0.5512
2024-01-10 21:57:50,648 - GAugM EPNet train, Epoch [  5/285]: loss 0.7209, auc 0.5712, ap 0.5345
2024-01-10 21:57:50,739 - GAugM EPNet train, Epoch [  6/285]: loss 0.7209, auc 0.4744, ap 0.4946
2024-01-10 21:57:50,835 - GAugM EPNet train, Epoch [  7/285]: loss 0.7209, auc 0.3690, ap 0.4154
2024-01-10 21:57:50,924 - GAugM EPNet train, Epoch [  8/285]: loss 0.7210, auc 0.4381, ap 0.4539
2024-01-10 21:57:51,014 - GAugM EPNet train, Epoch [  9/285]: loss 0.7209, auc 0.4790, ap 0.4869
2024-01-10 21:57:51,103 - GAugM EPNet train, Epoch [ 10/285]: loss 0.7208, auc 0.5085, ap 0.5080
2024-01-10 21:57:51,194 - GAugM EPNet train, Epoch [ 11/285]: loss 0.7209, auc 0.4366, ap 0.4826
2024-01-10 21:57:51,286 - GAugM EPNet train, Epoch [ 12/285]: loss 0.7210, auc 0.4414, ap 0.4825
2024-01-10 21:57:51,374 - GAugM EPNet train, Epoch [ 13/285]: loss 0.7209, auc 0.5303, ap 0.5412
2024-01-10 21:57:51,471 - GAugM EPNet train, Epoch [ 14/285]: loss 0.7209, auc 0.5224, ap 0.4985
2024-01-10 21:57:51,569 - GAugM EPNet train, Epoch [ 15/285]: loss 0.7210, auc 0.3969, ap 0.4418
2024-01-10 21:57:51,658 - GAugM EPNet train, Epoch [ 16/285]: loss 0.7209, auc 0.5052, ap 0.5124
2024-01-10 21:57:51,746 - GAugM EPNet train, Epoch [ 17/285]: loss 0.7210, auc 0.5372, ap 0.4903
2024-01-10 21:57:51,842 - GAugM EPNet train, Epoch [ 18/285]: loss 0.7210, auc 0.5283, ap 0.5321
2024-01-10 21:57:51,930 - GAugM EPNet train, Epoch [ 19/285]: loss 0.7209, auc 0.4948, ap 0.4869
2024-01-10 21:57:52,019 - GAugM EPNet train, Epoch [ 20/285]: loss 0.7210, auc 0.4943, ap 0.4818
2024-01-10 21:57:52,109 - GAugM EPNet train, Epoch [ 21/285]: loss 0.7209, auc 0.5073, ap 0.5011
2024-01-10 21:57:52,201 - GAugM EPNet train, Epoch [ 22/285]: loss 0.7210, auc 0.3930, ap 0.4329
2024-01-10 21:57:52,291 - GAugM EPNet train, Epoch [ 23/285]: loss 0.7208, auc 0.4507, ap 0.4602
2024-01-10 21:57:52,382 - GAugM EPNet train, Epoch [ 24/285]: loss 0.7209, auc 0.5425, ap 0.5097
2024-01-10 21:57:52,470 - GAugM EPNet train, Epoch [ 25/285]: loss 0.7209, auc 0.4288, ap 0.4657
2024-01-10 21:57:52,565 - GAugM EPNet train, Epoch [ 26/285]: loss 0.7210, auc 0.5304, ap 0.5036
2024-01-10 21:57:52,657 - GAugM EPNet train, Epoch [ 27/285]: loss 0.7209, auc 0.3786, ap 0.4204
2024-01-10 21:57:52,750 - GAugM EPNet train, Epoch [ 28/285]: loss 0.7209, auc 0.6057, ap 0.5786
2024-01-10 21:57:52,838 - GAugM EPNet train, Epoch [ 29/285]: loss 0.7210, auc 0.5744, ap 0.5450
2024-01-10 21:57:52,925 - GAugM EPNet train, Epoch [ 30/285]: loss 0.7209, auc 0.4559, ap 0.4688
2024-01-10 21:57:53,021 - GAugM EPNet train, Epoch [ 31/285]: loss 0.7208, auc 0.4767, ap 0.5006
2024-01-10 21:57:53,112 - GAugM EPNet train, Epoch [ 32/285]: loss 0.7210, auc 0.6169, ap 0.5759
2024-01-10 21:57:53,209 - GAugM EPNet train, Epoch [ 33/285]: loss 0.7209, auc 0.5292, ap 0.5222
2024-01-10 21:57:53,296 - GAugM EPNet train, Epoch [ 34/285]: loss 0.7209, auc 0.4539, ap 0.4713
2024-01-10 21:57:53,386 - GAugM EPNet train, Epoch [ 35/285]: loss 0.7209, auc 0.5676, ap 0.5463
2024-01-10 21:57:53,478 - GAugM EPNet train, Epoch [ 36/285]: loss 0.7209, auc 0.5799, ap 0.5549
2024-01-10 21:57:53,564 - GAugM EPNet train, Epoch [ 37/285]: loss 0.7209, auc 0.4916, ap 0.5005
2024-01-10 21:57:53,649 - GAugM EPNet train, Epoch [ 38/285]: loss 0.7209, auc 0.4827, ap 0.4819
2024-01-10 21:57:53,736 - GAugM EPNet train, Epoch [ 39/285]: loss 0.7208, auc 0.4462, ap 0.4617
2024-01-10 21:57:53,822 - GAugM EPNet train, Epoch [ 40/285]: loss 0.7210, auc 0.5404, ap 0.5202
2024-01-10 21:57:53,908 - GAugM EPNet train, Epoch [ 41/285]: loss 0.7210, auc 0.4982, ap 0.5121
2024-01-10 21:57:53,995 - GAugM EPNet train, Epoch [ 42/285]: loss 0.7209, auc 0.4904, ap 0.5326
2024-01-10 21:57:54,081 - GAugM EPNet train, Epoch [ 43/285]: loss 0.7208, auc 0.4176, ap 0.4453
2024-01-10 21:57:54,165 - GAugM EPNet train, Epoch [ 44/285]: loss 0.7208, auc 0.3937, ap 0.4254
2024-01-10 21:57:54,254 - GAugM EPNet train, Epoch [ 45/285]: loss 0.7209, auc 0.5525, ap 0.5385
2024-01-10 21:57:54,341 - GAugM EPNet train, Epoch [ 46/285]: loss 0.7209, auc 0.4078, ap 0.4523
2024-01-10 21:57:54,431 - GAugM EPNet train, Epoch [ 47/285]: loss 0.7210, auc 0.4174, ap 0.4303
2024-01-10 21:57:54,522 - GAugM EPNet train, Epoch [ 48/285]: loss 0.7210, auc 0.6029, ap 0.6155
2024-01-10 21:57:54,610 - GAugM EPNet train, Epoch [ 49/285]: loss 0.7209, auc 0.5676, ap 0.5672
2024-01-10 21:57:54,699 - GAugM EPNet train, Epoch [ 50/285]: loss 0.7210, auc 0.5856, ap 0.5504
2024-01-10 21:57:54,790 - GAugM EPNet train, Epoch [ 51/285]: loss 0.7210, auc 0.4391, ap 0.4432
2024-01-10 21:57:54,880 - GAugM EPNet train, Epoch [ 52/285]: loss 0.7209, auc 0.4398, ap 0.4398
2024-01-10 21:57:54,966 - GAugM EPNet train, Epoch [ 53/285]: loss 0.7209, auc 0.5306, ap 0.5335
2024-01-10 21:57:55,055 - GAugM EPNet train, Epoch [ 54/285]: loss 0.7211, auc 0.6132, ap 0.5712
2024-01-10 21:57:55,141 - GAugM EPNet train, Epoch [ 55/285]: loss 0.7209, auc 0.5117, ap 0.5252
2024-01-10 21:57:55,230 - GAugM EPNet train, Epoch [ 56/285]: loss 0.7208, auc 0.5495, ap 0.5438
2024-01-10 21:57:55,322 - GAugM EPNet train, Epoch [ 57/285]: loss 0.7209, auc 0.4605, ap 0.4531
2024-01-10 21:57:55,419 - GAugM EPNet train, Epoch [ 58/285]: loss 0.7210, auc 0.5434, ap 0.5631
2024-01-10 21:57:55,514 - GAugM EPNet train, Epoch [ 59/285]: loss 0.7211, auc 0.5112, ap 0.4990
2024-01-10 21:57:55,601 - GAugM EPNet train, Epoch [ 60/285]: loss 0.7210, auc 0.5151, ap 0.4986
2024-01-10 21:57:55,693 - GAugM EPNet train, Epoch [ 61/285]: loss 0.7209, auc 0.5671, ap 0.5226
2024-01-10 21:57:55,782 - GAugM EPNet train, Epoch [ 62/285]: loss 0.7210, auc 0.5281, ap 0.5346
2024-01-10 21:57:55,867 - GAugM EPNet train, Epoch [ 63/285]: loss 0.7208, auc 0.4518, ap 0.4499
2024-01-10 21:57:55,959 - GAugM EPNet train, Epoch [ 64/285]: loss 0.7208, auc 0.4870, ap 0.5146
2024-01-10 21:57:56,046 - GAugM EPNet train, Epoch [ 65/285]: loss 0.7208, auc 0.6171, ap 0.5908
2024-01-10 21:57:56,136 - GAugM EPNet train, Epoch [ 66/285]: loss 0.7209, auc 0.4391, ap 0.4578
2024-01-10 21:57:56,222 - GAugM EPNet train, Epoch [ 67/285]: loss 0.7209, auc 0.5297, ap 0.5175
2024-01-10 21:57:56,308 - GAugM EPNet train, Epoch [ 68/285]: loss 0.7210, auc 0.5032, ap 0.4954
2024-01-10 21:57:56,400 - GAugM EPNet train, Epoch [ 69/285]: loss 0.7210, auc 0.5571, ap 0.5511
2024-01-10 21:57:56,485 - GAugM EPNet train, Epoch [ 70/285]: loss 0.7210, auc 0.4906, ap 0.4848
2024-01-10 21:57:56,571 - GAugM EPNet train, Epoch [ 71/285]: loss 0.7210, auc 0.5438, ap 0.5115
2024-01-10 21:57:56,657 - GAugM EPNet train, Epoch [ 72/285]: loss 0.7210, auc 0.3688, ap 0.4347
2024-01-10 21:57:56,743 - GAugM EPNet train, Epoch [ 73/285]: loss 0.7209, auc 0.5089, ap 0.4779
2024-01-10 21:57:56,829 - GAugM EPNet train, Epoch [ 74/285]: loss 0.7209, auc 0.4786, ap 0.4904
2024-01-10 21:57:56,914 - GAugM EPNet train, Epoch [ 75/285]: loss 0.7210, auc 0.4701, ap 0.5037
2024-01-10 21:57:56,998 - GAugM EPNet train, Epoch [ 76/285]: loss 0.7209, auc 0.3839, ap 0.4167
2024-01-10 21:57:57,085 - GAugM EPNet train, Epoch [ 77/285]: loss 0.7208, auc 0.6072, ap 0.5833
2024-01-10 21:57:57,170 - GAugM EPNet train, Epoch [ 78/285]: loss 0.7209, auc 0.4879, ap 0.4745
2024-01-10 21:57:57,257 - GAugM EPNet train, Epoch [ 79/285]: loss 0.7208, auc 0.4822, ap 0.5012
2024-01-10 21:57:57,348 - GAugM EPNet train, Epoch [ 80/285]: loss 0.7209, auc 0.6054, ap 0.5547
2024-01-10 21:57:57,432 - GAugM EPNet train, Epoch [ 81/285]: loss 0.7209, auc 0.4840, ap 0.4686
2024-01-10 21:57:57,524 - GAugM EPNet train, Epoch [ 82/285]: loss 0.7210, auc 0.4521, ap 0.4572
2024-01-10 21:57:57,619 - GAugM EPNet train, Epoch [ 83/285]: loss 0.7209, auc 0.3706, ap 0.4246
2024-01-10 21:57:57,703 - GAugM EPNet train, Epoch [ 84/285]: loss 0.7209, auc 0.4368, ap 0.4678
2024-01-10 21:57:57,790 - GAugM EPNet train, Epoch [ 85/285]: loss 0.7210, auc 0.4687, ap 0.4834
2024-01-10 21:57:57,874 - GAugM EPNet train, Epoch [ 86/285]: loss 0.7208, auc 0.4717, ap 0.4792
2024-01-10 21:57:57,961 - GAugM EPNet train, Epoch [ 87/285]: loss 0.7209, auc 0.5627, ap 0.5242
2024-01-10 21:57:58,063 - GAugM EPNet train, Epoch [ 88/285]: loss 0.7210, auc 0.4450, ap 0.5004
2024-01-10 21:57:58,158 - GAugM EPNet train, Epoch [ 89/285]: loss 0.7210, auc 0.5431, ap 0.5449
2024-01-10 21:57:58,253 - GAugM EPNet train, Epoch [ 90/285]: loss 0.7209, auc 0.4046, ap 0.4417
2024-01-10 21:57:58,342 - GAugM EPNet train, Epoch [ 91/285]: loss 0.7208, auc 0.5344, ap 0.5152
2024-01-10 21:57:58,430 - GAugM EPNet train, Epoch [ 92/285]: loss 0.7209, auc 0.6155, ap 0.5709
2024-01-10 21:57:58,519 - GAugM EPNet train, Epoch [ 93/285]: loss 0.7209, auc 0.4559, ap 0.4655
2024-01-10 21:57:58,610 - GAugM EPNet train, Epoch [ 94/285]: loss 0.7210, auc 0.4970, ap 0.5156
2024-01-10 21:57:58,701 - GAugM EPNet train, Epoch [ 95/285]: loss 0.7210, auc 0.5023, ap 0.4813
2024-01-10 21:57:58,788 - GAugM EPNet train, Epoch [ 96/285]: loss 0.7209, auc 0.5600, ap 0.5602
2024-01-10 21:57:58,876 - GAugM EPNet train, Epoch [ 97/285]: loss 0.7209, auc 0.5125, ap 0.5251
2024-01-10 21:57:58,965 - GAugM EPNet train, Epoch [ 98/285]: loss 0.7209, auc 0.4135, ap 0.4457
2024-01-10 21:57:59,056 - GAugM EPNet train, Epoch [ 99/285]: loss 0.7209, auc 0.4936, ap 0.4970
2024-01-10 21:57:59,144 - GAugM EPNet train, Epoch [100/285]: loss 0.7210, auc 0.4535, ap 0.4612
2024-01-10 21:57:59,231 - GAugM EPNet train, Epoch [101/285]: loss 0.7210, auc 0.4632, ap 0.4864
2024-01-10 21:57:59,322 - GAugM EPNet train, Epoch [102/285]: loss 0.7209, auc 0.4920, ap 0.4829
2024-01-10 21:57:59,408 - GAugM EPNet train, Epoch [103/285]: loss 0.7209, auc 0.4576, ap 0.4903
2024-01-10 21:57:59,496 - GAugM EPNet train, Epoch [104/285]: loss 0.7209, auc 0.5059, ap 0.4981
2024-01-10 21:57:59,588 - GAugM EPNet train, Epoch [105/285]: loss 0.7209, auc 0.4626, ap 0.4724
2024-01-10 21:57:59,674 - GAugM EPNet train, Epoch [106/285]: loss 0.7210, auc 0.5249, ap 0.5153
2024-01-10 21:57:59,764 - GAugM EPNet train, Epoch [107/285]: loss 0.7210, auc 0.4583, ap 0.4945
2024-01-10 21:57:59,853 - GAugM EPNet train, Epoch [108/285]: loss 0.7208, auc 0.4751, ap 0.5009
2024-01-10 21:57:59,940 - GAugM EPNet train, Epoch [109/285]: loss 0.7210, auc 0.4740, ap 0.4951
2024-01-10 21:58:00,027 - GAugM EPNet train, Epoch [110/285]: loss 0.7209, auc 0.4681, ap 0.4912
2024-01-10 21:58:00,118 - GAugM EPNet train, Epoch [111/285]: loss 0.7210, auc 0.5463, ap 0.5460
2024-01-10 21:58:00,204 - GAugM EPNet train, Epoch [112/285]: loss 0.7209, auc 0.4596, ap 0.4926
2024-01-10 21:58:00,290 - GAugM EPNet train, Epoch [113/285]: loss 0.7210, auc 0.4653, ap 0.4744
2024-01-10 21:58:00,378 - GAugM EPNet train, Epoch [114/285]: loss 0.7209, auc 0.4171, ap 0.4367
2024-01-10 21:58:00,463 - GAugM EPNet train, Epoch [115/285]: loss 0.7210, auc 0.5534, ap 0.5565
2024-01-10 21:58:00,549 - GAugM EPNet train, Epoch [116/285]: loss 0.7209, auc 0.5208, ap 0.5392
2024-01-10 21:58:00,637 - GAugM EPNet train, Epoch [117/285]: loss 0.7208, auc 0.4413, ap 0.4667
2024-01-10 21:58:00,722 - GAugM EPNet train, Epoch [118/285]: loss 0.7209, auc 0.3800, ap 0.4144
2024-01-10 21:58:00,813 - GAugM EPNet train, Epoch [119/285]: loss 0.7209, auc 0.5319, ap 0.5483
2024-01-10 21:58:00,900 - GAugM EPNet train, Epoch [120/285]: loss 0.7210, auc 0.4295, ap 0.4358
2024-01-10 21:58:00,987 - GAugM EPNet train, Epoch [121/285]: loss 0.7210, auc 0.4477, ap 0.4723
2024-01-10 21:58:01,079 - GAugM EPNet train, Epoch [122/285]: loss 0.7209, auc 0.5538, ap 0.5306
2024-01-10 21:58:01,164 - GAugM EPNet train, Epoch [123/285]: loss 0.7209, auc 0.5894, ap 0.5903
2024-01-10 21:58:01,254 - GAugM EPNet train, Epoch [124/285]: loss 0.7210, auc 0.4498, ap 0.4468
2024-01-10 21:58:01,342 - GAugM EPNet train, Epoch [125/285]: loss 0.7209, auc 0.4350, ap 0.4399
2024-01-10 21:58:01,429 - GAugM EPNet train, Epoch [126/285]: loss 0.7210, auc 0.4897, ap 0.4745
2024-01-10 21:58:01,532 - GAugM EPNet train, Epoch [127/285]: loss 0.7209, auc 0.5194, ap 0.5014
2024-01-10 21:58:01,621 - GAugM EPNet train, Epoch [128/285]: loss 0.7210, auc 0.4957, ap 0.4926
2024-01-10 21:58:01,708 - GAugM EPNet train, Epoch [129/285]: loss 0.7208, auc 0.4295, ap 0.4538
2024-01-10 21:58:01,795 - GAugM EPNet train, Epoch [130/285]: loss 0.7210, auc 0.4829, ap 0.4974
2024-01-10 21:58:01,886 - GAugM EPNet train, Epoch [131/285]: loss 0.7210, auc 0.5516, ap 0.5429
2024-01-10 21:58:01,983 - GAugM EPNet train, Epoch [132/285]: loss 0.7209, auc 0.5543, ap 0.5303
2024-01-10 21:58:02,070 - GAugM EPNet train, Epoch [133/285]: loss 0.7209, auc 0.4923, ap 0.5364
2024-01-10 21:58:02,159 - GAugM EPNet train, Epoch [134/285]: loss 0.7210, auc 0.4950, ap 0.4846
2024-01-10 21:58:02,249 - GAugM EPNet train, Epoch [135/285]: loss 0.7209, auc 0.3955, ap 0.4456
2024-01-10 21:58:02,337 - GAugM EPNet train, Epoch [136/285]: loss 0.7209, auc 0.4672, ap 0.4773
2024-01-10 21:58:02,424 - GAugM EPNet train, Epoch [137/285]: loss 0.7210, auc 0.4689, ap 0.4803
2024-01-10 21:58:02,515 - GAugM EPNet train, Epoch [138/285]: loss 0.7210, auc 0.5936, ap 0.5489
2024-01-10 21:58:02,604 - GAugM EPNet train, Epoch [139/285]: loss 0.7210, auc 0.3943, ap 0.4282
2024-01-10 21:58:02,691 - GAugM EPNet train, Epoch [140/285]: loss 0.7209, auc 0.4811, ap 0.5178
2024-01-10 21:58:02,778 - GAugM EPNet train, Epoch [141/285]: loss 0.7209, auc 0.4964, ap 0.4861
2024-01-10 21:58:02,881 - GAugM EPNet train, Epoch [142/285]: loss 0.7209, auc 0.4749, ap 0.4949
2024-01-10 21:58:02,976 - GAugM EPNet train, Epoch [143/285]: loss 0.7209, auc 0.5109, ap 0.5162
2024-01-10 21:58:03,065 - GAugM EPNet train, Epoch [144/285]: loss 0.7209, auc 0.4915, ap 0.4884
2024-01-10 21:58:03,156 - GAugM EPNet train, Epoch [145/285]: loss 0.7209, auc 0.3923, ap 0.4563
2024-01-10 21:58:03,251 - GAugM EPNet train, Epoch [146/285]: loss 0.7209, auc 0.4931, ap 0.4796
2024-01-10 21:58:03,343 - GAugM EPNet train, Epoch [147/285]: loss 0.7209, auc 0.5288, ap 0.5662
2024-01-10 21:58:03,435 - GAugM EPNet train, Epoch [148/285]: loss 0.7209, auc 0.4512, ap 0.4602
2024-01-10 21:58:03,528 - GAugM EPNet train, Epoch [149/285]: loss 0.7208, auc 0.5676, ap 0.5427
2024-01-10 21:58:03,619 - GAugM EPNet train, Epoch [150/285]: loss 0.7209, auc 0.5482, ap 0.5367
2024-01-10 21:58:03,711 - GAugM EPNet train, Epoch [151/285]: loss 0.7209, auc 0.4729, ap 0.4784
2024-01-10 21:58:03,799 - GAugM EPNet train, Epoch [152/285]: loss 0.7209, auc 0.5689, ap 0.5543
2024-01-10 21:58:03,894 - GAugM EPNet train, Epoch [153/285]: loss 0.7209, auc 0.4452, ap 0.4742
2024-01-10 21:58:03,985 - GAugM EPNet train, Epoch [154/285]: loss 0.7209, auc 0.5320, ap 0.5342
2024-01-10 21:58:04,070 - GAugM EPNet train, Epoch [155/285]: loss 0.7209, auc 0.4532, ap 0.4553
2024-01-10 21:58:04,157 - GAugM EPNet train, Epoch [156/285]: loss 0.7209, auc 0.4729, ap 0.4733
2024-01-10 21:58:04,243 - GAugM EPNet train, Epoch [157/285]: loss 0.7209, auc 0.5075, ap 0.5214
2024-01-10 21:58:04,333 - GAugM EPNet train, Epoch [158/285]: loss 0.7208, auc 0.4138, ap 0.4488
2024-01-10 21:58:04,428 - GAugM EPNet train, Epoch [159/285]: loss 0.7208, auc 0.4680, ap 0.4835
2024-01-10 21:58:04,520 - GAugM EPNet train, Epoch [160/285]: loss 0.7209, auc 0.5527, ap 0.5387
2024-01-10 21:58:04,613 - GAugM EPNet train, Epoch [161/285]: loss 0.7209, auc 0.5055, ap 0.4850
2024-01-10 21:58:04,702 - GAugM EPNet train, Epoch [162/285]: loss 0.7209, auc 0.5000, ap 0.4933
2024-01-10 21:58:04,797 - GAugM EPNet train, Epoch [163/285]: loss 0.7209, auc 0.5489, ap 0.5222
2024-01-10 21:58:04,883 - GAugM EPNet train, Epoch [164/285]: loss 0.7211, auc 0.5182, ap 0.5022
2024-01-10 21:58:04,976 - GAugM EPNet train, Epoch [165/285]: loss 0.7210, auc 0.4986, ap 0.5043
2024-01-10 21:58:05,061 - GAugM EPNet train, Epoch [166/285]: loss 0.7208, auc 0.5356, ap 0.5132
2024-01-10 21:58:05,148 - GAugM EPNet train, Epoch [167/285]: loss 0.7209, auc 0.4576, ap 0.4929
2024-01-10 21:58:05,234 - GAugM EPNet train, Epoch [168/285]: loss 0.7209, auc 0.4959, ap 0.5339
2024-01-10 21:58:05,320 - GAugM EPNet train, Epoch [169/285]: loss 0.7209, auc 0.6303, ap 0.6354
2024-01-10 21:58:05,409 - GAugM EPNet train, Epoch [170/285]: loss 0.7210, auc 0.4883, ap 0.4770
2024-01-10 21:58:05,498 - GAugM EPNet train, Epoch [171/285]: loss 0.7209, auc 0.4439, ap 0.4535
2024-01-10 21:58:05,588 - GAugM EPNet train, Epoch [172/285]: loss 0.7208, auc 0.4138, ap 0.4459
2024-01-10 21:58:05,672 - GAugM EPNet train, Epoch [173/285]: loss 0.7209, auc 0.5125, ap 0.5060
2024-01-10 21:58:05,762 - GAugM EPNet train, Epoch [174/285]: loss 0.7209, auc 0.4865, ap 0.4688
2024-01-10 21:58:05,847 - GAugM EPNet train, Epoch [175/285]: loss 0.7209, auc 0.6079, ap 0.5541
2024-01-10 21:58:05,941 - GAugM EPNet train, Epoch [176/285]: loss 0.7209, auc 0.4824, ap 0.4750
2024-01-10 21:58:06,027 - GAugM EPNet train, Epoch [177/285]: loss 0.7210, auc 0.5146, ap 0.4854
2024-01-10 21:58:06,115 - GAugM EPNet train, Epoch [178/285]: loss 0.7210, auc 0.5167, ap 0.4960
2024-01-10 21:58:06,203 - GAugM EPNet train, Epoch [179/285]: loss 0.7210, auc 0.4482, ap 0.4791
2024-01-10 21:58:06,291 - GAugM EPNet train, Epoch [180/285]: loss 0.7210, auc 0.5190, ap 0.5639
2024-01-10 21:58:06,378 - GAugM EPNet train, Epoch [181/285]: loss 0.7209, auc 0.3843, ap 0.4302
2024-01-10 21:58:06,476 - GAugM EPNet train, Epoch [182/285]: loss 0.7209, auc 0.4454, ap 0.5056
2024-01-10 21:58:06,563 - GAugM EPNet train, Epoch [183/285]: loss 0.7210, auc 0.5477, ap 0.5368
2024-01-10 21:58:06,648 - GAugM EPNet train, Epoch [184/285]: loss 0.7209, auc 0.4735, ap 0.4854
2024-01-10 21:58:06,735 - GAugM EPNet train, Epoch [185/285]: loss 0.7209, auc 0.4575, ap 0.4880
2024-01-10 21:58:06,821 - GAugM EPNet train, Epoch [186/285]: loss 0.7208, auc 0.4187, ap 0.4553
2024-01-10 21:58:06,907 - GAugM EPNet train, Epoch [187/285]: loss 0.7209, auc 0.4868, ap 0.4866
2024-01-10 21:58:06,994 - GAugM EPNet train, Epoch [188/285]: loss 0.7209, auc 0.4706, ap 0.4668
2024-01-10 21:58:07,080 - GAugM EPNet train, Epoch [189/285]: loss 0.7209, auc 0.5723, ap 0.5809
2024-01-10 21:58:07,173 - GAugM EPNet train, Epoch [190/285]: loss 0.7209, auc 0.4400, ap 0.4596
2024-01-10 21:58:07,260 - GAugM EPNet train, Epoch [191/285]: loss 0.7209, auc 0.4544, ap 0.4858
2024-01-10 21:58:07,348 - GAugM EPNet train, Epoch [192/285]: loss 0.7209, auc 0.4697, ap 0.4684
2024-01-10 21:58:07,440 - GAugM EPNet train, Epoch [193/285]: loss 0.7209, auc 0.5986, ap 0.5806
2024-01-10 21:58:07,525 - GAugM EPNet train, Epoch [194/285]: loss 0.7209, auc 0.4656, ap 0.4759
2024-01-10 21:58:07,611 - GAugM EPNet train, Epoch [195/285]: loss 0.7209, auc 0.4799, ap 0.5087
2024-01-10 21:58:07,695 - GAugM EPNet train, Epoch [196/285]: loss 0.7208, auc 0.5589, ap 0.5157
2024-01-10 21:58:07,781 - GAugM EPNet train, Epoch [197/285]: loss 0.7210, auc 0.4592, ap 0.4596
2024-01-10 21:58:07,866 - GAugM EPNet train, Epoch [198/285]: loss 0.7210, auc 0.5888, ap 0.5413
2024-01-10 21:58:07,960 - GAugM EPNet train, Epoch [199/285]: loss 0.7209, auc 0.4306, ap 0.4465
2024-01-10 21:58:08,052 - GAugM EPNet train, Epoch [200/285]: loss 0.7210, auc 0.5162, ap 0.5052
2024-01-10 21:58:08,138 - GAugM EPNet train, Epoch [201/285]: loss 0.7209, auc 0.4067, ap 0.4354
2024-01-10 21:58:08,228 - GAugM EPNet train, Epoch [202/285]: loss 0.7210, auc 0.4696, ap 0.5088
2024-01-10 21:58:08,313 - GAugM EPNet train, Epoch [203/285]: loss 0.7210, auc 0.5021, ap 0.5092
2024-01-10 21:58:08,403 - GAugM EPNet train, Epoch [204/285]: loss 0.7209, auc 0.4217, ap 0.4617
2024-01-10 21:58:08,488 - GAugM EPNet train, Epoch [205/285]: loss 0.7209, auc 0.4685, ap 0.4912
2024-01-10 21:58:08,580 - GAugM EPNet train, Epoch [206/285]: loss 0.7209, auc 0.4667, ap 0.4877
2024-01-10 21:58:08,664 - GAugM EPNet train, Epoch [207/285]: loss 0.7210, auc 0.4747, ap 0.4756
2024-01-10 21:58:08,748 - GAugM EPNet train, Epoch [208/285]: loss 0.7209, auc 0.4512, ap 0.4821
2024-01-10 21:58:08,831 - GAugM EPNet train, Epoch [209/285]: loss 0.7210, auc 0.5513, ap 0.5300
2024-01-10 21:58:08,915 - GAugM EPNet train, Epoch [210/285]: loss 0.7209, auc 0.4875, ap 0.4875
2024-01-10 21:58:09,002 - GAugM EPNet train, Epoch [211/285]: loss 0.7210, auc 0.4598, ap 0.4866
2024-01-10 21:58:09,091 - GAugM EPNet train, Epoch [212/285]: loss 0.7210, auc 0.5304, ap 0.5179
2024-01-10 21:58:09,174 - GAugM EPNet train, Epoch [213/285]: loss 0.7208, auc 0.6396, ap 0.6522
2024-01-10 21:58:09,260 - GAugM EPNet train, Epoch [214/285]: loss 0.7210, auc 0.4630, ap 0.4821
2024-01-10 21:58:09,345 - GAugM EPNet train, Epoch [215/285]: loss 0.7210, auc 0.5484, ap 0.5353
2024-01-10 21:58:09,431 - GAugM EPNet train, Epoch [216/285]: loss 0.7209, auc 0.5064, ap 0.5057
2024-01-10 21:58:09,525 - GAugM EPNet train, Epoch [217/285]: loss 0.7209, auc 0.5411, ap 0.5332
2024-01-10 21:58:09,609 - GAugM EPNet train, Epoch [218/285]: loss 0.7209, auc 0.5342, ap 0.5765
2024-01-10 21:58:09,694 - GAugM EPNet train, Epoch [219/285]: loss 0.7208, auc 0.4649, ap 0.4853
2024-01-10 21:58:09,782 - GAugM EPNet train, Epoch [220/285]: loss 0.7210, auc 0.4461, ap 0.4818
2024-01-10 21:58:09,865 - GAugM EPNet train, Epoch [221/285]: loss 0.7209, auc 0.5358, ap 0.5265
2024-01-10 21:58:09,964 - GAugM EPNet train, Epoch [222/285]: loss 0.7209, auc 0.4260, ap 0.4438
2024-01-10 21:58:10,050 - GAugM EPNet train, Epoch [223/285]: loss 0.7209, auc 0.5584, ap 0.5365
2024-01-10 21:58:10,140 - GAugM EPNet train, Epoch [224/285]: loss 0.7210, auc 0.4847, ap 0.4676
2024-01-10 21:58:10,228 - GAugM EPNet train, Epoch [225/285]: loss 0.7209, auc 0.4464, ap 0.4623
2024-01-10 21:58:10,315 - GAugM EPNet train, Epoch [226/285]: loss 0.7210, auc 0.5406, ap 0.5260
2024-01-10 21:58:10,401 - GAugM EPNet train, Epoch [227/285]: loss 0.7210, auc 0.5449, ap 0.5346
2024-01-10 21:58:10,492 - GAugM EPNet train, Epoch [228/285]: loss 0.7209, auc 0.5164, ap 0.5260
2024-01-10 21:58:10,579 - GAugM EPNet train, Epoch [229/285]: loss 0.7209, auc 0.5064, ap 0.5231
2024-01-10 21:58:10,666 - GAugM EPNet train, Epoch [230/285]: loss 0.7209, auc 0.4827, ap 0.5109
2024-01-10 21:58:10,750 - GAugM EPNet train, Epoch [231/285]: loss 0.7209, auc 0.5037, ap 0.4891
2024-01-10 21:58:10,839 - GAugM EPNet train, Epoch [232/285]: loss 0.7209, auc 0.5014, ap 0.4984
2024-01-10 21:58:10,923 - GAugM EPNet train, Epoch [233/285]: loss 0.7210, auc 0.5660, ap 0.5533
2024-01-10 21:58:11,009 - GAugM EPNet train, Epoch [234/285]: loss 0.7209, auc 0.4138, ap 0.4647
2024-01-10 21:58:11,093 - GAugM EPNet train, Epoch [235/285]: loss 0.7209, auc 0.4646, ap 0.4615
2024-01-10 21:58:11,179 - GAugM EPNet train, Epoch [236/285]: loss 0.7209, auc 0.4614, ap 0.4709
2024-01-10 21:58:11,270 - GAugM EPNet train, Epoch [237/285]: loss 0.7210, auc 0.4890, ap 0.5297
2024-01-10 21:58:11,360 - GAugM EPNet train, Epoch [238/285]: loss 0.7210, auc 0.4705, ap 0.4643
2024-01-10 21:58:11,448 - GAugM EPNet train, Epoch [239/285]: loss 0.7209, auc 0.4544, ap 0.5087
2024-01-10 21:58:11,538 - GAugM EPNet train, Epoch [240/285]: loss 0.7209, auc 0.4847, ap 0.4947
2024-01-10 21:58:11,623 - GAugM EPNet train, Epoch [241/285]: loss 0.7209, auc 0.5762, ap 0.5479
2024-01-10 21:58:11,713 - GAugM EPNet train, Epoch [242/285]: loss 0.7210, auc 0.4767, ap 0.4659
2024-01-10 21:58:11,803 - GAugM EPNet train, Epoch [243/285]: loss 0.7210, auc 0.5319, ap 0.5822
2024-01-10 21:58:11,890 - GAugM EPNet train, Epoch [244/285]: loss 0.7209, auc 0.5886, ap 0.5577
2024-01-10 21:58:11,975 - GAugM EPNet train, Epoch [245/285]: loss 0.7210, auc 0.4608, ap 0.4658
2024-01-10 21:58:12,062 - GAugM EPNet train, Epoch [246/285]: loss 0.7208, auc 0.5237, ap 0.5105
2024-01-10 21:58:12,152 - GAugM EPNet train, Epoch [247/285]: loss 0.7209, auc 0.4897, ap 0.4947
2024-01-10 21:58:12,242 - GAugM EPNet train, Epoch [248/285]: loss 0.7211, auc 0.5575, ap 0.5302
2024-01-10 21:58:12,328 - GAugM EPNet train, Epoch [249/285]: loss 0.7209, auc 0.4916, ap 0.5250
2024-01-10 21:58:12,414 - GAugM EPNet train, Epoch [250/285]: loss 0.7208, auc 0.4843, ap 0.4769
2024-01-10 21:58:12,501 - GAugM EPNet train, Epoch [251/285]: loss 0.7209, auc 0.4569, ap 0.4946
2024-01-10 21:58:12,588 - GAugM EPNet train, Epoch [252/285]: loss 0.7210, auc 0.5520, ap 0.5704
2024-01-10 21:58:12,676 - GAugM EPNet train, Epoch [253/285]: loss 0.7209, auc 0.5929, ap 0.5662
2024-01-10 21:58:12,762 - GAugM EPNet train, Epoch [254/285]: loss 0.7210, auc 0.5103, ap 0.5466
2024-01-10 21:58:12,848 - GAugM EPNet train, Epoch [255/285]: loss 0.7209, auc 0.4934, ap 0.4827
2024-01-10 21:58:12,937 - GAugM EPNet train, Epoch [256/285]: loss 0.7210, auc 0.3939, ap 0.4724
2024-01-10 21:58:13,034 - GAugM EPNet train, Epoch [257/285]: loss 0.7210, auc 0.5748, ap 0.5488
2024-01-10 21:58:13,120 - GAugM EPNet train, Epoch [258/285]: loss 0.7208, auc 0.4753, ap 0.5260
2024-01-10 21:58:13,209 - GAugM EPNet train, Epoch [259/285]: loss 0.7208, auc 0.5822, ap 0.5384
2024-01-10 21:58:13,300 - GAugM EPNet train, Epoch [260/285]: loss 0.7210, auc 0.5247, ap 0.5092
2024-01-10 21:58:13,386 - GAugM EPNet train, Epoch [261/285]: loss 0.7209, auc 0.5655, ap 0.5294
2024-01-10 21:58:13,475 - GAugM EPNet train, Epoch [262/285]: loss 0.7208, auc 0.4850, ap 0.4905
2024-01-10 21:58:13,569 - GAugM EPNet train, Epoch [263/285]: loss 0.7209, auc 0.4931, ap 0.5083
2024-01-10 21:58:13,658 - GAugM EPNet train, Epoch [264/285]: loss 0.7210, auc 0.5352, ap 0.5085
2024-01-10 21:58:13,750 - GAugM EPNet train, Epoch [265/285]: loss 0.7209, auc 0.5659, ap 0.6205
2024-01-10 21:58:13,837 - GAugM EPNet train, Epoch [266/285]: loss 0.7209, auc 0.4674, ap 0.4637
2024-01-10 21:58:13,925 - GAugM EPNet train, Epoch [267/285]: loss 0.7210, auc 0.5449, ap 0.5196
2024-01-10 21:58:14,017 - GAugM EPNet train, Epoch [268/285]: loss 0.7210, auc 0.4669, ap 0.5073
2024-01-10 21:58:14,103 - GAugM EPNet train, Epoch [269/285]: loss 0.7209, auc 0.4931, ap 0.5167
2024-01-10 21:58:14,190 - GAugM EPNet train, Epoch [270/285]: loss 0.7210, auc 0.4518, ap 0.4731
2024-01-10 21:58:14,277 - GAugM EPNet train, Epoch [271/285]: loss 0.7209, auc 0.4163, ap 0.4516
2024-01-10 21:58:14,363 - GAugM EPNet train, Epoch [272/285]: loss 0.7209, auc 0.5484, ap 0.5665
2024-01-10 21:58:14,448 - GAugM EPNet train, Epoch [273/285]: loss 0.7209, auc 0.4475, ap 0.4847
2024-01-10 21:58:14,532 - GAugM EPNet train, Epoch [274/285]: loss 0.7209, auc 0.5119, ap 0.5354
2024-01-10 21:58:14,618 - GAugM EPNet train, Epoch [275/285]: loss 0.7208, auc 0.4883, ap 0.4830
2024-01-10 21:58:14,708 - GAugM EPNet train, Epoch [276/285]: loss 0.7210, auc 0.5805, ap 0.5542
2024-01-10 21:58:14,794 - GAugM EPNet train, Epoch [277/285]: loss 0.7208, auc 0.4439, ap 0.4486
2024-01-10 21:58:14,886 - GAugM EPNet train, Epoch [278/285]: loss 0.7209, auc 0.4801, ap 0.5090
2024-01-10 21:58:14,973 - GAugM EPNet train, Epoch [279/285]: loss 0.7209, auc 0.4986, ap 0.4872
2024-01-10 21:58:15,058 - GAugM EPNet train, Epoch [280/285]: loss 0.7209, auc 0.4197, ap 0.4324
2024-01-10 21:58:15,145 - GAugM EPNet train, Epoch [281/285]: loss 0.7209, auc 0.6244, ap 0.5887
2024-01-10 21:58:15,239 - GAugM EPNet train, Epoch [282/285]: loss 0.7209, auc 0.4728, ap 0.4737
2024-01-10 21:58:15,327 - GAugM EPNet train, Epoch [283/285]: loss 0.7209, auc 0.5271, ap 0.5429
2024-01-10 21:58:15,416 - GAugM EPNet train, Epoch [284/285]: loss 0.7209, auc 0.4445, ap 0.4637
2024-01-10 21:58:15,502 - GAugM EPNet train, Epoch [285/285]: loss 0.7209, auc 0.5600, ap 0.5347
2024-01-10 21:58:15,503 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035e7bd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:58:16,224 - GAugM EPNet train, Epoch [  1/285]: loss 0.7210, auc 0.5096, ap 0.5070
2024-01-10 21:58:16,307 - GAugM EPNet train, Epoch [  2/285]: loss 0.7210, auc 0.4801, ap 0.4932
2024-01-10 21:58:16,396 - GAugM EPNet train, Epoch [  3/285]: loss 0.7209, auc 0.5272, ap 0.5361
2024-01-10 21:58:16,486 - GAugM EPNet train, Epoch [  4/285]: loss 0.7209, auc 0.4874, ap 0.4729
2024-01-10 21:58:16,578 - GAugM EPNet train, Epoch [  5/285]: loss 0.7209, auc 0.5630, ap 0.5901
2024-01-10 21:58:16,664 - GAugM EPNet train, Epoch [  6/285]: loss 0.7209, auc 0.5417, ap 0.5170
2024-01-10 21:58:16,756 - GAugM EPNet train, Epoch [  7/285]: loss 0.7209, auc 0.4847, ap 0.4944
2024-01-10 21:58:16,847 - GAugM EPNet train, Epoch [  8/285]: loss 0.7210, auc 0.4621, ap 0.4909
2024-01-10 21:58:16,945 - GAugM EPNet train, Epoch [  9/285]: loss 0.7209, auc 0.4681, ap 0.4803
2024-01-10 21:58:17,036 - GAugM EPNet train, Epoch [ 10/285]: loss 0.7208, auc 0.5349, ap 0.5455
2024-01-10 21:58:17,123 - GAugM EPNet train, Epoch [ 11/285]: loss 0.7209, auc 0.5279, ap 0.5272
2024-01-10 21:58:17,210 - GAugM EPNet train, Epoch [ 12/285]: loss 0.7210, auc 0.4790, ap 0.4860
2024-01-10 21:58:17,305 - GAugM EPNet train, Epoch [ 13/285]: loss 0.7209, auc 0.5591, ap 0.5825
2024-01-10 21:58:17,395 - GAugM EPNet train, Epoch [ 14/285]: loss 0.7209, auc 0.4772, ap 0.4648
2024-01-10 21:58:17,481 - GAugM EPNet train, Epoch [ 15/285]: loss 0.7210, auc 0.4220, ap 0.4896
2024-01-10 21:58:17,573 - GAugM EPNet train, Epoch [ 16/285]: loss 0.7209, auc 0.4840, ap 0.5090
2024-01-10 21:58:17,660 - GAugM EPNet train, Epoch [ 17/285]: loss 0.7210, auc 0.5705, ap 0.5713
2024-01-10 21:58:17,750 - GAugM EPNet train, Epoch [ 18/285]: loss 0.7210, auc 0.5041, ap 0.5131
2024-01-10 21:58:17,836 - GAugM EPNet train, Epoch [ 19/285]: loss 0.7209, auc 0.4760, ap 0.4748
2024-01-10 21:58:17,924 - GAugM EPNet train, Epoch [ 20/285]: loss 0.7210, auc 0.5484, ap 0.5566
2024-01-10 21:58:18,014 - GAugM EPNet train, Epoch [ 21/285]: loss 0.7209, auc 0.5007, ap 0.4998
2024-01-10 21:58:18,103 - GAugM EPNet train, Epoch [ 22/285]: loss 0.7210, auc 0.3690, ap 0.4236
2024-01-10 21:58:18,192 - GAugM EPNet train, Epoch [ 23/285]: loss 0.7208, auc 0.4964, ap 0.5066
2024-01-10 21:58:18,289 - GAugM EPNet train, Epoch [ 24/285]: loss 0.7209, auc 0.4991, ap 0.5126
2024-01-10 21:58:18,374 - GAugM EPNet train, Epoch [ 25/285]: loss 0.7209, auc 0.4893, ap 0.5028
2024-01-10 21:58:18,460 - GAugM EPNet train, Epoch [ 26/285]: loss 0.7210, auc 0.5618, ap 0.5602
2024-01-10 21:58:18,549 - GAugM EPNet train, Epoch [ 27/285]: loss 0.7209, auc 0.4311, ap 0.4982
2024-01-10 21:58:18,636 - GAugM EPNet train, Epoch [ 28/285]: loss 0.7209, auc 0.6107, ap 0.6154
2024-01-10 21:58:18,724 - GAugM EPNet train, Epoch [ 29/285]: loss 0.7210, auc 0.5936, ap 0.5582
2024-01-10 21:58:18,813 - GAugM EPNet train, Epoch [ 30/285]: loss 0.7209, auc 0.5052, ap 0.5111
2024-01-10 21:58:18,901 - GAugM EPNet train, Epoch [ 31/285]: loss 0.7208, auc 0.5180, ap 0.5173
2024-01-10 21:58:18,988 - GAugM EPNet train, Epoch [ 32/285]: loss 0.7210, auc 0.4915, ap 0.5005
2024-01-10 21:58:19,084 - GAugM EPNet train, Epoch [ 33/285]: loss 0.7209, auc 0.6287, ap 0.5989
2024-01-10 21:58:19,173 - GAugM EPNet train, Epoch [ 34/285]: loss 0.7209, auc 0.4427, ap 0.4563
2024-01-10 21:58:19,260 - GAugM EPNet train, Epoch [ 35/285]: loss 0.7209, auc 0.5733, ap 0.5516
2024-01-10 21:58:19,347 - GAugM EPNet train, Epoch [ 36/285]: loss 0.7209, auc 0.6013, ap 0.5794
2024-01-10 21:58:19,439 - GAugM EPNet train, Epoch [ 37/285]: loss 0.7209, auc 0.4655, ap 0.4597
2024-01-10 21:58:19,527 - GAugM EPNet train, Epoch [ 38/285]: loss 0.7209, auc 0.4724, ap 0.4730
2024-01-10 21:58:19,627 - GAugM EPNet train, Epoch [ 39/285]: loss 0.7208, auc 0.4865, ap 0.4971
2024-01-10 21:58:19,713 - GAugM EPNet train, Epoch [ 40/285]: loss 0.7210, auc 0.5395, ap 0.5219
2024-01-10 21:58:19,802 - GAugM EPNet train, Epoch [ 41/285]: loss 0.7210, auc 0.4630, ap 0.4935
2024-01-10 21:58:19,891 - GAugM EPNet train, Epoch [ 42/285]: loss 0.7209, auc 0.4824, ap 0.5198
2024-01-10 21:58:19,986 - GAugM EPNet train, Epoch [ 43/285]: loss 0.7208, auc 0.5303, ap 0.5544
2024-01-10 21:58:20,073 - GAugM EPNet train, Epoch [ 44/285]: loss 0.7208, auc 0.4028, ap 0.4671
2024-01-10 21:58:20,160 - GAugM EPNet train, Epoch [ 45/285]: loss 0.7209, auc 0.5167, ap 0.5525
2024-01-10 21:58:20,254 - GAugM EPNet train, Epoch [ 46/285]: loss 0.7209, auc 0.4840, ap 0.4892
2024-01-10 21:58:20,344 - GAugM EPNet train, Epoch [ 47/285]: loss 0.7210, auc 0.4527, ap 0.4810
2024-01-10 21:58:20,445 - GAugM EPNet train, Epoch [ 48/285]: loss 0.7210, auc 0.6096, ap 0.5900
2024-01-10 21:58:20,536 - GAugM EPNet train, Epoch [ 49/285]: loss 0.7209, auc 0.5603, ap 0.5524
2024-01-10 21:58:20,629 - GAugM EPNet train, Epoch [ 50/285]: loss 0.7210, auc 0.5123, ap 0.5109
2024-01-10 21:58:20,722 - GAugM EPNet train, Epoch [ 51/285]: loss 0.7210, auc 0.4740, ap 0.4638
2024-01-10 21:58:20,819 - GAugM EPNet train, Epoch [ 52/285]: loss 0.7209, auc 0.4559, ap 0.4756
2024-01-10 21:58:20,909 - GAugM EPNet train, Epoch [ 53/285]: loss 0.7209, auc 0.5032, ap 0.5296
2024-01-10 21:58:20,999 - GAugM EPNet train, Epoch [ 54/285]: loss 0.7211, auc 0.5598, ap 0.5570
2024-01-10 21:58:21,093 - GAugM EPNet train, Epoch [ 55/285]: loss 0.7209, auc 0.6513, ap 0.6236
2024-01-10 21:58:21,182 - GAugM EPNet train, Epoch [ 56/285]: loss 0.7208, auc 0.4801, ap 0.5171
2024-01-10 21:58:21,274 - GAugM EPNet train, Epoch [ 57/285]: loss 0.7209, auc 0.5214, ap 0.4878
2024-01-10 21:58:21,362 - GAugM EPNet train, Epoch [ 58/285]: loss 0.7210, auc 0.5381, ap 0.5875
2024-01-10 21:58:21,451 - GAugM EPNet train, Epoch [ 59/285]: loss 0.7211, auc 0.5064, ap 0.5033
2024-01-10 21:58:21,544 - GAugM EPNet train, Epoch [ 60/285]: loss 0.7210, auc 0.5497, ap 0.5572
2024-01-10 21:58:21,632 - GAugM EPNet train, Epoch [ 61/285]: loss 0.7209, auc 0.5135, ap 0.5088
2024-01-10 21:58:21,719 - GAugM EPNet train, Epoch [ 62/285]: loss 0.7210, auc 0.6052, ap 0.6044
2024-01-10 21:58:21,807 - GAugM EPNet train, Epoch [ 63/285]: loss 0.7208, auc 0.4754, ap 0.4908
2024-01-10 21:58:21,894 - GAugM EPNet train, Epoch [ 64/285]: loss 0.7208, auc 0.4044, ap 0.4608
2024-01-10 21:58:21,986 - GAugM EPNet train, Epoch [ 65/285]: loss 0.7208, auc 0.4632, ap 0.4973
2024-01-10 21:58:22,073 - GAugM EPNet train, Epoch [ 66/285]: loss 0.7209, auc 0.3857, ap 0.4534
2024-01-10 21:58:22,159 - GAugM EPNet train, Epoch [ 67/285]: loss 0.7209, auc 0.5813, ap 0.5747
2024-01-10 21:58:22,255 - GAugM EPNet train, Epoch [ 68/285]: loss 0.7210, auc 0.4888, ap 0.5177
2024-01-10 21:58:22,343 - GAugM EPNet train, Epoch [ 69/285]: loss 0.7210, auc 0.4923, ap 0.5325
2024-01-10 21:58:22,433 - GAugM EPNet train, Epoch [ 70/285]: loss 0.7210, auc 0.4847, ap 0.4792
2024-01-10 21:58:22,522 - GAugM EPNet train, Epoch [ 71/285]: loss 0.7210, auc 0.5789, ap 0.5599
2024-01-10 21:58:22,611 - GAugM EPNet train, Epoch [ 72/285]: loss 0.7210, auc 0.4295, ap 0.4601
2024-01-10 21:58:22,705 - GAugM EPNet train, Epoch [ 73/285]: loss 0.7209, auc 0.5603, ap 0.5305
2024-01-10 21:58:22,796 - GAugM EPNet train, Epoch [ 74/285]: loss 0.7209, auc 0.5352, ap 0.5343
2024-01-10 21:58:22,882 - GAugM EPNet train, Epoch [ 75/285]: loss 0.7210, auc 0.4553, ap 0.4801
2024-01-10 21:58:22,976 - GAugM EPNet train, Epoch [ 76/285]: loss 0.7209, auc 0.4258, ap 0.4698
2024-01-10 21:58:23,071 - GAugM EPNet train, Epoch [ 77/285]: loss 0.7208, auc 0.5744, ap 0.5748
2024-01-10 21:58:23,159 - GAugM EPNet train, Epoch [ 78/285]: loss 0.7209, auc 0.5260, ap 0.5296
2024-01-10 21:58:23,245 - GAugM EPNet train, Epoch [ 79/285]: loss 0.7208, auc 0.5271, ap 0.5487
2024-01-10 21:58:23,329 - GAugM EPNet train, Epoch [ 80/285]: loss 0.7209, auc 0.5589, ap 0.5498
2024-01-10 21:58:23,412 - GAugM EPNet train, Epoch [ 81/285]: loss 0.7209, auc 0.5265, ap 0.5231
2024-01-10 21:58:23,496 - GAugM EPNet train, Epoch [ 82/285]: loss 0.7210, auc 0.4998, ap 0.5109
2024-01-10 21:58:23,585 - GAugM EPNet train, Epoch [ 83/285]: loss 0.7209, auc 0.4541, ap 0.4924
2024-01-10 21:58:23,673 - GAugM EPNet train, Epoch [ 84/285]: loss 0.7209, auc 0.3820, ap 0.4333
2024-01-10 21:58:23,757 - GAugM EPNet train, Epoch [ 85/285]: loss 0.7210, auc 0.4354, ap 0.4415
2024-01-10 21:58:23,848 - GAugM EPNet train, Epoch [ 86/285]: loss 0.7208, auc 0.4575, ap 0.4756
2024-01-10 21:58:23,932 - GAugM EPNet train, Epoch [ 87/285]: loss 0.7209, auc 0.5837, ap 0.5986
2024-01-10 21:58:24,016 - GAugM EPNet train, Epoch [ 88/285]: loss 0.7210, auc 0.5103, ap 0.5553
2024-01-10 21:58:24,100 - GAugM EPNet train, Epoch [ 89/285]: loss 0.7210, auc 0.5135, ap 0.5478
2024-01-10 21:58:24,183 - GAugM EPNet train, Epoch [ 90/285]: loss 0.7209, auc 0.3816, ap 0.4544
2024-01-10 21:58:24,269 - GAugM EPNet train, Epoch [ 91/285]: loss 0.7208, auc 0.4881, ap 0.4820
2024-01-10 21:58:24,358 - GAugM EPNet train, Epoch [ 92/285]: loss 0.7209, auc 0.6830, ap 0.6645
2024-01-10 21:58:24,444 - GAugM EPNet train, Epoch [ 93/285]: loss 0.7209, auc 0.4092, ap 0.4666
2024-01-10 21:58:24,534 - GAugM EPNet train, Epoch [ 94/285]: loss 0.7210, auc 0.4178, ap 0.4410
2024-01-10 21:58:24,628 - GAugM EPNet train, Epoch [ 95/285]: loss 0.7210, auc 0.5317, ap 0.5325
2024-01-10 21:58:24,716 - GAugM EPNet train, Epoch [ 96/285]: loss 0.7209, auc 0.5509, ap 0.5539
2024-01-10 21:58:24,807 - GAugM EPNet train, Epoch [ 97/285]: loss 0.7209, auc 0.4897, ap 0.4897
2024-01-10 21:58:24,899 - GAugM EPNet train, Epoch [ 98/285]: loss 0.7209, auc 0.5041, ap 0.5063
2024-01-10 21:58:24,994 - GAugM EPNet train, Epoch [ 99/285]: loss 0.7209, auc 0.4656, ap 0.4802
2024-01-10 21:58:25,086 - GAugM EPNet train, Epoch [100/285]: loss 0.7210, auc 0.4824, ap 0.5052
2024-01-10 21:58:25,175 - GAugM EPNet train, Epoch [101/285]: loss 0.7210, auc 0.4498, ap 0.5047
2024-01-10 21:58:25,264 - GAugM EPNet train, Epoch [102/285]: loss 0.7209, auc 0.4416, ap 0.4544
2024-01-10 21:58:25,350 - GAugM EPNet train, Epoch [103/285]: loss 0.7209, auc 0.4890, ap 0.5237
2024-01-10 21:58:25,439 - GAugM EPNet train, Epoch [104/285]: loss 0.7209, auc 0.4881, ap 0.5116
2024-01-10 21:58:25,536 - GAugM EPNet train, Epoch [105/285]: loss 0.7209, auc 0.4245, ap 0.4709
2024-01-10 21:58:25,623 - GAugM EPNet train, Epoch [106/285]: loss 0.7210, auc 0.4939, ap 0.4799
2024-01-10 21:58:25,712 - GAugM EPNet train, Epoch [107/285]: loss 0.7210, auc 0.5166, ap 0.5591
2024-01-10 21:58:25,805 - GAugM EPNet train, Epoch [108/285]: loss 0.7208, auc 0.4947, ap 0.4986
2024-01-10 21:58:25,894 - GAugM EPNet train, Epoch [109/285]: loss 0.7210, auc 0.3985, ap 0.4543
2024-01-10 21:58:25,982 - GAugM EPNet train, Epoch [110/285]: loss 0.7209, auc 0.4493, ap 0.4728
2024-01-10 21:58:26,073 - GAugM EPNet train, Epoch [111/285]: loss 0.7210, auc 0.4598, ap 0.4832
2024-01-10 21:58:26,168 - GAugM EPNet train, Epoch [112/285]: loss 0.7209, auc 0.5520, ap 0.5403
2024-01-10 21:58:26,257 - GAugM EPNet train, Epoch [113/285]: loss 0.7210, auc 0.5087, ap 0.5236
2024-01-10 21:58:26,348 - GAugM EPNet train, Epoch [114/285]: loss 0.7209, auc 0.5068, ap 0.5044
2024-01-10 21:58:26,438 - GAugM EPNet train, Epoch [115/285]: loss 0.7210, auc 0.4345, ap 0.4887
2024-01-10 21:58:26,521 - GAugM EPNet train, Epoch [116/285]: loss 0.7209, auc 0.4972, ap 0.5215
2024-01-10 21:58:26,599 - GAugM EPNet train, Epoch [117/285]: loss 0.7208, auc 0.4085, ap 0.4589
2024-01-10 21:58:26,685 - GAugM EPNet train, Epoch [118/285]: loss 0.7209, auc 0.4334, ap 0.4823
2024-01-10 21:58:26,779 - GAugM EPNet train, Epoch [119/285]: loss 0.7209, auc 0.4870, ap 0.5079
2024-01-10 21:58:26,873 - GAugM EPNet train, Epoch [120/285]: loss 0.7210, auc 0.4461, ap 0.4702
2024-01-10 21:58:26,968 - GAugM EPNet train, Epoch [121/285]: loss 0.7210, auc 0.3483, ap 0.4075
2024-01-10 21:58:27,068 - GAugM EPNet train, Epoch [122/285]: loss 0.7209, auc 0.4470, ap 0.4710
2024-01-10 21:58:27,159 - GAugM EPNet train, Epoch [123/285]: loss 0.7209, auc 0.5406, ap 0.5366
2024-01-10 21:58:27,248 - GAugM EPNet train, Epoch [124/285]: loss 0.7210, auc 0.4429, ap 0.4773
2024-01-10 21:58:27,339 - GAugM EPNet train, Epoch [125/285]: loss 0.7209, auc 0.5904, ap 0.5752
2024-01-10 21:58:27,428 - GAugM EPNet train, Epoch [126/285]: loss 0.7210, auc 0.4936, ap 0.5036
2024-01-10 21:58:27,511 - GAugM EPNet train, Epoch [127/285]: loss 0.7209, auc 0.5135, ap 0.5069
2024-01-10 21:58:27,591 - GAugM EPNet train, Epoch [128/285]: loss 0.7210, auc 0.4710, ap 0.4854
2024-01-10 21:58:27,684 - GAugM EPNet train, Epoch [129/285]: loss 0.7208, auc 0.4053, ap 0.4422
2024-01-10 21:58:27,776 - GAugM EPNet train, Epoch [130/285]: loss 0.7210, auc 0.4532, ap 0.4736
2024-01-10 21:58:27,860 - GAugM EPNet train, Epoch [131/285]: loss 0.7210, auc 0.5395, ap 0.5677
2024-01-10 21:58:27,951 - GAugM EPNet train, Epoch [132/285]: loss 0.7209, auc 0.5422, ap 0.5138
2024-01-10 21:58:28,045 - GAugM EPNet train, Epoch [133/285]: loss 0.7209, auc 0.4776, ap 0.5173
2024-01-10 21:58:28,124 - GAugM EPNet train, Epoch [134/285]: loss 0.7210, auc 0.5271, ap 0.5517
2024-01-10 21:58:28,214 - GAugM EPNet train, Epoch [135/285]: loss 0.7209, auc 0.3564, ap 0.4173
2024-01-10 21:58:28,299 - GAugM EPNet train, Epoch [136/285]: loss 0.7209, auc 0.5488, ap 0.5489
2024-01-10 21:58:28,381 - GAugM EPNet train, Epoch [137/285]: loss 0.7210, auc 0.4149, ap 0.4949
2024-01-10 21:58:28,459 - GAugM EPNet train, Epoch [138/285]: loss 0.7210, auc 0.5922, ap 0.5753
2024-01-10 21:58:28,546 - GAugM EPNet train, Epoch [139/285]: loss 0.7210, auc 0.5212, ap 0.5321
2024-01-10 21:58:28,635 - GAugM EPNet train, Epoch [140/285]: loss 0.7209, auc 0.4122, ap 0.4506
2024-01-10 21:58:28,724 - GAugM EPNet train, Epoch [141/285]: loss 0.7209, auc 0.5301, ap 0.5287
2024-01-10 21:58:28,814 - GAugM EPNet train, Epoch [142/285]: loss 0.7209, auc 0.5812, ap 0.5873
2024-01-10 21:58:28,906 - GAugM EPNet train, Epoch [143/285]: loss 0.7209, auc 0.4441, ap 0.4823
2024-01-10 21:58:28,991 - GAugM EPNet train, Epoch [144/285]: loss 0.7209, auc 0.4397, ap 0.4554
2024-01-10 21:58:29,085 - GAugM EPNet train, Epoch [145/285]: loss 0.7209, auc 0.4672, ap 0.5014
2024-01-10 21:58:29,173 - GAugM EPNet train, Epoch [146/285]: loss 0.7209, auc 0.5573, ap 0.5811
2024-01-10 21:58:29,267 - GAugM EPNet train, Epoch [147/285]: loss 0.7209, auc 0.5854, ap 0.5991
2024-01-10 21:58:29,352 - GAugM EPNet train, Epoch [148/285]: loss 0.7209, auc 0.5137, ap 0.5398
2024-01-10 21:58:29,441 - GAugM EPNet train, Epoch [149/285]: loss 0.7208, auc 0.5027, ap 0.5259
2024-01-10 21:58:29,528 - GAugM EPNet train, Epoch [150/285]: loss 0.7209, auc 0.5837, ap 0.5670
2024-01-10 21:58:29,617 - GAugM EPNet train, Epoch [151/285]: loss 0.7209, auc 0.5080, ap 0.5143
2024-01-10 21:58:29,704 - GAugM EPNet train, Epoch [152/285]: loss 0.7209, auc 0.4957, ap 0.4987
2024-01-10 21:58:29,791 - GAugM EPNet train, Epoch [153/285]: loss 0.7209, auc 0.4445, ap 0.4776
2024-01-10 21:58:29,879 - GAugM EPNet train, Epoch [154/285]: loss 0.7209, auc 0.5632, ap 0.5929
2024-01-10 21:58:29,965 - GAugM EPNet train, Epoch [155/285]: loss 0.7209, auc 0.5073, ap 0.5256
2024-01-10 21:58:30,050 - GAugM EPNet train, Epoch [156/285]: loss 0.7209, auc 0.5356, ap 0.5393
2024-01-10 21:58:30,143 - GAugM EPNet train, Epoch [157/285]: loss 0.7209, auc 0.5730, ap 0.5571
2024-01-10 21:58:30,230 - GAugM EPNet train, Epoch [158/285]: loss 0.7208, auc 0.5157, ap 0.5304
2024-01-10 21:58:30,322 - GAugM EPNet train, Epoch [159/285]: loss 0.7208, auc 0.5283, ap 0.5034
2024-01-10 21:58:30,412 - GAugM EPNet train, Epoch [160/285]: loss 0.7209, auc 0.5281, ap 0.5398
2024-01-10 21:58:30,499 - GAugM EPNet train, Epoch [161/285]: loss 0.7209, auc 0.5100, ap 0.5105
2024-01-10 21:58:30,586 - GAugM EPNet train, Epoch [162/285]: loss 0.7209, auc 0.4178, ap 0.4451
2024-01-10 21:58:30,673 - GAugM EPNet train, Epoch [163/285]: loss 0.7209, auc 0.5231, ap 0.5269
2024-01-10 21:58:30,763 - GAugM EPNet train, Epoch [164/285]: loss 0.7211, auc 0.5137, ap 0.5053
2024-01-10 21:58:30,855 - GAugM EPNet train, Epoch [165/285]: loss 0.7210, auc 0.4046, ap 0.4372
2024-01-10 21:58:30,952 - GAugM EPNet train, Epoch [166/285]: loss 0.7208, auc 0.5456, ap 0.5118
2024-01-10 21:58:31,039 - GAugM EPNet train, Epoch [167/285]: loss 0.7209, auc 0.4772, ap 0.4828
2024-01-10 21:58:31,126 - GAugM EPNet train, Epoch [168/285]: loss 0.7209, auc 0.4785, ap 0.5430
2024-01-10 21:58:31,211 - GAugM EPNet train, Epoch [169/285]: loss 0.7209, auc 0.5080, ap 0.5220
2024-01-10 21:58:31,304 - GAugM EPNet train, Epoch [170/285]: loss 0.7210, auc 0.4881, ap 0.4760
2024-01-10 21:58:31,402 - GAugM EPNet train, Epoch [171/285]: loss 0.7209, auc 0.4589, ap 0.4777
2024-01-10 21:58:31,494 - GAugM EPNet train, Epoch [172/285]: loss 0.7208, auc 0.4267, ap 0.4563
2024-01-10 21:58:31,581 - GAugM EPNet train, Epoch [173/285]: loss 0.7209, auc 0.5641, ap 0.6071
2024-01-10 21:58:31,668 - GAugM EPNet train, Epoch [174/285]: loss 0.7209, auc 0.4703, ap 0.4806
2024-01-10 21:58:31,755 - GAugM EPNet train, Epoch [175/285]: loss 0.7209, auc 0.6185, ap 0.5809
2024-01-10 21:58:31,842 - GAugM EPNet train, Epoch [176/285]: loss 0.7209, auc 0.4932, ap 0.4957
2024-01-10 21:58:31,938 - GAugM EPNet train, Epoch [177/285]: loss 0.7210, auc 0.4372, ap 0.4586
2024-01-10 21:58:32,023 - GAugM EPNet train, Epoch [178/285]: loss 0.7210, auc 0.5694, ap 0.5829
2024-01-10 21:58:32,113 - GAugM EPNet train, Epoch [179/285]: loss 0.7210, auc 0.4071, ap 0.4614
2024-01-10 21:58:32,205 - GAugM EPNet train, Epoch [180/285]: loss 0.7210, auc 0.5255, ap 0.5392
2024-01-10 21:58:32,294 - GAugM EPNet train, Epoch [181/285]: loss 0.7209, auc 0.4071, ap 0.4435
2024-01-10 21:58:32,390 - GAugM EPNet train, Epoch [182/285]: loss 0.7209, auc 0.5077, ap 0.5260
2024-01-10 21:58:32,480 - GAugM EPNet train, Epoch [183/285]: loss 0.7210, auc 0.5044, ap 0.5208
2024-01-10 21:58:32,569 - GAugM EPNet train, Epoch [184/285]: loss 0.7209, auc 0.5169, ap 0.5546
2024-01-10 21:58:32,661 - GAugM EPNet train, Epoch [185/285]: loss 0.7209, auc 0.5068, ap 0.5429
2024-01-10 21:58:32,749 - GAugM EPNet train, Epoch [186/285]: loss 0.7208, auc 0.5133, ap 0.5624
2024-01-10 21:58:32,839 - GAugM EPNet train, Epoch [187/285]: loss 0.7209, auc 0.4502, ap 0.4725
2024-01-10 21:58:32,927 - GAugM EPNet train, Epoch [188/285]: loss 0.7209, auc 0.3916, ap 0.4260
2024-01-10 21:58:33,015 - GAugM EPNet train, Epoch [189/285]: loss 0.7209, auc 0.6157, ap 0.6124
2024-01-10 21:58:33,108 - GAugM EPNet train, Epoch [190/285]: loss 0.7209, auc 0.4427, ap 0.4626
2024-01-10 21:58:33,198 - GAugM EPNet train, Epoch [191/285]: loss 0.7209, auc 0.4195, ap 0.4716
2024-01-10 21:58:33,295 - GAugM EPNet train, Epoch [192/285]: loss 0.7209, auc 0.4760, ap 0.4541
2024-01-10 21:58:33,387 - GAugM EPNet train, Epoch [193/285]: loss 0.7209, auc 0.5075, ap 0.4867
2024-01-10 21:58:33,476 - GAugM EPNet train, Epoch [194/285]: loss 0.7209, auc 0.4845, ap 0.4875
2024-01-10 21:58:33,565 - GAugM EPNet train, Epoch [195/285]: loss 0.7209, auc 0.4341, ap 0.4630
2024-01-10 21:58:33,651 - GAugM EPNet train, Epoch [196/285]: loss 0.7208, auc 0.5290, ap 0.5044
2024-01-10 21:58:33,742 - GAugM EPNet train, Epoch [197/285]: loss 0.7210, auc 0.4813, ap 0.4890
2024-01-10 21:58:33,835 - GAugM EPNet train, Epoch [198/285]: loss 0.7210, auc 0.5356, ap 0.5454
2024-01-10 21:58:33,924 - GAugM EPNet train, Epoch [199/285]: loss 0.7209, auc 0.4703, ap 0.4924
2024-01-10 21:58:34,010 - GAugM EPNet train, Epoch [200/285]: loss 0.7210, auc 0.4833, ap 0.4941
2024-01-10 21:58:34,104 - GAugM EPNet train, Epoch [201/285]: loss 0.7209, auc 0.4968, ap 0.5235
2024-01-10 21:58:34,193 - GAugM EPNet train, Epoch [202/285]: loss 0.7210, auc 0.5043, ap 0.5759
2024-01-10 21:58:34,287 - GAugM EPNet train, Epoch [203/285]: loss 0.7210, auc 0.5847, ap 0.6000
2024-01-10 21:58:34,375 - GAugM EPNet train, Epoch [204/285]: loss 0.7209, auc 0.4044, ap 0.4456
2024-01-10 21:58:34,469 - GAugM EPNet train, Epoch [205/285]: loss 0.7209, auc 0.5082, ap 0.5111
2024-01-10 21:58:34,560 - GAugM EPNet train, Epoch [206/285]: loss 0.7209, auc 0.4726, ap 0.4656
2024-01-10 21:58:34,651 - GAugM EPNet train, Epoch [207/285]: loss 0.7210, auc 0.5101, ap 0.5142
2024-01-10 21:58:34,749 - GAugM EPNet train, Epoch [208/285]: loss 0.7209, auc 0.4000, ap 0.4668
2024-01-10 21:58:34,845 - GAugM EPNet train, Epoch [209/285]: loss 0.7210, auc 0.5653, ap 0.5763
2024-01-10 21:58:34,928 - GAugM EPNet train, Epoch [210/285]: loss 0.7209, auc 0.4575, ap 0.4724
2024-01-10 21:58:35,018 - GAugM EPNet train, Epoch [211/285]: loss 0.7210, auc 0.4934, ap 0.4957
2024-01-10 21:58:35,113 - GAugM EPNet train, Epoch [212/285]: loss 0.7210, auc 0.4626, ap 0.4586
2024-01-10 21:58:35,205 - GAugM EPNet train, Epoch [213/285]: loss 0.7208, auc 0.5808, ap 0.5919
2024-01-10 21:58:35,289 - GAugM EPNet train, Epoch [214/285]: loss 0.7210, auc 0.4858, ap 0.4884
2024-01-10 21:58:35,380 - GAugM EPNet train, Epoch [215/285]: loss 0.7210, auc 0.5415, ap 0.5247
2024-01-10 21:58:35,479 - GAugM EPNet train, Epoch [216/285]: loss 0.7209, auc 0.5685, ap 0.5629
2024-01-10 21:58:35,573 - GAugM EPNet train, Epoch [217/285]: loss 0.7209, auc 0.5516, ap 0.6041
2024-01-10 21:58:35,671 - GAugM EPNet train, Epoch [218/285]: loss 0.7209, auc 0.5053, ap 0.5434
2024-01-10 21:58:35,760 - GAugM EPNet train, Epoch [219/285]: loss 0.7208, auc 0.5214, ap 0.5165
2024-01-10 21:58:35,848 - GAugM EPNet train, Epoch [220/285]: loss 0.7210, auc 0.4726, ap 0.5478
2024-01-10 21:58:35,940 - GAugM EPNet train, Epoch [221/285]: loss 0.7209, auc 0.5870, ap 0.5551
2024-01-10 21:58:36,035 - GAugM EPNet train, Epoch [222/285]: loss 0.7209, auc 0.4740, ap 0.4927
2024-01-10 21:58:36,125 - GAugM EPNet train, Epoch [223/285]: loss 0.7209, auc 0.5329, ap 0.5136
2024-01-10 21:58:36,216 - GAugM EPNet train, Epoch [224/285]: loss 0.7210, auc 0.3644, ap 0.4076
2024-01-10 21:58:36,309 - GAugM EPNet train, Epoch [225/285]: loss 0.7209, auc 0.4624, ap 0.4891
2024-01-10 21:58:36,400 - GAugM EPNet train, Epoch [226/285]: loss 0.7210, auc 0.4717, ap 0.4915
2024-01-10 21:58:36,497 - GAugM EPNet train, Epoch [227/285]: loss 0.7210, auc 0.5379, ap 0.5278
2024-01-10 21:58:36,588 - GAugM EPNet train, Epoch [228/285]: loss 0.7209, auc 0.4226, ap 0.4428
2024-01-10 21:58:36,680 - GAugM EPNet train, Epoch [229/285]: loss 0.7209, auc 0.5292, ap 0.5659
2024-01-10 21:58:36,772 - GAugM EPNet train, Epoch [230/285]: loss 0.7209, auc 0.4984, ap 0.5362
2024-01-10 21:58:36,862 - GAugM EPNet train, Epoch [231/285]: loss 0.7209, auc 0.5792, ap 0.5961
2024-01-10 21:58:36,959 - GAugM EPNet train, Epoch [232/285]: loss 0.7209, auc 0.4845, ap 0.5065
2024-01-10 21:58:37,053 - GAugM EPNet train, Epoch [233/285]: loss 0.7210, auc 0.4745, ap 0.4943
2024-01-10 21:58:37,144 - GAugM EPNet train, Epoch [234/285]: loss 0.7209, auc 0.4368, ap 0.4956
2024-01-10 21:58:37,243 - GAugM EPNet train, Epoch [235/285]: loss 0.7209, auc 0.4708, ap 0.4888
2024-01-10 21:58:37,336 - GAugM EPNet train, Epoch [236/285]: loss 0.7209, auc 0.4685, ap 0.5086
2024-01-10 21:58:37,428 - GAugM EPNet train, Epoch [237/285]: loss 0.7210, auc 0.5434, ap 0.5545
2024-01-10 21:58:37,517 - GAugM EPNet train, Epoch [238/285]: loss 0.7210, auc 0.4760, ap 0.4877
2024-01-10 21:58:37,608 - GAugM EPNet train, Epoch [239/285]: loss 0.7209, auc 0.5456, ap 0.5838
2024-01-10 21:58:37,704 - GAugM EPNet train, Epoch [240/285]: loss 0.7209, auc 0.4616, ap 0.4646
2024-01-10 21:58:37,795 - GAugM EPNet train, Epoch [241/285]: loss 0.7209, auc 0.4669, ap 0.4795
2024-01-10 21:58:37,888 - GAugM EPNet train, Epoch [242/285]: loss 0.7210, auc 0.4562, ap 0.4575
2024-01-10 21:58:37,987 - GAugM EPNet train, Epoch [243/285]: loss 0.7210, auc 0.5158, ap 0.5860
2024-01-10 21:58:38,083 - GAugM EPNet train, Epoch [244/285]: loss 0.7209, auc 0.5630, ap 0.5593
2024-01-10 21:58:38,172 - GAugM EPNet train, Epoch [245/285]: loss 0.7210, auc 0.5222, ap 0.5493
2024-01-10 21:58:38,263 - GAugM EPNet train, Epoch [246/285]: loss 0.7208, auc 0.5174, ap 0.5393
2024-01-10 21:58:38,355 - GAugM EPNet train, Epoch [247/285]: loss 0.7209, auc 0.5489, ap 0.5385
2024-01-10 21:58:38,445 - GAugM EPNet train, Epoch [248/285]: loss 0.7211, auc 0.5481, ap 0.5599
2024-01-10 21:58:38,535 - GAugM EPNet train, Epoch [249/285]: loss 0.7209, auc 0.4345, ap 0.4513
2024-01-10 21:58:38,632 - GAugM EPNet train, Epoch [250/285]: loss 0.7208, auc 0.4694, ap 0.4852
2024-01-10 21:58:38,720 - GAugM EPNet train, Epoch [251/285]: loss 0.7209, auc 0.5311, ap 0.5575
2024-01-10 21:58:38,809 - GAugM EPNet train, Epoch [252/285]: loss 0.7210, auc 0.5502, ap 0.5384
2024-01-10 21:58:38,898 - GAugM EPNet train, Epoch [253/285]: loss 0.7209, auc 0.5918, ap 0.5626
2024-01-10 21:58:38,988 - GAugM EPNet train, Epoch [254/285]: loss 0.7210, auc 0.4363, ap 0.4516
2024-01-10 21:58:39,075 - GAugM EPNet train, Epoch [255/285]: loss 0.7209, auc 0.4327, ap 0.4693
2024-01-10 21:58:39,166 - GAugM EPNet train, Epoch [256/285]: loss 0.7210, auc 0.3423, ap 0.4273
2024-01-10 21:58:39,257 - GAugM EPNet train, Epoch [257/285]: loss 0.7210, auc 0.4389, ap 0.4799
2024-01-10 21:58:39,353 - GAugM EPNet train, Epoch [258/285]: loss 0.7208, auc 0.4831, ap 0.4853
2024-01-10 21:58:39,439 - GAugM EPNet train, Epoch [259/285]: loss 0.7208, auc 0.5911, ap 0.5655
2024-01-10 21:58:39,519 - GAugM EPNet train, Epoch [260/285]: loss 0.7210, auc 0.5404, ap 0.5195
2024-01-10 21:58:39,611 - GAugM EPNet train, Epoch [261/285]: loss 0.7209, auc 0.4710, ap 0.4861
2024-01-10 21:58:39,694 - GAugM EPNet train, Epoch [262/285]: loss 0.7208, auc 0.5114, ap 0.5411
2024-01-10 21:58:39,792 - GAugM EPNet train, Epoch [263/285]: loss 0.7209, auc 0.5096, ap 0.5025
2024-01-10 21:58:39,888 - GAugM EPNet train, Epoch [264/285]: loss 0.7210, auc 0.4480, ap 0.4795
2024-01-10 21:58:39,976 - GAugM EPNet train, Epoch [265/285]: loss 0.7209, auc 0.5785, ap 0.6058
2024-01-10 21:58:40,067 - GAugM EPNet train, Epoch [266/285]: loss 0.7209, auc 0.4217, ap 0.4458
2024-01-10 21:58:40,158 - GAugM EPNet train, Epoch [267/285]: loss 0.7210, auc 0.4801, ap 0.4815
2024-01-10 21:58:40,246 - GAugM EPNet train, Epoch [268/285]: loss 0.7210, auc 0.4683, ap 0.5243
2024-01-10 21:58:40,342 - GAugM EPNet train, Epoch [269/285]: loss 0.7209, auc 0.5593, ap 0.5690
2024-01-10 21:58:40,431 - GAugM EPNet train, Epoch [270/285]: loss 0.7210, auc 0.5116, ap 0.5151
2024-01-10 21:58:40,519 - GAugM EPNet train, Epoch [271/285]: loss 0.7209, auc 0.5429, ap 0.5534
2024-01-10 21:58:40,611 - GAugM EPNet train, Epoch [272/285]: loss 0.7209, auc 0.4836, ap 0.4883
2024-01-10 21:58:40,701 - GAugM EPNet train, Epoch [273/285]: loss 0.7209, auc 0.4678, ap 0.4742
2024-01-10 21:58:40,783 - GAugM EPNet train, Epoch [274/285]: loss 0.7209, auc 0.5404, ap 0.5376
2024-01-10 21:58:40,865 - GAugM EPNet train, Epoch [275/285]: loss 0.7208, auc 0.4957, ap 0.5069
2024-01-10 21:58:40,953 - GAugM EPNet train, Epoch [276/285]: loss 0.7210, auc 0.5990, ap 0.6006
2024-01-10 21:58:41,043 - GAugM EPNet train, Epoch [277/285]: loss 0.7208, auc 0.5064, ap 0.5385
2024-01-10 21:58:41,134 - GAugM EPNet train, Epoch [278/285]: loss 0.7209, auc 0.5892, ap 0.5901
2024-01-10 21:58:41,221 - GAugM EPNet train, Epoch [279/285]: loss 0.7209, auc 0.5299, ap 0.5400
2024-01-10 21:58:41,308 - GAugM EPNet train, Epoch [280/285]: loss 0.7209, auc 0.3895, ap 0.4368
2024-01-10 21:58:41,404 - GAugM EPNet train, Epoch [281/285]: loss 0.7209, auc 0.5205, ap 0.5226
2024-01-10 21:58:41,491 - GAugM EPNet train, Epoch [282/285]: loss 0.7209, auc 0.5443, ap 0.5323
2024-01-10 21:58:41,580 - GAugM EPNet train, Epoch [283/285]: loss 0.7209, auc 0.4982, ap 0.5309
2024-01-10 21:58:41,673 - GAugM EPNet train, Epoch [284/285]: loss 0.7209, auc 0.3788, ap 0.4310
2024-01-10 21:58:41,758 - GAugM EPNet train, Epoch [285/285]: loss 0.7209, auc 0.5456, ap 0.5341
2024-01-10 21:58:41,759 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03536610>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:58:42,497 - GAugM EPNet train, Epoch [  1/285]: loss 0.7210, auc 0.5536, ap 0.5448
2024-01-10 21:58:42,582 - GAugM EPNet train, Epoch [  2/285]: loss 0.7210, auc 0.4927, ap 0.5085
2024-01-10 21:58:42,678 - GAugM EPNet train, Epoch [  3/285]: loss 0.7209, auc 0.5283, ap 0.5223
2024-01-10 21:58:42,766 - GAugM EPNet train, Epoch [  4/285]: loss 0.7209, auc 0.4591, ap 0.4832
2024-01-10 21:58:42,853 - GAugM EPNet train, Epoch [  5/285]: loss 0.7209, auc 0.5548, ap 0.5636
2024-01-10 21:58:42,944 - GAugM EPNet train, Epoch [  6/285]: loss 0.7209, auc 0.4975, ap 0.4804
2024-01-10 21:58:43,032 - GAugM EPNet train, Epoch [  7/285]: loss 0.7209, auc 0.4888, ap 0.4750
2024-01-10 21:58:43,124 - GAugM EPNet train, Epoch [  8/285]: loss 0.7210, auc 0.5328, ap 0.5563
2024-01-10 21:58:43,214 - GAugM EPNet train, Epoch [  9/285]: loss 0.7209, auc 0.4122, ap 0.4402
2024-01-10 21:58:43,303 - GAugM EPNet train, Epoch [ 10/285]: loss 0.7208, auc 0.4420, ap 0.4726
2024-01-10 21:58:43,405 - GAugM EPNet train, Epoch [ 11/285]: loss 0.7209, auc 0.5340, ap 0.5531
2024-01-10 21:58:43,494 - GAugM EPNet train, Epoch [ 12/285]: loss 0.7210, auc 0.4834, ap 0.5010
2024-01-10 21:58:43,581 - GAugM EPNet train, Epoch [ 13/285]: loss 0.7209, auc 0.5388, ap 0.5324
2024-01-10 21:58:43,669 - GAugM EPNet train, Epoch [ 14/285]: loss 0.7209, auc 0.4865, ap 0.4927
2024-01-10 21:58:43,761 - GAugM EPNet train, Epoch [ 15/285]: loss 0.7210, auc 0.4153, ap 0.4691
2024-01-10 21:58:43,848 - GAugM EPNet train, Epoch [ 16/285]: loss 0.7209, auc 0.4648, ap 0.5087
2024-01-10 21:58:43,936 - GAugM EPNet train, Epoch [ 17/285]: loss 0.7210, auc 0.4906, ap 0.4954
2024-01-10 21:58:44,024 - GAugM EPNet train, Epoch [ 18/285]: loss 0.7210, auc 0.6451, ap 0.6121
2024-01-10 21:58:44,118 - GAugM EPNet train, Epoch [ 19/285]: loss 0.7209, auc 0.5258, ap 0.5193
2024-01-10 21:58:44,207 - GAugM EPNet train, Epoch [ 20/285]: loss 0.7210, auc 0.4719, ap 0.5048
2024-01-10 21:58:44,295 - GAugM EPNet train, Epoch [ 21/285]: loss 0.7209, auc 0.5160, ap 0.5185
2024-01-10 21:58:44,387 - GAugM EPNet train, Epoch [ 22/285]: loss 0.7210, auc 0.4582, ap 0.5182
2024-01-10 21:58:44,474 - GAugM EPNet train, Epoch [ 23/285]: loss 0.7208, auc 0.5077, ap 0.5041
2024-01-10 21:58:44,567 - GAugM EPNet train, Epoch [ 24/285]: loss 0.7209, auc 0.4916, ap 0.4797
2024-01-10 21:58:44,656 - GAugM EPNet train, Epoch [ 25/285]: loss 0.7209, auc 0.4818, ap 0.4836
2024-01-10 21:58:44,747 - GAugM EPNet train, Epoch [ 26/285]: loss 0.7210, auc 0.5906, ap 0.5800
2024-01-10 21:58:44,837 - GAugM EPNet train, Epoch [ 27/285]: loss 0.7209, auc 0.4325, ap 0.5109
2024-01-10 21:58:44,924 - GAugM EPNet train, Epoch [ 28/285]: loss 0.7209, auc 0.5278, ap 0.5157
2024-01-10 21:58:45,010 - GAugM EPNet train, Epoch [ 29/285]: loss 0.7210, auc 0.5132, ap 0.5279
2024-01-10 21:58:45,098 - GAugM EPNet train, Epoch [ 30/285]: loss 0.7209, auc 0.5685, ap 0.6205
2024-01-10 21:58:45,184 - GAugM EPNet train, Epoch [ 31/285]: loss 0.7208, auc 0.5164, ap 0.5187
2024-01-10 21:58:45,275 - GAugM EPNet train, Epoch [ 32/285]: loss 0.7210, auc 0.5374, ap 0.5253
2024-01-10 21:58:45,363 - GAugM EPNet train, Epoch [ 33/285]: loss 0.7209, auc 0.5310, ap 0.5447
2024-01-10 21:58:45,451 - GAugM EPNet train, Epoch [ 34/285]: loss 0.7209, auc 0.4494, ap 0.4742
2024-01-10 21:58:45,538 - GAugM EPNet train, Epoch [ 35/285]: loss 0.7209, auc 0.4596, ap 0.4678
2024-01-10 21:58:45,632 - GAugM EPNet train, Epoch [ 36/285]: loss 0.7209, auc 0.5061, ap 0.5017
2024-01-10 21:58:45,720 - GAugM EPNet train, Epoch [ 37/285]: loss 0.7209, auc 0.5105, ap 0.5521
2024-01-10 21:58:45,806 - GAugM EPNet train, Epoch [ 38/285]: loss 0.7209, auc 0.5009, ap 0.4924
2024-01-10 21:58:45,900 - GAugM EPNet train, Epoch [ 39/285]: loss 0.7208, auc 0.4155, ap 0.4520
2024-01-10 21:58:45,988 - GAugM EPNet train, Epoch [ 40/285]: loss 0.7210, auc 0.6378, ap 0.5922
2024-01-10 21:58:46,075 - GAugM EPNet train, Epoch [ 41/285]: loss 0.7210, auc 0.4687, ap 0.5094
2024-01-10 21:58:46,162 - GAugM EPNet train, Epoch [ 42/285]: loss 0.7209, auc 0.5470, ap 0.5942
2024-01-10 21:58:46,252 - GAugM EPNet train, Epoch [ 43/285]: loss 0.7208, auc 0.4920, ap 0.5453
2024-01-10 21:58:46,340 - GAugM EPNet train, Epoch [ 44/285]: loss 0.7208, auc 0.3948, ap 0.4273
2024-01-10 21:58:46,434 - GAugM EPNet train, Epoch [ 45/285]: loss 0.7209, auc 0.5148, ap 0.5166
2024-01-10 21:58:46,522 - GAugM EPNet train, Epoch [ 46/285]: loss 0.7209, auc 0.4879, ap 0.5242
2024-01-10 21:58:46,609 - GAugM EPNet train, Epoch [ 47/285]: loss 0.7210, auc 0.4792, ap 0.4898
2024-01-10 21:58:46,695 - GAugM EPNet train, Epoch [ 48/285]: loss 0.7210, auc 0.5043, ap 0.5224
2024-01-10 21:58:46,783 - GAugM EPNet train, Epoch [ 49/285]: loss 0.7209, auc 0.4384, ap 0.4685
2024-01-10 21:58:46,875 - GAugM EPNet train, Epoch [ 50/285]: loss 0.7210, auc 0.4900, ap 0.4849
2024-01-10 21:58:46,967 - GAugM EPNet train, Epoch [ 51/285]: loss 0.7210, auc 0.5069, ap 0.5078
2024-01-10 21:58:47,056 - GAugM EPNet train, Epoch [ 52/285]: loss 0.7209, auc 0.4664, ap 0.5133
2024-01-10 21:58:47,144 - GAugM EPNet train, Epoch [ 53/285]: loss 0.7209, auc 0.5440, ap 0.5984
2024-01-10 21:58:47,237 - GAugM EPNet train, Epoch [ 54/285]: loss 0.7211, auc 0.6161, ap 0.6168
2024-01-10 21:58:47,327 - GAugM EPNet train, Epoch [ 55/285]: loss 0.7209, auc 0.6262, ap 0.6208
2024-01-10 21:58:47,416 - GAugM EPNet train, Epoch [ 56/285]: loss 0.7208, auc 0.4660, ap 0.4846
2024-01-10 21:58:47,510 - GAugM EPNet train, Epoch [ 57/285]: loss 0.7209, auc 0.4817, ap 0.4712
2024-01-10 21:58:47,598 - GAugM EPNet train, Epoch [ 58/285]: loss 0.7210, auc 0.5082, ap 0.5439
2024-01-10 21:58:47,688 - GAugM EPNet train, Epoch [ 59/285]: loss 0.7211, auc 0.5151, ap 0.5131
2024-01-10 21:58:47,776 - GAugM EPNet train, Epoch [ 60/285]: loss 0.7210, auc 0.4778, ap 0.4833
2024-01-10 21:58:47,863 - GAugM EPNet train, Epoch [ 61/285]: loss 0.7209, auc 0.5473, ap 0.5347
2024-01-10 21:58:47,955 - GAugM EPNet train, Epoch [ 62/285]: loss 0.7210, auc 0.4715, ap 0.5255
2024-01-10 21:58:48,040 - GAugM EPNet train, Epoch [ 63/285]: loss 0.7208, auc 0.4598, ap 0.4601
2024-01-10 21:58:48,126 - GAugM EPNet train, Epoch [ 64/285]: loss 0.7208, auc 0.4085, ap 0.4527
2024-01-10 21:58:48,211 - GAugM EPNet train, Epoch [ 65/285]: loss 0.7208, auc 0.5093, ap 0.5226
2024-01-10 21:58:48,300 - GAugM EPNet train, Epoch [ 66/285]: loss 0.7209, auc 0.3889, ap 0.4389
2024-01-10 21:58:48,394 - GAugM EPNet train, Epoch [ 67/285]: loss 0.7209, auc 0.5214, ap 0.5178
2024-01-10 21:58:48,484 - GAugM EPNet train, Epoch [ 68/285]: loss 0.7210, auc 0.4904, ap 0.5382
2024-01-10 21:58:48,572 - GAugM EPNet train, Epoch [ 69/285]: loss 0.7210, auc 0.4797, ap 0.5030
2024-01-10 21:58:48,658 - GAugM EPNet train, Epoch [ 70/285]: loss 0.7210, auc 0.4391, ap 0.4509
2024-01-10 21:58:48,746 - GAugM EPNet train, Epoch [ 71/285]: loss 0.7210, auc 0.5222, ap 0.5266
2024-01-10 21:58:48,833 - GAugM EPNet train, Epoch [ 72/285]: loss 0.7210, auc 0.3836, ap 0.4470
2024-01-10 21:58:48,922 - GAugM EPNet train, Epoch [ 73/285]: loss 0.7209, auc 0.5801, ap 0.5572
2024-01-10 21:58:49,010 - GAugM EPNet train, Epoch [ 74/285]: loss 0.7209, auc 0.4883, ap 0.4906
2024-01-10 21:58:49,097 - GAugM EPNet train, Epoch [ 75/285]: loss 0.7210, auc 0.4706, ap 0.4896
2024-01-10 21:58:49,186 - GAugM EPNet train, Epoch [ 76/285]: loss 0.7209, auc 0.3782, ap 0.4273
2024-01-10 21:58:49,271 - GAugM EPNet train, Epoch [ 77/285]: loss 0.7208, auc 0.6164, ap 0.6131
2024-01-10 21:58:49,360 - GAugM EPNet train, Epoch [ 78/285]: loss 0.7209, auc 0.4681, ap 0.4744
2024-01-10 21:58:49,452 - GAugM EPNet train, Epoch [ 79/285]: loss 0.7208, auc 0.5689, ap 0.5745
2024-01-10 21:58:49,540 - GAugM EPNet train, Epoch [ 80/285]: loss 0.7209, auc 0.6137, ap 0.5735
2024-01-10 21:58:49,630 - GAugM EPNet train, Epoch [ 81/285]: loss 0.7209, auc 0.4491, ap 0.4610
2024-01-10 21:58:49,726 - GAugM EPNet train, Epoch [ 82/285]: loss 0.7210, auc 0.4792, ap 0.4838
2024-01-10 21:58:49,819 - GAugM EPNet train, Epoch [ 83/285]: loss 0.7209, auc 0.5036, ap 0.5262
2024-01-10 21:58:49,909 - GAugM EPNet train, Epoch [ 84/285]: loss 0.7209, auc 0.4671, ap 0.4740
2024-01-10 21:58:49,999 - GAugM EPNet train, Epoch [ 85/285]: loss 0.7210, auc 0.4299, ap 0.4701
2024-01-10 21:58:50,090 - GAugM EPNet train, Epoch [ 86/285]: loss 0.7208, auc 0.5190, ap 0.5144
2024-01-10 21:58:50,186 - GAugM EPNet train, Epoch [ 87/285]: loss 0.7209, auc 0.5150, ap 0.4966
2024-01-10 21:58:50,274 - GAugM EPNet train, Epoch [ 88/285]: loss 0.7210, auc 0.5166, ap 0.5686
2024-01-10 21:58:50,367 - GAugM EPNet train, Epoch [ 89/285]: loss 0.7210, auc 0.4019, ap 0.4550
2024-01-10 21:58:50,457 - GAugM EPNet train, Epoch [ 90/285]: loss 0.7209, auc 0.3628, ap 0.4074
2024-01-10 21:58:50,542 - GAugM EPNet train, Epoch [ 91/285]: loss 0.7208, auc 0.5908, ap 0.5670
2024-01-10 21:58:50,634 - GAugM EPNet train, Epoch [ 92/285]: loss 0.7209, auc 0.5593, ap 0.5583
2024-01-10 21:58:50,724 - GAugM EPNet train, Epoch [ 93/285]: loss 0.7209, auc 0.3491, ap 0.4194
2024-01-10 21:58:50,810 - GAugM EPNet train, Epoch [ 94/285]: loss 0.7210, auc 0.4523, ap 0.4889
2024-01-10 21:58:50,897 - GAugM EPNet train, Epoch [ 95/285]: loss 0.7210, auc 0.4569, ap 0.4781
2024-01-10 21:58:50,984 - GAugM EPNet train, Epoch [ 96/285]: loss 0.7209, auc 0.5308, ap 0.5441
2024-01-10 21:58:51,074 - GAugM EPNet train, Epoch [ 97/285]: loss 0.7209, auc 0.4151, ap 0.4684
2024-01-10 21:58:51,166 - GAugM EPNet train, Epoch [ 98/285]: loss 0.7209, auc 0.4229, ap 0.4410
2024-01-10 21:58:51,252 - GAugM EPNet train, Epoch [ 99/285]: loss 0.7209, auc 0.4213, ap 0.4585
2024-01-10 21:58:51,339 - GAugM EPNet train, Epoch [100/285]: loss 0.7210, auc 0.5945, ap 0.5867
2024-01-10 21:58:51,433 - GAugM EPNet train, Epoch [101/285]: loss 0.7210, auc 0.4665, ap 0.5120
2024-01-10 21:58:51,518 - GAugM EPNet train, Epoch [102/285]: loss 0.7209, auc 0.4169, ap 0.4488
2024-01-10 21:58:51,604 - GAugM EPNet train, Epoch [103/285]: loss 0.7209, auc 0.4923, ap 0.5533
2024-01-10 21:58:51,696 - GAugM EPNet train, Epoch [104/285]: loss 0.7209, auc 0.4258, ap 0.4713
2024-01-10 21:58:51,786 - GAugM EPNet train, Epoch [105/285]: loss 0.7209, auc 0.4281, ap 0.4462
2024-01-10 21:58:51,877 - GAugM EPNet train, Epoch [106/285]: loss 0.7210, auc 0.5411, ap 0.5195
2024-01-10 21:58:51,966 - GAugM EPNet train, Epoch [107/285]: loss 0.7210, auc 0.4623, ap 0.4805
2024-01-10 21:58:52,056 - GAugM EPNet train, Epoch [108/285]: loss 0.7208, auc 0.5443, ap 0.5373
2024-01-10 21:58:52,142 - GAugM EPNet train, Epoch [109/285]: loss 0.7210, auc 0.4683, ap 0.4640
2024-01-10 21:58:52,227 - GAugM EPNet train, Epoch [110/285]: loss 0.7209, auc 0.4737, ap 0.5067
2024-01-10 21:58:52,317 - GAugM EPNet train, Epoch [111/285]: loss 0.7210, auc 0.5913, ap 0.5961
2024-01-10 21:58:52,404 - GAugM EPNet train, Epoch [112/285]: loss 0.7209, auc 0.4877, ap 0.4981
2024-01-10 21:58:52,493 - GAugM EPNet train, Epoch [113/285]: loss 0.7210, auc 0.4450, ap 0.4802
2024-01-10 21:58:52,581 - GAugM EPNet train, Epoch [114/285]: loss 0.7209, auc 0.4151, ap 0.4440
2024-01-10 21:58:52,669 - GAugM EPNet train, Epoch [115/285]: loss 0.7210, auc 0.5153, ap 0.4973
2024-01-10 21:58:52,760 - GAugM EPNet train, Epoch [116/285]: loss 0.7209, auc 0.5628, ap 0.5698
2024-01-10 21:58:52,853 - GAugM EPNet train, Epoch [117/285]: loss 0.7208, auc 0.4605, ap 0.4711
2024-01-10 21:58:52,940 - GAugM EPNet train, Epoch [118/285]: loss 0.7209, auc 0.4309, ap 0.4715
2024-01-10 21:58:53,027 - GAugM EPNet train, Epoch [119/285]: loss 0.7209, auc 0.5418, ap 0.5451
2024-01-10 21:58:53,118 - GAugM EPNet train, Epoch [120/285]: loss 0.7210, auc 0.4341, ap 0.4441
2024-01-10 21:58:53,205 - GAugM EPNet train, Epoch [121/285]: loss 0.7210, auc 0.4854, ap 0.5302
2024-01-10 21:58:53,296 - GAugM EPNet train, Epoch [122/285]: loss 0.7209, auc 0.5753, ap 0.5730
2024-01-10 21:58:53,385 - GAugM EPNet train, Epoch [123/285]: loss 0.7209, auc 0.4575, ap 0.5143
2024-01-10 21:58:53,471 - GAugM EPNet train, Epoch [124/285]: loss 0.7210, auc 0.5345, ap 0.5277
2024-01-10 21:58:53,562 - GAugM EPNet train, Epoch [125/285]: loss 0.7209, auc 0.5504, ap 0.5639
2024-01-10 21:58:53,655 - GAugM EPNet train, Epoch [126/285]: loss 0.7210, auc 0.4899, ap 0.4880
2024-01-10 21:58:53,744 - GAugM EPNet train, Epoch [127/285]: loss 0.7209, auc 0.5726, ap 0.5571
2024-01-10 21:58:53,830 - GAugM EPNet train, Epoch [128/285]: loss 0.7210, auc 0.5164, ap 0.5004
2024-01-10 21:58:53,917 - GAugM EPNet train, Epoch [129/285]: loss 0.7208, auc 0.3564, ap 0.4145
2024-01-10 21:58:54,004 - GAugM EPNet train, Epoch [130/285]: loss 0.7210, auc 0.5046, ap 0.5174
2024-01-10 21:58:54,093 - GAugM EPNet train, Epoch [131/285]: loss 0.7210, auc 0.5417, ap 0.5867
2024-01-10 21:58:54,182 - GAugM EPNet train, Epoch [132/285]: loss 0.7209, auc 0.5283, ap 0.5359
2024-01-10 21:58:54,269 - GAugM EPNet train, Epoch [133/285]: loss 0.7209, auc 0.4261, ap 0.4829
2024-01-10 21:58:54,358 - GAugM EPNet train, Epoch [134/285]: loss 0.7210, auc 0.5085, ap 0.5044
2024-01-10 21:58:54,445 - GAugM EPNet train, Epoch [135/285]: loss 0.7209, auc 0.3661, ap 0.4381
2024-01-10 21:58:54,538 - GAugM EPNet train, Epoch [136/285]: loss 0.7209, auc 0.5084, ap 0.5292
2024-01-10 21:58:54,631 - GAugM EPNet train, Epoch [137/285]: loss 0.7210, auc 0.4941, ap 0.5241
2024-01-10 21:58:54,722 - GAugM EPNet train, Epoch [138/285]: loss 0.7210, auc 0.5568, ap 0.5475
2024-01-10 21:58:54,810 - GAugM EPNet train, Epoch [139/285]: loss 0.7210, auc 0.5085, ap 0.5311
2024-01-10 21:58:54,902 - GAugM EPNet train, Epoch [140/285]: loss 0.7209, auc 0.5637, ap 0.5944
2024-01-10 21:58:54,989 - GAugM EPNet train, Epoch [141/285]: loss 0.7209, auc 0.4957, ap 0.4714
2024-01-10 21:58:55,076 - GAugM EPNet train, Epoch [142/285]: loss 0.7209, auc 0.5237, ap 0.5291
2024-01-10 21:58:55,160 - GAugM EPNet train, Epoch [143/285]: loss 0.7209, auc 0.3818, ap 0.4552
2024-01-10 21:58:55,250 - GAugM EPNet train, Epoch [144/285]: loss 0.7209, auc 0.5541, ap 0.5370
2024-01-10 21:58:55,333 - GAugM EPNet train, Epoch [145/285]: loss 0.7209, auc 0.4811, ap 0.5467
2024-01-10 21:58:55,426 - GAugM EPNet train, Epoch [146/285]: loss 0.7209, auc 0.5075, ap 0.5016
2024-01-10 21:58:55,515 - GAugM EPNet train, Epoch [147/285]: loss 0.7209, auc 0.5719, ap 0.5921
2024-01-10 21:58:55,605 - GAugM EPNet train, Epoch [148/285]: loss 0.7209, auc 0.5263, ap 0.5561
2024-01-10 21:58:55,695 - GAugM EPNet train, Epoch [149/285]: loss 0.7208, auc 0.5500, ap 0.5712
2024-01-10 21:58:55,789 - GAugM EPNet train, Epoch [150/285]: loss 0.7209, auc 0.4867, ap 0.5005
2024-01-10 21:58:55,875 - GAugM EPNet train, Epoch [151/285]: loss 0.7209, auc 0.5374, ap 0.5248
2024-01-10 21:58:55,951 - GAugM EPNet train, Epoch [152/285]: loss 0.7209, auc 0.5993, ap 0.5984
2024-01-10 21:58:56,032 - GAugM EPNet train, Epoch [153/285]: loss 0.7209, auc 0.4818, ap 0.5451
2024-01-10 21:58:56,120 - GAugM EPNet train, Epoch [154/285]: loss 0.7209, auc 0.5486, ap 0.5796
2024-01-10 21:58:56,207 - GAugM EPNet train, Epoch [155/285]: loss 0.7209, auc 0.4197, ap 0.4626
2024-01-10 21:58:56,285 - GAugM EPNet train, Epoch [156/285]: loss 0.7209, auc 0.4349, ap 0.4830
2024-01-10 21:58:56,374 - GAugM EPNet train, Epoch [157/285]: loss 0.7209, auc 0.4760, ap 0.4625
2024-01-10 21:58:56,467 - GAugM EPNet train, Epoch [158/285]: loss 0.7208, auc 0.4701, ap 0.4791
2024-01-10 21:58:56,557 - GAugM EPNet train, Epoch [159/285]: loss 0.7208, auc 0.4941, ap 0.4918
2024-01-10 21:58:56,648 - GAugM EPNet train, Epoch [160/285]: loss 0.7209, auc 0.5443, ap 0.5386
2024-01-10 21:58:56,733 - GAugM EPNet train, Epoch [161/285]: loss 0.7209, auc 0.5215, ap 0.5077
2024-01-10 21:58:56,813 - GAugM EPNet train, Epoch [162/285]: loss 0.7209, auc 0.4195, ap 0.4483
2024-01-10 21:58:56,894 - GAugM EPNet train, Epoch [163/285]: loss 0.7209, auc 0.5032, ap 0.4895
2024-01-10 21:58:56,973 - GAugM EPNet train, Epoch [164/285]: loss 0.7211, auc 0.5198, ap 0.5009
2024-01-10 21:58:57,049 - GAugM EPNet train, Epoch [165/285]: loss 0.7210, auc 0.4943, ap 0.4940
2024-01-10 21:58:57,126 - GAugM EPNet train, Epoch [166/285]: loss 0.7208, auc 0.5173, ap 0.5200
2024-01-10 21:58:57,201 - GAugM EPNet train, Epoch [167/285]: loss 0.7209, auc 0.4738, ap 0.5002
2024-01-10 21:58:57,288 - GAugM EPNet train, Epoch [168/285]: loss 0.7209, auc 0.4877, ap 0.5274
2024-01-10 21:58:57,378 - GAugM EPNet train, Epoch [169/285]: loss 0.7209, auc 0.4715, ap 0.5086
2024-01-10 21:58:57,474 - GAugM EPNet train, Epoch [170/285]: loss 0.7210, auc 0.4541, ap 0.4599
2024-01-10 21:58:57,560 - GAugM EPNet train, Epoch [171/285]: loss 0.7209, auc 0.4473, ap 0.4764
2024-01-10 21:58:57,640 - GAugM EPNet train, Epoch [172/285]: loss 0.7208, auc 0.4219, ap 0.4505
2024-01-10 21:58:57,717 - GAugM EPNet train, Epoch [173/285]: loss 0.7209, auc 0.5208, ap 0.5573
2024-01-10 21:58:57,793 - GAugM EPNet train, Epoch [174/285]: loss 0.7209, auc 0.5112, ap 0.5137
2024-01-10 21:58:57,871 - GAugM EPNet train, Epoch [175/285]: loss 0.7209, auc 0.5936, ap 0.5933
2024-01-10 21:58:57,966 - GAugM EPNet train, Epoch [176/285]: loss 0.7209, auc 0.5269, ap 0.5144
2024-01-10 21:58:58,050 - GAugM EPNet train, Epoch [177/285]: loss 0.7210, auc 0.5445, ap 0.5322
2024-01-10 21:58:58,138 - GAugM EPNet train, Epoch [178/285]: loss 0.7210, auc 0.4564, ap 0.5007
2024-01-10 21:58:58,229 - GAugM EPNet train, Epoch [179/285]: loss 0.7210, auc 0.4190, ap 0.4819
2024-01-10 21:58:58,319 - GAugM EPNet train, Epoch [180/285]: loss 0.7210, auc 0.5627, ap 0.5851
2024-01-10 21:58:58,406 - GAugM EPNet train, Epoch [181/285]: loss 0.7209, auc 0.4338, ap 0.4805
2024-01-10 21:58:58,494 - GAugM EPNet train, Epoch [182/285]: loss 0.7209, auc 0.4756, ap 0.5198
2024-01-10 21:58:58,586 - GAugM EPNet train, Epoch [183/285]: loss 0.7210, auc 0.5390, ap 0.5262
2024-01-10 21:58:58,674 - GAugM EPNet train, Epoch [184/285]: loss 0.7209, auc 0.4334, ap 0.4866
2024-01-10 21:58:58,764 - GAugM EPNet train, Epoch [185/285]: loss 0.7209, auc 0.4845, ap 0.5031
2024-01-10 21:58:58,849 - GAugM EPNet train, Epoch [186/285]: loss 0.7208, auc 0.4146, ap 0.4971
2024-01-10 21:58:58,937 - GAugM EPNet train, Epoch [187/285]: loss 0.7209, auc 0.5418, ap 0.5442
2024-01-10 21:58:59,023 - GAugM EPNet train, Epoch [188/285]: loss 0.7209, auc 0.4457, ap 0.4557
2024-01-10 21:58:59,109 - GAugM EPNet train, Epoch [189/285]: loss 0.7209, auc 0.6897, ap 0.6692
2024-01-10 21:58:59,195 - GAugM EPNet train, Epoch [190/285]: loss 0.7209, auc 0.5039, ap 0.4900
2024-01-10 21:58:59,282 - GAugM EPNet train, Epoch [191/285]: loss 0.7209, auc 0.4155, ap 0.4821
2024-01-10 21:58:59,373 - GAugM EPNet train, Epoch [192/285]: loss 0.7209, auc 0.5406, ap 0.5090
2024-01-10 21:58:59,465 - GAugM EPNet train, Epoch [193/285]: loss 0.7209, auc 0.5144, ap 0.5001
2024-01-10 21:58:59,551 - GAugM EPNet train, Epoch [194/285]: loss 0.7209, auc 0.5308, ap 0.5153
2024-01-10 21:58:59,640 - GAugM EPNet train, Epoch [195/285]: loss 0.7209, auc 0.3834, ap 0.4257
2024-01-10 21:58:59,727 - GAugM EPNet train, Epoch [196/285]: loss 0.7208, auc 0.4998, ap 0.5102
2024-01-10 21:58:59,817 - GAugM EPNet train, Epoch [197/285]: loss 0.7210, auc 0.4462, ap 0.4785
2024-01-10 21:58:59,900 - GAugM EPNet train, Epoch [198/285]: loss 0.7210, auc 0.5153, ap 0.5192
2024-01-10 21:58:59,993 - GAugM EPNet train, Epoch [199/285]: loss 0.7209, auc 0.4432, ap 0.4689
2024-01-10 21:59:00,080 - GAugM EPNet train, Epoch [200/285]: loss 0.7210, auc 0.4824, ap 0.4838
2024-01-10 21:59:00,169 - GAugM EPNet train, Epoch [201/285]: loss 0.7209, auc 0.4220, ap 0.4497
2024-01-10 21:59:00,258 - GAugM EPNet train, Epoch [202/285]: loss 0.7210, auc 0.5465, ap 0.5863
2024-01-10 21:59:00,348 - GAugM EPNet train, Epoch [203/285]: loss 0.7210, auc 0.4655, ap 0.4988
2024-01-10 21:59:00,439 - GAugM EPNet train, Epoch [204/285]: loss 0.7209, auc 0.5201, ap 0.5200
2024-01-10 21:59:00,533 - GAugM EPNet train, Epoch [205/285]: loss 0.7209, auc 0.4420, ap 0.4666
2024-01-10 21:59:00,618 - GAugM EPNet train, Epoch [206/285]: loss 0.7209, auc 0.3898, ap 0.4495
2024-01-10 21:59:00,704 - GAugM EPNet train, Epoch [207/285]: loss 0.7210, auc 0.5002, ap 0.5261
2024-01-10 21:59:00,796 - GAugM EPNet train, Epoch [208/285]: loss 0.7209, auc 0.4897, ap 0.5475
2024-01-10 21:59:00,881 - GAugM EPNet train, Epoch [209/285]: loss 0.7210, auc 0.5940, ap 0.5721
2024-01-10 21:59:00,972 - GAugM EPNet train, Epoch [210/285]: loss 0.7209, auc 0.5125, ap 0.4944
2024-01-10 21:59:01,063 - GAugM EPNet train, Epoch [211/285]: loss 0.7210, auc 0.5198, ap 0.5146
2024-01-10 21:59:01,150 - GAugM EPNet train, Epoch [212/285]: loss 0.7210, auc 0.5023, ap 0.5022
2024-01-10 21:59:01,236 - GAugM EPNet train, Epoch [213/285]: loss 0.7208, auc 0.6493, ap 0.6498
2024-01-10 21:59:01,331 - GAugM EPNet train, Epoch [214/285]: loss 0.7210, auc 0.4991, ap 0.5004
2024-01-10 21:59:01,419 - GAugM EPNet train, Epoch [215/285]: loss 0.7210, auc 0.4824, ap 0.4862
2024-01-10 21:59:01,518 - GAugM EPNet train, Epoch [216/285]: loss 0.7209, auc 0.5096, ap 0.5037
2024-01-10 21:59:01,605 - GAugM EPNet train, Epoch [217/285]: loss 0.7209, auc 0.4996, ap 0.5149
2024-01-10 21:59:01,693 - GAugM EPNet train, Epoch [218/285]: loss 0.7209, auc 0.5545, ap 0.5476
2024-01-10 21:59:01,786 - GAugM EPNet train, Epoch [219/285]: loss 0.7208, auc 0.5053, ap 0.5127
2024-01-10 21:59:01,869 - GAugM EPNet train, Epoch [220/285]: loss 0.7210, auc 0.5046, ap 0.5315
2024-01-10 21:59:01,955 - GAugM EPNet train, Epoch [221/285]: loss 0.7209, auc 0.5644, ap 0.5492
2024-01-10 21:59:02,040 - GAugM EPNet train, Epoch [222/285]: loss 0.7209, auc 0.4879, ap 0.5170
2024-01-10 21:59:02,126 - GAugM EPNet train, Epoch [223/285]: loss 0.7209, auc 0.5093, ap 0.5288
2024-01-10 21:59:02,215 - GAugM EPNet train, Epoch [224/285]: loss 0.7210, auc 0.4400, ap 0.4485
2024-01-10 21:59:02,303 - GAugM EPNet train, Epoch [225/285]: loss 0.7209, auc 0.4854, ap 0.5021
2024-01-10 21:59:02,407 - GAugM EPNet train, Epoch [226/285]: loss 0.7210, auc 0.4979, ap 0.5040
2024-01-10 21:59:02,496 - GAugM EPNet train, Epoch [227/285]: loss 0.7210, auc 0.4357, ap 0.4485
2024-01-10 21:59:02,588 - GAugM EPNet train, Epoch [228/285]: loss 0.7209, auc 0.4998, ap 0.5589
2024-01-10 21:59:02,681 - GAugM EPNet train, Epoch [229/285]: loss 0.7209, auc 0.4913, ap 0.4825
2024-01-10 21:59:02,769 - GAugM EPNet train, Epoch [230/285]: loss 0.7209, auc 0.4818, ap 0.5245
2024-01-10 21:59:02,861 - GAugM EPNet train, Epoch [231/285]: loss 0.7209, auc 0.5230, ap 0.5196
2024-01-10 21:59:02,951 - GAugM EPNet train, Epoch [232/285]: loss 0.7209, auc 0.5833, ap 0.5793
2024-01-10 21:59:03,044 - GAugM EPNet train, Epoch [233/285]: loss 0.7210, auc 0.5431, ap 0.5623
2024-01-10 21:59:03,131 - GAugM EPNet train, Epoch [234/285]: loss 0.7209, auc 0.3848, ap 0.4764
2024-01-10 21:59:03,210 - GAugM EPNet train, Epoch [235/285]: loss 0.7209, auc 0.3907, ap 0.4308
2024-01-10 21:59:03,302 - GAugM EPNet train, Epoch [236/285]: loss 0.7209, auc 0.5488, ap 0.5926
2024-01-10 21:59:03,395 - GAugM EPNet train, Epoch [237/285]: loss 0.7210, auc 0.5329, ap 0.5083
2024-01-10 21:59:03,485 - GAugM EPNet train, Epoch [238/285]: loss 0.7210, auc 0.4667, ap 0.5187
2024-01-10 21:59:03,579 - GAugM EPNet train, Epoch [239/285]: loss 0.7209, auc 0.5174, ap 0.5835
2024-01-10 21:59:03,669 - GAugM EPNet train, Epoch [240/285]: loss 0.7209, auc 0.4646, ap 0.4673
2024-01-10 21:59:03,758 - GAugM EPNet train, Epoch [241/285]: loss 0.7209, auc 0.5253, ap 0.5049
2024-01-10 21:59:03,849 - GAugM EPNet train, Epoch [242/285]: loss 0.7210, auc 0.4808, ap 0.5266
2024-01-10 21:59:03,938 - GAugM EPNet train, Epoch [243/285]: loss 0.7210, auc 0.5466, ap 0.5969
2024-01-10 21:59:04,024 - GAugM EPNet train, Epoch [244/285]: loss 0.7209, auc 0.4801, ap 0.4819
2024-01-10 21:59:04,114 - GAugM EPNet train, Epoch [245/285]: loss 0.7210, auc 0.4644, ap 0.5116
2024-01-10 21:59:04,201 - GAugM EPNet train, Epoch [246/285]: loss 0.7208, auc 0.5879, ap 0.5796
2024-01-10 21:59:04,293 - GAugM EPNet train, Epoch [247/285]: loss 0.7209, auc 0.4573, ap 0.4668
2024-01-10 21:59:04,382 - GAugM EPNet train, Epoch [248/285]: loss 0.7211, auc 0.5176, ap 0.5160
2024-01-10 21:59:04,472 - GAugM EPNet train, Epoch [249/285]: loss 0.7209, auc 0.5055, ap 0.4926
2024-01-10 21:59:04,566 - GAugM EPNet train, Epoch [250/285]: loss 0.7208, auc 0.5546, ap 0.5490
2024-01-10 21:59:04,657 - GAugM EPNet train, Epoch [251/285]: loss 0.7209, auc 0.5190, ap 0.5258
2024-01-10 21:59:04,753 - GAugM EPNet train, Epoch [252/285]: loss 0.7210, auc 0.5395, ap 0.5769
2024-01-10 21:59:04,844 - GAugM EPNet train, Epoch [253/285]: loss 0.7209, auc 0.5402, ap 0.5280
2024-01-10 21:59:04,933 - GAugM EPNet train, Epoch [254/285]: loss 0.7210, auc 0.5244, ap 0.5508
2024-01-10 21:59:05,025 - GAugM EPNet train, Epoch [255/285]: loss 0.7209, auc 0.4655, ap 0.5111
2024-01-10 21:59:05,115 - GAugM EPNet train, Epoch [256/285]: loss 0.7210, auc 0.4242, ap 0.5204
2024-01-10 21:59:05,202 - GAugM EPNet train, Epoch [257/285]: loss 0.7210, auc 0.4852, ap 0.5104
2024-01-10 21:59:05,288 - GAugM EPNet train, Epoch [258/285]: loss 0.7208, auc 0.5826, ap 0.5838
2024-01-10 21:59:05,381 - GAugM EPNet train, Epoch [259/285]: loss 0.7208, auc 0.5748, ap 0.5356
2024-01-10 21:59:05,467 - GAugM EPNet train, Epoch [260/285]: loss 0.7210, auc 0.5242, ap 0.5180
2024-01-10 21:59:05,557 - GAugM EPNet train, Epoch [261/285]: loss 0.7209, auc 0.4548, ap 0.4923
2024-01-10 21:59:05,644 - GAugM EPNet train, Epoch [262/285]: loss 0.7208, auc 0.5196, ap 0.5281
2024-01-10 21:59:05,730 - GAugM EPNet train, Epoch [263/285]: loss 0.7209, auc 0.5295, ap 0.5297
2024-01-10 21:59:05,815 - GAugM EPNet train, Epoch [264/285]: loss 0.7210, auc 0.4575, ap 0.4721
2024-01-10 21:59:05,902 - GAugM EPNet train, Epoch [265/285]: loss 0.7209, auc 0.4667, ap 0.5072
2024-01-10 21:59:05,990 - GAugM EPNet train, Epoch [266/285]: loss 0.7209, auc 0.5185, ap 0.5143
2024-01-10 21:59:06,081 - GAugM EPNet train, Epoch [267/285]: loss 0.7210, auc 0.5061, ap 0.5331
2024-01-10 21:59:06,170 - GAugM EPNet train, Epoch [268/285]: loss 0.7210, auc 0.5053, ap 0.5419
2024-01-10 21:59:06,256 - GAugM EPNet train, Epoch [269/285]: loss 0.7209, auc 0.5436, ap 0.5531
2024-01-10 21:59:06,342 - GAugM EPNet train, Epoch [270/285]: loss 0.7210, auc 0.4603, ap 0.4801
2024-01-10 21:59:06,429 - GAugM EPNet train, Epoch [271/285]: loss 0.7209, auc 0.4340, ap 0.4822
2024-01-10 21:59:06,515 - GAugM EPNet train, Epoch [272/285]: loss 0.7209, auc 0.5228, ap 0.5253
2024-01-10 21:59:06,612 - GAugM EPNet train, Epoch [273/285]: loss 0.7209, auc 0.4906, ap 0.5026
2024-01-10 21:59:06,699 - GAugM EPNet train, Epoch [274/285]: loss 0.7209, auc 0.5137, ap 0.5256
2024-01-10 21:59:06,793 - GAugM EPNet train, Epoch [275/285]: loss 0.7208, auc 0.5071, ap 0.5093
2024-01-10 21:59:06,883 - GAugM EPNet train, Epoch [276/285]: loss 0.7210, auc 0.5408, ap 0.5641
2024-01-10 21:59:06,976 - GAugM EPNet train, Epoch [277/285]: loss 0.7208, auc 0.4713, ap 0.5250
2024-01-10 21:59:07,061 - GAugM EPNet train, Epoch [278/285]: loss 0.7209, auc 0.4808, ap 0.5079
2024-01-10 21:59:07,148 - GAugM EPNet train, Epoch [279/285]: loss 0.7209, auc 0.5256, ap 0.5565
2024-01-10 21:59:07,243 - GAugM EPNet train, Epoch [280/285]: loss 0.7209, auc 0.3448, ap 0.4072
2024-01-10 21:59:07,330 - GAugM EPNet train, Epoch [281/285]: loss 0.7209, auc 0.6182, ap 0.5900
2024-01-10 21:59:07,422 - GAugM EPNet train, Epoch [282/285]: loss 0.7209, auc 0.4989, ap 0.5307
2024-01-10 21:59:07,511 - GAugM EPNet train, Epoch [283/285]: loss 0.7209, auc 0.4948, ap 0.4944
2024-01-10 21:59:07,596 - GAugM EPNet train, Epoch [284/285]: loss 0.7209, auc 0.4509, ap 0.4925
2024-01-10 21:59:07,681 - GAugM EPNet train, Epoch [285/285]: loss 0.7209, auc 0.5773, ap 0.5584
2024-01-10 21:59:07,682 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d0356aa90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:59:08,392 - GAugM EPNet train, Epoch [  1/285]: loss 0.7210, auc 0.4309, ap 0.4510
2024-01-10 21:59:08,483 - GAugM EPNet train, Epoch [  2/285]: loss 0.7210, auc 0.4697, ap 0.4816
2024-01-10 21:59:08,570 - GAugM EPNet train, Epoch [  3/285]: loss 0.7209, auc 0.5093, ap 0.5062
2024-01-10 21:59:08,657 - GAugM EPNet train, Epoch [  4/285]: loss 0.7209, auc 0.5331, ap 0.5308
2024-01-10 21:59:08,745 - GAugM EPNet train, Epoch [  5/285]: loss 0.7209, auc 0.6082, ap 0.6104
2024-01-10 21:59:08,831 - GAugM EPNet train, Epoch [  6/285]: loss 0.7209, auc 0.4797, ap 0.4956
2024-01-10 21:59:08,918 - GAugM EPNet train, Epoch [  7/285]: loss 0.7209, auc 0.4726, ap 0.4730
2024-01-10 21:59:09,005 - GAugM EPNet train, Epoch [  8/285]: loss 0.7210, auc 0.5011, ap 0.5289
2024-01-10 21:59:09,089 - GAugM EPNet train, Epoch [  9/285]: loss 0.7209, auc 0.4765, ap 0.4687
2024-01-10 21:59:09,183 - GAugM EPNet train, Epoch [ 10/285]: loss 0.7208, auc 0.4309, ap 0.4491
2024-01-10 21:59:09,273 - GAugM EPNet train, Epoch [ 11/285]: loss 0.7209, auc 0.4811, ap 0.5256
2024-01-10 21:59:09,362 - GAugM EPNet train, Epoch [ 12/285]: loss 0.7210, auc 0.4594, ap 0.4792
2024-01-10 21:59:09,448 - GAugM EPNet train, Epoch [ 13/285]: loss 0.7209, auc 0.4786, ap 0.4664
2024-01-10 21:59:09,534 - GAugM EPNet train, Epoch [ 14/285]: loss 0.7209, auc 0.5328, ap 0.5326
2024-01-10 21:59:09,623 - GAugM EPNet train, Epoch [ 15/285]: loss 0.7210, auc 0.4534, ap 0.4971
2024-01-10 21:59:09,709 - GAugM EPNet train, Epoch [ 16/285]: loss 0.7209, auc 0.4886, ap 0.5031
2024-01-10 21:59:09,796 - GAugM EPNet train, Epoch [ 17/285]: loss 0.7210, auc 0.5434, ap 0.5312
2024-01-10 21:59:09,882 - GAugM EPNet train, Epoch [ 18/285]: loss 0.7210, auc 0.6036, ap 0.5939
2024-01-10 21:59:09,965 - GAugM EPNet train, Epoch [ 19/285]: loss 0.7209, auc 0.4745, ap 0.4949
2024-01-10 21:59:10,054 - GAugM EPNet train, Epoch [ 20/285]: loss 0.7210, auc 0.5214, ap 0.5579
2024-01-10 21:59:10,139 - GAugM EPNet train, Epoch [ 21/285]: loss 0.7209, auc 0.4783, ap 0.4746
2024-01-10 21:59:10,231 - GAugM EPNet train, Epoch [ 22/285]: loss 0.7210, auc 0.3629, ap 0.4178
2024-01-10 21:59:10,316 - GAugM EPNet train, Epoch [ 23/285]: loss 0.7208, auc 0.4623, ap 0.4870
2024-01-10 21:59:10,406 - GAugM EPNet train, Epoch [ 24/285]: loss 0.7209, auc 0.4925, ap 0.4953
2024-01-10 21:59:10,491 - GAugM EPNet train, Epoch [ 25/285]: loss 0.7209, auc 0.4551, ap 0.4797
2024-01-10 21:59:10,578 - GAugM EPNet train, Epoch [ 26/285]: loss 0.7210, auc 0.5509, ap 0.5633
2024-01-10 21:59:10,663 - GAugM EPNet train, Epoch [ 27/285]: loss 0.7209, auc 0.4007, ap 0.4538
2024-01-10 21:59:10,748 - GAugM EPNet train, Epoch [ 28/285]: loss 0.7209, auc 0.5904, ap 0.5899
2024-01-10 21:59:10,832 - GAugM EPNet train, Epoch [ 29/285]: loss 0.7210, auc 0.4345, ap 0.4527
2024-01-10 21:59:10,918 - GAugM EPNet train, Epoch [ 30/285]: loss 0.7209, auc 0.4452, ap 0.4743
2024-01-10 21:59:11,004 - GAugM EPNet train, Epoch [ 31/285]: loss 0.7208, auc 0.5039, ap 0.4958
2024-01-10 21:59:11,090 - GAugM EPNet train, Epoch [ 32/285]: loss 0.7210, auc 0.5395, ap 0.5221
2024-01-10 21:59:11,175 - GAugM EPNet train, Epoch [ 33/285]: loss 0.7209, auc 0.5342, ap 0.5673
2024-01-10 21:59:11,261 - GAugM EPNet train, Epoch [ 34/285]: loss 0.7209, auc 0.4961, ap 0.5226
2024-01-10 21:59:11,347 - GAugM EPNet train, Epoch [ 35/285]: loss 0.7209, auc 0.5434, ap 0.5230
2024-01-10 21:59:11,432 - GAugM EPNet train, Epoch [ 36/285]: loss 0.7209, auc 0.5655, ap 0.5596
2024-01-10 21:59:11,524 - GAugM EPNet train, Epoch [ 37/285]: loss 0.7209, auc 0.5256, ap 0.5410
2024-01-10 21:59:11,610 - GAugM EPNet train, Epoch [ 38/285]: loss 0.7209, auc 0.5947, ap 0.5528
2024-01-10 21:59:11,696 - GAugM EPNet train, Epoch [ 39/285]: loss 0.7208, auc 0.4299, ap 0.4691
2024-01-10 21:59:11,780 - GAugM EPNet train, Epoch [ 40/285]: loss 0.7210, auc 0.5890, ap 0.5453
2024-01-10 21:59:11,866 - GAugM EPNet train, Epoch [ 41/285]: loss 0.7210, auc 0.5420, ap 0.5327
2024-01-10 21:59:11,953 - GAugM EPNet train, Epoch [ 42/285]: loss 0.7209, auc 0.5434, ap 0.5712
2024-01-10 21:59:12,042 - GAugM EPNet train, Epoch [ 43/285]: loss 0.7208, auc 0.4612, ap 0.5160
2024-01-10 21:59:12,130 - GAugM EPNet train, Epoch [ 44/285]: loss 0.7208, auc 0.3640, ap 0.4150
2024-01-10 21:59:12,215 - GAugM EPNet train, Epoch [ 45/285]: loss 0.7209, auc 0.5292, ap 0.5287
2024-01-10 21:59:12,299 - GAugM EPNet train, Epoch [ 46/285]: loss 0.7209, auc 0.4744, ap 0.5070
2024-01-10 21:59:12,384 - GAugM EPNet train, Epoch [ 47/285]: loss 0.7210, auc 0.4758, ap 0.5186
2024-01-10 21:59:12,469 - GAugM EPNet train, Epoch [ 48/285]: loss 0.7210, auc 0.6089, ap 0.6209
2024-01-10 21:59:12,554 - GAugM EPNet train, Epoch [ 49/285]: loss 0.7209, auc 0.4996, ap 0.5041
2024-01-10 21:59:12,639 - GAugM EPNet train, Epoch [ 50/285]: loss 0.7210, auc 0.4726, ap 0.4792
2024-01-10 21:59:12,730 - GAugM EPNet train, Epoch [ 51/285]: loss 0.7210, auc 0.4897, ap 0.4862
2024-01-10 21:59:12,815 - GAugM EPNet train, Epoch [ 52/285]: loss 0.7209, auc 0.4583, ap 0.4920
2024-01-10 21:59:12,900 - GAugM EPNet train, Epoch [ 53/285]: loss 0.7209, auc 0.5644, ap 0.5840
2024-01-10 21:59:12,985 - GAugM EPNet train, Epoch [ 54/285]: loss 0.7211, auc 0.5726, ap 0.5634
2024-01-10 21:59:13,075 - GAugM EPNet train, Epoch [ 55/285]: loss 0.7209, auc 0.5566, ap 0.5546
2024-01-10 21:59:13,159 - GAugM EPNet train, Epoch [ 56/285]: loss 0.7208, auc 0.5328, ap 0.5036
2024-01-10 21:59:13,245 - GAugM EPNet train, Epoch [ 57/285]: loss 0.7209, auc 0.4683, ap 0.4658
2024-01-10 21:59:13,328 - GAugM EPNet train, Epoch [ 58/285]: loss 0.7210, auc 0.5345, ap 0.5587
2024-01-10 21:59:13,414 - GAugM EPNet train, Epoch [ 59/285]: loss 0.7211, auc 0.5409, ap 0.5304
2024-01-10 21:59:13,500 - GAugM EPNet train, Epoch [ 60/285]: loss 0.7210, auc 0.5089, ap 0.5199
2024-01-10 21:59:13,584 - GAugM EPNet train, Epoch [ 61/285]: loss 0.7209, auc 0.5705, ap 0.5718
2024-01-10 21:59:13,668 - GAugM EPNet train, Epoch [ 62/285]: loss 0.7210, auc 0.5801, ap 0.5759
2024-01-10 21:59:13,761 - GAugM EPNet train, Epoch [ 63/285]: loss 0.7208, auc 0.4676, ap 0.4773
2024-01-10 21:59:13,846 - GAugM EPNet train, Epoch [ 64/285]: loss 0.7208, auc 0.4363, ap 0.4759
2024-01-10 21:59:13,932 - GAugM EPNet train, Epoch [ 65/285]: loss 0.7208, auc 0.5901, ap 0.5752
2024-01-10 21:59:14,017 - GAugM EPNet train, Epoch [ 66/285]: loss 0.7209, auc 0.4651, ap 0.4756
2024-01-10 21:59:14,104 - GAugM EPNet train, Epoch [ 67/285]: loss 0.7209, auc 0.4583, ap 0.4696
2024-01-10 21:59:14,188 - GAugM EPNet train, Epoch [ 68/285]: loss 0.7210, auc 0.5698, ap 0.5974
2024-01-10 21:59:14,273 - GAugM EPNet train, Epoch [ 69/285]: loss 0.7210, auc 0.4989, ap 0.5096
2024-01-10 21:59:14,359 - GAugM EPNet train, Epoch [ 70/285]: loss 0.7210, auc 0.5082, ap 0.4941
2024-01-10 21:59:14,445 - GAugM EPNet train, Epoch [ 71/285]: loss 0.7210, auc 0.5424, ap 0.5281
2024-01-10 21:59:14,530 - GAugM EPNet train, Epoch [ 72/285]: loss 0.7210, auc 0.4822, ap 0.5049
2024-01-10 21:59:14,619 - GAugM EPNet train, Epoch [ 73/285]: loss 0.7209, auc 0.4598, ap 0.4750
2024-01-10 21:59:14,706 - GAugM EPNet train, Epoch [ 74/285]: loss 0.7209, auc 0.5068, ap 0.5105
2024-01-10 21:59:14,792 - GAugM EPNet train, Epoch [ 75/285]: loss 0.7210, auc 0.4722, ap 0.4726
2024-01-10 21:59:14,877 - GAugM EPNet train, Epoch [ 76/285]: loss 0.7209, auc 0.4413, ap 0.4633
2024-01-10 21:59:14,963 - GAugM EPNet train, Epoch [ 77/285]: loss 0.7208, auc 0.6075, ap 0.6013
2024-01-10 21:59:15,052 - GAugM EPNet train, Epoch [ 78/285]: loss 0.7209, auc 0.5342, ap 0.5382
2024-01-10 21:59:15,136 - GAugM EPNet train, Epoch [ 79/285]: loss 0.7208, auc 0.5100, ap 0.5006
2024-01-10 21:59:15,224 - GAugM EPNet train, Epoch [ 80/285]: loss 0.7209, auc 0.5769, ap 0.5626
2024-01-10 21:59:15,311 - GAugM EPNet train, Epoch [ 81/285]: loss 0.7209, auc 0.4769, ap 0.4789
2024-01-10 21:59:15,395 - GAugM EPNet train, Epoch [ 82/285]: loss 0.7210, auc 0.5018, ap 0.5008
2024-01-10 21:59:15,479 - GAugM EPNet train, Epoch [ 83/285]: loss 0.7209, auc 0.4776, ap 0.4972
2024-01-10 21:59:15,567 - GAugM EPNet train, Epoch [ 84/285]: loss 0.7209, auc 0.5295, ap 0.5394
2024-01-10 21:59:15,652 - GAugM EPNet train, Epoch [ 85/285]: loss 0.7210, auc 0.4854, ap 0.4851
2024-01-10 21:59:15,736 - GAugM EPNet train, Epoch [ 86/285]: loss 0.7208, auc 0.3804, ap 0.4174
2024-01-10 21:59:15,820 - GAugM EPNet train, Epoch [ 87/285]: loss 0.7209, auc 0.5150, ap 0.4985
2024-01-10 21:59:15,912 - GAugM EPNet train, Epoch [ 88/285]: loss 0.7210, auc 0.5356, ap 0.5535
2024-01-10 21:59:15,996 - GAugM EPNet train, Epoch [ 89/285]: loss 0.7210, auc 0.4904, ap 0.5292
2024-01-10 21:59:16,080 - GAugM EPNet train, Epoch [ 90/285]: loss 0.7209, auc 0.4252, ap 0.4490
2024-01-10 21:59:16,170 - GAugM EPNet train, Epoch [ 91/285]: loss 0.7208, auc 0.5773, ap 0.5550
2024-01-10 21:59:16,256 - GAugM EPNet train, Epoch [ 92/285]: loss 0.7209, auc 0.5805, ap 0.5681
2024-01-10 21:59:16,341 - GAugM EPNet train, Epoch [ 93/285]: loss 0.7209, auc 0.4516, ap 0.4855
2024-01-10 21:59:16,424 - GAugM EPNet train, Epoch [ 94/285]: loss 0.7210, auc 0.4153, ap 0.4893
2024-01-10 21:59:16,509 - GAugM EPNet train, Epoch [ 95/285]: loss 0.7210, auc 0.5260, ap 0.5022
2024-01-10 21:59:16,594 - GAugM EPNet train, Epoch [ 96/285]: loss 0.7209, auc 0.5972, ap 0.5923
2024-01-10 21:59:16,679 - GAugM EPNet train, Epoch [ 97/285]: loss 0.7209, auc 0.4665, ap 0.5317
2024-01-10 21:59:16,763 - GAugM EPNet train, Epoch [ 98/285]: loss 0.7209, auc 0.5231, ap 0.4938
2024-01-10 21:59:16,853 - GAugM EPNet train, Epoch [ 99/285]: loss 0.7209, auc 0.5338, ap 0.5623
2024-01-10 21:59:16,938 - GAugM EPNet train, Epoch [100/285]: loss 0.7210, auc 0.4975, ap 0.5142
2024-01-10 21:59:17,026 - GAugM EPNet train, Epoch [101/285]: loss 0.7210, auc 0.3811, ap 0.4361
2024-01-10 21:59:17,114 - GAugM EPNet train, Epoch [102/285]: loss 0.7209, auc 0.5409, ap 0.5727
2024-01-10 21:59:17,199 - GAugM EPNet train, Epoch [103/285]: loss 0.7209, auc 0.5837, ap 0.5978
2024-01-10 21:59:17,289 - GAugM EPNet train, Epoch [104/285]: loss 0.7209, auc 0.4370, ap 0.4472
2024-01-10 21:59:17,374 - GAugM EPNet train, Epoch [105/285]: loss 0.7209, auc 0.4915, ap 0.5080
2024-01-10 21:59:17,462 - GAugM EPNet train, Epoch [106/285]: loss 0.7210, auc 0.5384, ap 0.5572
2024-01-10 21:59:17,549 - GAugM EPNet train, Epoch [107/285]: loss 0.7210, auc 0.4583, ap 0.5034
2024-01-10 21:59:17,633 - GAugM EPNet train, Epoch [108/285]: loss 0.7208, auc 0.5559, ap 0.5426
2024-01-10 21:59:17,717 - GAugM EPNet train, Epoch [109/285]: loss 0.7210, auc 0.4356, ap 0.4612
2024-01-10 21:59:17,806 - GAugM EPNet train, Epoch [110/285]: loss 0.7209, auc 0.4434, ap 0.4721
2024-01-10 21:59:17,892 - GAugM EPNet train, Epoch [111/285]: loss 0.7210, auc 0.5146, ap 0.5049
2024-01-10 21:59:17,978 - GAugM EPNet train, Epoch [112/285]: loss 0.7209, auc 0.5132, ap 0.5190
2024-01-10 21:59:18,064 - GAugM EPNet train, Epoch [113/285]: loss 0.7210, auc 0.4737, ap 0.5056
2024-01-10 21:59:18,151 - GAugM EPNet train, Epoch [114/285]: loss 0.7209, auc 0.5032, ap 0.4986
2024-01-10 21:59:18,238 - GAugM EPNet train, Epoch [115/285]: loss 0.7210, auc 0.4911, ap 0.4786
2024-01-10 21:59:18,329 - GAugM EPNet train, Epoch [116/285]: loss 0.7209, auc 0.5616, ap 0.5488
2024-01-10 21:59:18,413 - GAugM EPNet train, Epoch [117/285]: loss 0.7208, auc 0.4288, ap 0.4573
2024-01-10 21:59:18,500 - GAugM EPNet train, Epoch [118/285]: loss 0.7209, auc 0.5303, ap 0.5797
2024-01-10 21:59:18,584 - GAugM EPNet train, Epoch [119/285]: loss 0.7209, auc 0.4890, ap 0.5039
2024-01-10 21:59:18,668 - GAugM EPNet train, Epoch [120/285]: loss 0.7210, auc 0.4395, ap 0.4421
2024-01-10 21:59:18,753 - GAugM EPNet train, Epoch [121/285]: loss 0.7210, auc 0.4046, ap 0.4635
2024-01-10 21:59:18,840 - GAugM EPNet train, Epoch [122/285]: loss 0.7209, auc 0.5046, ap 0.5214
2024-01-10 21:59:18,925 - GAugM EPNet train, Epoch [123/285]: loss 0.7209, auc 0.4858, ap 0.4879
2024-01-10 21:59:19,014 - GAugM EPNet train, Epoch [124/285]: loss 0.7210, auc 0.4922, ap 0.5098
2024-01-10 21:59:19,099 - GAugM EPNet train, Epoch [125/285]: loss 0.7209, auc 0.5249, ap 0.5002
2024-01-10 21:59:19,184 - GAugM EPNet train, Epoch [126/285]: loss 0.7210, auc 0.4509, ap 0.4662
2024-01-10 21:59:19,276 - GAugM EPNet train, Epoch [127/285]: loss 0.7209, auc 0.5256, ap 0.5131
2024-01-10 21:59:19,361 - GAugM EPNet train, Epoch [128/285]: loss 0.7210, auc 0.5498, ap 0.5346
2024-01-10 21:59:19,445 - GAugM EPNet train, Epoch [129/285]: loss 0.7208, auc 0.3110, ap 0.3909
2024-01-10 21:59:19,529 - GAugM EPNet train, Epoch [130/285]: loss 0.7210, auc 0.5043, ap 0.5031
2024-01-10 21:59:19,618 - GAugM EPNet train, Epoch [131/285]: loss 0.7210, auc 0.4993, ap 0.5468
2024-01-10 21:59:19,705 - GAugM EPNet train, Epoch [132/285]: loss 0.7209, auc 0.5032, ap 0.4991
2024-01-10 21:59:19,790 - GAugM EPNet train, Epoch [133/285]: loss 0.7209, auc 0.4260, ap 0.4556
2024-01-10 21:59:19,879 - GAugM EPNet train, Epoch [134/285]: loss 0.7210, auc 0.4826, ap 0.4993
2024-01-10 21:59:19,964 - GAugM EPNet train, Epoch [135/285]: loss 0.7209, auc 0.4530, ap 0.4818
2024-01-10 21:59:20,053 - GAugM EPNet train, Epoch [136/285]: loss 0.7209, auc 0.4708, ap 0.4796
2024-01-10 21:59:20,143 - GAugM EPNet train, Epoch [137/285]: loss 0.7210, auc 0.4203, ap 0.4409
2024-01-10 21:59:20,227 - GAugM EPNet train, Epoch [138/285]: loss 0.7210, auc 0.4982, ap 0.4963
2024-01-10 21:59:20,316 - GAugM EPNet train, Epoch [139/285]: loss 0.7210, auc 0.5075, ap 0.5233
2024-01-10 21:59:20,401 - GAugM EPNet train, Epoch [140/285]: loss 0.7209, auc 0.4836, ap 0.5318
2024-01-10 21:59:20,486 - GAugM EPNet train, Epoch [141/285]: loss 0.7209, auc 0.5078, ap 0.5110
2024-01-10 21:59:20,570 - GAugM EPNet train, Epoch [142/285]: loss 0.7209, auc 0.5822, ap 0.5660
2024-01-10 21:59:20,658 - GAugM EPNet train, Epoch [143/285]: loss 0.7209, auc 0.3868, ap 0.4455
2024-01-10 21:59:20,743 - GAugM EPNet train, Epoch [144/285]: loss 0.7209, auc 0.5021, ap 0.4995
2024-01-10 21:59:20,827 - GAugM EPNet train, Epoch [145/285]: loss 0.7209, auc 0.4843, ap 0.5132
2024-01-10 21:59:20,910 - GAugM EPNet train, Epoch [146/285]: loss 0.7209, auc 0.5666, ap 0.5646
2024-01-10 21:59:20,997 - GAugM EPNet train, Epoch [147/285]: loss 0.7209, auc 0.5894, ap 0.6059
2024-01-10 21:59:21,080 - GAugM EPNet train, Epoch [148/285]: loss 0.7209, auc 0.5014, ap 0.5423
2024-01-10 21:59:21,168 - GAugM EPNet train, Epoch [149/285]: loss 0.7208, auc 0.5360, ap 0.5057
2024-01-10 21:59:21,251 - GAugM EPNet train, Epoch [150/285]: loss 0.7209, auc 0.4737, ap 0.4807
2024-01-10 21:59:21,335 - GAugM EPNet train, Epoch [151/285]: loss 0.7209, auc 0.6086, ap 0.5831
2024-01-10 21:59:21,413 - GAugM EPNet train, Epoch [152/285]: loss 0.7209, auc 0.5534, ap 0.5525
2024-01-10 21:59:21,489 - GAugM EPNet train, Epoch [153/285]: loss 0.7209, auc 0.4544, ap 0.4712
2024-01-10 21:59:21,564 - GAugM EPNet train, Epoch [154/285]: loss 0.7209, auc 0.4975, ap 0.5734
2024-01-10 21:59:21,640 - GAugM EPNet train, Epoch [155/285]: loss 0.7209, auc 0.4626, ap 0.4708
2024-01-10 21:59:21,716 - GAugM EPNet train, Epoch [156/285]: loss 0.7209, auc 0.5075, ap 0.5197
2024-01-10 21:59:21,792 - GAugM EPNet train, Epoch [157/285]: loss 0.7209, auc 0.5046, ap 0.4923
2024-01-10 21:59:21,872 - GAugM EPNet train, Epoch [158/285]: loss 0.7208, auc 0.4886, ap 0.4963
2024-01-10 21:59:21,956 - GAugM EPNet train, Epoch [159/285]: loss 0.7208, auc 0.4786, ap 0.4947
2024-01-10 21:59:22,031 - GAugM EPNet train, Epoch [160/285]: loss 0.7209, auc 0.5157, ap 0.5154
2024-01-10 21:59:22,107 - GAugM EPNet train, Epoch [161/285]: loss 0.7209, auc 0.6007, ap 0.5740
2024-01-10 21:59:22,182 - GAugM EPNet train, Epoch [162/285]: loss 0.7209, auc 0.4936, ap 0.5018
2024-01-10 21:59:22,257 - GAugM EPNet train, Epoch [163/285]: loss 0.7209, auc 0.4701, ap 0.4753
2024-01-10 21:59:22,333 - GAugM EPNet train, Epoch [164/285]: loss 0.7211, auc 0.5164, ap 0.5050
2024-01-10 21:59:22,408 - GAugM EPNet train, Epoch [165/285]: loss 0.7210, auc 0.4494, ap 0.4561
2024-01-10 21:59:22,487 - GAugM EPNet train, Epoch [166/285]: loss 0.7208, auc 0.5481, ap 0.5231
2024-01-10 21:59:22,562 - GAugM EPNet train, Epoch [167/285]: loss 0.7209, auc 0.4074, ap 0.4581
2024-01-10 21:59:22,637 - GAugM EPNet train, Epoch [168/285]: loss 0.7209, auc 0.4883, ap 0.5438
2024-01-10 21:59:22,712 - GAugM EPNet train, Epoch [169/285]: loss 0.7209, auc 0.5167, ap 0.5651
2024-01-10 21:59:22,793 - GAugM EPNet train, Epoch [170/285]: loss 0.7210, auc 0.4886, ap 0.4916
2024-01-10 21:59:22,869 - GAugM EPNet train, Epoch [171/285]: loss 0.7209, auc 0.4893, ap 0.4993
2024-01-10 21:59:22,944 - GAugM EPNet train, Epoch [172/285]: loss 0.7208, auc 0.4409, ap 0.4518
2024-01-10 21:59:23,021 - GAugM EPNet train, Epoch [173/285]: loss 0.7209, auc 0.5018, ap 0.5411
2024-01-10 21:59:23,103 - GAugM EPNet train, Epoch [174/285]: loss 0.7209, auc 0.5007, ap 0.4918
2024-01-10 21:59:23,189 - GAugM EPNet train, Epoch [175/285]: loss 0.7209, auc 0.6082, ap 0.5772
2024-01-10 21:59:23,271 - GAugM EPNet train, Epoch [176/285]: loss 0.7209, auc 0.4979, ap 0.4939
2024-01-10 21:59:23,354 - GAugM EPNet train, Epoch [177/285]: loss 0.7210, auc 0.4680, ap 0.4612
2024-01-10 21:59:23,436 - GAugM EPNet train, Epoch [178/285]: loss 0.7210, auc 0.4758, ap 0.4973
2024-01-10 21:59:23,515 - GAugM EPNet train, Epoch [179/285]: loss 0.7210, auc 0.4452, ap 0.4891
2024-01-10 21:59:23,596 - GAugM EPNet train, Epoch [180/285]: loss 0.7210, auc 0.4904, ap 0.5227
2024-01-10 21:59:23,675 - GAugM EPNet train, Epoch [181/285]: loss 0.7209, auc 0.4680, ap 0.4710
2024-01-10 21:59:23,752 - GAugM EPNet train, Epoch [182/285]: loss 0.7209, auc 0.5028, ap 0.5428
2024-01-10 21:59:23,833 - GAugM EPNet train, Epoch [183/285]: loss 0.7210, auc 0.5445, ap 0.5475
2024-01-10 21:59:23,909 - GAugM EPNet train, Epoch [184/285]: loss 0.7209, auc 0.4697, ap 0.4865
2024-01-10 21:59:23,983 - GAugM EPNet train, Epoch [185/285]: loss 0.7209, auc 0.4758, ap 0.4749
2024-01-10 21:59:24,059 - GAugM EPNet train, Epoch [186/285]: loss 0.7208, auc 0.4060, ap 0.4499
2024-01-10 21:59:24,134 - GAugM EPNet train, Epoch [187/285]: loss 0.7209, auc 0.5185, ap 0.5240
2024-01-10 21:59:24,209 - GAugM EPNet train, Epoch [188/285]: loss 0.7209, auc 0.4448, ap 0.4638
2024-01-10 21:59:24,283 - GAugM EPNet train, Epoch [189/285]: loss 0.7209, auc 0.5434, ap 0.5834
2024-01-10 21:59:24,358 - GAugM EPNet train, Epoch [190/285]: loss 0.7209, auc 0.4416, ap 0.4520
2024-01-10 21:59:24,439 - GAugM EPNet train, Epoch [191/285]: loss 0.7209, auc 0.3921, ap 0.4535
2024-01-10 21:59:24,514 - GAugM EPNet train, Epoch [192/285]: loss 0.7209, auc 0.5352, ap 0.4966
2024-01-10 21:59:24,588 - GAugM EPNet train, Epoch [193/285]: loss 0.7209, auc 0.5666, ap 0.5636
2024-01-10 21:59:24,664 - GAugM EPNet train, Epoch [194/285]: loss 0.7209, auc 0.4751, ap 0.4919
2024-01-10 21:59:24,739 - GAugM EPNet train, Epoch [195/285]: loss 0.7209, auc 0.4694, ap 0.4604
2024-01-10 21:59:24,815 - GAugM EPNet train, Epoch [196/285]: loss 0.7208, auc 0.4384, ap 0.4564
2024-01-10 21:59:24,890 - GAugM EPNet train, Epoch [197/285]: loss 0.7210, auc 0.4334, ap 0.4556
2024-01-10 21:59:24,965 - GAugM EPNet train, Epoch [198/285]: loss 0.7210, auc 0.5150, ap 0.5264
2024-01-10 21:59:25,040 - GAugM EPNet train, Epoch [199/285]: loss 0.7209, auc 0.5235, ap 0.5131
2024-01-10 21:59:25,116 - GAugM EPNet train, Epoch [200/285]: loss 0.7210, auc 0.4929, ap 0.4832
2024-01-10 21:59:25,192 - GAugM EPNet train, Epoch [201/285]: loss 0.7209, auc 0.4341, ap 0.4653
2024-01-10 21:59:25,267 - GAugM EPNet train, Epoch [202/285]: loss 0.7210, auc 0.6068, ap 0.6228
2024-01-10 21:59:25,340 - GAugM EPNet train, Epoch [203/285]: loss 0.7210, auc 0.5555, ap 0.5526
2024-01-10 21:59:25,421 - GAugM EPNet train, Epoch [204/285]: loss 0.7209, auc 0.4712, ap 0.4807
2024-01-10 21:59:25,497 - GAugM EPNet train, Epoch [205/285]: loss 0.7209, auc 0.4352, ap 0.4856
2024-01-10 21:59:25,573 - GAugM EPNet train, Epoch [206/285]: loss 0.7209, auc 0.4320, ap 0.4677
2024-01-10 21:59:25,652 - GAugM EPNet train, Epoch [207/285]: loss 0.7210, auc 0.4669, ap 0.5121
2024-01-10 21:59:25,728 - GAugM EPNet train, Epoch [208/285]: loss 0.7209, auc 0.4566, ap 0.4961
2024-01-10 21:59:25,804 - GAugM EPNet train, Epoch [209/285]: loss 0.7210, auc 0.5961, ap 0.5735
2024-01-10 21:59:25,878 - GAugM EPNet train, Epoch [210/285]: loss 0.7209, auc 0.3896, ap 0.4284
2024-01-10 21:59:25,952 - GAugM EPNet train, Epoch [211/285]: loss 0.7210, auc 0.5417, ap 0.5627
2024-01-10 21:59:26,028 - GAugM EPNet train, Epoch [212/285]: loss 0.7210, auc 0.4833, ap 0.4764
2024-01-10 21:59:26,101 - GAugM EPNet train, Epoch [213/285]: loss 0.7208, auc 0.6709, ap 0.6378
2024-01-10 21:59:26,176 - GAugM EPNet train, Epoch [214/285]: loss 0.7210, auc 0.5242, ap 0.5202
2024-01-10 21:59:26,250 - GAugM EPNet train, Epoch [215/285]: loss 0.7210, auc 0.4466, ap 0.4786
2024-01-10 21:59:26,329 - GAugM EPNet train, Epoch [216/285]: loss 0.7209, auc 0.4829, ap 0.4850
2024-01-10 21:59:26,404 - GAugM EPNet train, Epoch [217/285]: loss 0.7209, auc 0.5723, ap 0.6023
2024-01-10 21:59:26,480 - GAugM EPNet train, Epoch [218/285]: loss 0.7209, auc 0.5317, ap 0.5510
2024-01-10 21:59:26,556 - GAugM EPNet train, Epoch [219/285]: loss 0.7208, auc 0.4608, ap 0.4735
2024-01-10 21:59:26,646 - GAugM EPNet train, Epoch [220/285]: loss 0.7210, auc 0.4509, ap 0.5023
2024-01-10 21:59:26,737 - GAugM EPNet train, Epoch [221/285]: loss 0.7209, auc 0.5904, ap 0.5550
2024-01-10 21:59:26,830 - GAugM EPNet train, Epoch [222/285]: loss 0.7209, auc 0.5285, ap 0.5292
2024-01-10 21:59:26,919 - GAugM EPNet train, Epoch [223/285]: loss 0.7209, auc 0.5093, ap 0.5335
2024-01-10 21:59:27,009 - GAugM EPNet train, Epoch [224/285]: loss 0.7210, auc 0.4648, ap 0.4557
2024-01-10 21:59:27,096 - GAugM EPNet train, Epoch [225/285]: loss 0.7209, auc 0.4719, ap 0.4889
2024-01-10 21:59:27,189 - GAugM EPNet train, Epoch [226/285]: loss 0.7210, auc 0.4003, ap 0.4383
2024-01-10 21:59:27,276 - GAugM EPNet train, Epoch [227/285]: loss 0.7210, auc 0.5021, ap 0.5134
2024-01-10 21:59:27,366 - GAugM EPNet train, Epoch [228/285]: loss 0.7209, auc 0.5203, ap 0.5317
2024-01-10 21:59:27,454 - GAugM EPNet train, Epoch [229/285]: loss 0.7209, auc 0.4761, ap 0.4736
2024-01-10 21:59:27,546 - GAugM EPNet train, Epoch [230/285]: loss 0.7209, auc 0.4566, ap 0.5111
2024-01-10 21:59:27,634 - GAugM EPNet train, Epoch [231/285]: loss 0.7209, auc 0.4947, ap 0.5100
2024-01-10 21:59:27,728 - GAugM EPNet train, Epoch [232/285]: loss 0.7209, auc 0.5598, ap 0.5654
2024-01-10 21:59:27,817 - GAugM EPNet train, Epoch [233/285]: loss 0.7210, auc 0.4829, ap 0.5242
2024-01-10 21:59:27,905 - GAugM EPNet train, Epoch [234/285]: loss 0.7209, auc 0.4438, ap 0.4782
2024-01-10 21:59:27,997 - GAugM EPNet train, Epoch [235/285]: loss 0.7209, auc 0.4292, ap 0.4446
2024-01-10 21:59:28,083 - GAugM EPNet train, Epoch [236/285]: loss 0.7209, auc 0.5075, ap 0.5420
2024-01-10 21:59:28,169 - GAugM EPNet train, Epoch [237/285]: loss 0.7210, auc 0.5562, ap 0.5492
2024-01-10 21:59:28,259 - GAugM EPNet train, Epoch [238/285]: loss 0.7210, auc 0.4986, ap 0.5362
2024-01-10 21:59:28,348 - GAugM EPNet train, Epoch [239/285]: loss 0.7209, auc 0.5481, ap 0.5993
2024-01-10 21:59:28,439 - GAugM EPNet train, Epoch [240/285]: loss 0.7209, auc 0.5185, ap 0.5061
2024-01-10 21:59:28,526 - GAugM EPNet train, Epoch [241/285]: loss 0.7209, auc 0.5666, ap 0.5555
2024-01-10 21:59:28,615 - GAugM EPNet train, Epoch [242/285]: loss 0.7210, auc 0.4744, ap 0.5169
2024-01-10 21:59:28,703 - GAugM EPNet train, Epoch [243/285]: loss 0.7210, auc 0.5370, ap 0.5986
2024-01-10 21:59:28,793 - GAugM EPNet train, Epoch [244/285]: loss 0.7209, auc 0.5335, ap 0.5063
2024-01-10 21:59:28,880 - GAugM EPNet train, Epoch [245/285]: loss 0.7210, auc 0.4373, ap 0.4545
2024-01-10 21:59:28,967 - GAugM EPNet train, Epoch [246/285]: loss 0.7208, auc 0.4904, ap 0.5277
2024-01-10 21:59:29,055 - GAugM EPNet train, Epoch [247/285]: loss 0.7209, auc 0.5552, ap 0.5609
2024-01-10 21:59:29,146 - GAugM EPNet train, Epoch [248/285]: loss 0.7211, auc 0.5260, ap 0.5534
2024-01-10 21:59:29,234 - GAugM EPNet train, Epoch [249/285]: loss 0.7209, auc 0.4850, ap 0.4930
2024-01-10 21:59:29,320 - GAugM EPNet train, Epoch [250/285]: loss 0.7208, auc 0.5096, ap 0.5237
2024-01-10 21:59:29,407 - GAugM EPNet train, Epoch [251/285]: loss 0.7209, auc 0.4893, ap 0.5062
2024-01-10 21:59:29,494 - GAugM EPNet train, Epoch [252/285]: loss 0.7210, auc 0.5285, ap 0.5808
2024-01-10 21:59:29,582 - GAugM EPNet train, Epoch [253/285]: loss 0.7209, auc 0.6356, ap 0.5918
2024-01-10 21:59:29,669 - GAugM EPNet train, Epoch [254/285]: loss 0.7210, auc 0.4904, ap 0.5025
2024-01-10 21:59:29,761 - GAugM EPNet train, Epoch [255/285]: loss 0.7209, auc 0.4341, ap 0.4795
2024-01-10 21:59:29,855 - GAugM EPNet train, Epoch [256/285]: loss 0.7210, auc 0.3483, ap 0.4416
2024-01-10 21:59:29,942 - GAugM EPNet train, Epoch [257/285]: loss 0.7210, auc 0.5196, ap 0.5107
2024-01-10 21:59:30,028 - GAugM EPNet train, Epoch [258/285]: loss 0.7208, auc 0.5338, ap 0.5183
2024-01-10 21:59:30,115 - GAugM EPNet train, Epoch [259/285]: loss 0.7208, auc 0.5936, ap 0.5815
2024-01-10 21:59:30,200 - GAugM EPNet train, Epoch [260/285]: loss 0.7210, auc 0.5053, ap 0.4863
2024-01-10 21:59:30,285 - GAugM EPNet train, Epoch [261/285]: loss 0.7209, auc 0.4192, ap 0.4492
2024-01-10 21:59:30,369 - GAugM EPNet train, Epoch [262/285]: loss 0.7208, auc 0.5634, ap 0.5837
2024-01-10 21:59:30,455 - GAugM EPNet train, Epoch [263/285]: loss 0.7209, auc 0.4758, ap 0.4850
2024-01-10 21:59:30,541 - GAugM EPNet train, Epoch [264/285]: loss 0.7210, auc 0.4662, ap 0.4725
2024-01-10 21:59:30,630 - GAugM EPNet train, Epoch [265/285]: loss 0.7209, auc 0.4900, ap 0.5506
2024-01-10 21:59:30,714 - GAugM EPNet train, Epoch [266/285]: loss 0.7209, auc 0.5687, ap 0.5449
2024-01-10 21:59:30,800 - GAugM EPNet train, Epoch [267/285]: loss 0.7210, auc 0.4769, ap 0.4951
2024-01-10 21:59:30,886 - GAugM EPNet train, Epoch [268/285]: loss 0.7210, auc 0.4719, ap 0.5105
2024-01-10 21:59:30,974 - GAugM EPNet train, Epoch [269/285]: loss 0.7209, auc 0.6367, ap 0.6184
2024-01-10 21:59:31,058 - GAugM EPNet train, Epoch [270/285]: loss 0.7210, auc 0.5043, ap 0.5216
2024-01-10 21:59:31,142 - GAugM EPNet train, Epoch [271/285]: loss 0.7209, auc 0.4875, ap 0.5085
2024-01-10 21:59:31,231 - GAugM EPNet train, Epoch [272/285]: loss 0.7209, auc 0.4598, ap 0.4876
2024-01-10 21:59:31,314 - GAugM EPNet train, Epoch [273/285]: loss 0.7209, auc 0.4327, ap 0.4645
2024-01-10 21:59:31,397 - GAugM EPNet train, Epoch [274/285]: loss 0.7209, auc 0.5057, ap 0.4882
2024-01-10 21:59:31,484 - GAugM EPNet train, Epoch [275/285]: loss 0.7208, auc 0.4256, ap 0.4454
2024-01-10 21:59:31,571 - GAugM EPNet train, Epoch [276/285]: loss 0.7210, auc 0.5228, ap 0.5450
2024-01-10 21:59:31,655 - GAugM EPNet train, Epoch [277/285]: loss 0.7208, auc 0.4665, ap 0.5165
2024-01-10 21:59:31,737 - GAugM EPNet train, Epoch [278/285]: loss 0.7209, auc 0.5840, ap 0.5643
2024-01-10 21:59:31,824 - GAugM EPNet train, Epoch [279/285]: loss 0.7209, auc 0.4815, ap 0.4895
2024-01-10 21:59:31,907 - GAugM EPNet train, Epoch [280/285]: loss 0.7209, auc 0.3601, ap 0.4054
2024-01-10 21:59:31,989 - GAugM EPNet train, Epoch [281/285]: loss 0.7209, auc 0.6396, ap 0.6255
2024-01-10 21:59:32,070 - GAugM EPNet train, Epoch [282/285]: loss 0.7209, auc 0.5502, ap 0.5279
2024-01-10 21:59:32,152 - GAugM EPNet train, Epoch [283/285]: loss 0.7209, auc 0.4972, ap 0.5204
2024-01-10 21:59:32,233 - GAugM EPNet train, Epoch [284/285]: loss 0.7209, auc 0.4509, ap 0.4539
2024-01-10 21:59:32,319 - GAugM EPNet train, Epoch [285/285]: loss 0.7209, auc 0.5125, ap 0.5168
2024-01-10 21:59:32,324 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03bfc8d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:59:33,138 - GAugM EPNet train, Epoch [  1/285]: loss 0.7210, auc 0.4833, ap 0.4996
2024-01-10 21:59:33,226 - GAugM EPNet train, Epoch [  2/285]: loss 0.7210, auc 0.4377, ap 0.4498
2024-01-10 21:59:33,313 - GAugM EPNet train, Epoch [  3/285]: loss 0.7209, auc 0.4760, ap 0.4887
2024-01-10 21:59:33,394 - GAugM EPNet train, Epoch [  4/285]: loss 0.7209, auc 0.5267, ap 0.5109
2024-01-10 21:59:33,480 - GAugM EPNet train, Epoch [  5/285]: loss 0.7209, auc 0.5486, ap 0.5423
2024-01-10 21:59:33,563 - GAugM EPNet train, Epoch [  6/285]: loss 0.7209, auc 0.4502, ap 0.4554
2024-01-10 21:59:33,643 - GAugM EPNet train, Epoch [  7/285]: loss 0.7209, auc 0.4680, ap 0.4803
2024-01-10 21:59:33,726 - GAugM EPNet train, Epoch [  8/285]: loss 0.7210, auc 0.5292, ap 0.5384
2024-01-10 21:59:33,805 - GAugM EPNet train, Epoch [  9/285]: loss 0.7209, auc 0.5233, ap 0.5044
2024-01-10 21:59:33,880 - GAugM EPNet train, Epoch [ 10/285]: loss 0.7208, auc 0.5114, ap 0.5369
2024-01-10 21:59:33,960 - GAugM EPNet train, Epoch [ 11/285]: loss 0.7209, auc 0.4995, ap 0.4996
2024-01-10 21:59:34,040 - GAugM EPNet train, Epoch [ 12/285]: loss 0.7210, auc 0.5117, ap 0.5450
2024-01-10 21:59:34,114 - GAugM EPNet train, Epoch [ 13/285]: loss 0.7209, auc 0.6326, ap 0.6206
2024-01-10 21:59:34,190 - GAugM EPNet train, Epoch [ 14/285]: loss 0.7209, auc 0.5904, ap 0.5577
2024-01-10 21:59:34,267 - GAugM EPNet train, Epoch [ 15/285]: loss 0.7210, auc 0.3823, ap 0.4448
2024-01-10 21:59:34,349 - GAugM EPNet train, Epoch [ 16/285]: loss 0.7209, auc 0.5303, ap 0.5470
2024-01-10 21:59:34,429 - GAugM EPNet train, Epoch [ 17/285]: loss 0.7210, auc 0.5304, ap 0.5249
2024-01-10 21:59:34,506 - GAugM EPNet train, Epoch [ 18/285]: loss 0.7210, auc 0.6221, ap 0.5792
2024-01-10 21:59:34,588 - GAugM EPNet train, Epoch [ 19/285]: loss 0.7209, auc 0.5344, ap 0.5205
2024-01-10 21:59:34,663 - GAugM EPNet train, Epoch [ 20/285]: loss 0.7210, auc 0.5278, ap 0.5366
2024-01-10 21:59:34,739 - GAugM EPNet train, Epoch [ 21/285]: loss 0.7209, auc 0.5333, ap 0.5551
2024-01-10 21:59:34,813 - GAugM EPNet train, Epoch [ 22/285]: loss 0.7210, auc 0.3948, ap 0.4365
2024-01-10 21:59:34,891 - GAugM EPNet train, Epoch [ 23/285]: loss 0.7208, auc 0.4867, ap 0.4870
2024-01-10 21:59:34,972 - GAugM EPNet train, Epoch [ 24/285]: loss 0.7209, auc 0.5936, ap 0.5539
2024-01-10 21:59:35,047 - GAugM EPNet train, Epoch [ 25/285]: loss 0.7209, auc 0.4774, ap 0.4889
2024-01-10 21:59:35,125 - GAugM EPNet train, Epoch [ 26/285]: loss 0.7210, auc 0.5189, ap 0.5064
2024-01-10 21:59:35,208 - GAugM EPNet train, Epoch [ 27/285]: loss 0.7209, auc 0.3450, ap 0.4410
2024-01-10 21:59:35,284 - GAugM EPNet train, Epoch [ 28/285]: loss 0.7209, auc 0.5235, ap 0.5140
2024-01-10 21:59:35,358 - GAugM EPNet train, Epoch [ 29/285]: loss 0.7210, auc 0.4717, ap 0.4999
2024-01-10 21:59:35,434 - GAugM EPNet train, Epoch [ 30/285]: loss 0.7209, auc 0.5107, ap 0.5315
2024-01-10 21:59:35,510 - GAugM EPNet train, Epoch [ 31/285]: loss 0.7208, auc 0.5352, ap 0.5577
2024-01-10 21:59:35,602 - GAugM EPNet train, Epoch [ 32/285]: loss 0.7210, auc 0.4754, ap 0.4758
2024-01-10 21:59:35,690 - GAugM EPNet train, Epoch [ 33/285]: loss 0.7209, auc 0.4753, ap 0.4713
2024-01-10 21:59:35,781 - GAugM EPNet train, Epoch [ 34/285]: loss 0.7209, auc 0.5002, ap 0.4889
2024-01-10 21:59:35,871 - GAugM EPNet train, Epoch [ 35/285]: loss 0.7209, auc 0.5164, ap 0.5075
2024-01-10 21:59:35,952 - GAugM EPNet train, Epoch [ 36/285]: loss 0.7209, auc 0.5287, ap 0.5444
2024-01-10 21:59:36,041 - GAugM EPNet train, Epoch [ 37/285]: loss 0.7209, auc 0.4478, ap 0.4714
2024-01-10 21:59:36,124 - GAugM EPNet train, Epoch [ 38/285]: loss 0.7209, auc 0.5144, ap 0.5030
2024-01-10 21:59:36,206 - GAugM EPNet train, Epoch [ 39/285]: loss 0.7208, auc 0.4562, ap 0.5128
2024-01-10 21:59:36,288 - GAugM EPNet train, Epoch [ 40/285]: loss 0.7210, auc 0.4842, ap 0.4999
2024-01-10 21:59:36,375 - GAugM EPNet train, Epoch [ 41/285]: loss 0.7210, auc 0.5376, ap 0.5561
2024-01-10 21:59:36,461 - GAugM EPNet train, Epoch [ 42/285]: loss 0.7209, auc 0.5262, ap 0.5438
2024-01-10 21:59:36,545 - GAugM EPNet train, Epoch [ 43/285]: loss 0.7208, auc 0.4624, ap 0.5115
2024-01-10 21:59:36,628 - GAugM EPNet train, Epoch [ 44/285]: loss 0.7208, auc 0.4297, ap 0.4660
2024-01-10 21:59:36,708 - GAugM EPNet train, Epoch [ 45/285]: loss 0.7209, auc 0.5922, ap 0.5997
2024-01-10 21:59:36,793 - GAugM EPNet train, Epoch [ 46/285]: loss 0.7209, auc 0.4126, ap 0.4542
2024-01-10 21:59:36,872 - GAugM EPNet train, Epoch [ 47/285]: loss 0.7210, auc 0.4535, ap 0.4861
2024-01-10 21:59:36,957 - GAugM EPNet train, Epoch [ 48/285]: loss 0.7210, auc 0.5721, ap 0.5813
2024-01-10 21:59:37,040 - GAugM EPNet train, Epoch [ 49/285]: loss 0.7209, auc 0.5712, ap 0.5364
2024-01-10 21:59:37,124 - GAugM EPNet train, Epoch [ 50/285]: loss 0.7210, auc 0.5769, ap 0.5639
2024-01-10 21:59:37,206 - GAugM EPNet train, Epoch [ 51/285]: loss 0.7210, auc 0.5488, ap 0.5832
2024-01-10 21:59:37,292 - GAugM EPNet train, Epoch [ 52/285]: loss 0.7209, auc 0.4872, ap 0.5100
2024-01-10 21:59:37,375 - GAugM EPNet train, Epoch [ 53/285]: loss 0.7209, auc 0.5489, ap 0.5616
2024-01-10 21:59:37,456 - GAugM EPNet train, Epoch [ 54/285]: loss 0.7211, auc 0.4856, ap 0.4718
2024-01-10 21:59:37,544 - GAugM EPNet train, Epoch [ 55/285]: loss 0.7209, auc 0.5936, ap 0.5850
2024-01-10 21:59:37,626 - GAugM EPNet train, Epoch [ 56/285]: loss 0.7208, auc 0.5007, ap 0.4891
2024-01-10 21:59:37,709 - GAugM EPNet train, Epoch [ 57/285]: loss 0.7209, auc 0.5183, ap 0.4986
2024-01-10 21:59:37,797 - GAugM EPNet train, Epoch [ 58/285]: loss 0.7210, auc 0.4487, ap 0.4947
2024-01-10 21:59:37,879 - GAugM EPNet train, Epoch [ 59/285]: loss 0.7211, auc 0.5417, ap 0.5241
2024-01-10 21:59:37,966 - GAugM EPNet train, Epoch [ 60/285]: loss 0.7210, auc 0.5313, ap 0.5100
2024-01-10 21:59:38,048 - GAugM EPNet train, Epoch [ 61/285]: loss 0.7209, auc 0.5828, ap 0.5731
2024-01-10 21:59:38,131 - GAugM EPNet train, Epoch [ 62/285]: loss 0.7210, auc 0.5148, ap 0.5467
2024-01-10 21:59:38,209 - GAugM EPNet train, Epoch [ 63/285]: loss 0.7208, auc 0.5231, ap 0.4987
2024-01-10 21:59:38,296 - GAugM EPNet train, Epoch [ 64/285]: loss 0.7208, auc 0.4888, ap 0.5004
2024-01-10 21:59:38,378 - GAugM EPNet train, Epoch [ 65/285]: loss 0.7208, auc 0.5536, ap 0.5571
2024-01-10 21:59:38,457 - GAugM EPNet train, Epoch [ 66/285]: loss 0.7209, auc 0.5116, ap 0.5375
2024-01-10 21:59:38,539 - GAugM EPNet train, Epoch [ 67/285]: loss 0.7209, auc 0.5776, ap 0.5536
2024-01-10 21:59:38,621 - GAugM EPNet train, Epoch [ 68/285]: loss 0.7210, auc 0.5415, ap 0.6059
2024-01-10 21:59:38,704 - GAugM EPNet train, Epoch [ 69/285]: loss 0.7210, auc 0.4607, ap 0.4954
2024-01-10 21:59:38,784 - GAugM EPNet train, Epoch [ 70/285]: loss 0.7210, auc 0.4710, ap 0.4763
2024-01-10 21:59:38,865 - GAugM EPNet train, Epoch [ 71/285]: loss 0.7210, auc 0.4790, ap 0.4828
2024-01-10 21:59:38,951 - GAugM EPNet train, Epoch [ 72/285]: loss 0.7210, auc 0.4227, ap 0.4592
2024-01-10 21:59:39,038 - GAugM EPNet train, Epoch [ 73/285]: loss 0.7209, auc 0.5482, ap 0.5200
2024-01-10 21:59:39,125 - GAugM EPNet train, Epoch [ 74/285]: loss 0.7209, auc 0.4923, ap 0.5158
2024-01-10 21:59:39,214 - GAugM EPNet train, Epoch [ 75/285]: loss 0.7210, auc 0.4788, ap 0.4752
2024-01-10 21:59:39,297 - GAugM EPNet train, Epoch [ 76/285]: loss 0.7209, auc 0.4667, ap 0.4702
2024-01-10 21:59:39,380 - GAugM EPNet train, Epoch [ 77/285]: loss 0.7208, auc 0.5324, ap 0.5422
2024-01-10 21:59:39,470 - GAugM EPNet train, Epoch [ 78/285]: loss 0.7209, auc 0.4313, ap 0.4576
2024-01-10 21:59:39,546 - GAugM EPNet train, Epoch [ 79/285]: loss 0.7208, auc 0.5822, ap 0.5669
2024-01-10 21:59:39,629 - GAugM EPNet train, Epoch [ 80/285]: loss 0.7209, auc 0.5945, ap 0.5657
2024-01-10 21:59:39,709 - GAugM EPNet train, Epoch [ 81/285]: loss 0.7209, auc 0.5317, ap 0.5168
2024-01-10 21:59:39,791 - GAugM EPNet train, Epoch [ 82/285]: loss 0.7210, auc 0.4772, ap 0.4816
2024-01-10 21:59:39,872 - GAugM EPNet train, Epoch [ 83/285]: loss 0.7209, auc 0.4286, ap 0.4883
2024-01-10 21:59:39,953 - GAugM EPNet train, Epoch [ 84/285]: loss 0.7209, auc 0.4721, ap 0.4935
2024-01-10 21:59:40,034 - GAugM EPNet train, Epoch [ 85/285]: loss 0.7210, auc 0.4174, ap 0.4529
2024-01-10 21:59:40,113 - GAugM EPNet train, Epoch [ 86/285]: loss 0.7208, auc 0.4227, ap 0.4590
2024-01-10 21:59:40,194 - GAugM EPNet train, Epoch [ 87/285]: loss 0.7209, auc 0.5486, ap 0.5239
2024-01-10 21:59:40,274 - GAugM EPNet train, Epoch [ 88/285]: loss 0.7210, auc 0.4845, ap 0.5050
2024-01-10 21:59:40,356 - GAugM EPNet train, Epoch [ 89/285]: loss 0.7210, auc 0.4920, ap 0.5086
2024-01-10 21:59:40,437 - GAugM EPNet train, Epoch [ 90/285]: loss 0.7209, auc 0.4425, ap 0.4614
2024-01-10 21:59:40,519 - GAugM EPNet train, Epoch [ 91/285]: loss 0.7208, auc 0.5707, ap 0.5369
2024-01-10 21:59:40,598 - GAugM EPNet train, Epoch [ 92/285]: loss 0.7209, auc 0.6412, ap 0.6306
2024-01-10 21:59:40,679 - GAugM EPNet train, Epoch [ 93/285]: loss 0.7209, auc 0.3855, ap 0.4415
2024-01-10 21:59:40,765 - GAugM EPNet train, Epoch [ 94/285]: loss 0.7210, auc 0.3952, ap 0.4422
2024-01-10 21:59:40,844 - GAugM EPNet train, Epoch [ 95/285]: loss 0.7210, auc 0.4881, ap 0.5147
2024-01-10 21:59:40,929 - GAugM EPNet train, Epoch [ 96/285]: loss 0.7209, auc 0.5360, ap 0.5353
2024-01-10 21:59:41,012 - GAugM EPNet train, Epoch [ 97/285]: loss 0.7209, auc 0.5044, ap 0.5211
2024-01-10 21:59:41,092 - GAugM EPNet train, Epoch [ 98/285]: loss 0.7209, auc 0.4311, ap 0.4501
2024-01-10 21:59:41,172 - GAugM EPNet train, Epoch [ 99/285]: loss 0.7209, auc 0.4829, ap 0.5122
2024-01-10 21:59:41,254 - GAugM EPNet train, Epoch [100/285]: loss 0.7210, auc 0.4874, ap 0.5116
2024-01-10 21:59:41,342 - GAugM EPNet train, Epoch [101/285]: loss 0.7210, auc 0.5094, ap 0.5470
2024-01-10 21:59:41,423 - GAugM EPNet train, Epoch [102/285]: loss 0.7209, auc 0.4879, ap 0.4934
2024-01-10 21:59:41,508 - GAugM EPNet train, Epoch [103/285]: loss 0.7209, auc 0.5639, ap 0.5817
2024-01-10 21:59:41,588 - GAugM EPNet train, Epoch [104/285]: loss 0.7209, auc 0.4521, ap 0.4762
2024-01-10 21:59:41,669 - GAugM EPNet train, Epoch [105/285]: loss 0.7209, auc 0.4062, ap 0.4376
2024-01-10 21:59:41,751 - GAugM EPNet train, Epoch [106/285]: loss 0.7210, auc 0.4507, ap 0.4758
2024-01-10 21:59:41,838 - GAugM EPNet train, Epoch [107/285]: loss 0.7210, auc 0.4468, ap 0.5040
2024-01-10 21:59:41,920 - GAugM EPNet train, Epoch [108/285]: loss 0.7208, auc 0.5205, ap 0.5089
2024-01-10 21:59:42,002 - GAugM EPNet train, Epoch [109/285]: loss 0.7210, auc 0.4929, ap 0.5025
2024-01-10 21:59:42,094 - GAugM EPNet train, Epoch [110/285]: loss 0.7209, auc 0.5089, ap 0.4901
2024-01-10 21:59:42,177 - GAugM EPNet train, Epoch [111/285]: loss 0.7210, auc 0.4842, ap 0.4842
2024-01-10 21:59:42,270 - GAugM EPNet train, Epoch [112/285]: loss 0.7209, auc 0.4863, ap 0.5033
2024-01-10 21:59:42,351 - GAugM EPNet train, Epoch [113/285]: loss 0.7210, auc 0.4763, ap 0.5287
2024-01-10 21:59:42,434 - GAugM EPNet train, Epoch [114/285]: loss 0.7209, auc 0.4272, ap 0.4425
2024-01-10 21:59:42,521 - GAugM EPNet train, Epoch [115/285]: loss 0.7210, auc 0.5390, ap 0.5426
2024-01-10 21:59:42,601 - GAugM EPNet train, Epoch [116/285]: loss 0.7209, auc 0.5141, ap 0.5242
2024-01-10 21:59:42,681 - GAugM EPNet train, Epoch [117/285]: loss 0.7208, auc 0.4934, ap 0.4928
2024-01-10 21:59:42,761 - GAugM EPNet train, Epoch [118/285]: loss 0.7209, auc 0.4420, ap 0.4707
2024-01-10 21:59:42,841 - GAugM EPNet train, Epoch [119/285]: loss 0.7209, auc 0.4644, ap 0.5035
2024-01-10 21:59:42,921 - GAugM EPNet train, Epoch [120/285]: loss 0.7210, auc 0.4300, ap 0.4444
2024-01-10 21:59:43,002 - GAugM EPNet train, Epoch [121/285]: loss 0.7210, auc 0.5150, ap 0.5252
2024-01-10 21:59:43,086 - GAugM EPNet train, Epoch [122/285]: loss 0.7209, auc 0.4902, ap 0.5108
2024-01-10 21:59:43,178 - GAugM EPNet train, Epoch [123/285]: loss 0.7209, auc 0.4452, ap 0.4870
2024-01-10 21:59:43,259 - GAugM EPNet train, Epoch [124/285]: loss 0.7210, auc 0.4325, ap 0.4517
2024-01-10 21:59:43,339 - GAugM EPNet train, Epoch [125/285]: loss 0.7209, auc 0.5246, ap 0.5515
2024-01-10 21:59:43,418 - GAugM EPNet train, Epoch [126/285]: loss 0.7210, auc 0.4402, ap 0.4482
2024-01-10 21:59:43,499 - GAugM EPNet train, Epoch [127/285]: loss 0.7209, auc 0.5320, ap 0.5032
2024-01-10 21:59:43,581 - GAugM EPNet train, Epoch [128/285]: loss 0.7210, auc 0.4685, ap 0.4825
2024-01-10 21:59:43,661 - GAugM EPNet train, Epoch [129/285]: loss 0.7208, auc 0.3784, ap 0.4323
2024-01-10 21:59:43,741 - GAugM EPNet train, Epoch [130/285]: loss 0.7210, auc 0.4674, ap 0.4737
2024-01-10 21:59:43,819 - GAugM EPNet train, Epoch [131/285]: loss 0.7210, auc 0.5673, ap 0.5886
2024-01-10 21:59:43,901 - GAugM EPNet train, Epoch [132/285]: loss 0.7209, auc 0.5611, ap 0.5696
2024-01-10 21:59:43,985 - GAugM EPNet train, Epoch [133/285]: loss 0.7209, auc 0.3996, ap 0.4630
2024-01-10 21:59:44,074 - GAugM EPNet train, Epoch [134/285]: loss 0.7210, auc 0.4867, ap 0.5048
2024-01-10 21:59:44,163 - GAugM EPNet train, Epoch [135/285]: loss 0.7209, auc 0.3443, ap 0.4106
2024-01-10 21:59:44,235 - GAugM EPNet train, Epoch [136/285]: loss 0.7209, auc 0.4694, ap 0.4908
2024-01-10 21:59:44,309 - GAugM EPNet train, Epoch [137/285]: loss 0.7210, auc 0.4710, ap 0.5050
2024-01-10 21:59:44,396 - GAugM EPNet train, Epoch [138/285]: loss 0.7210, auc 0.5283, ap 0.5081
2024-01-10 21:59:44,483 - GAugM EPNet train, Epoch [139/285]: loss 0.7210, auc 0.4973, ap 0.5046
2024-01-10 21:59:44,571 - GAugM EPNet train, Epoch [140/285]: loss 0.7209, auc 0.5062, ap 0.5067
2024-01-10 21:59:44,648 - GAugM EPNet train, Epoch [141/285]: loss 0.7209, auc 0.5628, ap 0.5551
2024-01-10 21:59:44,728 - GAugM EPNet train, Epoch [142/285]: loss 0.7209, auc 0.5845, ap 0.5468
2024-01-10 21:59:44,815 - GAugM EPNet train, Epoch [143/285]: loss 0.7209, auc 0.4304, ap 0.4493
2024-01-10 21:59:44,895 - GAugM EPNet train, Epoch [144/285]: loss 0.7209, auc 0.5214, ap 0.5007
2024-01-10 21:59:44,969 - GAugM EPNet train, Epoch [145/285]: loss 0.7209, auc 0.4651, ap 0.5138
2024-01-10 21:59:45,045 - GAugM EPNet train, Epoch [146/285]: loss 0.7209, auc 0.4991, ap 0.4995
2024-01-10 21:59:45,118 - GAugM EPNet train, Epoch [147/285]: loss 0.7209, auc 0.6554, ap 0.6468
2024-01-10 21:59:45,195 - GAugM EPNet train, Epoch [148/285]: loss 0.7209, auc 0.5643, ap 0.5394
2024-01-10 21:59:45,278 - GAugM EPNet train, Epoch [149/285]: loss 0.7208, auc 0.4578, ap 0.4596
2024-01-10 21:59:45,362 - GAugM EPNet train, Epoch [150/285]: loss 0.7209, auc 0.4644, ap 0.4670
2024-01-10 21:59:45,452 - GAugM EPNet train, Epoch [151/285]: loss 0.7209, auc 0.5511, ap 0.5368
2024-01-10 21:59:45,540 - GAugM EPNet train, Epoch [152/285]: loss 0.7209, auc 0.6223, ap 0.6071
2024-01-10 21:59:45,623 - GAugM EPNet train, Epoch [153/285]: loss 0.7209, auc 0.4153, ap 0.4519
2024-01-10 21:59:45,708 - GAugM EPNet train, Epoch [154/285]: loss 0.7209, auc 0.4361, ap 0.4690
2024-01-10 21:59:45,791 - GAugM EPNet train, Epoch [155/285]: loss 0.7209, auc 0.5320, ap 0.5419
2024-01-10 21:59:45,874 - GAugM EPNet train, Epoch [156/285]: loss 0.7209, auc 0.3604, ap 0.4288
2024-01-10 21:59:45,956 - GAugM EPNet train, Epoch [157/285]: loss 0.7209, auc 0.5354, ap 0.5168
2024-01-10 21:59:46,032 - GAugM EPNet train, Epoch [158/285]: loss 0.7208, auc 0.5619, ap 0.5422
2024-01-10 21:59:46,114 - GAugM EPNet train, Epoch [159/285]: loss 0.7208, auc 0.4607, ap 0.4678
2024-01-10 21:59:46,198 - GAugM EPNet train, Epoch [160/285]: loss 0.7209, auc 0.5041, ap 0.5091
2024-01-10 21:59:46,280 - GAugM EPNet train, Epoch [161/285]: loss 0.7209, auc 0.5755, ap 0.5735
2024-01-10 21:59:46,360 - GAugM EPNet train, Epoch [162/285]: loss 0.7209, auc 0.4037, ap 0.4286
2024-01-10 21:59:46,439 - GAugM EPNet train, Epoch [163/285]: loss 0.7209, auc 0.5121, ap 0.5138
2024-01-10 21:59:46,517 - GAugM EPNet train, Epoch [164/285]: loss 0.7211, auc 0.5011, ap 0.4967
2024-01-10 21:59:46,590 - GAugM EPNet train, Epoch [165/285]: loss 0.7210, auc 0.4165, ap 0.4327
2024-01-10 21:59:46,669 - GAugM EPNet train, Epoch [166/285]: loss 0.7208, auc 0.5899, ap 0.5706
2024-01-10 21:59:46,749 - GAugM EPNet train, Epoch [167/285]: loss 0.7209, auc 0.5139, ap 0.5103
2024-01-10 21:59:46,823 - GAugM EPNet train, Epoch [168/285]: loss 0.7209, auc 0.5009, ap 0.5360
2024-01-10 21:59:46,913 - GAugM EPNet train, Epoch [169/285]: loss 0.7209, auc 0.6114, ap 0.6237
2024-01-10 21:59:46,995 - GAugM EPNet train, Epoch [170/285]: loss 0.7210, auc 0.4854, ap 0.4897
2024-01-10 21:59:47,074 - GAugM EPNet train, Epoch [171/285]: loss 0.7209, auc 0.4740, ap 0.4740
2024-01-10 21:59:47,155 - GAugM EPNet train, Epoch [172/285]: loss 0.7208, auc 0.5011, ap 0.5000
2024-01-10 21:59:47,239 - GAugM EPNet train, Epoch [173/285]: loss 0.7209, auc 0.4649, ap 0.4862
2024-01-10 21:59:47,319 - GAugM EPNet train, Epoch [174/285]: loss 0.7209, auc 0.5338, ap 0.5082
2024-01-10 21:59:47,404 - GAugM EPNet train, Epoch [175/285]: loss 0.7209, auc 0.6543, ap 0.6058
2024-01-10 21:59:47,488 - GAugM EPNet train, Epoch [176/285]: loss 0.7209, auc 0.4432, ap 0.4625
2024-01-10 21:59:47,568 - GAugM EPNet train, Epoch [177/285]: loss 0.7210, auc 0.4998, ap 0.5045
2024-01-10 21:59:47,651 - GAugM EPNet train, Epoch [178/285]: loss 0.7210, auc 0.5226, ap 0.5285
2024-01-10 21:59:47,730 - GAugM EPNet train, Epoch [179/285]: loss 0.7210, auc 0.3870, ap 0.4603
2024-01-10 21:59:47,807 - GAugM EPNet train, Epoch [180/285]: loss 0.7210, auc 0.5562, ap 0.5955
2024-01-10 21:59:47,882 - GAugM EPNet train, Epoch [181/285]: loss 0.7209, auc 0.4624, ap 0.5133
2024-01-10 21:59:47,967 - GAugM EPNet train, Epoch [182/285]: loss 0.7209, auc 0.4596, ap 0.4783
2024-01-10 21:59:48,057 - GAugM EPNet train, Epoch [183/285]: loss 0.7210, auc 0.5381, ap 0.5273
2024-01-10 21:59:48,143 - GAugM EPNet train, Epoch [184/285]: loss 0.7209, auc 0.5370, ap 0.5509
2024-01-10 21:59:48,228 - GAugM EPNet train, Epoch [185/285]: loss 0.7209, auc 0.4788, ap 0.4963
2024-01-10 21:59:48,314 - GAugM EPNet train, Epoch [186/285]: loss 0.7208, auc 0.4375, ap 0.4881
2024-01-10 21:59:48,403 - GAugM EPNet train, Epoch [187/285]: loss 0.7209, auc 0.4665, ap 0.4757
2024-01-10 21:59:48,499 - GAugM EPNet train, Epoch [188/285]: loss 0.7209, auc 0.4511, ap 0.4605
2024-01-10 21:59:48,585 - GAugM EPNet train, Epoch [189/285]: loss 0.7209, auc 0.5808, ap 0.6034
2024-01-10 21:59:48,672 - GAugM EPNet train, Epoch [190/285]: loss 0.7209, auc 0.4293, ap 0.4415
2024-01-10 21:59:48,764 - GAugM EPNet train, Epoch [191/285]: loss 0.7209, auc 0.4808, ap 0.5220
2024-01-10 21:59:48,846 - GAugM EPNet train, Epoch [192/285]: loss 0.7209, auc 0.4932, ap 0.4800
2024-01-10 21:59:48,923 - GAugM EPNet train, Epoch [193/285]: loss 0.7209, auc 0.4660, ap 0.4651
2024-01-10 21:59:49,001 - GAugM EPNet train, Epoch [194/285]: loss 0.7209, auc 0.4632, ap 0.4807
2024-01-10 21:59:49,082 - GAugM EPNet train, Epoch [195/285]: loss 0.7209, auc 0.4172, ap 0.4722
2024-01-10 21:59:49,156 - GAugM EPNet train, Epoch [196/285]: loss 0.7208, auc 0.5650, ap 0.5301
2024-01-10 21:59:49,230 - GAugM EPNet train, Epoch [197/285]: loss 0.7210, auc 0.4203, ap 0.4437
2024-01-10 21:59:49,316 - GAugM EPNet train, Epoch [198/285]: loss 0.7210, auc 0.5185, ap 0.5098
2024-01-10 21:59:49,403 - GAugM EPNet train, Epoch [199/285]: loss 0.7209, auc 0.5425, ap 0.5630
2024-01-10 21:59:49,486 - GAugM EPNet train, Epoch [200/285]: loss 0.7210, auc 0.6009, ap 0.5668
2024-01-10 21:59:49,560 - GAugM EPNet train, Epoch [201/285]: loss 0.7209, auc 0.4973, ap 0.4727
2024-01-10 21:59:49,651 - GAugM EPNet train, Epoch [202/285]: loss 0.7210, auc 0.5945, ap 0.5974
2024-01-10 21:59:49,738 - GAugM EPNet train, Epoch [203/285]: loss 0.7210, auc 0.5635, ap 0.5731
2024-01-10 21:59:49,823 - GAugM EPNet train, Epoch [204/285]: loss 0.7209, auc 0.4551, ap 0.4802
2024-01-10 21:59:49,911 - GAugM EPNet train, Epoch [205/285]: loss 0.7209, auc 0.4623, ap 0.5029
2024-01-10 21:59:49,990 - GAugM EPNet train, Epoch [206/285]: loss 0.7209, auc 0.4126, ap 0.4514
2024-01-10 21:59:50,077 - GAugM EPNet train, Epoch [207/285]: loss 0.7210, auc 0.4653, ap 0.4751
2024-01-10 21:59:50,162 - GAugM EPNet train, Epoch [208/285]: loss 0.7209, auc 0.4400, ap 0.4654
2024-01-10 21:59:50,252 - GAugM EPNet train, Epoch [209/285]: loss 0.7210, auc 0.5732, ap 0.5628
2024-01-10 21:59:50,338 - GAugM EPNet train, Epoch [210/285]: loss 0.7209, auc 0.3779, ap 0.4215
2024-01-10 21:59:50,424 - GAugM EPNet train, Epoch [211/285]: loss 0.7210, auc 0.5691, ap 0.5658
2024-01-10 21:59:50,517 - GAugM EPNet train, Epoch [212/285]: loss 0.7210, auc 0.4067, ap 0.4654
2024-01-10 21:59:50,603 - GAugM EPNet train, Epoch [213/285]: loss 0.7208, auc 0.6096, ap 0.6169
2024-01-10 21:59:50,692 - GAugM EPNet train, Epoch [214/285]: loss 0.7210, auc 0.5835, ap 0.5670
2024-01-10 21:59:50,782 - GAugM EPNet train, Epoch [215/285]: loss 0.7210, auc 0.5320, ap 0.5280
2024-01-10 21:59:50,875 - GAugM EPNet train, Epoch [216/285]: loss 0.7209, auc 0.5714, ap 0.5295
2024-01-10 21:59:50,963 - GAugM EPNet train, Epoch [217/285]: loss 0.7209, auc 0.5107, ap 0.5534
2024-01-10 21:59:51,050 - GAugM EPNet train, Epoch [218/285]: loss 0.7209, auc 0.5580, ap 0.5769
2024-01-10 21:59:51,139 - GAugM EPNet train, Epoch [219/285]: loss 0.7208, auc 0.5326, ap 0.5157
2024-01-10 21:59:51,233 - GAugM EPNet train, Epoch [220/285]: loss 0.7210, auc 0.3888, ap 0.4648
2024-01-10 21:59:51,324 - GAugM EPNet train, Epoch [221/285]: loss 0.7209, auc 0.5623, ap 0.5425
2024-01-10 21:59:51,412 - GAugM EPNet train, Epoch [222/285]: loss 0.7209, auc 0.5043, ap 0.4971
2024-01-10 21:59:51,506 - GAugM EPNet train, Epoch [223/285]: loss 0.7209, auc 0.4904, ap 0.4771
2024-01-10 21:59:51,594 - GAugM EPNet train, Epoch [224/285]: loss 0.7210, auc 0.4621, ap 0.4841
2024-01-10 21:59:51,682 - GAugM EPNet train, Epoch [225/285]: loss 0.7209, auc 0.4101, ap 0.4572
2024-01-10 21:59:51,771 - GAugM EPNet train, Epoch [226/285]: loss 0.7210, auc 0.4929, ap 0.5043
2024-01-10 21:59:51,863 - GAugM EPNet train, Epoch [227/285]: loss 0.7210, auc 0.5133, ap 0.5172
2024-01-10 21:59:51,958 - GAugM EPNet train, Epoch [228/285]: loss 0.7209, auc 0.4722, ap 0.5010
2024-01-10 21:59:52,045 - GAugM EPNet train, Epoch [229/285]: loss 0.7209, auc 0.5077, ap 0.4812
2024-01-10 21:59:52,135 - GAugM EPNet train, Epoch [230/285]: loss 0.7209, auc 0.4818, ap 0.5166
2024-01-10 21:59:52,225 - GAugM EPNet train, Epoch [231/285]: loss 0.7209, auc 0.4754, ap 0.4749
2024-01-10 21:59:52,316 - GAugM EPNet train, Epoch [232/285]: loss 0.7209, auc 0.5032, ap 0.4990
2024-01-10 21:59:52,405 - GAugM EPNet train, Epoch [233/285]: loss 0.7210, auc 0.5226, ap 0.5363
2024-01-10 21:59:52,492 - GAugM EPNet train, Epoch [234/285]: loss 0.7209, auc 0.3809, ap 0.4327
2024-01-10 21:59:52,582 - GAugM EPNet train, Epoch [235/285]: loss 0.7209, auc 0.4099, ap 0.4480
2024-01-10 21:59:52,667 - GAugM EPNet train, Epoch [236/285]: loss 0.7209, auc 0.5682, ap 0.5904
2024-01-10 21:59:52,757 - GAugM EPNet train, Epoch [237/285]: loss 0.7210, auc 0.5000, ap 0.5212
2024-01-10 21:59:52,844 - GAugM EPNet train, Epoch [238/285]: loss 0.7210, auc 0.5198, ap 0.5355
2024-01-10 21:59:52,926 - GAugM EPNet train, Epoch [239/285]: loss 0.7209, auc 0.4927, ap 0.5474
2024-01-10 21:59:53,009 - GAugM EPNet train, Epoch [240/285]: loss 0.7209, auc 0.4404, ap 0.4537
2024-01-10 21:59:53,092 - GAugM EPNet train, Epoch [241/285]: loss 0.7209, auc 0.4689, ap 0.4712
2024-01-10 21:59:53,177 - GAugM EPNet train, Epoch [242/285]: loss 0.7210, auc 0.4142, ap 0.4799
2024-01-10 21:59:53,262 - GAugM EPNet train, Epoch [243/285]: loss 0.7210, auc 0.4219, ap 0.4782
2024-01-10 21:59:53,351 - GAugM EPNet train, Epoch [244/285]: loss 0.7209, auc 0.5028, ap 0.4823
2024-01-10 21:59:53,436 - GAugM EPNet train, Epoch [245/285]: loss 0.7210, auc 0.4276, ap 0.4523
2024-01-10 21:59:53,525 - GAugM EPNet train, Epoch [246/285]: loss 0.7208, auc 0.5618, ap 0.5689
2024-01-10 21:59:53,609 - GAugM EPNet train, Epoch [247/285]: loss 0.7209, auc 0.5201, ap 0.5353
2024-01-10 21:59:53,692 - GAugM EPNet train, Epoch [248/285]: loss 0.7211, auc 0.4781, ap 0.5070
2024-01-10 21:59:53,775 - GAugM EPNet train, Epoch [249/285]: loss 0.7209, auc 0.4347, ap 0.4399
2024-01-10 21:59:53,862 - GAugM EPNet train, Epoch [250/285]: loss 0.7208, auc 0.5488, ap 0.5463
2024-01-10 21:59:53,947 - GAugM EPNet train, Epoch [251/285]: loss 0.7209, auc 0.4147, ap 0.4552
2024-01-10 21:59:54,031 - GAugM EPNet train, Epoch [252/285]: loss 0.7210, auc 0.5461, ap 0.5662
2024-01-10 21:59:54,114 - GAugM EPNet train, Epoch [253/285]: loss 0.7209, auc 0.6435, ap 0.6094
2024-01-10 21:59:54,197 - GAugM EPNet train, Epoch [254/285]: loss 0.7210, auc 0.4849, ap 0.5005
2024-01-10 21:59:54,287 - GAugM EPNet train, Epoch [255/285]: loss 0.7209, auc 0.4316, ap 0.4868
2024-01-10 21:59:54,370 - GAugM EPNet train, Epoch [256/285]: loss 0.7210, auc 0.3101, ap 0.4210
2024-01-10 21:59:54,458 - GAugM EPNet train, Epoch [257/285]: loss 0.7210, auc 0.5251, ap 0.5303
2024-01-10 21:59:54,542 - GAugM EPNet train, Epoch [258/285]: loss 0.7208, auc 0.5821, ap 0.6010
2024-01-10 21:59:54,632 - GAugM EPNet train, Epoch [259/285]: loss 0.7208, auc 0.5817, ap 0.5589
2024-01-10 21:59:54,715 - GAugM EPNet train, Epoch [260/285]: loss 0.7210, auc 0.5374, ap 0.5393
2024-01-10 21:59:54,799 - GAugM EPNet train, Epoch [261/285]: loss 0.7209, auc 0.4503, ap 0.4714
2024-01-10 21:59:54,888 - GAugM EPNet train, Epoch [262/285]: loss 0.7208, auc 0.4514, ap 0.4787
2024-01-10 21:59:54,983 - GAugM EPNet train, Epoch [263/285]: loss 0.7209, auc 0.4662, ap 0.4641
2024-01-10 21:59:55,068 - GAugM EPNet train, Epoch [264/285]: loss 0.7210, auc 0.4941, ap 0.4900
2024-01-10 21:59:55,151 - GAugM EPNet train, Epoch [265/285]: loss 0.7209, auc 0.4416, ap 0.4757
2024-01-10 21:59:55,236 - GAugM EPNet train, Epoch [266/285]: loss 0.7209, auc 0.5559, ap 0.5239
2024-01-10 21:59:55,320 - GAugM EPNet train, Epoch [267/285]: loss 0.7210, auc 0.4715, ap 0.5209
2024-01-10 21:59:55,402 - GAugM EPNet train, Epoch [268/285]: loss 0.7210, auc 0.4770, ap 0.5147
2024-01-10 21:59:55,485 - GAugM EPNet train, Epoch [269/285]: loss 0.7209, auc 0.4735, ap 0.4983
2024-01-10 21:59:55,568 - GAugM EPNet train, Epoch [270/285]: loss 0.7210, auc 0.5137, ap 0.5146
2024-01-10 21:59:55,651 - GAugM EPNet train, Epoch [271/285]: loss 0.7209, auc 0.4961, ap 0.4943
2024-01-10 21:59:55,737 - GAugM EPNet train, Epoch [272/285]: loss 0.7209, auc 0.4760, ap 0.4903
2024-01-10 21:59:55,819 - GAugM EPNet train, Epoch [273/285]: loss 0.7209, auc 0.4204, ap 0.4481
2024-01-10 21:59:55,901 - GAugM EPNet train, Epoch [274/285]: loss 0.7209, auc 0.4528, ap 0.4621
2024-01-10 21:59:55,995 - GAugM EPNet train, Epoch [275/285]: loss 0.7208, auc 0.3088, ap 0.3901
2024-01-10 21:59:56,081 - GAugM EPNet train, Epoch [276/285]: loss 0.7210, auc 0.5125, ap 0.5564
2024-01-10 21:59:56,164 - GAugM EPNet train, Epoch [277/285]: loss 0.7208, auc 0.5495, ap 0.5795
2024-01-10 21:59:56,257 - GAugM EPNet train, Epoch [278/285]: loss 0.7209, auc 0.5408, ap 0.6005
2024-01-10 21:59:56,342 - GAugM EPNet train, Epoch [279/285]: loss 0.7209, auc 0.4995, ap 0.4999
2024-01-10 21:59:56,426 - GAugM EPNet train, Epoch [280/285]: loss 0.7209, auc 0.4115, ap 0.4437
2024-01-10 21:59:56,511 - GAugM EPNet train, Epoch [281/285]: loss 0.7209, auc 0.4977, ap 0.4922
2024-01-10 21:59:56,599 - GAugM EPNet train, Epoch [282/285]: loss 0.7209, auc 0.5005, ap 0.4915
2024-01-10 21:59:56,684 - GAugM EPNet train, Epoch [283/285]: loss 0.7209, auc 0.3889, ap 0.4236
2024-01-10 21:59:56,767 - GAugM EPNet train, Epoch [284/285]: loss 0.7209, auc 0.4258, ap 0.4548
2024-01-10 21:59:56,853 - GAugM EPNet train, Epoch [285/285]: loss 0.7209, auc 0.5249, ap 0.5097
2024-01-10 21:59:56,861 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa003890>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 21:59:57,618 - GAugM EPNet train, Epoch [  1/285]: loss 0.7210, auc 0.4578, ap 0.4740
2024-01-10 21:59:57,702 - GAugM EPNet train, Epoch [  2/285]: loss 0.7210, auc 0.5062, ap 0.5123
2024-01-10 21:59:57,780 - GAugM EPNet train, Epoch [  3/285]: loss 0.7209, auc 0.5967, ap 0.6125
2024-01-10 21:59:57,855 - GAugM EPNet train, Epoch [  4/285]: loss 0.7209, auc 0.5077, ap 0.5069
2024-01-10 21:59:57,929 - GAugM EPNet train, Epoch [  5/285]: loss 0.7209, auc 0.5557, ap 0.5815
2024-01-10 21:59:58,013 - GAugM EPNet train, Epoch [  6/285]: loss 0.7209, auc 0.5137, ap 0.5304
2024-01-10 21:59:58,098 - GAugM EPNet train, Epoch [  7/285]: loss 0.7209, auc 0.4838, ap 0.4798
2024-01-10 21:59:58,188 - GAugM EPNet train, Epoch [  8/285]: loss 0.7210, auc 0.4696, ap 0.4853
2024-01-10 21:59:58,275 - GAugM EPNet train, Epoch [  9/285]: loss 0.7209, auc 0.4614, ap 0.4682
2024-01-10 21:59:58,361 - GAugM EPNet train, Epoch [ 10/285]: loss 0.7208, auc 0.5126, ap 0.5221
2024-01-10 21:59:58,451 - GAugM EPNet train, Epoch [ 11/285]: loss 0.7209, auc 0.5215, ap 0.5330
2024-01-10 21:59:58,540 - GAugM EPNet train, Epoch [ 12/285]: loss 0.7210, auc 0.4137, ap 0.4518
2024-01-10 21:59:58,624 - GAugM EPNet train, Epoch [ 13/285]: loss 0.7209, auc 0.5781, ap 0.5372
2024-01-10 21:59:58,708 - GAugM EPNet train, Epoch [ 14/285]: loss 0.7209, auc 0.5055, ap 0.5245
2024-01-10 21:59:58,798 - GAugM EPNet train, Epoch [ 15/285]: loss 0.7210, auc 0.4005, ap 0.4669
2024-01-10 21:59:58,881 - GAugM EPNet train, Epoch [ 16/285]: loss 0.7209, auc 0.5422, ap 0.5432
2024-01-10 21:59:58,965 - GAugM EPNet train, Epoch [ 17/285]: loss 0.7210, auc 0.4845, ap 0.4876
2024-01-10 21:59:59,049 - GAugM EPNet train, Epoch [ 18/285]: loss 0.7210, auc 0.6148, ap 0.5903
2024-01-10 21:59:59,140 - GAugM EPNet train, Epoch [ 19/285]: loss 0.7209, auc 0.4624, ap 0.4725
2024-01-10 21:59:59,223 - GAugM EPNet train, Epoch [ 20/285]: loss 0.7210, auc 0.4920, ap 0.5620
2024-01-10 21:59:59,311 - GAugM EPNet train, Epoch [ 21/285]: loss 0.7209, auc 0.5012, ap 0.4856
2024-01-10 21:59:59,393 - GAugM EPNet train, Epoch [ 22/285]: loss 0.7210, auc 0.4137, ap 0.4741
2024-01-10 21:59:59,475 - GAugM EPNet train, Epoch [ 23/285]: loss 0.7208, auc 0.5468, ap 0.5267
2024-01-10 21:59:59,570 - GAugM EPNet train, Epoch [ 24/285]: loss 0.7209, auc 0.5230, ap 0.4886
2024-01-10 21:59:59,655 - GAugM EPNet train, Epoch [ 25/285]: loss 0.7209, auc 0.4322, ap 0.4553
2024-01-10 21:59:59,739 - GAugM EPNet train, Epoch [ 26/285]: loss 0.7210, auc 0.5493, ap 0.5715
2024-01-10 21:59:59,827 - GAugM EPNet train, Epoch [ 27/285]: loss 0.7209, auc 0.4678, ap 0.5108
2024-01-10 21:59:59,916 - GAugM EPNet train, Epoch [ 28/285]: loss 0.7209, auc 0.6383, ap 0.6378
2024-01-10 22:00:00,001 - GAugM EPNet train, Epoch [ 29/285]: loss 0.7210, auc 0.4742, ap 0.4944
2024-01-10 22:00:00,087 - GAugM EPNet train, Epoch [ 30/285]: loss 0.7209, auc 0.5276, ap 0.5504
2024-01-10 22:00:00,171 - GAugM EPNet train, Epoch [ 31/285]: loss 0.7208, auc 0.5472, ap 0.5426
2024-01-10 22:00:00,257 - GAugM EPNet train, Epoch [ 32/285]: loss 0.7210, auc 0.5664, ap 0.5383
2024-01-10 22:00:00,347 - GAugM EPNet train, Epoch [ 33/285]: loss 0.7209, auc 0.5465, ap 0.5278
2024-01-10 22:00:00,430 - GAugM EPNet train, Epoch [ 34/285]: loss 0.7209, auc 0.4859, ap 0.4918
2024-01-10 22:00:00,515 - GAugM EPNet train, Epoch [ 35/285]: loss 0.7209, auc 0.5646, ap 0.5456
2024-01-10 22:00:00,598 - GAugM EPNet train, Epoch [ 36/285]: loss 0.7209, auc 0.6187, ap 0.5981
2024-01-10 22:00:00,683 - GAugM EPNet train, Epoch [ 37/285]: loss 0.7209, auc 0.4656, ap 0.5312
2024-01-10 22:00:00,767 - GAugM EPNet train, Epoch [ 38/285]: loss 0.7209, auc 0.4429, ap 0.4609
2024-01-10 22:00:00,849 - GAugM EPNet train, Epoch [ 39/285]: loss 0.7208, auc 0.3585, ap 0.4163
2024-01-10 22:00:00,934 - GAugM EPNet train, Epoch [ 40/285]: loss 0.7210, auc 0.4991, ap 0.5028
2024-01-10 22:00:01,029 - GAugM EPNet train, Epoch [ 41/285]: loss 0.7210, auc 0.4567, ap 0.4951
2024-01-10 22:00:01,112 - GAugM EPNet train, Epoch [ 42/285]: loss 0.7209, auc 0.5899, ap 0.6150
2024-01-10 22:00:01,200 - GAugM EPNet train, Epoch [ 43/285]: loss 0.7208, auc 0.4012, ap 0.4524
2024-01-10 22:00:01,286 - GAugM EPNet train, Epoch [ 44/285]: loss 0.7208, auc 0.4354, ap 0.4797
2024-01-10 22:00:01,370 - GAugM EPNet train, Epoch [ 45/285]: loss 0.7209, auc 0.5582, ap 0.5285
2024-01-10 22:00:01,448 - GAugM EPNet train, Epoch [ 46/285]: loss 0.7209, auc 0.4379, ap 0.4950
2024-01-10 22:00:01,536 - GAugM EPNet train, Epoch [ 47/285]: loss 0.7210, auc 0.4728, ap 0.5209
2024-01-10 22:00:01,624 - GAugM EPNet train, Epoch [ 48/285]: loss 0.7210, auc 0.5077, ap 0.5292
2024-01-10 22:00:01,711 - GAugM EPNet train, Epoch [ 49/285]: loss 0.7209, auc 0.5789, ap 0.5724
2024-01-10 22:00:01,800 - GAugM EPNet train, Epoch [ 50/285]: loss 0.7210, auc 0.5860, ap 0.5662
2024-01-10 22:00:01,888 - GAugM EPNet train, Epoch [ 51/285]: loss 0.7210, auc 0.3713, ap 0.4389
2024-01-10 22:00:01,976 - GAugM EPNet train, Epoch [ 52/285]: loss 0.7209, auc 0.4603, ap 0.5041
2024-01-10 22:00:02,068 - GAugM EPNet train, Epoch [ 53/285]: loss 0.7209, auc 0.5489, ap 0.5794
2024-01-10 22:00:02,153 - GAugM EPNet train, Epoch [ 54/285]: loss 0.7211, auc 0.5368, ap 0.5376
2024-01-10 22:00:02,239 - GAugM EPNet train, Epoch [ 55/285]: loss 0.7209, auc 0.5653, ap 0.5745
2024-01-10 22:00:02,324 - GAugM EPNet train, Epoch [ 56/285]: loss 0.7208, auc 0.5411, ap 0.5332
2024-01-10 22:00:02,411 - GAugM EPNet train, Epoch [ 57/285]: loss 0.7209, auc 0.4995, ap 0.5061
2024-01-10 22:00:02,501 - GAugM EPNet train, Epoch [ 58/285]: loss 0.7210, auc 0.4411, ap 0.4980
2024-01-10 22:00:02,579 - GAugM EPNet train, Epoch [ 59/285]: loss 0.7211, auc 0.5180, ap 0.5001
2024-01-10 22:00:02,665 - GAugM EPNet train, Epoch [ 60/285]: loss 0.7210, auc 0.5557, ap 0.5457
2024-01-10 22:00:02,752 - GAugM EPNet train, Epoch [ 61/285]: loss 0.7209, auc 0.4802, ap 0.4827
2024-01-10 22:00:02,838 - GAugM EPNet train, Epoch [ 62/285]: loss 0.7210, auc 0.4842, ap 0.4949
2024-01-10 22:00:02,925 - GAugM EPNet train, Epoch [ 63/285]: loss 0.7208, auc 0.4941, ap 0.4736
2024-01-10 22:00:03,012 - GAugM EPNet train, Epoch [ 64/285]: loss 0.7208, auc 0.4713, ap 0.5090
2024-01-10 22:00:03,104 - GAugM EPNet train, Epoch [ 65/285]: loss 0.7208, auc 0.5831, ap 0.5717
2024-01-10 22:00:03,190 - GAugM EPNet train, Epoch [ 66/285]: loss 0.7209, auc 0.4696, ap 0.5146
2024-01-10 22:00:03,277 - GAugM EPNet train, Epoch [ 67/285]: loss 0.7209, auc 0.5408, ap 0.5512
2024-01-10 22:00:03,367 - GAugM EPNet train, Epoch [ 68/285]: loss 0.7210, auc 0.4913, ap 0.5423
2024-01-10 22:00:03,455 - GAugM EPNet train, Epoch [ 69/285]: loss 0.7210, auc 0.5137, ap 0.5577
2024-01-10 22:00:03,540 - GAugM EPNet train, Epoch [ 70/285]: loss 0.7210, auc 0.4802, ap 0.4867
2024-01-10 22:00:03,620 - GAugM EPNet train, Epoch [ 71/285]: loss 0.7210, auc 0.5522, ap 0.5209
2024-01-10 22:00:03,705 - GAugM EPNet train, Epoch [ 72/285]: loss 0.7210, auc 0.4585, ap 0.4888
2024-01-10 22:00:03,791 - GAugM EPNet train, Epoch [ 73/285]: loss 0.7209, auc 0.5974, ap 0.5650
2024-01-10 22:00:03,879 - GAugM EPNet train, Epoch [ 74/285]: loss 0.7209, auc 0.5158, ap 0.5285
2024-01-10 22:00:03,969 - GAugM EPNet train, Epoch [ 75/285]: loss 0.7210, auc 0.4884, ap 0.5325
2024-01-10 22:00:04,057 - GAugM EPNet train, Epoch [ 76/285]: loss 0.7209, auc 0.4514, ap 0.4935
2024-01-10 22:00:04,149 - GAugM EPNet train, Epoch [ 77/285]: loss 0.7208, auc 0.5984, ap 0.5902
2024-01-10 22:00:04,234 - GAugM EPNet train, Epoch [ 78/285]: loss 0.7209, auc 0.4827, ap 0.4861
2024-01-10 22:00:04,322 - GAugM EPNet train, Epoch [ 79/285]: loss 0.7208, auc 0.5133, ap 0.5087
2024-01-10 22:00:04,410 - GAugM EPNet train, Epoch [ 80/285]: loss 0.7209, auc 0.5842, ap 0.5734
2024-01-10 22:00:04,497 - GAugM EPNet train, Epoch [ 81/285]: loss 0.7209, auc 0.5230, ap 0.5090
2024-01-10 22:00:04,588 - GAugM EPNet train, Epoch [ 82/285]: loss 0.7210, auc 0.5226, ap 0.5283
2024-01-10 22:00:04,674 - GAugM EPNet train, Epoch [ 83/285]: loss 0.7209, auc 0.4468, ap 0.4977
2024-01-10 22:00:04,765 - GAugM EPNet train, Epoch [ 84/285]: loss 0.7209, auc 0.4589, ap 0.4688
2024-01-10 22:00:04,852 - GAugM EPNet train, Epoch [ 85/285]: loss 0.7210, auc 0.4575, ap 0.5058
2024-01-10 22:00:04,941 - GAugM EPNet train, Epoch [ 86/285]: loss 0.7208, auc 0.5415, ap 0.5485
2024-01-10 22:00:05,026 - GAugM EPNet train, Epoch [ 87/285]: loss 0.7209, auc 0.5714, ap 0.5669
2024-01-10 22:00:05,112 - GAugM EPNet train, Epoch [ 88/285]: loss 0.7210, auc 0.3969, ap 0.4489
2024-01-10 22:00:05,197 - GAugM EPNet train, Epoch [ 89/285]: loss 0.7210, auc 0.5664, ap 0.5947
2024-01-10 22:00:05,286 - GAugM EPNet train, Epoch [ 90/285]: loss 0.7209, auc 0.4432, ap 0.4989
2024-01-10 22:00:05,374 - GAugM EPNet train, Epoch [ 91/285]: loss 0.7208, auc 0.5910, ap 0.5642
2024-01-10 22:00:05,465 - GAugM EPNet train, Epoch [ 92/285]: loss 0.7209, auc 0.5105, ap 0.5315
2024-01-10 22:00:05,548 - GAugM EPNet train, Epoch [ 93/285]: loss 0.7209, auc 0.4073, ap 0.4651
2024-01-10 22:00:05,621 - GAugM EPNet train, Epoch [ 94/285]: loss 0.7210, auc 0.4122, ap 0.4519
2024-01-10 22:00:05,709 - GAugM EPNet train, Epoch [ 95/285]: loss 0.7210, auc 0.5258, ap 0.5210
2024-01-10 22:00:05,795 - GAugM EPNet train, Epoch [ 96/285]: loss 0.7209, auc 0.4414, ap 0.4926
2024-01-10 22:00:05,885 - GAugM EPNet train, Epoch [ 97/285]: loss 0.7209, auc 0.4375, ap 0.4918
2024-01-10 22:00:05,971 - GAugM EPNet train, Epoch [ 98/285]: loss 0.7209, auc 0.5098, ap 0.5065
2024-01-10 22:00:06,061 - GAugM EPNet train, Epoch [ 99/285]: loss 0.7209, auc 0.4464, ap 0.4702
2024-01-10 22:00:06,146 - GAugM EPNet train, Epoch [100/285]: loss 0.7210, auc 0.5803, ap 0.5495
2024-01-10 22:00:06,231 - GAugM EPNet train, Epoch [101/285]: loss 0.7210, auc 0.5301, ap 0.5693
2024-01-10 22:00:06,319 - GAugM EPNet train, Epoch [102/285]: loss 0.7209, auc 0.5283, ap 0.5593
2024-01-10 22:00:06,406 - GAugM EPNet train, Epoch [103/285]: loss 0.7209, auc 0.4745, ap 0.5223
2024-01-10 22:00:06,496 - GAugM EPNet train, Epoch [104/285]: loss 0.7209, auc 0.4543, ap 0.4678
2024-01-10 22:00:06,584 - GAugM EPNet train, Epoch [105/285]: loss 0.7209, auc 0.4204, ap 0.4585
2024-01-10 22:00:06,670 - GAugM EPNet train, Epoch [106/285]: loss 0.7210, auc 0.4977, ap 0.5056
2024-01-10 22:00:06,754 - GAugM EPNet train, Epoch [107/285]: loss 0.7210, auc 0.4870, ap 0.4929
2024-01-10 22:00:06,842 - GAugM EPNet train, Epoch [108/285]: loss 0.7208, auc 0.4785, ap 0.4974
2024-01-10 22:00:06,925 - GAugM EPNet train, Epoch [109/285]: loss 0.7210, auc 0.3966, ap 0.4722
2024-01-10 22:00:07,008 - GAugM EPNet train, Epoch [110/285]: loss 0.7209, auc 0.4411, ap 0.4574
2024-01-10 22:00:07,090 - GAugM EPNet train, Epoch [111/285]: loss 0.7210, auc 0.5290, ap 0.5424
2024-01-10 22:00:07,173 - GAugM EPNet train, Epoch [112/285]: loss 0.7209, auc 0.5148, ap 0.5229
2024-01-10 22:00:07,255 - GAugM EPNet train, Epoch [113/285]: loss 0.7210, auc 0.4642, ap 0.4851
2024-01-10 22:00:07,338 - GAugM EPNet train, Epoch [114/285]: loss 0.7209, auc 0.4308, ap 0.4410
2024-01-10 22:00:07,420 - GAugM EPNet train, Epoch [115/285]: loss 0.7210, auc 0.5283, ap 0.5256
2024-01-10 22:00:07,503 - GAugM EPNet train, Epoch [116/285]: loss 0.7209, auc 0.5653, ap 0.5760
2024-01-10 22:00:07,584 - GAugM EPNet train, Epoch [117/285]: loss 0.7208, auc 0.5155, ap 0.5303
2024-01-10 22:00:07,667 - GAugM EPNet train, Epoch [118/285]: loss 0.7209, auc 0.5489, ap 0.5654
2024-01-10 22:00:07,748 - GAugM EPNet train, Epoch [119/285]: loss 0.7209, auc 0.4500, ap 0.5097
2024-01-10 22:00:07,831 - GAugM EPNet train, Epoch [120/285]: loss 0.7210, auc 0.4899, ap 0.4864
2024-01-10 22:00:07,919 - GAugM EPNet train, Epoch [121/285]: loss 0.7210, auc 0.4276, ap 0.4850
2024-01-10 22:00:08,000 - GAugM EPNet train, Epoch [122/285]: loss 0.7209, auc 0.4852, ap 0.5324
2024-01-10 22:00:08,083 - GAugM EPNet train, Epoch [123/285]: loss 0.7209, auc 0.4856, ap 0.5119
2024-01-10 22:00:08,165 - GAugM EPNet train, Epoch [124/285]: loss 0.7210, auc 0.5041, ap 0.4978
2024-01-10 22:00:08,248 - GAugM EPNet train, Epoch [125/285]: loss 0.7209, auc 0.4952, ap 0.5132
2024-01-10 22:00:08,330 - GAugM EPNet train, Epoch [126/285]: loss 0.7210, auc 0.4788, ap 0.4790
2024-01-10 22:00:08,412 - GAugM EPNet train, Epoch [127/285]: loss 0.7209, auc 0.4938, ap 0.4994
2024-01-10 22:00:08,495 - GAugM EPNet train, Epoch [128/285]: loss 0.7210, auc 0.4600, ap 0.4729
2024-01-10 22:00:08,596 - GAugM EPNet train, Epoch [129/285]: loss 0.7208, auc 0.4607, ap 0.4736
2024-01-10 22:00:08,683 - GAugM EPNet train, Epoch [130/285]: loss 0.7210, auc 0.4973, ap 0.5476
2024-01-10 22:00:08,776 - GAugM EPNet train, Epoch [131/285]: loss 0.7210, auc 0.5518, ap 0.5765
2024-01-10 22:00:08,862 - GAugM EPNet train, Epoch [132/285]: loss 0.7209, auc 0.5144, ap 0.5136
2024-01-10 22:00:08,947 - GAugM EPNet train, Epoch [133/285]: loss 0.7209, auc 0.4806, ap 0.5292
2024-01-10 22:00:09,035 - GAugM EPNet train, Epoch [134/285]: loss 0.7210, auc 0.5486, ap 0.5503
2024-01-10 22:00:09,120 - GAugM EPNet train, Epoch [135/285]: loss 0.7209, auc 0.3969, ap 0.4478
2024-01-10 22:00:09,210 - GAugM EPNet train, Epoch [136/285]: loss 0.7209, auc 0.4664, ap 0.4952
2024-01-10 22:00:09,299 - GAugM EPNet train, Epoch [137/285]: loss 0.7210, auc 0.4208, ap 0.4635
2024-01-10 22:00:09,389 - GAugM EPNet train, Epoch [138/285]: loss 0.7210, auc 0.5297, ap 0.5224
2024-01-10 22:00:09,479 - GAugM EPNet train, Epoch [139/285]: loss 0.7210, auc 0.5365, ap 0.5242
2024-01-10 22:00:09,572 - GAugM EPNet train, Epoch [140/285]: loss 0.7209, auc 0.4397, ap 0.4806
2024-01-10 22:00:09,661 - GAugM EPNet train, Epoch [141/285]: loss 0.7209, auc 0.5351, ap 0.5385
2024-01-10 22:00:09,752 - GAugM EPNet train, Epoch [142/285]: loss 0.7209, auc 0.5650, ap 0.5840
2024-01-10 22:00:09,842 - GAugM EPNet train, Epoch [143/285]: loss 0.7209, auc 0.4525, ap 0.4716
2024-01-10 22:00:09,931 - GAugM EPNet train, Epoch [144/285]: loss 0.7209, auc 0.4834, ap 0.5042
2024-01-10 22:00:10,017 - GAugM EPNet train, Epoch [145/285]: loss 0.7209, auc 0.4208, ap 0.4674
2024-01-10 22:00:10,102 - GAugM EPNet train, Epoch [146/285]: loss 0.7209, auc 0.5304, ap 0.5584
2024-01-10 22:00:10,192 - GAugM EPNet train, Epoch [147/285]: loss 0.7209, auc 0.6636, ap 0.6572
2024-01-10 22:00:10,285 - GAugM EPNet train, Epoch [148/285]: loss 0.7209, auc 0.4795, ap 0.4903
2024-01-10 22:00:10,374 - GAugM EPNet train, Epoch [149/285]: loss 0.7208, auc 0.5187, ap 0.5152
2024-01-10 22:00:10,465 - GAugM EPNet train, Epoch [150/285]: loss 0.7209, auc 0.4678, ap 0.4809
2024-01-10 22:00:10,556 - GAugM EPNet train, Epoch [151/285]: loss 0.7209, auc 0.5518, ap 0.5464
2024-01-10 22:00:10,643 - GAugM EPNet train, Epoch [152/285]: loss 0.7209, auc 0.5272, ap 0.5424
2024-01-10 22:00:10,732 - GAugM EPNet train, Epoch [153/285]: loss 0.7209, auc 0.4162, ap 0.4645
2024-01-10 22:00:10,819 - GAugM EPNet train, Epoch [154/285]: loss 0.7209, auc 0.5988, ap 0.6333
2024-01-10 22:00:10,912 - GAugM EPNet train, Epoch [155/285]: loss 0.7209, auc 0.4977, ap 0.5181
2024-01-10 22:00:11,000 - GAugM EPNet train, Epoch [156/285]: loss 0.7209, auc 0.4094, ap 0.4769
2024-01-10 22:00:11,089 - GAugM EPNet train, Epoch [157/285]: loss 0.7209, auc 0.5543, ap 0.5409
2024-01-10 22:00:11,183 - GAugM EPNet train, Epoch [158/285]: loss 0.7208, auc 0.4094, ap 0.4572
2024-01-10 22:00:11,267 - GAugM EPNet train, Epoch [159/285]: loss 0.7208, auc 0.4432, ap 0.4572
2024-01-10 22:00:11,354 - GAugM EPNet train, Epoch [160/285]: loss 0.7209, auc 0.5514, ap 0.5666
2024-01-10 22:00:11,438 - GAugM EPNet train, Epoch [161/285]: loss 0.7209, auc 0.5361, ap 0.5636
2024-01-10 22:00:11,525 - GAugM EPNet train, Epoch [162/285]: loss 0.7209, auc 0.4400, ap 0.4654
2024-01-10 22:00:11,614 - GAugM EPNet train, Epoch [163/285]: loss 0.7209, auc 0.5155, ap 0.5012
2024-01-10 22:00:11,703 - GAugM EPNet train, Epoch [164/285]: loss 0.7211, auc 0.4454, ap 0.4663
2024-01-10 22:00:11,792 - GAugM EPNet train, Epoch [165/285]: loss 0.7210, auc 0.4521, ap 0.4732
2024-01-10 22:00:11,878 - GAugM EPNet train, Epoch [166/285]: loss 0.7208, auc 0.5226, ap 0.5177
2024-01-10 22:00:11,965 - GAugM EPNet train, Epoch [167/285]: loss 0.7209, auc 0.4443, ap 0.4765
2024-01-10 22:00:12,050 - GAugM EPNet train, Epoch [168/285]: loss 0.7209, auc 0.4087, ap 0.4706
2024-01-10 22:00:12,138 - GAugM EPNet train, Epoch [169/285]: loss 0.7209, auc 0.5265, ap 0.5343
2024-01-10 22:00:12,228 - GAugM EPNet train, Epoch [170/285]: loss 0.7210, auc 0.4988, ap 0.4962
2024-01-10 22:00:12,312 - GAugM EPNet train, Epoch [171/285]: loss 0.7209, auc 0.3927, ap 0.4408
2024-01-10 22:00:12,399 - GAugM EPNet train, Epoch [172/285]: loss 0.7208, auc 0.4888, ap 0.4807
2024-01-10 22:00:12,488 - GAugM EPNet train, Epoch [173/285]: loss 0.7209, auc 0.4639, ap 0.5245
2024-01-10 22:00:12,574 - GAugM EPNet train, Epoch [174/285]: loss 0.7209, auc 0.4799, ap 0.4817
2024-01-10 22:00:12,664 - GAugM EPNet train, Epoch [175/285]: loss 0.7209, auc 0.5902, ap 0.5483
2024-01-10 22:00:12,751 - GAugM EPNet train, Epoch [176/285]: loss 0.7209, auc 0.4546, ap 0.4760
2024-01-10 22:00:12,845 - GAugM EPNet train, Epoch [177/285]: loss 0.7210, auc 0.5255, ap 0.5204
2024-01-10 22:00:12,936 - GAugM EPNet train, Epoch [178/285]: loss 0.7210, auc 0.5578, ap 0.5745
2024-01-10 22:00:13,023 - GAugM EPNet train, Epoch [179/285]: loss 0.7210, auc 0.4560, ap 0.5019
2024-01-10 22:00:13,109 - GAugM EPNet train, Epoch [180/285]: loss 0.7210, auc 0.5824, ap 0.5829
2024-01-10 22:00:13,194 - GAugM EPNet train, Epoch [181/285]: loss 0.7209, auc 0.4315, ap 0.4480
2024-01-10 22:00:13,279 - GAugM EPNet train, Epoch [182/285]: loss 0.7209, auc 0.4660, ap 0.5260
2024-01-10 22:00:13,365 - GAugM EPNet train, Epoch [183/285]: loss 0.7210, auc 0.4760, ap 0.4729
2024-01-10 22:00:13,454 - GAugM EPNet train, Epoch [184/285]: loss 0.7209, auc 0.5294, ap 0.5298
2024-01-10 22:00:13,538 - GAugM EPNet train, Epoch [185/285]: loss 0.7209, auc 0.4155, ap 0.4484
2024-01-10 22:00:13,625 - GAugM EPNet train, Epoch [186/285]: loss 0.7208, auc 0.4923, ap 0.5375
2024-01-10 22:00:13,716 - GAugM EPNet train, Epoch [187/285]: loss 0.7209, auc 0.5194, ap 0.5326
2024-01-10 22:00:13,802 - GAugM EPNet train, Epoch [188/285]: loss 0.7209, auc 0.4774, ap 0.4829
2024-01-10 22:00:13,891 - GAugM EPNet train, Epoch [189/285]: loss 0.7209, auc 0.6433, ap 0.6254
2024-01-10 22:00:13,978 - GAugM EPNet train, Epoch [190/285]: loss 0.7209, auc 0.4329, ap 0.4669
2024-01-10 22:00:14,067 - GAugM EPNet train, Epoch [191/285]: loss 0.7209, auc 0.4069, ap 0.4952
2024-01-10 22:00:14,152 - GAugM EPNet train, Epoch [192/285]: loss 0.7209, auc 0.4899, ap 0.4705
2024-01-10 22:00:14,238 - GAugM EPNet train, Epoch [193/285]: loss 0.7209, auc 0.5794, ap 0.5272
2024-01-10 22:00:14,321 - GAugM EPNet train, Epoch [194/285]: loss 0.7209, auc 0.4938, ap 0.5023
2024-01-10 22:00:14,405 - GAugM EPNet train, Epoch [195/285]: loss 0.7209, auc 0.3952, ap 0.4280
2024-01-10 22:00:14,493 - GAugM EPNet train, Epoch [196/285]: loss 0.7208, auc 0.5440, ap 0.5355
2024-01-10 22:00:14,587 - GAugM EPNet train, Epoch [197/285]: loss 0.7210, auc 0.4500, ap 0.4763
2024-01-10 22:00:14,680 - GAugM EPNet train, Epoch [198/285]: loss 0.7210, auc 0.5141, ap 0.5212
2024-01-10 22:00:14,770 - GAugM EPNet train, Epoch [199/285]: loss 0.7209, auc 0.4923, ap 0.5082
2024-01-10 22:00:14,861 - GAugM EPNet train, Epoch [200/285]: loss 0.7210, auc 0.4728, ap 0.5149
2024-01-10 22:00:14,956 - GAugM EPNet train, Epoch [201/285]: loss 0.7209, auc 0.4521, ap 0.4830
2024-01-10 22:00:15,044 - GAugM EPNet train, Epoch [202/285]: loss 0.7210, auc 0.5190, ap 0.5485
2024-01-10 22:00:15,135 - GAugM EPNet train, Epoch [203/285]: loss 0.7210, auc 0.5376, ap 0.5667
2024-01-10 22:00:15,228 - GAugM EPNet train, Epoch [204/285]: loss 0.7209, auc 0.3645, ap 0.4098
2024-01-10 22:00:15,316 - GAugM EPNet train, Epoch [205/285]: loss 0.7209, auc 0.5151, ap 0.5385
2024-01-10 22:00:15,406 - GAugM EPNet train, Epoch [206/285]: loss 0.7209, auc 0.4589, ap 0.4888
2024-01-10 22:00:15,500 - GAugM EPNet train, Epoch [207/285]: loss 0.7210, auc 0.4507, ap 0.5213
2024-01-10 22:00:15,591 - GAugM EPNet train, Epoch [208/285]: loss 0.7209, auc 0.4813, ap 0.5269
2024-01-10 22:00:15,678 - GAugM EPNet train, Epoch [209/285]: loss 0.7210, auc 0.4966, ap 0.5136
2024-01-10 22:00:15,765 - GAugM EPNet train, Epoch [210/285]: loss 0.7209, auc 0.4963, ap 0.4914
2024-01-10 22:00:15,854 - GAugM EPNet train, Epoch [211/285]: loss 0.7210, auc 0.5201, ap 0.5276
2024-01-10 22:00:15,943 - GAugM EPNet train, Epoch [212/285]: loss 0.7210, auc 0.4596, ap 0.4854
2024-01-10 22:00:16,032 - GAugM EPNet train, Epoch [213/285]: loss 0.7208, auc 0.6376, ap 0.6786
2024-01-10 22:00:16,120 - GAugM EPNet train, Epoch [214/285]: loss 0.7210, auc 0.5376, ap 0.5184
2024-01-10 22:00:16,208 - GAugM EPNet train, Epoch [215/285]: loss 0.7210, auc 0.5550, ap 0.5430
2024-01-10 22:00:16,300 - GAugM EPNet train, Epoch [216/285]: loss 0.7209, auc 0.5539, ap 0.5387
2024-01-10 22:00:16,390 - GAugM EPNet train, Epoch [217/285]: loss 0.7209, auc 0.5646, ap 0.5955
2024-01-10 22:00:16,480 - GAugM EPNet train, Epoch [218/285]: loss 0.7209, auc 0.5279, ap 0.5199
2024-01-10 22:00:16,570 - GAugM EPNet train, Epoch [219/285]: loss 0.7208, auc 0.4810, ap 0.4957
2024-01-10 22:00:16,659 - GAugM EPNet train, Epoch [220/285]: loss 0.7210, auc 0.4083, ap 0.4936
2024-01-10 22:00:16,747 - GAugM EPNet train, Epoch [221/285]: loss 0.7209, auc 0.5301, ap 0.5248
2024-01-10 22:00:16,838 - GAugM EPNet train, Epoch [222/285]: loss 0.7209, auc 0.4728, ap 0.5051
2024-01-10 22:00:16,929 - GAugM EPNet train, Epoch [223/285]: loss 0.7209, auc 0.6123, ap 0.6057
2024-01-10 22:00:17,017 - GAugM EPNet train, Epoch [224/285]: loss 0.7210, auc 0.4464, ap 0.4638
2024-01-10 22:00:17,108 - GAugM EPNet train, Epoch [225/285]: loss 0.7209, auc 0.4717, ap 0.5112
2024-01-10 22:00:17,196 - GAugM EPNet train, Epoch [226/285]: loss 0.7210, auc 0.5190, ap 0.5474
2024-01-10 22:00:17,286 - GAugM EPNet train, Epoch [227/285]: loss 0.7210, auc 0.5482, ap 0.5474
2024-01-10 22:00:17,376 - GAugM EPNet train, Epoch [228/285]: loss 0.7209, auc 0.4379, ap 0.4783
2024-01-10 22:00:17,470 - GAugM EPNet train, Epoch [229/285]: loss 0.7209, auc 0.6155, ap 0.6111
2024-01-10 22:00:17,562 - GAugM EPNet train, Epoch [230/285]: loss 0.7209, auc 0.4859, ap 0.5242
2024-01-10 22:00:17,656 - GAugM EPNet train, Epoch [231/285]: loss 0.7209, auc 0.5141, ap 0.5429
2024-01-10 22:00:17,743 - GAugM EPNet train, Epoch [232/285]: loss 0.7209, auc 0.5155, ap 0.5101
2024-01-10 22:00:17,834 - GAugM EPNet train, Epoch [233/285]: loss 0.7210, auc 0.4678, ap 0.5122
2024-01-10 22:00:17,922 - GAugM EPNet train, Epoch [234/285]: loss 0.7209, auc 0.4247, ap 0.4891
2024-01-10 22:00:18,011 - GAugM EPNet train, Epoch [235/285]: loss 0.7209, auc 0.4589, ap 0.4547
2024-01-10 22:00:18,099 - GAugM EPNet train, Epoch [236/285]: loss 0.7209, auc 0.4567, ap 0.5131
2024-01-10 22:00:18,190 - GAugM EPNet train, Epoch [237/285]: loss 0.7210, auc 0.4977, ap 0.5419
2024-01-10 22:00:18,278 - GAugM EPNet train, Epoch [238/285]: loss 0.7210, auc 0.5582, ap 0.5512
2024-01-10 22:00:18,367 - GAugM EPNet train, Epoch [239/285]: loss 0.7209, auc 0.5653, ap 0.5942
2024-01-10 22:00:18,460 - GAugM EPNet train, Epoch [240/285]: loss 0.7209, auc 0.4959, ap 0.4864
2024-01-10 22:00:18,548 - GAugM EPNet train, Epoch [241/285]: loss 0.7209, auc 0.5066, ap 0.5152
2024-01-10 22:00:18,638 - GAugM EPNet train, Epoch [242/285]: loss 0.7210, auc 0.4258, ap 0.4787
2024-01-10 22:00:18,730 - GAugM EPNet train, Epoch [243/285]: loss 0.7210, auc 0.5518, ap 0.5730
2024-01-10 22:00:18,817 - GAugM EPNet train, Epoch [244/285]: loss 0.7209, auc 0.5717, ap 0.5581
2024-01-10 22:00:18,909 - GAugM EPNet train, Epoch [245/285]: loss 0.7210, auc 0.4486, ap 0.4608
2024-01-10 22:00:18,997 - GAugM EPNet train, Epoch [246/285]: loss 0.7208, auc 0.4938, ap 0.5151
2024-01-10 22:00:19,087 - GAugM EPNet train, Epoch [247/285]: loss 0.7209, auc 0.4834, ap 0.5045
2024-01-10 22:00:19,176 - GAugM EPNet train, Epoch [248/285]: loss 0.7211, auc 0.5546, ap 0.5587
2024-01-10 22:00:19,267 - GAugM EPNet train, Epoch [249/285]: loss 0.7209, auc 0.5133, ap 0.5014
2024-01-10 22:00:19,353 - GAugM EPNet train, Epoch [250/285]: loss 0.7208, auc 0.5123, ap 0.5080
2024-01-10 22:00:19,438 - GAugM EPNet train, Epoch [251/285]: loss 0.7209, auc 0.3891, ap 0.4251
2024-01-10 22:00:19,531 - GAugM EPNet train, Epoch [252/285]: loss 0.7210, auc 0.5077, ap 0.5255
2024-01-10 22:00:19,616 - GAugM EPNet train, Epoch [253/285]: loss 0.7209, auc 0.6173, ap 0.5793
2024-01-10 22:00:19,702 - GAugM EPNet train, Epoch [254/285]: loss 0.7210, auc 0.4585, ap 0.5069
2024-01-10 22:00:19,786 - GAugM EPNet train, Epoch [255/285]: loss 0.7209, auc 0.4532, ap 0.4738
2024-01-10 22:00:19,872 - GAugM EPNet train, Epoch [256/285]: loss 0.7210, auc 0.4881, ap 0.5563
2024-01-10 22:00:19,965 - GAugM EPNet train, Epoch [257/285]: loss 0.7210, auc 0.4286, ap 0.4519
2024-01-10 22:00:20,051 - GAugM EPNet train, Epoch [258/285]: loss 0.7208, auc 0.5518, ap 0.5620
2024-01-10 22:00:20,146 - GAugM EPNet train, Epoch [259/285]: loss 0.7208, auc 0.5920, ap 0.5591
2024-01-10 22:00:20,236 - GAugM EPNet train, Epoch [260/285]: loss 0.7210, auc 0.5144, ap 0.5378
2024-01-10 22:00:20,336 - GAugM EPNet train, Epoch [261/285]: loss 0.7209, auc 0.4389, ap 0.4789
2024-01-10 22:00:20,422 - GAugM EPNet train, Epoch [262/285]: loss 0.7208, auc 0.4418, ap 0.4682
2024-01-10 22:00:20,508 - GAugM EPNet train, Epoch [263/285]: loss 0.7209, auc 0.5279, ap 0.5323
2024-01-10 22:00:20,594 - GAugM EPNet train, Epoch [264/285]: loss 0.7210, auc 0.4197, ap 0.4491
2024-01-10 22:00:20,683 - GAugM EPNet train, Epoch [265/285]: loss 0.7209, auc 0.4703, ap 0.5298
2024-01-10 22:00:20,767 - GAugM EPNet train, Epoch [266/285]: loss 0.7209, auc 0.4763, ap 0.4807
2024-01-10 22:00:20,854 - GAugM EPNet train, Epoch [267/285]: loss 0.7210, auc 0.5379, ap 0.5505
2024-01-10 22:00:20,942 - GAugM EPNet train, Epoch [268/285]: loss 0.7210, auc 0.5130, ap 0.5378
2024-01-10 22:00:21,039 - GAugM EPNet train, Epoch [269/285]: loss 0.7209, auc 0.5340, ap 0.5444
2024-01-10 22:00:21,132 - GAugM EPNet train, Epoch [270/285]: loss 0.7210, auc 0.5158, ap 0.5445
2024-01-10 22:00:21,224 - GAugM EPNet train, Epoch [271/285]: loss 0.7209, auc 0.5158, ap 0.5281
2024-01-10 22:00:21,315 - GAugM EPNet train, Epoch [272/285]: loss 0.7209, auc 0.4642, ap 0.5056
2024-01-10 22:00:21,403 - GAugM EPNet train, Epoch [273/285]: loss 0.7209, auc 0.4952, ap 0.5081
2024-01-10 22:00:21,494 - GAugM EPNet train, Epoch [274/285]: loss 0.7209, auc 0.5351, ap 0.5251
2024-01-10 22:00:21,583 - GAugM EPNet train, Epoch [275/285]: loss 0.7208, auc 0.3834, ap 0.4314
2024-01-10 22:00:21,678 - GAugM EPNet train, Epoch [276/285]: loss 0.7210, auc 0.5329, ap 0.5750
2024-01-10 22:00:21,768 - GAugM EPNet train, Epoch [277/285]: loss 0.7208, auc 0.5162, ap 0.5551
2024-01-10 22:00:21,857 - GAugM EPNet train, Epoch [278/285]: loss 0.7209, auc 0.4977, ap 0.5204
2024-01-10 22:00:21,948 - GAugM EPNet train, Epoch [279/285]: loss 0.7209, auc 0.5283, ap 0.5494
2024-01-10 22:00:22,036 - GAugM EPNet train, Epoch [280/285]: loss 0.7209, auc 0.3813, ap 0.4348
2024-01-10 22:00:22,123 - GAugM EPNet train, Epoch [281/285]: loss 0.7209, auc 0.5166, ap 0.5172
2024-01-10 22:00:22,216 - GAugM EPNet train, Epoch [282/285]: loss 0.7209, auc 0.4724, ap 0.4795
2024-01-10 22:00:22,304 - GAugM EPNet train, Epoch [283/285]: loss 0.7209, auc 0.4286, ap 0.4551
2024-01-10 22:00:22,388 - GAugM EPNet train, Epoch [284/285]: loss 0.7209, auc 0.3855, ap 0.4319
2024-01-10 22:00:22,474 - GAugM EPNet train, Epoch [285/285]: loss 0.7209, auc 0.4600, ap 0.4770
2024-01-10 22:00:22,475 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03bfc8d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:00:23,297 - GAugM EPNet train, Epoch [  1/285]: loss 0.7210, auc 0.4776, ap 0.4785
2024-01-10 22:00:23,391 - GAugM EPNet train, Epoch [  2/285]: loss 0.7210, auc 0.5347, ap 0.5253
2024-01-10 22:00:23,475 - GAugM EPNet train, Epoch [  3/285]: loss 0.7209, auc 0.5463, ap 0.5225
2024-01-10 22:00:23,564 - GAugM EPNet train, Epoch [  4/285]: loss 0.7209, auc 0.4806, ap 0.5009
2024-01-10 22:00:23,652 - GAugM EPNet train, Epoch [  5/285]: loss 0.7209, auc 0.5684, ap 0.5831
2024-01-10 22:00:23,742 - GAugM EPNet train, Epoch [  6/285]: loss 0.7209, auc 0.5224, ap 0.5070
2024-01-10 22:00:23,833 - GAugM EPNet train, Epoch [  7/285]: loss 0.7209, auc 0.4646, ap 0.4830
2024-01-10 22:00:23,923 - GAugM EPNet train, Epoch [  8/285]: loss 0.7210, auc 0.4494, ap 0.4706
2024-01-10 22:00:24,012 - GAugM EPNet train, Epoch [  9/285]: loss 0.7209, auc 0.4724, ap 0.4722
2024-01-10 22:00:24,103 - GAugM EPNet train, Epoch [ 10/285]: loss 0.7208, auc 0.5472, ap 0.5640
2024-01-10 22:00:24,192 - GAugM EPNet train, Epoch [ 11/285]: loss 0.7209, auc 0.5294, ap 0.5721
2024-01-10 22:00:24,289 - GAugM EPNet train, Epoch [ 12/285]: loss 0.7210, auc 0.4541, ap 0.4600
2024-01-10 22:00:24,376 - GAugM EPNet train, Epoch [ 13/285]: loss 0.7209, auc 0.6152, ap 0.5832
2024-01-10 22:00:24,472 - GAugM EPNet train, Epoch [ 14/285]: loss 0.7209, auc 0.5748, ap 0.5727
2024-01-10 22:00:24,563 - GAugM EPNet train, Epoch [ 15/285]: loss 0.7210, auc 0.4475, ap 0.4920
2024-01-10 22:00:24,651 - GAugM EPNet train, Epoch [ 16/285]: loss 0.7209, auc 0.5489, ap 0.5387
2024-01-10 22:00:24,739 - GAugM EPNet train, Epoch [ 17/285]: loss 0.7210, auc 0.5557, ap 0.5515
2024-01-10 22:00:24,834 - GAugM EPNet train, Epoch [ 18/285]: loss 0.7210, auc 0.6239, ap 0.6175
2024-01-10 22:00:24,924 - GAugM EPNet train, Epoch [ 19/285]: loss 0.7209, auc 0.4996, ap 0.4825
2024-01-10 22:00:25,014 - GAugM EPNet train, Epoch [ 20/285]: loss 0.7210, auc 0.4163, ap 0.4534
2024-01-10 22:00:25,101 - GAugM EPNet train, Epoch [ 21/285]: loss 0.7209, auc 0.4697, ap 0.4655
2024-01-10 22:00:25,186 - GAugM EPNet train, Epoch [ 22/285]: loss 0.7210, auc 0.4557, ap 0.4657
2024-01-10 22:00:25,281 - GAugM EPNet train, Epoch [ 23/285]: loss 0.7208, auc 0.4509, ap 0.4997
2024-01-10 22:00:25,365 - GAugM EPNet train, Epoch [ 24/285]: loss 0.7209, auc 0.5315, ap 0.5103
2024-01-10 22:00:25,454 - GAugM EPNet train, Epoch [ 25/285]: loss 0.7209, auc 0.5030, ap 0.5166
2024-01-10 22:00:25,547 - GAugM EPNet train, Epoch [ 26/285]: loss 0.7210, auc 0.4934, ap 0.5249
2024-01-10 22:00:25,634 - GAugM EPNet train, Epoch [ 27/285]: loss 0.7209, auc 0.4247, ap 0.5027
2024-01-10 22:00:25,724 - GAugM EPNet train, Epoch [ 28/285]: loss 0.7209, auc 0.5255, ap 0.5180
2024-01-10 22:00:25,811 - GAugM EPNet train, Epoch [ 29/285]: loss 0.7210, auc 0.5034, ap 0.5237
2024-01-10 22:00:25,897 - GAugM EPNet train, Epoch [ 30/285]: loss 0.7209, auc 0.4585, ap 0.4975
2024-01-10 22:00:25,981 - GAugM EPNet train, Epoch [ 31/285]: loss 0.7208, auc 0.4820, ap 0.5088
2024-01-10 22:00:26,060 - GAugM EPNet train, Epoch [ 32/285]: loss 0.7210, auc 0.5244, ap 0.5205
2024-01-10 22:00:26,137 - GAugM EPNet train, Epoch [ 33/285]: loss 0.7209, auc 0.5119, ap 0.5216
2024-01-10 22:00:26,223 - GAugM EPNet train, Epoch [ 34/285]: loss 0.7209, auc 0.4820, ap 0.5002
2024-01-10 22:00:26,299 - GAugM EPNet train, Epoch [ 35/285]: loss 0.7209, auc 0.5726, ap 0.5460
2024-01-10 22:00:26,377 - GAugM EPNet train, Epoch [ 36/285]: loss 0.7209, auc 0.5304, ap 0.5304
2024-01-10 22:00:26,461 - GAugM EPNet train, Epoch [ 37/285]: loss 0.7209, auc 0.4632, ap 0.4961
2024-01-10 22:00:26,540 - GAugM EPNet train, Epoch [ 38/285]: loss 0.7209, auc 0.4525, ap 0.4600
2024-01-10 22:00:26,617 - GAugM EPNet train, Epoch [ 39/285]: loss 0.7208, auc 0.4293, ap 0.4879
2024-01-10 22:00:26,696 - GAugM EPNet train, Epoch [ 40/285]: loss 0.7210, auc 0.5424, ap 0.5184
2024-01-10 22:00:26,781 - GAugM EPNet train, Epoch [ 41/285]: loss 0.7210, auc 0.4548, ap 0.4786
2024-01-10 22:00:26,862 - GAugM EPNet train, Epoch [ 42/285]: loss 0.7209, auc 0.4923, ap 0.5312
2024-01-10 22:00:26,939 - GAugM EPNet train, Epoch [ 43/285]: loss 0.7208, auc 0.4395, ap 0.4789
2024-01-10 22:00:27,015 - GAugM EPNet train, Epoch [ 44/285]: loss 0.7208, auc 0.3911, ap 0.4351
2024-01-10 22:00:27,092 - GAugM EPNet train, Epoch [ 45/285]: loss 0.7209, auc 0.5374, ap 0.5538
2024-01-10 22:00:27,170 - GAugM EPNet train, Epoch [ 46/285]: loss 0.7209, auc 0.3601, ap 0.4422
2024-01-10 22:00:27,248 - GAugM EPNet train, Epoch [ 47/285]: loss 0.7210, auc 0.4938, ap 0.4858
2024-01-10 22:00:27,332 - GAugM EPNet train, Epoch [ 48/285]: loss 0.7210, auc 0.5771, ap 0.5971
2024-01-10 22:00:27,408 - GAugM EPNet train, Epoch [ 49/285]: loss 0.7209, auc 0.4601, ap 0.4854
2024-01-10 22:00:27,485 - GAugM EPNet train, Epoch [ 50/285]: loss 0.7210, auc 0.5144, ap 0.5266
2024-01-10 22:00:27,562 - GAugM EPNet train, Epoch [ 51/285]: loss 0.7210, auc 0.4336, ap 0.4750
2024-01-10 22:00:27,639 - GAugM EPNet train, Epoch [ 52/285]: loss 0.7209, auc 0.4382, ap 0.4990
2024-01-10 22:00:27,715 - GAugM EPNet train, Epoch [ 53/285]: loss 0.7209, auc 0.5470, ap 0.5444
2024-01-10 22:00:27,799 - GAugM EPNet train, Epoch [ 54/285]: loss 0.7211, auc 0.6111, ap 0.5698
2024-01-10 22:00:27,874 - GAugM EPNet train, Epoch [ 55/285]: loss 0.7209, auc 0.5717, ap 0.5712
2024-01-10 22:00:27,955 - GAugM EPNet train, Epoch [ 56/285]: loss 0.7208, auc 0.4630, ap 0.4870
2024-01-10 22:00:28,035 - GAugM EPNet train, Epoch [ 57/285]: loss 0.7209, auc 0.4329, ap 0.4599
2024-01-10 22:00:28,114 - GAugM EPNet train, Epoch [ 58/285]: loss 0.7210, auc 0.4733, ap 0.5441
2024-01-10 22:00:28,199 - GAugM EPNet train, Epoch [ 59/285]: loss 0.7211, auc 0.5838, ap 0.5914
2024-01-10 22:00:28,279 - GAugM EPNet train, Epoch [ 60/285]: loss 0.7210, auc 0.5564, ap 0.5363
2024-01-10 22:00:28,359 - GAugM EPNet train, Epoch [ 61/285]: loss 0.7209, auc 0.5749, ap 0.5746
2024-01-10 22:00:28,443 - GAugM EPNet train, Epoch [ 62/285]: loss 0.7210, auc 0.5016, ap 0.5272
2024-01-10 22:00:28,523 - GAugM EPNet train, Epoch [ 63/285]: loss 0.7208, auc 0.5176, ap 0.5090
2024-01-10 22:00:28,605 - GAugM EPNet train, Epoch [ 64/285]: loss 0.7208, auc 0.5166, ap 0.5384
2024-01-10 22:00:28,685 - GAugM EPNet train, Epoch [ 65/285]: loss 0.7208, auc 0.5920, ap 0.5748
2024-01-10 22:00:28,772 - GAugM EPNet train, Epoch [ 66/285]: loss 0.7209, auc 0.4621, ap 0.5060
2024-01-10 22:00:28,862 - GAugM EPNet train, Epoch [ 67/285]: loss 0.7209, auc 0.5075, ap 0.4960
2024-01-10 22:00:28,951 - GAugM EPNet train, Epoch [ 68/285]: loss 0.7210, auc 0.5826, ap 0.5733
2024-01-10 22:00:29,033 - GAugM EPNet train, Epoch [ 69/285]: loss 0.7210, auc 0.5279, ap 0.5312
2024-01-10 22:00:29,129 - GAugM EPNet train, Epoch [ 70/285]: loss 0.7210, auc 0.5214, ap 0.5091
2024-01-10 22:00:29,221 - GAugM EPNet train, Epoch [ 71/285]: loss 0.7210, auc 0.5482, ap 0.5496
2024-01-10 22:00:29,316 - GAugM EPNet train, Epoch [ 72/285]: loss 0.7210, auc 0.4381, ap 0.4685
2024-01-10 22:00:29,408 - GAugM EPNet train, Epoch [ 73/285]: loss 0.7209, auc 0.5132, ap 0.4854
2024-01-10 22:00:29,495 - GAugM EPNet train, Epoch [ 74/285]: loss 0.7209, auc 0.5520, ap 0.5460
2024-01-10 22:00:29,582 - GAugM EPNet train, Epoch [ 75/285]: loss 0.7210, auc 0.4708, ap 0.5121
2024-01-10 22:00:29,672 - GAugM EPNet train, Epoch [ 76/285]: loss 0.7209, auc 0.4308, ap 0.4595
2024-01-10 22:00:29,759 - GAugM EPNet train, Epoch [ 77/285]: loss 0.7208, auc 0.5265, ap 0.5406
2024-01-10 22:00:29,835 - GAugM EPNet train, Epoch [ 78/285]: loss 0.7209, auc 0.5365, ap 0.5281
2024-01-10 22:00:29,911 - GAugM EPNet train, Epoch [ 79/285]: loss 0.7208, auc 0.5529, ap 0.5399
2024-01-10 22:00:29,989 - GAugM EPNet train, Epoch [ 80/285]: loss 0.7209, auc 0.5853, ap 0.5465
2024-01-10 22:00:30,067 - GAugM EPNet train, Epoch [ 81/285]: loss 0.7209, auc 0.5061, ap 0.5052
2024-01-10 22:00:30,149 - GAugM EPNet train, Epoch [ 82/285]: loss 0.7210, auc 0.5561, ap 0.5558
2024-01-10 22:00:30,226 - GAugM EPNet train, Epoch [ 83/285]: loss 0.7209, auc 0.4290, ap 0.4604
2024-01-10 22:00:30,303 - GAugM EPNet train, Epoch [ 84/285]: loss 0.7209, auc 0.4375, ap 0.4589
2024-01-10 22:00:30,378 - GAugM EPNet train, Epoch [ 85/285]: loss 0.7210, auc 0.4140, ap 0.4526
2024-01-10 22:00:30,456 - GAugM EPNet train, Epoch [ 86/285]: loss 0.7208, auc 0.4779, ap 0.4788
2024-01-10 22:00:30,534 - GAugM EPNet train, Epoch [ 87/285]: loss 0.7209, auc 0.5577, ap 0.5509
2024-01-10 22:00:30,613 - GAugM EPNet train, Epoch [ 88/285]: loss 0.7210, auc 0.4473, ap 0.4871
2024-01-10 22:00:30,689 - GAugM EPNet train, Epoch [ 89/285]: loss 0.7210, auc 0.4724, ap 0.4975
2024-01-10 22:00:30,765 - GAugM EPNet train, Epoch [ 90/285]: loss 0.7209, auc 0.4660, ap 0.5053
2024-01-10 22:00:30,840 - GAugM EPNet train, Epoch [ 91/285]: loss 0.7208, auc 0.5902, ap 0.5937
2024-01-10 22:00:30,921 - GAugM EPNet train, Epoch [ 92/285]: loss 0.7209, auc 0.5381, ap 0.5474
2024-01-10 22:00:30,999 - GAugM EPNet train, Epoch [ 93/285]: loss 0.7209, auc 0.4252, ap 0.5002
2024-01-10 22:00:31,073 - GAugM EPNet train, Epoch [ 94/285]: loss 0.7210, auc 0.3596, ap 0.4286
2024-01-10 22:00:31,159 - GAugM EPNet train, Epoch [ 95/285]: loss 0.7210, auc 0.5493, ap 0.5286
2024-01-10 22:00:31,237 - GAugM EPNet train, Epoch [ 96/285]: loss 0.7209, auc 0.5162, ap 0.5012
2024-01-10 22:00:31,323 - GAugM EPNet train, Epoch [ 97/285]: loss 0.7209, auc 0.5041, ap 0.4970
2024-01-10 22:00:31,412 - GAugM EPNet train, Epoch [ 98/285]: loss 0.7209, auc 0.5062, ap 0.4858
2024-01-10 22:00:31,489 - GAugM EPNet train, Epoch [ 99/285]: loss 0.7209, auc 0.4850, ap 0.5251
2024-01-10 22:00:31,566 - GAugM EPNet train, Epoch [100/285]: loss 0.7210, auc 0.5075, ap 0.5358
2024-01-10 22:00:31,645 - GAugM EPNet train, Epoch [101/285]: loss 0.7210, auc 0.4947, ap 0.5132
2024-01-10 22:00:31,736 - GAugM EPNet train, Epoch [102/285]: loss 0.7209, auc 0.4906, ap 0.5045
2024-01-10 22:00:31,810 - GAugM EPNet train, Epoch [103/285]: loss 0.7209, auc 0.3898, ap 0.4593
2024-01-10 22:00:31,885 - GAugM EPNet train, Epoch [104/285]: loss 0.7209, auc 0.4001, ap 0.4593
2024-01-10 22:00:31,960 - GAugM EPNet train, Epoch [105/285]: loss 0.7209, auc 0.4046, ap 0.4593
2024-01-10 22:00:32,037 - GAugM EPNet train, Epoch [106/285]: loss 0.7210, auc 0.4486, ap 0.4604
2024-01-10 22:00:32,113 - GAugM EPNet train, Epoch [107/285]: loss 0.7210, auc 0.4539, ap 0.4836
2024-01-10 22:00:32,188 - GAugM EPNet train, Epoch [108/285]: loss 0.7208, auc 0.4929, ap 0.5019
2024-01-10 22:00:32,262 - GAugM EPNet train, Epoch [109/285]: loss 0.7210, auc 0.4543, ap 0.4857
2024-01-10 22:00:32,339 - GAugM EPNet train, Epoch [110/285]: loss 0.7209, auc 0.5395, ap 0.5346
2024-01-10 22:00:32,418 - GAugM EPNet train, Epoch [111/285]: loss 0.7210, auc 0.5037, ap 0.5199
2024-01-10 22:00:32,494 - GAugM EPNet train, Epoch [112/285]: loss 0.7209, auc 0.4717, ap 0.5052
2024-01-10 22:00:32,573 - GAugM EPNet train, Epoch [113/285]: loss 0.7210, auc 0.4439, ap 0.4693
2024-01-10 22:00:32,647 - GAugM EPNet train, Epoch [114/285]: loss 0.7209, auc 0.4496, ap 0.4484
2024-01-10 22:00:32,721 - GAugM EPNet train, Epoch [115/285]: loss 0.7210, auc 0.4754, ap 0.4852
2024-01-10 22:00:32,799 - GAugM EPNet train, Epoch [116/285]: loss 0.7209, auc 0.5315, ap 0.5712
2024-01-10 22:00:32,874 - GAugM EPNet train, Epoch [117/285]: loss 0.7208, auc 0.5137, ap 0.5379
2024-01-10 22:00:32,952 - GAugM EPNet train, Epoch [118/285]: loss 0.7209, auc 0.4858, ap 0.5046
2024-01-10 22:00:33,027 - GAugM EPNet train, Epoch [119/285]: loss 0.7209, auc 0.5481, ap 0.5371
2024-01-10 22:00:33,102 - GAugM EPNet train, Epoch [120/285]: loss 0.7210, auc 0.5361, ap 0.5074
2024-01-10 22:00:33,175 - GAugM EPNet train, Epoch [121/285]: loss 0.7210, auc 0.5194, ap 0.5062
2024-01-10 22:00:33,255 - GAugM EPNet train, Epoch [122/285]: loss 0.7209, auc 0.5354, ap 0.5520
2024-01-10 22:00:33,333 - GAugM EPNet train, Epoch [123/285]: loss 0.7209, auc 0.5064, ap 0.5149
2024-01-10 22:00:33,409 - GAugM EPNet train, Epoch [124/285]: loss 0.7210, auc 0.4352, ap 0.4555
2024-01-10 22:00:33,485 - GAugM EPNet train, Epoch [125/285]: loss 0.7209, auc 0.4845, ap 0.5031
2024-01-10 22:00:33,562 - GAugM EPNet train, Epoch [126/285]: loss 0.7210, auc 0.4802, ap 0.4996
2024-01-10 22:00:33,643 - GAugM EPNet train, Epoch [127/285]: loss 0.7209, auc 0.5189, ap 0.5169
2024-01-10 22:00:33,719 - GAugM EPNet train, Epoch [128/285]: loss 0.7210, auc 0.4799, ap 0.5033
2024-01-10 22:00:33,794 - GAugM EPNet train, Epoch [129/285]: loss 0.7208, auc 0.4181, ap 0.4486
2024-01-10 22:00:33,890 - GAugM EPNet train, Epoch [130/285]: loss 0.7210, auc 0.5484, ap 0.5516
2024-01-10 22:00:33,971 - GAugM EPNet train, Epoch [131/285]: loss 0.7210, auc 0.5429, ap 0.5504
2024-01-10 22:00:34,054 - GAugM EPNet train, Epoch [132/285]: loss 0.7209, auc 0.4589, ap 0.4807
2024-01-10 22:00:34,128 - GAugM EPNet train, Epoch [133/285]: loss 0.7209, auc 0.4632, ap 0.4798
2024-01-10 22:00:34,203 - GAugM EPNet train, Epoch [134/285]: loss 0.7210, auc 0.4788, ap 0.4882
2024-01-10 22:00:34,277 - GAugM EPNet train, Epoch [135/285]: loss 0.7209, auc 0.3880, ap 0.4368
2024-01-10 22:00:34,354 - GAugM EPNet train, Epoch [136/285]: loss 0.7209, auc 0.4491, ap 0.4755
2024-01-10 22:00:34,430 - GAugM EPNet train, Epoch [137/285]: loss 0.7210, auc 0.4429, ap 0.4634
2024-01-10 22:00:34,506 - GAugM EPNet train, Epoch [138/285]: loss 0.7210, auc 0.5705, ap 0.5471
2024-01-10 22:00:34,585 - GAugM EPNet train, Epoch [139/285]: loss 0.7210, auc 0.4628, ap 0.4870
2024-01-10 22:00:34,660 - GAugM EPNet train, Epoch [140/285]: loss 0.7209, auc 0.4567, ap 0.5042
2024-01-10 22:00:34,734 - GAugM EPNet train, Epoch [141/285]: loss 0.7209, auc 0.5183, ap 0.4993
2024-01-10 22:00:34,809 - GAugM EPNet train, Epoch [142/285]: loss 0.7209, auc 0.5765, ap 0.5700
2024-01-10 22:00:34,884 - GAugM EPNet train, Epoch [143/285]: loss 0.7209, auc 0.4993, ap 0.4855
2024-01-10 22:00:34,958 - GAugM EPNet train, Epoch [144/285]: loss 0.7209, auc 0.4731, ap 0.4703
2024-01-10 22:00:35,033 - GAugM EPNet train, Epoch [145/285]: loss 0.7209, auc 0.4404, ap 0.4796
2024-01-10 22:00:35,107 - GAugM EPNet train, Epoch [146/285]: loss 0.7209, auc 0.6111, ap 0.6136
2024-01-10 22:00:35,184 - GAugM EPNet train, Epoch [147/285]: loss 0.7209, auc 0.5991, ap 0.6055
2024-01-10 22:00:35,261 - GAugM EPNet train, Epoch [148/285]: loss 0.7209, auc 0.4872, ap 0.4826
2024-01-10 22:00:35,340 - GAugM EPNet train, Epoch [149/285]: loss 0.7208, auc 0.4852, ap 0.4786
2024-01-10 22:00:35,416 - GAugM EPNet train, Epoch [150/285]: loss 0.7209, auc 0.5497, ap 0.5284
2024-01-10 22:00:35,499 - GAugM EPNet train, Epoch [151/285]: loss 0.7209, auc 0.5351, ap 0.5451
2024-01-10 22:00:35,576 - GAugM EPNet train, Epoch [152/285]: loss 0.7209, auc 0.5130, ap 0.5083
2024-01-10 22:00:35,655 - GAugM EPNet train, Epoch [153/285]: loss 0.7209, auc 0.4252, ap 0.4419
2024-01-10 22:00:35,731 - GAugM EPNet train, Epoch [154/285]: loss 0.7209, auc 0.5379, ap 0.5597
2024-01-10 22:00:35,808 - GAugM EPNet train, Epoch [155/285]: loss 0.7209, auc 0.5174, ap 0.5293
2024-01-10 22:00:35,884 - GAugM EPNet train, Epoch [156/285]: loss 0.7209, auc 0.4708, ap 0.4780
2024-01-10 22:00:35,967 - GAugM EPNet train, Epoch [157/285]: loss 0.7209, auc 0.4322, ap 0.4452
2024-01-10 22:00:36,042 - GAugM EPNet train, Epoch [158/285]: loss 0.7208, auc 0.5297, ap 0.5132
2024-01-10 22:00:36,121 - GAugM EPNet train, Epoch [159/285]: loss 0.7208, auc 0.5030, ap 0.4976
2024-01-10 22:00:36,198 - GAugM EPNet train, Epoch [160/285]: loss 0.7209, auc 0.5819, ap 0.5815
2024-01-10 22:00:36,275 - GAugM EPNet train, Epoch [161/285]: loss 0.7209, auc 0.5468, ap 0.5582
2024-01-10 22:00:36,360 - GAugM EPNet train, Epoch [162/285]: loss 0.7209, auc 0.4879, ap 0.4933
2024-01-10 22:00:36,437 - GAugM EPNet train, Epoch [163/285]: loss 0.7209, auc 0.5778, ap 0.5463
2024-01-10 22:00:36,512 - GAugM EPNet train, Epoch [164/285]: loss 0.7211, auc 0.4961, ap 0.4899
2024-01-10 22:00:36,590 - GAugM EPNet train, Epoch [165/285]: loss 0.7210, auc 0.4365, ap 0.4586
2024-01-10 22:00:36,679 - GAugM EPNet train, Epoch [166/285]: loss 0.7208, auc 0.5183, ap 0.5117
2024-01-10 22:00:36,756 - GAugM EPNet train, Epoch [167/285]: loss 0.7209, auc 0.4149, ap 0.4422
2024-01-10 22:00:36,831 - GAugM EPNet train, Epoch [168/285]: loss 0.7209, auc 0.4715, ap 0.5202
2024-01-10 22:00:36,908 - GAugM EPNet train, Epoch [169/285]: loss 0.7209, auc 0.5376, ap 0.5480
2024-01-10 22:00:36,984 - GAugM EPNet train, Epoch [170/285]: loss 0.7210, auc 0.4991, ap 0.4818
2024-01-10 22:00:37,066 - GAugM EPNet train, Epoch [171/285]: loss 0.7209, auc 0.4872, ap 0.4879
2024-01-10 22:00:37,144 - GAugM EPNet train, Epoch [172/285]: loss 0.7208, auc 0.5021, ap 0.4950
2024-01-10 22:00:37,220 - GAugM EPNet train, Epoch [173/285]: loss 0.7209, auc 0.5596, ap 0.5631
2024-01-10 22:00:37,310 - GAugM EPNet train, Epoch [174/285]: loss 0.7209, auc 0.4313, ap 0.4465
2024-01-10 22:00:37,386 - GAugM EPNet train, Epoch [175/285]: loss 0.7209, auc 0.5753, ap 0.5731
2024-01-10 22:00:37,463 - GAugM EPNet train, Epoch [176/285]: loss 0.7209, auc 0.4859, ap 0.4974
2024-01-10 22:00:37,547 - GAugM EPNet train, Epoch [177/285]: loss 0.7210, auc 0.5354, ap 0.5283
2024-01-10 22:00:37,635 - GAugM EPNet train, Epoch [178/285]: loss 0.7210, auc 0.5020, ap 0.5304
2024-01-10 22:00:37,711 - GAugM EPNet train, Epoch [179/285]: loss 0.7210, auc 0.3928, ap 0.4748
2024-01-10 22:00:37,788 - GAugM EPNet train, Epoch [180/285]: loss 0.7210, auc 0.5274, ap 0.5431
2024-01-10 22:00:37,865 - GAugM EPNet train, Epoch [181/285]: loss 0.7209, auc 0.4126, ap 0.4754
2024-01-10 22:00:37,942 - GAugM EPNet train, Epoch [182/285]: loss 0.7209, auc 0.4767, ap 0.4853
2024-01-10 22:00:38,015 - GAugM EPNet train, Epoch [183/285]: loss 0.7210, auc 0.5087, ap 0.5211
2024-01-10 22:00:38,089 - GAugM EPNet train, Epoch [184/285]: loss 0.7209, auc 0.5082, ap 0.5282
2024-01-10 22:00:38,165 - GAugM EPNet train, Epoch [185/285]: loss 0.7209, auc 0.5012, ap 0.4992
2024-01-10 22:00:38,239 - GAugM EPNet train, Epoch [186/285]: loss 0.7208, auc 0.4592, ap 0.4890
2024-01-10 22:00:38,316 - GAugM EPNet train, Epoch [187/285]: loss 0.7209, auc 0.5306, ap 0.5177
2024-01-10 22:00:38,399 - GAugM EPNet train, Epoch [188/285]: loss 0.7209, auc 0.3960, ap 0.4272
2024-01-10 22:00:38,473 - GAugM EPNet train, Epoch [189/285]: loss 0.7209, auc 0.5239, ap 0.5276
2024-01-10 22:00:38,549 - GAugM EPNet train, Epoch [190/285]: loss 0.7209, auc 0.4886, ap 0.4974
2024-01-10 22:00:38,624 - GAugM EPNet train, Epoch [191/285]: loss 0.7209, auc 0.4988, ap 0.5368
2024-01-10 22:00:38,700 - GAugM EPNet train, Epoch [192/285]: loss 0.7209, auc 0.4608, ap 0.4503
2024-01-10 22:00:38,776 - GAugM EPNet train, Epoch [193/285]: loss 0.7209, auc 0.5831, ap 0.5710
2024-01-10 22:00:38,852 - GAugM EPNet train, Epoch [194/285]: loss 0.7209, auc 0.4477, ap 0.4571
2024-01-10 22:00:38,928 - GAugM EPNet train, Epoch [195/285]: loss 0.7209, auc 0.5046, ap 0.5286
2024-01-10 22:00:39,013 - GAugM EPNet train, Epoch [196/285]: loss 0.7208, auc 0.4813, ap 0.4848
2024-01-10 22:00:39,089 - GAugM EPNet train, Epoch [197/285]: loss 0.7210, auc 0.4689, ap 0.4883
2024-01-10 22:00:39,165 - GAugM EPNet train, Epoch [198/285]: loss 0.7210, auc 0.5094, ap 0.5288
2024-01-10 22:00:39,251 - GAugM EPNet train, Epoch [199/285]: loss 0.7209, auc 0.4843, ap 0.4841
2024-01-10 22:00:39,329 - GAugM EPNet train, Epoch [200/285]: loss 0.7210, auc 0.4284, ap 0.4628
2024-01-10 22:00:39,408 - GAugM EPNet train, Epoch [201/285]: loss 0.7209, auc 0.5297, ap 0.5198
2024-01-10 22:00:39,495 - GAugM EPNet train, Epoch [202/285]: loss 0.7210, auc 0.4744, ap 0.5204
2024-01-10 22:00:39,577 - GAugM EPNet train, Epoch [203/285]: loss 0.7210, auc 0.5473, ap 0.5534
2024-01-10 22:00:39,657 - GAugM EPNet train, Epoch [204/285]: loss 0.7209, auc 0.4907, ap 0.4970
2024-01-10 22:00:39,733 - GAugM EPNet train, Epoch [205/285]: loss 0.7209, auc 0.4845, ap 0.5235
2024-01-10 22:00:39,815 - GAugM EPNet train, Epoch [206/285]: loss 0.7209, auc 0.4300, ap 0.4562
2024-01-10 22:00:39,892 - GAugM EPNet train, Epoch [207/285]: loss 0.7210, auc 0.4432, ap 0.4609
2024-01-10 22:00:39,968 - GAugM EPNet train, Epoch [208/285]: loss 0.7209, auc 0.4927, ap 0.5323
2024-01-10 22:00:40,044 - GAugM EPNet train, Epoch [209/285]: loss 0.7210, auc 0.6283, ap 0.6115
2024-01-10 22:00:40,131 - GAugM EPNet train, Epoch [210/285]: loss 0.7209, auc 0.4377, ap 0.4647
2024-01-10 22:00:40,209 - GAugM EPNet train, Epoch [211/285]: loss 0.7210, auc 0.5541, ap 0.5612
2024-01-10 22:00:40,291 - GAugM EPNet train, Epoch [212/285]: loss 0.7210, auc 0.4804, ap 0.4662
2024-01-10 22:00:40,367 - GAugM EPNet train, Epoch [213/285]: loss 0.7208, auc 0.6102, ap 0.5862
2024-01-10 22:00:40,452 - GAugM EPNet train, Epoch [214/285]: loss 0.7210, auc 0.5247, ap 0.5187
2024-01-10 22:00:40,536 - GAugM EPNet train, Epoch [215/285]: loss 0.7210, auc 0.4817, ap 0.4938
2024-01-10 22:00:40,618 - GAugM EPNet train, Epoch [216/285]: loss 0.7209, auc 0.5110, ap 0.5125
2024-01-10 22:00:40,701 - GAugM EPNet train, Epoch [217/285]: loss 0.7209, auc 0.4911, ap 0.5192
2024-01-10 22:00:40,778 - GAugM EPNet train, Epoch [218/285]: loss 0.7209, auc 0.5785, ap 0.5858
2024-01-10 22:00:40,854 - GAugM EPNet train, Epoch [219/285]: loss 0.7208, auc 0.5025, ap 0.5066
2024-01-10 22:00:40,934 - GAugM EPNet train, Epoch [220/285]: loss 0.7210, auc 0.4827, ap 0.5001
2024-01-10 22:00:41,012 - GAugM EPNet train, Epoch [221/285]: loss 0.7209, auc 0.5146, ap 0.4908
2024-01-10 22:00:41,089 - GAugM EPNet train, Epoch [222/285]: loss 0.7209, auc 0.4952, ap 0.4947
2024-01-10 22:00:41,172 - GAugM EPNet train, Epoch [223/285]: loss 0.7209, auc 0.6470, ap 0.6327
2024-01-10 22:00:41,252 - GAugM EPNet train, Epoch [224/285]: loss 0.7210, auc 0.4872, ap 0.4958
2024-01-10 22:00:41,329 - GAugM EPNet train, Epoch [225/285]: loss 0.7209, auc 0.4760, ap 0.4864
2024-01-10 22:00:41,409 - GAugM EPNet train, Epoch [226/285]: loss 0.7210, auc 0.5094, ap 0.5226
2024-01-10 22:00:41,490 - GAugM EPNet train, Epoch [227/285]: loss 0.7210, auc 0.5386, ap 0.5460
2024-01-10 22:00:41,573 - GAugM EPNet train, Epoch [228/285]: loss 0.7209, auc 0.3941, ap 0.4480
2024-01-10 22:00:41,652 - GAugM EPNet train, Epoch [229/285]: loss 0.7209, auc 0.5404, ap 0.5201
2024-01-10 22:00:41,729 - GAugM EPNet train, Epoch [230/285]: loss 0.7209, auc 0.4827, ap 0.5167
2024-01-10 22:00:41,811 - GAugM EPNet train, Epoch [231/285]: loss 0.7209, auc 0.4760, ap 0.4881
2024-01-10 22:00:41,896 - GAugM EPNet train, Epoch [232/285]: loss 0.7209, auc 0.5121, ap 0.5255
2024-01-10 22:00:41,985 - GAugM EPNet train, Epoch [233/285]: loss 0.7210, auc 0.4986, ap 0.5312
2024-01-10 22:00:42,061 - GAugM EPNet train, Epoch [234/285]: loss 0.7209, auc 0.4432, ap 0.4963
2024-01-10 22:00:42,141 - GAugM EPNet train, Epoch [235/285]: loss 0.7209, auc 0.3909, ap 0.4342
2024-01-10 22:00:42,219 - GAugM EPNet train, Epoch [236/285]: loss 0.7209, auc 0.4404, ap 0.4823
2024-01-10 22:00:42,299 - GAugM EPNet train, Epoch [237/285]: loss 0.7210, auc 0.4373, ap 0.4621
2024-01-10 22:00:42,375 - GAugM EPNet train, Epoch [238/285]: loss 0.7210, auc 0.5069, ap 0.5263
2024-01-10 22:00:42,452 - GAugM EPNet train, Epoch [239/285]: loss 0.7209, auc 0.4494, ap 0.5058
2024-01-10 22:00:42,535 - GAugM EPNet train, Epoch [240/285]: loss 0.7209, auc 0.5345, ap 0.5125
2024-01-10 22:00:42,612 - GAugM EPNet train, Epoch [241/285]: loss 0.7209, auc 0.4916, ap 0.4828
2024-01-10 22:00:42,694 - GAugM EPNet train, Epoch [242/285]: loss 0.7210, auc 0.4130, ap 0.4644
2024-01-10 22:00:42,771 - GAugM EPNet train, Epoch [243/285]: loss 0.7210, auc 0.4778, ap 0.4927
2024-01-10 22:00:42,846 - GAugM EPNet train, Epoch [244/285]: loss 0.7209, auc 0.5288, ap 0.5468
2024-01-10 22:00:42,921 - GAugM EPNet train, Epoch [245/285]: loss 0.7210, auc 0.4140, ap 0.4695
2024-01-10 22:00:42,997 - GAugM EPNet train, Epoch [246/285]: loss 0.7208, auc 0.4818, ap 0.4844
2024-01-10 22:00:43,074 - GAugM EPNet train, Epoch [247/285]: loss 0.7209, auc 0.4802, ap 0.4996
2024-01-10 22:00:43,153 - GAugM EPNet train, Epoch [248/285]: loss 0.7211, auc 0.4742, ap 0.4898
2024-01-10 22:00:43,238 - GAugM EPNet train, Epoch [249/285]: loss 0.7209, auc 0.4966, ap 0.4920
2024-01-10 22:00:43,316 - GAugM EPNet train, Epoch [250/285]: loss 0.7208, auc 0.5039, ap 0.4872
2024-01-10 22:00:43,395 - GAugM EPNet train, Epoch [251/285]: loss 0.7209, auc 0.4523, ap 0.4792
2024-01-10 22:00:43,474 - GAugM EPNet train, Epoch [252/285]: loss 0.7210, auc 0.5121, ap 0.5425
2024-01-10 22:00:43,555 - GAugM EPNet train, Epoch [253/285]: loss 0.7209, auc 0.5005, ap 0.4843
2024-01-10 22:00:43,632 - GAugM EPNet train, Epoch [254/285]: loss 0.7210, auc 0.4870, ap 0.5024
2024-01-10 22:00:43,710 - GAugM EPNet train, Epoch [255/285]: loss 0.7209, auc 0.5235, ap 0.5356
2024-01-10 22:00:43,787 - GAugM EPNet train, Epoch [256/285]: loss 0.7210, auc 0.3882, ap 0.4346
2024-01-10 22:00:43,862 - GAugM EPNet train, Epoch [257/285]: loss 0.7210, auc 0.4963, ap 0.5255
2024-01-10 22:00:43,952 - GAugM EPNet train, Epoch [258/285]: loss 0.7208, auc 0.4468, ap 0.4783
2024-01-10 22:00:44,030 - GAugM EPNet train, Epoch [259/285]: loss 0.7208, auc 0.6226, ap 0.6010
2024-01-10 22:00:44,114 - GAugM EPNet train, Epoch [260/285]: loss 0.7210, auc 0.4705, ap 0.4701
2024-01-10 22:00:44,191 - GAugM EPNet train, Epoch [261/285]: loss 0.7209, auc 0.4329, ap 0.4727
2024-01-10 22:00:44,269 - GAugM EPNet train, Epoch [262/285]: loss 0.7208, auc 0.5228, ap 0.5280
2024-01-10 22:00:44,357 - GAugM EPNet train, Epoch [263/285]: loss 0.7209, auc 0.5377, ap 0.5396
2024-01-10 22:00:44,433 - GAugM EPNet train, Epoch [264/285]: loss 0.7210, auc 0.5304, ap 0.5182
2024-01-10 22:00:44,511 - GAugM EPNet train, Epoch [265/285]: loss 0.7209, auc 0.5555, ap 0.5795
2024-01-10 22:00:44,588 - GAugM EPNet train, Epoch [266/285]: loss 0.7209, auc 0.4263, ap 0.4657
2024-01-10 22:00:44,669 - GAugM EPNet train, Epoch [267/285]: loss 0.7210, auc 0.4939, ap 0.5004
2024-01-10 22:00:44,744 - GAugM EPNet train, Epoch [268/285]: loss 0.7210, auc 0.4176, ap 0.4809
2024-01-10 22:00:44,820 - GAugM EPNet train, Epoch [269/285]: loss 0.7209, auc 0.5183, ap 0.5309
2024-01-10 22:00:44,896 - GAugM EPNet train, Epoch [270/285]: loss 0.7210, auc 0.4628, ap 0.4812
2024-01-10 22:00:44,972 - GAugM EPNet train, Epoch [271/285]: loss 0.7209, auc 0.5365, ap 0.5585
2024-01-10 22:00:45,047 - GAugM EPNet train, Epoch [272/285]: loss 0.7209, auc 0.5338, ap 0.5273
2024-01-10 22:00:45,122 - GAugM EPNet train, Epoch [273/285]: loss 0.7209, auc 0.4365, ap 0.4553
2024-01-10 22:00:45,197 - GAugM EPNet train, Epoch [274/285]: loss 0.7209, auc 0.5078, ap 0.5162
2024-01-10 22:00:45,279 - GAugM EPNet train, Epoch [275/285]: loss 0.7208, auc 0.4425, ap 0.4696
2024-01-10 22:00:45,357 - GAugM EPNet train, Epoch [276/285]: loss 0.7210, auc 0.5287, ap 0.5492
2024-01-10 22:00:45,433 - GAugM EPNet train, Epoch [277/285]: loss 0.7208, auc 0.4861, ap 0.5297
2024-01-10 22:00:45,511 - GAugM EPNet train, Epoch [278/285]: loss 0.7209, auc 0.6023, ap 0.6113
2024-01-10 22:00:45,593 - GAugM EPNet train, Epoch [279/285]: loss 0.7209, auc 0.5098, ap 0.5345
2024-01-10 22:00:45,675 - GAugM EPNet train, Epoch [280/285]: loss 0.7209, auc 0.3904, ap 0.4370
2024-01-10 22:00:45,752 - GAugM EPNet train, Epoch [281/285]: loss 0.7209, auc 0.5728, ap 0.5575
2024-01-10 22:00:45,836 - GAugM EPNet train, Epoch [282/285]: loss 0.7209, auc 0.4553, ap 0.4884
2024-01-10 22:00:45,914 - GAugM EPNet train, Epoch [283/285]: loss 0.7209, auc 0.5055, ap 0.5224
2024-01-10 22:00:45,988 - GAugM EPNet train, Epoch [284/285]: loss 0.7209, auc 0.4824, ap 0.4940
2024-01-10 22:00:46,070 - GAugM EPNet train, Epoch [285/285]: loss 0.7209, auc 0.5324, ap 0.5255
2024-01-10 22:00:46,078 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03568410>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:00:46,812 - GAugM EPNet train, Epoch [  1/285]: loss 0.7210, auc 0.4119, ap 0.4392
2024-01-10 22:00:46,900 - GAugM EPNet train, Epoch [  2/285]: loss 0.7210, auc 0.5457, ap 0.5137
2024-01-10 22:00:46,997 - GAugM EPNet train, Epoch [  3/285]: loss 0.7209, auc 0.5700, ap 0.5587
2024-01-10 22:00:47,078 - GAugM EPNet train, Epoch [  4/285]: loss 0.7209, auc 0.4550, ap 0.4752
2024-01-10 22:00:47,154 - GAugM EPNet train, Epoch [  5/285]: loss 0.7209, auc 0.5522, ap 0.5804
2024-01-10 22:00:47,232 - GAugM EPNet train, Epoch [  6/285]: loss 0.7209, auc 0.4503, ap 0.4815
2024-01-10 22:00:47,310 - GAugM EPNet train, Epoch [  7/285]: loss 0.7209, auc 0.4414, ap 0.4591
2024-01-10 22:00:47,388 - GAugM EPNet train, Epoch [  8/285]: loss 0.7210, auc 0.4671, ap 0.5021
2024-01-10 22:00:47,475 - GAugM EPNet train, Epoch [  9/285]: loss 0.7209, auc 0.4557, ap 0.4750
2024-01-10 22:00:47,553 - GAugM EPNet train, Epoch [ 10/285]: loss 0.7208, auc 0.5532, ap 0.5266
2024-01-10 22:00:47,632 - GAugM EPNet train, Epoch [ 11/285]: loss 0.7209, auc 0.4322, ap 0.4723
2024-01-10 22:00:47,709 - GAugM EPNet train, Epoch [ 12/285]: loss 0.7210, auc 0.4436, ap 0.4560
2024-01-10 22:00:47,787 - GAugM EPNet train, Epoch [ 13/285]: loss 0.7209, auc 0.6226, ap 0.6341
2024-01-10 22:00:47,871 - GAugM EPNet train, Epoch [ 14/285]: loss 0.7209, auc 0.5194, ap 0.5132
2024-01-10 22:00:47,953 - GAugM EPNet train, Epoch [ 15/285]: loss 0.7210, auc 0.4706, ap 0.5277
2024-01-10 22:00:48,030 - GAugM EPNet train, Epoch [ 16/285]: loss 0.7209, auc 0.5048, ap 0.5135
2024-01-10 22:00:48,107 - GAugM EPNet train, Epoch [ 17/285]: loss 0.7210, auc 0.5493, ap 0.5462
2024-01-10 22:00:48,191 - GAugM EPNet train, Epoch [ 18/285]: loss 0.7210, auc 0.5954, ap 0.5886
2024-01-10 22:00:48,274 - GAugM EPNet train, Epoch [ 19/285]: loss 0.7209, auc 0.4811, ap 0.4794
2024-01-10 22:00:48,352 - GAugM EPNet train, Epoch [ 20/285]: loss 0.7210, auc 0.4635, ap 0.5127
2024-01-10 22:00:48,429 - GAugM EPNet train, Epoch [ 21/285]: loss 0.7209, auc 0.4731, ap 0.4911
2024-01-10 22:00:48,507 - GAugM EPNet train, Epoch [ 22/285]: loss 0.7210, auc 0.4122, ap 0.4600
2024-01-10 22:00:48,585 - GAugM EPNet train, Epoch [ 23/285]: loss 0.7208, auc 0.5162, ap 0.5178
2024-01-10 22:00:48,679 - GAugM EPNet train, Epoch [ 24/285]: loss 0.7209, auc 0.4279, ap 0.4606
2024-01-10 22:00:48,756 - GAugM EPNet train, Epoch [ 25/285]: loss 0.7209, auc 0.4575, ap 0.4706
2024-01-10 22:00:48,834 - GAugM EPNet train, Epoch [ 26/285]: loss 0.7210, auc 0.5176, ap 0.5215
2024-01-10 22:00:48,916 - GAugM EPNet train, Epoch [ 27/285]: loss 0.7209, auc 0.4628, ap 0.5106
2024-01-10 22:00:48,998 - GAugM EPNet train, Epoch [ 28/285]: loss 0.7209, auc 0.5148, ap 0.5140
2024-01-10 22:00:49,075 - GAugM EPNet train, Epoch [ 29/285]: loss 0.7210, auc 0.5169, ap 0.5343
2024-01-10 22:00:49,153 - GAugM EPNet train, Epoch [ 30/285]: loss 0.7209, auc 0.5653, ap 0.5849
2024-01-10 22:00:49,231 - GAugM EPNet train, Epoch [ 31/285]: loss 0.7208, auc 0.4414, ap 0.4778
2024-01-10 22:00:49,306 - GAugM EPNet train, Epoch [ 32/285]: loss 0.7210, auc 0.6412, ap 0.6221
2024-01-10 22:00:49,387 - GAugM EPNet train, Epoch [ 33/285]: loss 0.7209, auc 0.4756, ap 0.5145
2024-01-10 22:00:49,464 - GAugM EPNet train, Epoch [ 34/285]: loss 0.7209, auc 0.4753, ap 0.4898
2024-01-10 22:00:49,541 - GAugM EPNet train, Epoch [ 35/285]: loss 0.7209, auc 0.5365, ap 0.5341
2024-01-10 22:00:49,617 - GAugM EPNet train, Epoch [ 36/285]: loss 0.7209, auc 0.5418, ap 0.5342
2024-01-10 22:00:49,694 - GAugM EPNet train, Epoch [ 37/285]: loss 0.7209, auc 0.5383, ap 0.5459
2024-01-10 22:00:49,770 - GAugM EPNet train, Epoch [ 38/285]: loss 0.7209, auc 0.4692, ap 0.4767
2024-01-10 22:00:49,846 - GAugM EPNet train, Epoch [ 39/285]: loss 0.7208, auc 0.4468, ap 0.5051
2024-01-10 22:00:49,930 - GAugM EPNet train, Epoch [ 40/285]: loss 0.7210, auc 0.5422, ap 0.5184
2024-01-10 22:00:50,006 - GAugM EPNet train, Epoch [ 41/285]: loss 0.7210, auc 0.5532, ap 0.5563
2024-01-10 22:00:50,088 - GAugM EPNet train, Epoch [ 42/285]: loss 0.7209, auc 0.5885, ap 0.5867
2024-01-10 22:00:50,166 - GAugM EPNet train, Epoch [ 43/285]: loss 0.7208, auc 0.4600, ap 0.5073
2024-01-10 22:00:50,240 - GAugM EPNet train, Epoch [ 44/285]: loss 0.7208, auc 0.3809, ap 0.4358
2024-01-10 22:00:50,316 - GAugM EPNet train, Epoch [ 45/285]: loss 0.7209, auc 0.4749, ap 0.5054
2024-01-10 22:00:50,400 - GAugM EPNet train, Epoch [ 46/285]: loss 0.7209, auc 0.4582, ap 0.4932
2024-01-10 22:00:50,476 - GAugM EPNet train, Epoch [ 47/285]: loss 0.7210, auc 0.4354, ap 0.4572
2024-01-10 22:00:50,552 - GAugM EPNet train, Epoch [ 48/285]: loss 0.7210, auc 0.5493, ap 0.5637
2024-01-10 22:00:50,634 - GAugM EPNet train, Epoch [ 49/285]: loss 0.7209, auc 0.5344, ap 0.5349
2024-01-10 22:00:50,712 - GAugM EPNet train, Epoch [ 50/285]: loss 0.7210, auc 0.5835, ap 0.5733
2024-01-10 22:00:50,788 - GAugM EPNet train, Epoch [ 51/285]: loss 0.7210, auc 0.4774, ap 0.5155
2024-01-10 22:00:50,864 - GAugM EPNet train, Epoch [ 52/285]: loss 0.7209, auc 0.4952, ap 0.5552
2024-01-10 22:00:50,946 - GAugM EPNet train, Epoch [ 53/285]: loss 0.7209, auc 0.5301, ap 0.5352
2024-01-10 22:00:51,023 - GAugM EPNet train, Epoch [ 54/285]: loss 0.7211, auc 0.5721, ap 0.5503
2024-01-10 22:00:51,101 - GAugM EPNet train, Epoch [ 55/285]: loss 0.7209, auc 0.6280, ap 0.6167
2024-01-10 22:00:51,177 - GAugM EPNet train, Epoch [ 56/285]: loss 0.7208, auc 0.5548, ap 0.5413
2024-01-10 22:00:51,264 - GAugM EPNet train, Epoch [ 57/285]: loss 0.7209, auc 0.4881, ap 0.4820
2024-01-10 22:00:51,342 - GAugM EPNet train, Epoch [ 58/285]: loss 0.7210, auc 0.5158, ap 0.5652
2024-01-10 22:00:51,419 - GAugM EPNet train, Epoch [ 59/285]: loss 0.7211, auc 0.4948, ap 0.4857
2024-01-10 22:00:51,501 - GAugM EPNet train, Epoch [ 60/285]: loss 0.7210, auc 0.5005, ap 0.5081
2024-01-10 22:00:51,578 - GAugM EPNet train, Epoch [ 61/285]: loss 0.7209, auc 0.5529, ap 0.5390
2024-01-10 22:00:51,654 - GAugM EPNet train, Epoch [ 62/285]: loss 0.7210, auc 0.5454, ap 0.5556
2024-01-10 22:00:51,732 - GAugM EPNet train, Epoch [ 63/285]: loss 0.7208, auc 0.4436, ap 0.4715
2024-01-10 22:00:51,819 - GAugM EPNet train, Epoch [ 64/285]: loss 0.7208, auc 0.4721, ap 0.4941
2024-01-10 22:00:51,900 - GAugM EPNet train, Epoch [ 65/285]: loss 0.7208, auc 0.5821, ap 0.5580
2024-01-10 22:00:51,975 - GAugM EPNet train, Epoch [ 66/285]: loss 0.7209, auc 0.5653, ap 0.5977
2024-01-10 22:00:52,051 - GAugM EPNet train, Epoch [ 67/285]: loss 0.7209, auc 0.5027, ap 0.5047
2024-01-10 22:00:52,128 - GAugM EPNet train, Epoch [ 68/285]: loss 0.7210, auc 0.5692, ap 0.5934
2024-01-10 22:00:52,205 - GAugM EPNet train, Epoch [ 69/285]: loss 0.7210, auc 0.5301, ap 0.5655
2024-01-10 22:00:52,281 - GAugM EPNet train, Epoch [ 70/285]: loss 0.7210, auc 0.4998, ap 0.4849
2024-01-10 22:00:52,359 - GAugM EPNet train, Epoch [ 71/285]: loss 0.7210, auc 0.5290, ap 0.5172
2024-01-10 22:00:52,434 - GAugM EPNet train, Epoch [ 72/285]: loss 0.7210, auc 0.4810, ap 0.5102
2024-01-10 22:00:52,512 - GAugM EPNet train, Epoch [ 73/285]: loss 0.7209, auc 0.5119, ap 0.5157
2024-01-10 22:00:52,595 - GAugM EPNet train, Epoch [ 74/285]: loss 0.7209, auc 0.5018, ap 0.5327
2024-01-10 22:00:52,673 - GAugM EPNet train, Epoch [ 75/285]: loss 0.7210, auc 0.4051, ap 0.4525
2024-01-10 22:00:52,750 - GAugM EPNet train, Epoch [ 76/285]: loss 0.7209, auc 0.4781, ap 0.5035
2024-01-10 22:00:52,828 - GAugM EPNet train, Epoch [ 77/285]: loss 0.7208, auc 0.6006, ap 0.5958
2024-01-10 22:00:52,903 - GAugM EPNet train, Epoch [ 78/285]: loss 0.7209, auc 0.4827, ap 0.4908
2024-01-10 22:00:52,979 - GAugM EPNet train, Epoch [ 79/285]: loss 0.7208, auc 0.4813, ap 0.4867
2024-01-10 22:00:53,056 - GAugM EPNet train, Epoch [ 80/285]: loss 0.7209, auc 0.6159, ap 0.5833
2024-01-10 22:00:53,134 - GAugM EPNet train, Epoch [ 81/285]: loss 0.7209, auc 0.4325, ap 0.4584
2024-01-10 22:00:53,211 - GAugM EPNet train, Epoch [ 82/285]: loss 0.7210, auc 0.5436, ap 0.5435
2024-01-10 22:00:53,292 - GAugM EPNet train, Epoch [ 83/285]: loss 0.7209, auc 0.4849, ap 0.4984
2024-01-10 22:00:53,370 - GAugM EPNet train, Epoch [ 84/285]: loss 0.7209, auc 0.4842, ap 0.5084
2024-01-10 22:00:53,446 - GAugM EPNet train, Epoch [ 85/285]: loss 0.7210, auc 0.4521, ap 0.4938
2024-01-10 22:00:53,529 - GAugM EPNet train, Epoch [ 86/285]: loss 0.7208, auc 0.5192, ap 0.5119
2024-01-10 22:00:53,604 - GAugM EPNet train, Epoch [ 87/285]: loss 0.7209, auc 0.5529, ap 0.5485
2024-01-10 22:00:53,684 - GAugM EPNet train, Epoch [ 88/285]: loss 0.7210, auc 0.4664, ap 0.4900
2024-01-10 22:00:53,768 - GAugM EPNet train, Epoch [ 89/285]: loss 0.7210, auc 0.4169, ap 0.4801
2024-01-10 22:00:53,846 - GAugM EPNet train, Epoch [ 90/285]: loss 0.7209, auc 0.4261, ap 0.4797
2024-01-10 22:00:53,922 - GAugM EPNet train, Epoch [ 91/285]: loss 0.7208, auc 0.5347, ap 0.5039
2024-01-10 22:00:54,014 - GAugM EPNet train, Epoch [ 92/285]: loss 0.7209, auc 0.5518, ap 0.5783
2024-01-10 22:00:54,090 - GAugM EPNet train, Epoch [ 93/285]: loss 0.7209, auc 0.4183, ap 0.4569
2024-01-10 22:00:54,172 - GAugM EPNet train, Epoch [ 94/285]: loss 0.7210, auc 0.4190, ap 0.4632
2024-01-10 22:00:54,255 - GAugM EPNet train, Epoch [ 95/285]: loss 0.7210, auc 0.5009, ap 0.5026
2024-01-10 22:00:54,333 - GAugM EPNet train, Epoch [ 96/285]: loss 0.7209, auc 0.5675, ap 0.5628
2024-01-10 22:00:54,412 - GAugM EPNet train, Epoch [ 97/285]: loss 0.7209, auc 0.4375, ap 0.5003
2024-01-10 22:00:54,486 - GAugM EPNet train, Epoch [ 98/285]: loss 0.7209, auc 0.4856, ap 0.5073
2024-01-10 22:00:54,564 - GAugM EPNet train, Epoch [ 99/285]: loss 0.7209, auc 0.4977, ap 0.5298
2024-01-10 22:00:54,645 - GAugM EPNet train, Epoch [100/285]: loss 0.7210, auc 0.4158, ap 0.4564
2024-01-10 22:00:54,724 - GAugM EPNet train, Epoch [101/285]: loss 0.7210, auc 0.5027, ap 0.5408
2024-01-10 22:00:54,805 - GAugM EPNet train, Epoch [102/285]: loss 0.7209, auc 0.5511, ap 0.5574
2024-01-10 22:00:54,882 - GAugM EPNet train, Epoch [103/285]: loss 0.7209, auc 0.4347, ap 0.4841
2024-01-10 22:00:54,963 - GAugM EPNet train, Epoch [104/285]: loss 0.7209, auc 0.5386, ap 0.5566
2024-01-10 22:00:55,042 - GAugM EPNet train, Epoch [105/285]: loss 0.7209, auc 0.4503, ap 0.4711
2024-01-10 22:00:55,120 - GAugM EPNet train, Epoch [106/285]: loss 0.7210, auc 0.5596, ap 0.5388
2024-01-10 22:00:55,210 - GAugM EPNet train, Epoch [107/285]: loss 0.7210, auc 0.5080, ap 0.5363
2024-01-10 22:00:55,287 - GAugM EPNet train, Epoch [108/285]: loss 0.7208, auc 0.5094, ap 0.5175
2024-01-10 22:00:55,364 - GAugM EPNet train, Epoch [109/285]: loss 0.7210, auc 0.4009, ap 0.4326
2024-01-10 22:00:55,440 - GAugM EPNet train, Epoch [110/285]: loss 0.7209, auc 0.4201, ap 0.4496
2024-01-10 22:00:55,522 - GAugM EPNet train, Epoch [111/285]: loss 0.7210, auc 0.4649, ap 0.5051
2024-01-10 22:00:55,598 - GAugM EPNet train, Epoch [112/285]: loss 0.7209, auc 0.4956, ap 0.5080
2024-01-10 22:00:55,675 - GAugM EPNet train, Epoch [113/285]: loss 0.7210, auc 0.5660, ap 0.5787
2024-01-10 22:00:55,750 - GAugM EPNet train, Epoch [114/285]: loss 0.7209, auc 0.5034, ap 0.5050
2024-01-10 22:00:55,832 - GAugM EPNet train, Epoch [115/285]: loss 0.7210, auc 0.4984, ap 0.5048
2024-01-10 22:00:55,910 - GAugM EPNet train, Epoch [116/285]: loss 0.7209, auc 0.5582, ap 0.5626
2024-01-10 22:00:55,986 - GAugM EPNet train, Epoch [117/285]: loss 0.7208, auc 0.4315, ap 0.4618
2024-01-10 22:00:56,074 - GAugM EPNet train, Epoch [118/285]: loss 0.7209, auc 0.4913, ap 0.5020
2024-01-10 22:00:56,151 - GAugM EPNet train, Epoch [119/285]: loss 0.7209, auc 0.5222, ap 0.5384
2024-01-10 22:00:56,237 - GAugM EPNet train, Epoch [120/285]: loss 0.7210, auc 0.4621, ap 0.5107
2024-01-10 22:00:56,317 - GAugM EPNet train, Epoch [121/285]: loss 0.7210, auc 0.4973, ap 0.5129
2024-01-10 22:00:56,395 - GAugM EPNet train, Epoch [122/285]: loss 0.7209, auc 0.5500, ap 0.5421
2024-01-10 22:00:56,472 - GAugM EPNet train, Epoch [123/285]: loss 0.7209, auc 0.4290, ap 0.4631
2024-01-10 22:00:56,556 - GAugM EPNet train, Epoch [124/285]: loss 0.7210, auc 0.4614, ap 0.4972
2024-01-10 22:00:56,638 - GAugM EPNet train, Epoch [125/285]: loss 0.7209, auc 0.4546, ap 0.4935
2024-01-10 22:00:56,714 - GAugM EPNet train, Epoch [126/285]: loss 0.7210, auc 0.4745, ap 0.4893
2024-01-10 22:00:56,792 - GAugM EPNet train, Epoch [127/285]: loss 0.7209, auc 0.4439, ap 0.4619
2024-01-10 22:00:56,874 - GAugM EPNet train, Epoch [128/285]: loss 0.7210, auc 0.5137, ap 0.5250
2024-01-10 22:00:56,950 - GAugM EPNet train, Epoch [129/285]: loss 0.7208, auc 0.4706, ap 0.4849
2024-01-10 22:00:57,028 - GAugM EPNet train, Epoch [130/285]: loss 0.7210, auc 0.5044, ap 0.5094
2024-01-10 22:00:57,110 - GAugM EPNet train, Epoch [131/285]: loss 0.7210, auc 0.4966, ap 0.5177
2024-01-10 22:00:57,188 - GAugM EPNet train, Epoch [132/285]: loss 0.7209, auc 0.4770, ap 0.5086
2024-01-10 22:00:57,275 - GAugM EPNet train, Epoch [133/285]: loss 0.7209, auc 0.5255, ap 0.5671
2024-01-10 22:00:57,363 - GAugM EPNet train, Epoch [134/285]: loss 0.7210, auc 0.4208, ap 0.4969
2024-01-10 22:00:57,450 - GAugM EPNet train, Epoch [135/285]: loss 0.7209, auc 0.3514, ap 0.4439
2024-01-10 22:00:57,528 - GAugM EPNet train, Epoch [136/285]: loss 0.7209, auc 0.5176, ap 0.5158
2024-01-10 22:00:57,604 - GAugM EPNet train, Epoch [137/285]: loss 0.7210, auc 0.4603, ap 0.4784
2024-01-10 22:00:57,683 - GAugM EPNet train, Epoch [138/285]: loss 0.7210, auc 0.5550, ap 0.5540
2024-01-10 22:00:57,766 - GAugM EPNet train, Epoch [139/285]: loss 0.7210, auc 0.4489, ap 0.4771
2024-01-10 22:00:57,842 - GAugM EPNet train, Epoch [140/285]: loss 0.7209, auc 0.5112, ap 0.5289
2024-01-10 22:00:57,918 - GAugM EPNet train, Epoch [141/285]: loss 0.7209, auc 0.4842, ap 0.4812
2024-01-10 22:00:57,996 - GAugM EPNet train, Epoch [142/285]: loss 0.7209, auc 0.5126, ap 0.5477
2024-01-10 22:00:58,071 - GAugM EPNet train, Epoch [143/285]: loss 0.7209, auc 0.4365, ap 0.4690
2024-01-10 22:00:58,149 - GAugM EPNet train, Epoch [144/285]: loss 0.7209, auc 0.4778, ap 0.4784
2024-01-10 22:00:58,226 - GAugM EPNet train, Epoch [145/285]: loss 0.7209, auc 0.4664, ap 0.5015
2024-01-10 22:00:58,300 - GAugM EPNet train, Epoch [146/285]: loss 0.7209, auc 0.5052, ap 0.5314
2024-01-10 22:00:58,376 - GAugM EPNet train, Epoch [147/285]: loss 0.7209, auc 0.6234, ap 0.6363
2024-01-10 22:00:58,457 - GAugM EPNet train, Epoch [148/285]: loss 0.7209, auc 0.4183, ap 0.4688
2024-01-10 22:00:58,535 - GAugM EPNet train, Epoch [149/285]: loss 0.7208, auc 0.4567, ap 0.4838
2024-01-10 22:00:58,613 - GAugM EPNet train, Epoch [150/285]: loss 0.7209, auc 0.4792, ap 0.4876
2024-01-10 22:00:58,689 - GAugM EPNet train, Epoch [151/285]: loss 0.7209, auc 0.5044, ap 0.5149
2024-01-10 22:00:58,766 - GAugM EPNet train, Epoch [152/285]: loss 0.7209, auc 0.5942, ap 0.5754
2024-01-10 22:00:58,855 - GAugM EPNet train, Epoch [153/285]: loss 0.7209, auc 0.4959, ap 0.5427
2024-01-10 22:00:58,934 - GAugM EPNet train, Epoch [154/285]: loss 0.7209, auc 0.5902, ap 0.6184
2024-01-10 22:00:59,014 - GAugM EPNet train, Epoch [155/285]: loss 0.7209, auc 0.5027, ap 0.4970
2024-01-10 22:00:59,100 - GAugM EPNet train, Epoch [156/285]: loss 0.7209, auc 0.4414, ap 0.4885
2024-01-10 22:00:59,177 - GAugM EPNet train, Epoch [157/285]: loss 0.7209, auc 0.4567, ap 0.4608
2024-01-10 22:00:59,255 - GAugM EPNet train, Epoch [158/285]: loss 0.7208, auc 0.4315, ap 0.4758
2024-01-10 22:00:59,340 - GAugM EPNet train, Epoch [159/285]: loss 0.7208, auc 0.4849, ap 0.5162
2024-01-10 22:00:59,417 - GAugM EPNet train, Epoch [160/285]: loss 0.7209, auc 0.5735, ap 0.5673
2024-01-10 22:00:59,494 - GAugM EPNet train, Epoch [161/285]: loss 0.7209, auc 0.5255, ap 0.5544
2024-01-10 22:00:59,570 - GAugM EPNet train, Epoch [162/285]: loss 0.7209, auc 0.4778, ap 0.4913
2024-01-10 22:00:59,654 - GAugM EPNet train, Epoch [163/285]: loss 0.7209, auc 0.5112, ap 0.5231
2024-01-10 22:00:59,732 - GAugM EPNet train, Epoch [164/285]: loss 0.7211, auc 0.5518, ap 0.5314
2024-01-10 22:00:59,814 - GAugM EPNet train, Epoch [165/285]: loss 0.7210, auc 0.4699, ap 0.4881
2024-01-10 22:00:59,899 - GAugM EPNet train, Epoch [166/285]: loss 0.7208, auc 0.5628, ap 0.5540
2024-01-10 22:00:59,975 - GAugM EPNet train, Epoch [167/285]: loss 0.7209, auc 0.4033, ap 0.4457
2024-01-10 22:01:00,056 - GAugM EPNet train, Epoch [168/285]: loss 0.7209, auc 0.4706, ap 0.5169
2024-01-10 22:01:00,133 - GAugM EPNet train, Epoch [169/285]: loss 0.7209, auc 0.4792, ap 0.5092
2024-01-10 22:01:00,213 - GAugM EPNet train, Epoch [170/285]: loss 0.7210, auc 0.5230, ap 0.5197
2024-01-10 22:01:00,289 - GAugM EPNet train, Epoch [171/285]: loss 0.7209, auc 0.4105, ap 0.4551
2024-01-10 22:01:00,365 - GAugM EPNet train, Epoch [172/285]: loss 0.7208, auc 0.4325, ap 0.4487
2024-01-10 22:01:00,447 - GAugM EPNet train, Epoch [173/285]: loss 0.7209, auc 0.4567, ap 0.5160
2024-01-10 22:01:00,524 - GAugM EPNet train, Epoch [174/285]: loss 0.7209, auc 0.4575, ap 0.4649
2024-01-10 22:01:00,598 - GAugM EPNet train, Epoch [175/285]: loss 0.7209, auc 0.5611, ap 0.5599
2024-01-10 22:01:00,685 - GAugM EPNet train, Epoch [176/285]: loss 0.7209, auc 0.5269, ap 0.5176
2024-01-10 22:01:00,762 - GAugM EPNet train, Epoch [177/285]: loss 0.7210, auc 0.5162, ap 0.5249
2024-01-10 22:01:00,840 - GAugM EPNet train, Epoch [178/285]: loss 0.7210, auc 0.5397, ap 0.5530
2024-01-10 22:01:00,918 - GAugM EPNet train, Epoch [179/285]: loss 0.7210, auc 0.4236, ap 0.4630
2024-01-10 22:01:01,005 - GAugM EPNet train, Epoch [180/285]: loss 0.7210, auc 0.5714, ap 0.5927
2024-01-10 22:01:01,084 - GAugM EPNet train, Epoch [181/285]: loss 0.7209, auc 0.4354, ap 0.4596
2024-01-10 22:01:01,163 - GAugM EPNet train, Epoch [182/285]: loss 0.7209, auc 0.5853, ap 0.5892
2024-01-10 22:01:01,240 - GAugM EPNet train, Epoch [183/285]: loss 0.7210, auc 0.5166, ap 0.5175
2024-01-10 22:01:01,328 - GAugM EPNet train, Epoch [184/285]: loss 0.7209, auc 0.5062, ap 0.5172
2024-01-10 22:01:01,405 - GAugM EPNet train, Epoch [185/285]: loss 0.7209, auc 0.5493, ap 0.5514
2024-01-10 22:01:01,495 - GAugM EPNet train, Epoch [186/285]: loss 0.7208, auc 0.4158, ap 0.4774
2024-01-10 22:01:01,571 - GAugM EPNet train, Epoch [187/285]: loss 0.7209, auc 0.4621, ap 0.4658
2024-01-10 22:01:01,647 - GAugM EPNet train, Epoch [188/285]: loss 0.7209, auc 0.5183, ap 0.5149
2024-01-10 22:01:01,723 - GAugM EPNet train, Epoch [189/285]: loss 0.7209, auc 0.5760, ap 0.6159
2024-01-10 22:01:01,799 - GAugM EPNet train, Epoch [190/285]: loss 0.7209, auc 0.4187, ap 0.4448
2024-01-10 22:01:01,876 - GAugM EPNet train, Epoch [191/285]: loss 0.7209, auc 0.3756, ap 0.4689
2024-01-10 22:01:01,952 - GAugM EPNet train, Epoch [192/285]: loss 0.7209, auc 0.4881, ap 0.4886
2024-01-10 22:01:02,028 - GAugM EPNet train, Epoch [193/285]: loss 0.7209, auc 0.4763, ap 0.5060
2024-01-10 22:01:02,112 - GAugM EPNet train, Epoch [194/285]: loss 0.7209, auc 0.5002, ap 0.4943
2024-01-10 22:01:02,200 - GAugM EPNet train, Epoch [195/285]: loss 0.7209, auc 0.4162, ap 0.4555
2024-01-10 22:01:02,278 - GAugM EPNet train, Epoch [196/285]: loss 0.7208, auc 0.5326, ap 0.5108
2024-01-10 22:01:02,359 - GAugM EPNet train, Epoch [197/285]: loss 0.7210, auc 0.4215, ap 0.4541
2024-01-10 22:01:02,447 - GAugM EPNet train, Epoch [198/285]: loss 0.7210, auc 0.5557, ap 0.5446
2024-01-10 22:01:02,524 - GAugM EPNet train, Epoch [199/285]: loss 0.7209, auc 0.4859, ap 0.5046
2024-01-10 22:01:02,606 - GAugM EPNet train, Epoch [200/285]: loss 0.7210, auc 0.4350, ap 0.4796
2024-01-10 22:01:02,686 - GAugM EPNet train, Epoch [201/285]: loss 0.7209, auc 0.4026, ap 0.4392
2024-01-10 22:01:02,763 - GAugM EPNet train, Epoch [202/285]: loss 0.7210, auc 0.5069, ap 0.5269
2024-01-10 22:01:02,850 - GAugM EPNet train, Epoch [203/285]: loss 0.7210, auc 0.5632, ap 0.5836
2024-01-10 22:01:02,942 - GAugM EPNet train, Epoch [204/285]: loss 0.7209, auc 0.3980, ap 0.4365
2024-01-10 22:01:03,018 - GAugM EPNet train, Epoch [205/285]: loss 0.7209, auc 0.5635, ap 0.5989
2024-01-10 22:01:03,096 - GAugM EPNet train, Epoch [206/285]: loss 0.7209, auc 0.4194, ap 0.4432
2024-01-10 22:01:03,172 - GAugM EPNet train, Epoch [207/285]: loss 0.7210, auc 0.4681, ap 0.5046
2024-01-10 22:01:03,250 - GAugM EPNet train, Epoch [208/285]: loss 0.7209, auc 0.4329, ap 0.4629
2024-01-10 22:01:03,325 - GAugM EPNet train, Epoch [209/285]: loss 0.7210, auc 0.6127, ap 0.6144
2024-01-10 22:01:03,410 - GAugM EPNet train, Epoch [210/285]: loss 0.7209, auc 0.4617, ap 0.4838
2024-01-10 22:01:03,486 - GAugM EPNet train, Epoch [211/285]: loss 0.7210, auc 0.5621, ap 0.5508
2024-01-10 22:01:03,563 - GAugM EPNet train, Epoch [212/285]: loss 0.7210, auc 0.4877, ap 0.5034
2024-01-10 22:01:03,639 - GAugM EPNet train, Epoch [213/285]: loss 0.7208, auc 0.5742, ap 0.6126
2024-01-10 22:01:03,722 - GAugM EPNet train, Epoch [214/285]: loss 0.7210, auc 0.5020, ap 0.5143
2024-01-10 22:01:03,804 - GAugM EPNet train, Epoch [215/285]: loss 0.7210, auc 0.4475, ap 0.4789
2024-01-10 22:01:03,889 - GAugM EPNet train, Epoch [216/285]: loss 0.7209, auc 0.5012, ap 0.4981
2024-01-10 22:01:03,974 - GAugM EPNet train, Epoch [217/285]: loss 0.7209, auc 0.5230, ap 0.5699
2024-01-10 22:01:04,069 - GAugM EPNet train, Epoch [218/285]: loss 0.7209, auc 0.5522, ap 0.5805
2024-01-10 22:01:04,154 - GAugM EPNet train, Epoch [219/285]: loss 0.7208, auc 0.5329, ap 0.5562
2024-01-10 22:01:04,241 - GAugM EPNet train, Epoch [220/285]: loss 0.7210, auc 0.4778, ap 0.5333
2024-01-10 22:01:04,319 - GAugM EPNet train, Epoch [221/285]: loss 0.7209, auc 0.4778, ap 0.4812
2024-01-10 22:01:04,396 - GAugM EPNet train, Epoch [222/285]: loss 0.7209, auc 0.5522, ap 0.5738
2024-01-10 22:01:04,474 - GAugM EPNet train, Epoch [223/285]: loss 0.7209, auc 0.4838, ap 0.5290
2024-01-10 22:01:04,554 - GAugM EPNet train, Epoch [224/285]: loss 0.7210, auc 0.3799, ap 0.4167
2024-01-10 22:01:04,629 - GAugM EPNet train, Epoch [225/285]: loss 0.7209, auc 0.4564, ap 0.4819
2024-01-10 22:01:04,706 - GAugM EPNet train, Epoch [226/285]: loss 0.7210, auc 0.4956, ap 0.5107
2024-01-10 22:01:04,783 - GAugM EPNet train, Epoch [227/285]: loss 0.7210, auc 0.5062, ap 0.5010
2024-01-10 22:01:04,867 - GAugM EPNet train, Epoch [228/285]: loss 0.7209, auc 0.4923, ap 0.4943
2024-01-10 22:01:04,943 - GAugM EPNet train, Epoch [229/285]: loss 0.7209, auc 0.5457, ap 0.5782
2024-01-10 22:01:05,019 - GAugM EPNet train, Epoch [230/285]: loss 0.7209, auc 0.4614, ap 0.4728
2024-01-10 22:01:05,094 - GAugM EPNet train, Epoch [231/285]: loss 0.7209, auc 0.5849, ap 0.5757
2024-01-10 22:01:05,176 - GAugM EPNet train, Epoch [232/285]: loss 0.7209, auc 0.4874, ap 0.5087
2024-01-10 22:01:05,254 - GAugM EPNet train, Epoch [233/285]: loss 0.7210, auc 0.5792, ap 0.5775
2024-01-10 22:01:05,335 - GAugM EPNet train, Epoch [234/285]: loss 0.7209, auc 0.3870, ap 0.4476
2024-01-10 22:01:05,412 - GAugM EPNet train, Epoch [235/285]: loss 0.7209, auc 0.4813, ap 0.4793
2024-01-10 22:01:05,489 - GAugM EPNet train, Epoch [236/285]: loss 0.7209, auc 0.4329, ap 0.4672
2024-01-10 22:01:05,565 - GAugM EPNet train, Epoch [237/285]: loss 0.7210, auc 0.5358, ap 0.5641
2024-01-10 22:01:05,649 - GAugM EPNet train, Epoch [238/285]: loss 0.7210, auc 0.5265, ap 0.5133
2024-01-10 22:01:05,725 - GAugM EPNet train, Epoch [239/285]: loss 0.7209, auc 0.5514, ap 0.5935
2024-01-10 22:01:05,804 - GAugM EPNet train, Epoch [240/285]: loss 0.7209, auc 0.5002, ap 0.4840
2024-01-10 22:01:05,881 - GAugM EPNet train, Epoch [241/285]: loss 0.7209, auc 0.4607, ap 0.4845
2024-01-10 22:01:05,958 - GAugM EPNet train, Epoch [242/285]: loss 0.7210, auc 0.4347, ap 0.4833
2024-01-10 22:01:06,032 - GAugM EPNet train, Epoch [243/285]: loss 0.7210, auc 0.5536, ap 0.6008
2024-01-10 22:01:06,110 - GAugM EPNet train, Epoch [244/285]: loss 0.7209, auc 0.4963, ap 0.5281
2024-01-10 22:01:06,191 - GAugM EPNet train, Epoch [245/285]: loss 0.7210, auc 0.4653, ap 0.4850
2024-01-10 22:01:06,267 - GAugM EPNet train, Epoch [246/285]: loss 0.7208, auc 0.4432, ap 0.4744
2024-01-10 22:01:06,345 - GAugM EPNet train, Epoch [247/285]: loss 0.7209, auc 0.4422, ap 0.4560
2024-01-10 22:01:06,421 - GAugM EPNet train, Epoch [248/285]: loss 0.7211, auc 0.4998, ap 0.5193
2024-01-10 22:01:06,499 - GAugM EPNet train, Epoch [249/285]: loss 0.7209, auc 0.5044, ap 0.5096
2024-01-10 22:01:06,581 - GAugM EPNet train, Epoch [250/285]: loss 0.7208, auc 0.5123, ap 0.4989
2024-01-10 22:01:06,658 - GAugM EPNet train, Epoch [251/285]: loss 0.7209, auc 0.4838, ap 0.5113
2024-01-10 22:01:06,736 - GAugM EPNet train, Epoch [252/285]: loss 0.7210, auc 0.5443, ap 0.5611
2024-01-10 22:01:06,817 - GAugM EPNet train, Epoch [253/285]: loss 0.7209, auc 0.6034, ap 0.5552
2024-01-10 22:01:06,896 - GAugM EPNet train, Epoch [254/285]: loss 0.7210, auc 0.4995, ap 0.5442
2024-01-10 22:01:06,973 - GAugM EPNet train, Epoch [255/285]: loss 0.7209, auc 0.5012, ap 0.5026
2024-01-10 22:01:07,052 - GAugM EPNet train, Epoch [256/285]: loss 0.7210, auc 0.3998, ap 0.4714
2024-01-10 22:01:07,130 - GAugM EPNet train, Epoch [257/285]: loss 0.7210, auc 0.4888, ap 0.5079
2024-01-10 22:01:07,207 - GAugM EPNet train, Epoch [258/285]: loss 0.7208, auc 0.5906, ap 0.6142
2024-01-10 22:01:07,291 - GAugM EPNet train, Epoch [259/285]: loss 0.7208, auc 0.5543, ap 0.5309
2024-01-10 22:01:07,374 - GAugM EPNet train, Epoch [260/285]: loss 0.7210, auc 0.5176, ap 0.5305
2024-01-10 22:01:07,452 - GAugM EPNet train, Epoch [261/285]: loss 0.7209, auc 0.5276, ap 0.5544
2024-01-10 22:01:07,548 - GAugM EPNet train, Epoch [262/285]: loss 0.7208, auc 0.5080, ap 0.5401
2024-01-10 22:01:07,633 - GAugM EPNet train, Epoch [263/285]: loss 0.7209, auc 0.5151, ap 0.5159
2024-01-10 22:01:07,716 - GAugM EPNet train, Epoch [264/285]: loss 0.7210, auc 0.4610, ap 0.4939
2024-01-10 22:01:07,795 - GAugM EPNet train, Epoch [265/285]: loss 0.7209, auc 0.5002, ap 0.5523
2024-01-10 22:01:07,877 - GAugM EPNet train, Epoch [266/285]: loss 0.7209, auc 0.5671, ap 0.5596
2024-01-10 22:01:07,954 - GAugM EPNet train, Epoch [267/285]: loss 0.7210, auc 0.4854, ap 0.4842
2024-01-10 22:01:08,028 - GAugM EPNet train, Epoch [268/285]: loss 0.7210, auc 0.4589, ap 0.5008
2024-01-10 22:01:08,114 - GAugM EPNet train, Epoch [269/285]: loss 0.7209, auc 0.5027, ap 0.5171
2024-01-10 22:01:08,190 - GAugM EPNet train, Epoch [270/285]: loss 0.7210, auc 0.4742, ap 0.4906
2024-01-10 22:01:08,268 - GAugM EPNet train, Epoch [271/285]: loss 0.7209, auc 0.4461, ap 0.4853
2024-01-10 22:01:08,342 - GAugM EPNet train, Epoch [272/285]: loss 0.7209, auc 0.5205, ap 0.5141
2024-01-10 22:01:08,428 - GAugM EPNet train, Epoch [273/285]: loss 0.7209, auc 0.5037, ap 0.4984
2024-01-10 22:01:08,505 - GAugM EPNet train, Epoch [274/285]: loss 0.7209, auc 0.4735, ap 0.4876
2024-01-10 22:01:08,585 - GAugM EPNet train, Epoch [275/285]: loss 0.7208, auc 0.5020, ap 0.4926
2024-01-10 22:01:08,669 - GAugM EPNet train, Epoch [276/285]: loss 0.7210, auc 0.5358, ap 0.5475
2024-01-10 22:01:08,747 - GAugM EPNet train, Epoch [277/285]: loss 0.7208, auc 0.4874, ap 0.5267
2024-01-10 22:01:08,828 - GAugM EPNet train, Epoch [278/285]: loss 0.7209, auc 0.5546, ap 0.5364
2024-01-10 22:01:08,904 - GAugM EPNet train, Epoch [279/285]: loss 0.7209, auc 0.4475, ap 0.4595
2024-01-10 22:01:08,981 - GAugM EPNet train, Epoch [280/285]: loss 0.7209, auc 0.4557, ap 0.4506
2024-01-10 22:01:09,057 - GAugM EPNet train, Epoch [281/285]: loss 0.7209, auc 0.4927, ap 0.4911
2024-01-10 22:01:09,144 - GAugM EPNet train, Epoch [282/285]: loss 0.7209, auc 0.4781, ap 0.4989
2024-01-10 22:01:09,223 - GAugM EPNet train, Epoch [283/285]: loss 0.7209, auc 0.4671, ap 0.4908
2024-01-10 22:01:09,305 - GAugM EPNet train, Epoch [284/285]: loss 0.7209, auc 0.3702, ap 0.4654
2024-01-10 22:01:09,392 - GAugM EPNet train, Epoch [285/285]: loss 0.7209, auc 0.5596, ap 0.5533
2024-01-10 22:01:09,402 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035ee450>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:01:10,134 - GAugM EPNet train, Epoch [  1/230]: loss 0.7210, auc 0.3927, ap 0.4347
2024-01-10 22:01:10,249 - GAugM EPNet train, Epoch [  2/230]: loss 0.7210, auc 0.5249, ap 0.5218
2024-01-10 22:01:10,345 - GAugM EPNet train, Epoch [  3/230]: loss 0.7209, auc 0.5609, ap 0.5447
2024-01-10 22:01:10,440 - GAugM EPNet train, Epoch [  4/230]: loss 0.7209, auc 0.4678, ap 0.5206
2024-01-10 22:01:10,539 - GAugM EPNet train, Epoch [  5/230]: loss 0.7209, auc 0.5977, ap 0.6448
2024-01-10 22:01:10,634 - GAugM EPNet train, Epoch [  6/230]: loss 0.7209, auc 0.5344, ap 0.5176
2024-01-10 22:01:10,730 - GAugM EPNet train, Epoch [  7/230]: loss 0.7209, auc 0.5198, ap 0.4971
2024-01-10 22:01:10,826 - GAugM EPNet train, Epoch [  8/230]: loss 0.7210, auc 0.4811, ap 0.5318
2024-01-10 22:01:10,917 - GAugM EPNet train, Epoch [  9/230]: loss 0.7209, auc 0.4361, ap 0.4862
2024-01-10 22:01:11,010 - GAugM EPNet train, Epoch [ 10/230]: loss 0.7208, auc 0.4710, ap 0.4841
2024-01-10 22:01:11,103 - GAugM EPNet train, Epoch [ 11/230]: loss 0.7209, auc 0.5429, ap 0.5677
2024-01-10 22:01:11,197 - GAugM EPNet train, Epoch [ 12/230]: loss 0.7210, auc 0.4009, ap 0.4525
2024-01-10 22:01:11,293 - GAugM EPNet train, Epoch [ 13/230]: loss 0.7209, auc 0.5942, ap 0.6085
2024-01-10 22:01:11,386 - GAugM EPNet train, Epoch [ 14/230]: loss 0.7209, auc 0.5746, ap 0.5580
2024-01-10 22:01:11,474 - GAugM EPNet train, Epoch [ 15/230]: loss 0.7210, auc 0.4160, ap 0.4892
2024-01-10 22:01:11,559 - GAugM EPNet train, Epoch [ 16/230]: loss 0.7209, auc 0.5466, ap 0.5605
2024-01-10 22:01:11,639 - GAugM EPNet train, Epoch [ 17/230]: loss 0.7210, auc 0.6415, ap 0.6297
2024-01-10 22:01:11,721 - GAugM EPNet train, Epoch [ 18/230]: loss 0.7210, auc 0.5684, ap 0.5780
2024-01-10 22:01:11,812 - GAugM EPNet train, Epoch [ 19/230]: loss 0.7209, auc 0.5148, ap 0.5156
2024-01-10 22:01:11,892 - GAugM EPNet train, Epoch [ 20/230]: loss 0.7210, auc 0.4888, ap 0.5495
2024-01-10 22:01:11,975 - GAugM EPNet train, Epoch [ 21/230]: loss 0.7209, auc 0.4430, ap 0.4899
2024-01-10 22:01:12,059 - GAugM EPNet train, Epoch [ 22/230]: loss 0.7210, auc 0.3898, ap 0.4533
2024-01-10 22:01:12,139 - GAugM EPNet train, Epoch [ 23/230]: loss 0.7208, auc 0.4605, ap 0.4740
2024-01-10 22:01:12,228 - GAugM EPNet train, Epoch [ 24/230]: loss 0.7209, auc 0.5142, ap 0.5287
2024-01-10 22:01:12,307 - GAugM EPNet train, Epoch [ 25/230]: loss 0.7209, auc 0.5046, ap 0.5190
2024-01-10 22:01:12,388 - GAugM EPNet train, Epoch [ 26/230]: loss 0.7210, auc 0.4135, ap 0.4540
2024-01-10 22:01:12,476 - GAugM EPNet train, Epoch [ 27/230]: loss 0.7209, auc 0.4612, ap 0.5059
2024-01-10 22:01:12,558 - GAugM EPNet train, Epoch [ 28/230]: loss 0.7209, auc 0.5614, ap 0.5861
2024-01-10 22:01:12,638 - GAugM EPNet train, Epoch [ 29/230]: loss 0.7210, auc 0.5561, ap 0.5638
2024-01-10 22:01:12,718 - GAugM EPNet train, Epoch [ 30/230]: loss 0.7209, auc 0.4818, ap 0.5277
2024-01-10 22:01:12,804 - GAugM EPNet train, Epoch [ 31/230]: loss 0.7208, auc 0.4671, ap 0.4778
2024-01-10 22:01:12,884 - GAugM EPNet train, Epoch [ 32/230]: loss 0.7210, auc 0.5536, ap 0.5635
2024-01-10 22:01:12,967 - GAugM EPNet train, Epoch [ 33/230]: loss 0.7209, auc 0.5119, ap 0.5498
2024-01-10 22:01:13,055 - GAugM EPNet train, Epoch [ 34/230]: loss 0.7209, auc 0.4017, ap 0.4564
2024-01-10 22:01:13,135 - GAugM EPNet train, Epoch [ 35/230]: loss 0.7209, auc 0.5586, ap 0.5416
2024-01-10 22:01:13,214 - GAugM EPNet train, Epoch [ 36/230]: loss 0.7209, auc 0.5482, ap 0.5473
2024-01-10 22:01:13,298 - GAugM EPNet train, Epoch [ 37/230]: loss 0.7209, auc 0.4824, ap 0.4990
2024-01-10 22:01:13,373 - GAugM EPNet train, Epoch [ 38/230]: loss 0.7209, auc 0.5383, ap 0.5208
2024-01-10 22:01:13,451 - GAugM EPNet train, Epoch [ 39/230]: loss 0.7208, auc 0.4544, ap 0.5061
2024-01-10 22:01:13,530 - GAugM EPNet train, Epoch [ 40/230]: loss 0.7210, auc 0.5438, ap 0.5279
2024-01-10 22:01:13,608 - GAugM EPNet train, Epoch [ 41/230]: loss 0.7210, auc 0.5281, ap 0.5343
2024-01-10 22:01:13,684 - GAugM EPNet train, Epoch [ 42/230]: loss 0.7209, auc 0.5016, ap 0.5373
2024-01-10 22:01:13,773 - GAugM EPNet train, Epoch [ 43/230]: loss 0.7208, auc 0.4988, ap 0.5559
2024-01-10 22:01:13,854 - GAugM EPNet train, Epoch [ 44/230]: loss 0.7208, auc 0.3660, ap 0.4447
2024-01-10 22:01:13,935 - GAugM EPNet train, Epoch [ 45/230]: loss 0.7209, auc 0.5059, ap 0.5117
2024-01-10 22:01:14,013 - GAugM EPNet train, Epoch [ 46/230]: loss 0.7209, auc 0.4493, ap 0.4874
2024-01-10 22:01:14,099 - GAugM EPNet train, Epoch [ 47/230]: loss 0.7210, auc 0.5004, ap 0.5137
2024-01-10 22:01:14,181 - GAugM EPNet train, Epoch [ 48/230]: loss 0.7210, auc 0.5904, ap 0.6106
2024-01-10 22:01:14,263 - GAugM EPNet train, Epoch [ 49/230]: loss 0.7209, auc 0.5717, ap 0.5573
2024-01-10 22:01:14,340 - GAugM EPNet train, Epoch [ 50/230]: loss 0.7210, auc 0.5215, ap 0.5424
2024-01-10 22:01:14,418 - GAugM EPNet train, Epoch [ 51/230]: loss 0.7210, auc 0.4194, ap 0.4850
2024-01-10 22:01:14,500 - GAugM EPNet train, Epoch [ 52/230]: loss 0.7209, auc 0.4656, ap 0.5285
2024-01-10 22:01:14,582 - GAugM EPNet train, Epoch [ 53/230]: loss 0.7209, auc 0.5726, ap 0.5593
2024-01-10 22:01:14,668 - GAugM EPNet train, Epoch [ 54/230]: loss 0.7211, auc 0.5117, ap 0.5452
2024-01-10 22:01:14,747 - GAugM EPNet train, Epoch [ 55/230]: loss 0.7209, auc 0.5851, ap 0.5993
2024-01-10 22:01:14,830 - GAugM EPNet train, Epoch [ 56/230]: loss 0.7208, auc 0.5251, ap 0.5094
2024-01-10 22:01:14,911 - GAugM EPNet train, Epoch [ 57/230]: loss 0.7209, auc 0.4635, ap 0.4546
2024-01-10 22:01:14,990 - GAugM EPNet train, Epoch [ 58/230]: loss 0.7210, auc 0.5461, ap 0.6004
2024-01-10 22:01:15,068 - GAugM EPNet train, Epoch [ 59/230]: loss 0.7211, auc 0.4660, ap 0.4721
2024-01-10 22:01:15,146 - GAugM EPNet train, Epoch [ 60/230]: loss 0.7210, auc 0.4833, ap 0.5037
2024-01-10 22:01:15,232 - GAugM EPNet train, Epoch [ 61/230]: loss 0.7209, auc 0.5945, ap 0.5944
2024-01-10 22:01:15,323 - GAugM EPNet train, Epoch [ 62/230]: loss 0.7210, auc 0.4957, ap 0.5876
2024-01-10 22:01:15,404 - GAugM EPNet train, Epoch [ 63/230]: loss 0.7208, auc 0.4525, ap 0.4709
2024-01-10 22:01:15,481 - GAugM EPNet train, Epoch [ 64/230]: loss 0.7208, auc 0.4377, ap 0.4693
2024-01-10 22:01:15,561 - GAugM EPNet train, Epoch [ 65/230]: loss 0.7208, auc 0.5094, ap 0.5283
2024-01-10 22:01:15,645 - GAugM EPNet train, Epoch [ 66/230]: loss 0.7209, auc 0.4681, ap 0.5084
2024-01-10 22:01:15,725 - GAugM EPNet train, Epoch [ 67/230]: loss 0.7209, auc 0.5237, ap 0.5226
2024-01-10 22:01:15,809 - GAugM EPNet train, Epoch [ 68/230]: loss 0.7210, auc 0.5153, ap 0.5689
2024-01-10 22:01:15,888 - GAugM EPNet train, Epoch [ 69/230]: loss 0.7210, auc 0.4014, ap 0.4694
2024-01-10 22:01:15,969 - GAugM EPNet train, Epoch [ 70/230]: loss 0.7210, auc 0.4042, ap 0.4281
2024-01-10 22:01:16,059 - GAugM EPNet train, Epoch [ 71/230]: loss 0.7210, auc 0.5087, ap 0.5310
2024-01-10 22:01:16,140 - GAugM EPNet train, Epoch [ 72/230]: loss 0.7210, auc 0.4279, ap 0.4681
2024-01-10 22:01:16,222 - GAugM EPNet train, Epoch [ 73/230]: loss 0.7209, auc 0.4817, ap 0.4940
2024-01-10 22:01:16,304 - GAugM EPNet train, Epoch [ 74/230]: loss 0.7209, auc 0.4477, ap 0.4643
2024-01-10 22:01:16,391 - GAugM EPNet train, Epoch [ 75/230]: loss 0.7210, auc 0.4842, ap 0.5390
2024-01-10 22:01:16,473 - GAugM EPNet train, Epoch [ 76/230]: loss 0.7209, auc 0.4614, ap 0.4917
2024-01-10 22:01:16,552 - GAugM EPNet train, Epoch [ 77/230]: loss 0.7208, auc 0.4836, ap 0.5154
2024-01-10 22:01:16,632 - GAugM EPNet train, Epoch [ 78/230]: loss 0.7209, auc 0.4826, ap 0.5115
2024-01-10 22:01:16,709 - GAugM EPNet train, Epoch [ 79/230]: loss 0.7208, auc 0.5459, ap 0.5311
2024-01-10 22:01:16,799 - GAugM EPNet train, Epoch [ 80/230]: loss 0.7209, auc 0.5643, ap 0.5524
2024-01-10 22:01:16,879 - GAugM EPNet train, Epoch [ 81/230]: loss 0.7209, auc 0.4870, ap 0.4945
2024-01-10 22:01:16,958 - GAugM EPNet train, Epoch [ 82/230]: loss 0.7210, auc 0.4852, ap 0.5087
2024-01-10 22:01:17,037 - GAugM EPNet train, Epoch [ 83/230]: loss 0.7209, auc 0.4705, ap 0.5166
2024-01-10 22:01:17,118 - GAugM EPNet train, Epoch [ 84/230]: loss 0.7209, auc 0.4849, ap 0.5352
2024-01-10 22:01:17,203 - GAugM EPNet train, Epoch [ 85/230]: loss 0.7210, auc 0.4744, ap 0.5278
2024-01-10 22:01:17,293 - GAugM EPNet train, Epoch [ 86/230]: loss 0.7208, auc 0.4792, ap 0.4827
2024-01-10 22:01:17,374 - GAugM EPNet train, Epoch [ 87/230]: loss 0.7209, auc 0.5630, ap 0.5478
2024-01-10 22:01:17,458 - GAugM EPNet train, Epoch [ 88/230]: loss 0.7210, auc 0.4731, ap 0.5347
2024-01-10 22:01:17,540 - GAugM EPNet train, Epoch [ 89/230]: loss 0.7210, auc 0.4738, ap 0.5061
2024-01-10 22:01:17,626 - GAugM EPNet train, Epoch [ 90/230]: loss 0.7209, auc 0.4888, ap 0.4922
2024-01-10 22:01:17,707 - GAugM EPNet train, Epoch [ 91/230]: loss 0.7208, auc 0.5728, ap 0.5686
2024-01-10 22:01:17,786 - GAugM EPNet train, Epoch [ 92/230]: loss 0.7209, auc 0.6059, ap 0.5875
2024-01-10 22:01:17,867 - GAugM EPNet train, Epoch [ 93/230]: loss 0.7209, auc 0.4519, ap 0.4790
2024-01-10 22:01:17,948 - GAugM EPNet train, Epoch [ 94/230]: loss 0.7210, auc 0.4251, ap 0.4964
2024-01-10 22:01:18,032 - GAugM EPNet train, Epoch [ 95/230]: loss 0.7210, auc 0.5500, ap 0.5578
2024-01-10 22:01:18,115 - GAugM EPNet train, Epoch [ 96/230]: loss 0.7209, auc 0.4724, ap 0.4866
2024-01-10 22:01:18,194 - GAugM EPNet train, Epoch [ 97/230]: loss 0.7209, auc 0.4973, ap 0.5432
2024-01-10 22:01:18,272 - GAugM EPNet train, Epoch [ 98/230]: loss 0.7209, auc 0.5226, ap 0.5126
2024-01-10 22:01:18,360 - GAugM EPNet train, Epoch [ 99/230]: loss 0.7209, auc 0.4865, ap 0.5012
2024-01-10 22:01:18,440 - GAugM EPNet train, Epoch [100/230]: loss 0.7210, auc 0.5055, ap 0.5313
2024-01-10 22:01:18,519 - GAugM EPNet train, Epoch [101/230]: loss 0.7210, auc 0.4911, ap 0.5207
2024-01-10 22:01:18,596 - GAugM EPNet train, Epoch [102/230]: loss 0.7209, auc 0.4863, ap 0.5330
2024-01-10 22:01:18,682 - GAugM EPNet train, Epoch [103/230]: loss 0.7209, auc 0.4099, ap 0.4821
2024-01-10 22:01:18,764 - GAugM EPNet train, Epoch [104/230]: loss 0.7209, auc 0.4678, ap 0.4900
2024-01-10 22:01:18,844 - GAugM EPNet train, Epoch [105/230]: loss 0.7209, auc 0.4500, ap 0.4885
2024-01-10 22:01:18,926 - GAugM EPNet train, Epoch [106/230]: loss 0.7210, auc 0.4343, ap 0.4540
2024-01-10 22:01:19,008 - GAugM EPNet train, Epoch [107/230]: loss 0.7210, auc 0.5043, ap 0.5609
2024-01-10 22:01:19,087 - GAugM EPNet train, Epoch [108/230]: loss 0.7208, auc 0.4333, ap 0.4502
2024-01-10 22:01:19,166 - GAugM EPNet train, Epoch [109/230]: loss 0.7210, auc 0.4567, ap 0.4913
2024-01-10 22:01:19,254 - GAugM EPNet train, Epoch [110/230]: loss 0.7209, auc 0.4729, ap 0.5411
2024-01-10 22:01:19,330 - GAugM EPNet train, Epoch [111/230]: loss 0.7210, auc 0.5514, ap 0.5741
2024-01-10 22:01:19,411 - GAugM EPNet train, Epoch [112/230]: loss 0.7209, auc 0.4945, ap 0.5412
2024-01-10 22:01:19,495 - GAugM EPNet train, Epoch [113/230]: loss 0.7210, auc 0.5100, ap 0.5417
2024-01-10 22:01:19,583 - GAugM EPNet train, Epoch [114/230]: loss 0.7209, auc 0.4667, ap 0.4924
2024-01-10 22:01:19,663 - GAugM EPNet train, Epoch [115/230]: loss 0.7210, auc 0.4370, ap 0.4554
2024-01-10 22:01:19,737 - GAugM EPNet train, Epoch [116/230]: loss 0.7209, auc 0.5603, ap 0.5874
2024-01-10 22:01:19,816 - GAugM EPNet train, Epoch [117/230]: loss 0.7208, auc 0.4471, ap 0.4801
2024-01-10 22:01:19,905 - GAugM EPNet train, Epoch [118/230]: loss 0.7209, auc 0.5239, ap 0.5273
2024-01-10 22:01:19,985 - GAugM EPNet train, Epoch [119/230]: loss 0.7209, auc 0.4464, ap 0.5058
2024-01-10 22:01:20,065 - GAugM EPNet train, Epoch [120/230]: loss 0.7210, auc 0.3964, ap 0.4485
2024-01-10 22:01:20,156 - GAugM EPNet train, Epoch [121/230]: loss 0.7210, auc 0.5094, ap 0.5243
2024-01-10 22:01:20,238 - GAugM EPNet train, Epoch [122/230]: loss 0.7209, auc 0.4030, ap 0.4885
2024-01-10 22:01:20,319 - GAugM EPNet train, Epoch [123/230]: loss 0.7209, auc 0.5319, ap 0.5828
2024-01-10 22:01:20,413 - GAugM EPNet train, Epoch [124/230]: loss 0.7210, auc 0.4925, ap 0.4906
2024-01-10 22:01:20,493 - GAugM EPNet train, Epoch [125/230]: loss 0.7209, auc 0.5101, ap 0.5175
2024-01-10 22:01:20,572 - GAugM EPNet train, Epoch [126/230]: loss 0.7210, auc 0.5222, ap 0.5340
2024-01-10 22:01:20,653 - GAugM EPNet train, Epoch [127/230]: loss 0.7209, auc 0.5135, ap 0.5242
2024-01-10 22:01:20,731 - GAugM EPNet train, Epoch [128/230]: loss 0.7210, auc 0.5187, ap 0.5207
2024-01-10 22:01:20,815 - GAugM EPNet train, Epoch [129/230]: loss 0.7208, auc 0.4450, ap 0.4592
2024-01-10 22:01:20,895 - GAugM EPNet train, Epoch [130/230]: loss 0.7210, auc 0.4760, ap 0.5318
2024-01-10 22:01:20,975 - GAugM EPNet train, Epoch [131/230]: loss 0.7210, auc 0.5447, ap 0.5849
2024-01-10 22:01:21,067 - GAugM EPNet train, Epoch [132/230]: loss 0.7209, auc 0.5538, ap 0.5566
2024-01-10 22:01:21,146 - GAugM EPNet train, Epoch [133/230]: loss 0.7209, auc 0.4984, ap 0.5623
2024-01-10 22:01:21,244 - GAugM EPNet train, Epoch [134/230]: loss 0.7210, auc 0.4566, ap 0.4861
2024-01-10 22:01:21,338 - GAugM EPNet train, Epoch [135/230]: loss 0.7209, auc 0.4432, ap 0.4887
2024-01-10 22:01:21,427 - GAugM EPNet train, Epoch [136/230]: loss 0.7209, auc 0.4422, ap 0.4643
2024-01-10 22:01:21,518 - GAugM EPNet train, Epoch [137/230]: loss 0.7210, auc 0.4340, ap 0.4873
2024-01-10 22:01:21,610 - GAugM EPNet train, Epoch [138/230]: loss 0.7210, auc 0.5842, ap 0.5761
2024-01-10 22:01:21,695 - GAugM EPNet train, Epoch [139/230]: loss 0.7210, auc 0.4277, ap 0.4600
2024-01-10 22:01:21,785 - GAugM EPNet train, Epoch [140/230]: loss 0.7209, auc 0.5577, ap 0.5976
2024-01-10 22:01:21,872 - GAugM EPNet train, Epoch [141/230]: loss 0.7209, auc 0.5336, ap 0.5428
2024-01-10 22:01:21,966 - GAugM EPNet train, Epoch [142/230]: loss 0.7209, auc 0.5443, ap 0.5652
2024-01-10 22:01:22,053 - GAugM EPNet train, Epoch [143/230]: loss 0.7209, auc 0.4836, ap 0.5114
2024-01-10 22:01:22,140 - GAugM EPNet train, Epoch [144/230]: loss 0.7209, auc 0.4174, ap 0.4400
2024-01-10 22:01:22,227 - GAugM EPNet train, Epoch [145/230]: loss 0.7209, auc 0.4466, ap 0.4926
2024-01-10 22:01:22,314 - GAugM EPNet train, Epoch [146/230]: loss 0.7209, auc 0.6150, ap 0.6241
2024-01-10 22:01:22,404 - GAugM EPNet train, Epoch [147/230]: loss 0.7209, auc 0.5694, ap 0.6038
2024-01-10 22:01:22,492 - GAugM EPNet train, Epoch [148/230]: loss 0.7209, auc 0.4756, ap 0.5216
2024-01-10 22:01:22,583 - GAugM EPNet train, Epoch [149/230]: loss 0.7208, auc 0.5030, ap 0.5134
2024-01-10 22:01:22,669 - GAugM EPNet train, Epoch [150/230]: loss 0.7209, auc 0.4671, ap 0.4823
2024-01-10 22:01:22,757 - GAugM EPNet train, Epoch [151/230]: loss 0.7209, auc 0.5059, ap 0.5140
2024-01-10 22:01:22,847 - GAugM EPNet train, Epoch [152/230]: loss 0.7209, auc 0.5776, ap 0.5754
2024-01-10 22:01:22,931 - GAugM EPNet train, Epoch [153/230]: loss 0.7209, auc 0.4810, ap 0.5293
2024-01-10 22:01:23,019 - GAugM EPNet train, Epoch [154/230]: loss 0.7209, auc 0.4895, ap 0.5574
2024-01-10 22:01:23,105 - GAugM EPNet train, Epoch [155/230]: loss 0.7209, auc 0.4726, ap 0.4944
2024-01-10 22:01:23,193 - GAugM EPNet train, Epoch [156/230]: loss 0.7209, auc 0.5304, ap 0.5698
2024-01-10 22:01:23,282 - GAugM EPNet train, Epoch [157/230]: loss 0.7209, auc 0.4528, ap 0.4673
2024-01-10 22:01:23,368 - GAugM EPNet train, Epoch [158/230]: loss 0.7208, auc 0.5141, ap 0.5136
2024-01-10 22:01:23,456 - GAugM EPNet train, Epoch [159/230]: loss 0.7208, auc 0.4569, ap 0.4904
2024-01-10 22:01:23,547 - GAugM EPNet train, Epoch [160/230]: loss 0.7209, auc 0.5821, ap 0.5915
2024-01-10 22:01:23,633 - GAugM EPNet train, Epoch [161/230]: loss 0.7209, auc 0.5465, ap 0.5678
2024-01-10 22:01:23,724 - GAugM EPNet train, Epoch [162/230]: loss 0.7209, auc 0.3904, ap 0.4382
2024-01-10 22:01:23,812 - GAugM EPNet train, Epoch [163/230]: loss 0.7209, auc 0.4792, ap 0.4876
2024-01-10 22:01:23,899 - GAugM EPNet train, Epoch [164/230]: loss 0.7211, auc 0.4662, ap 0.4842
2024-01-10 22:01:23,987 - GAugM EPNet train, Epoch [165/230]: loss 0.7210, auc 0.5372, ap 0.5436
2024-01-10 22:01:24,082 - GAugM EPNet train, Epoch [166/230]: loss 0.7208, auc 0.5018, ap 0.5249
2024-01-10 22:01:24,167 - GAugM EPNet train, Epoch [167/230]: loss 0.7209, auc 0.4970, ap 0.5323
2024-01-10 22:01:24,253 - GAugM EPNet train, Epoch [168/230]: loss 0.7209, auc 0.4660, ap 0.5029
2024-01-10 22:01:24,335 - GAugM EPNet train, Epoch [169/230]: loss 0.7209, auc 0.5262, ap 0.5669
2024-01-10 22:01:24,427 - GAugM EPNet train, Epoch [170/230]: loss 0.7210, auc 0.4785, ap 0.4764
2024-01-10 22:01:24,520 - GAugM EPNet train, Epoch [171/230]: loss 0.7209, auc 0.4082, ap 0.4510
2024-01-10 22:01:24,609 - GAugM EPNet train, Epoch [172/230]: loss 0.7208, auc 0.4576, ap 0.4749
2024-01-10 22:01:24,694 - GAugM EPNet train, Epoch [173/230]: loss 0.7209, auc 0.4327, ap 0.5119
2024-01-10 22:01:24,785 - GAugM EPNet train, Epoch [174/230]: loss 0.7209, auc 0.4664, ap 0.4737
2024-01-10 22:01:24,872 - GAugM EPNet train, Epoch [175/230]: loss 0.7209, auc 0.5399, ap 0.5363
2024-01-10 22:01:24,957 - GAugM EPNet train, Epoch [176/230]: loss 0.7209, auc 0.4616, ap 0.4791
2024-01-10 22:01:25,042 - GAugM EPNet train, Epoch [177/230]: loss 0.7210, auc 0.4541, ap 0.4902
2024-01-10 22:01:25,133 - GAugM EPNet train, Epoch [178/230]: loss 0.7210, auc 0.5427, ap 0.5699
2024-01-10 22:01:25,228 - GAugM EPNet train, Epoch [179/230]: loss 0.7210, auc 0.4224, ap 0.4924
2024-01-10 22:01:25,321 - GAugM EPNet train, Epoch [180/230]: loss 0.7210, auc 0.5265, ap 0.5637
2024-01-10 22:01:25,409 - GAugM EPNet train, Epoch [181/230]: loss 0.7209, auc 0.4171, ap 0.4416
2024-01-10 22:01:25,497 - GAugM EPNet train, Epoch [182/230]: loss 0.7209, auc 0.5333, ap 0.5610
2024-01-10 22:01:25,590 - GAugM EPNet train, Epoch [183/230]: loss 0.7210, auc 0.5671, ap 0.5665
2024-01-10 22:01:25,677 - GAugM EPNet train, Epoch [184/230]: loss 0.7209, auc 0.4439, ap 0.4641
2024-01-10 22:01:25,770 - GAugM EPNet train, Epoch [185/230]: loss 0.7209, auc 0.4096, ap 0.4551
2024-01-10 22:01:25,855 - GAugM EPNet train, Epoch [186/230]: loss 0.7208, auc 0.4583, ap 0.5244
2024-01-10 22:01:25,945 - GAugM EPNet train, Epoch [187/230]: loss 0.7209, auc 0.4806, ap 0.4980
2024-01-10 22:01:26,036 - GAugM EPNet train, Epoch [188/230]: loss 0.7209, auc 0.4375, ap 0.4625
2024-01-10 22:01:26,127 - GAugM EPNet train, Epoch [189/230]: loss 0.7209, auc 0.5425, ap 0.5899
2024-01-10 22:01:26,216 - GAugM EPNet train, Epoch [190/230]: loss 0.7209, auc 0.4708, ap 0.4843
2024-01-10 22:01:26,304 - GAugM EPNet train, Epoch [191/230]: loss 0.7209, auc 0.3848, ap 0.4680
2024-01-10 22:01:26,394 - GAugM EPNet train, Epoch [192/230]: loss 0.7209, auc 0.5093, ap 0.4925
2024-01-10 22:01:26,482 - GAugM EPNet train, Epoch [193/230]: loss 0.7209, auc 0.5116, ap 0.5329
2024-01-10 22:01:26,570 - GAugM EPNet train, Epoch [194/230]: loss 0.7209, auc 0.4407, ap 0.4665
2024-01-10 22:01:26,647 - GAugM EPNet train, Epoch [195/230]: loss 0.7209, auc 0.4754, ap 0.4852
2024-01-10 22:01:26,723 - GAugM EPNet train, Epoch [196/230]: loss 0.7208, auc 0.5002, ap 0.5202
2024-01-10 22:01:26,808 - GAugM EPNet train, Epoch [197/230]: loss 0.7210, auc 0.4407, ap 0.4884
2024-01-10 22:01:26,887 - GAugM EPNet train, Epoch [198/230]: loss 0.7210, auc 0.5260, ap 0.5247
2024-01-10 22:01:26,968 - GAugM EPNet train, Epoch [199/230]: loss 0.7209, auc 0.5311, ap 0.5470
2024-01-10 22:01:27,045 - GAugM EPNet train, Epoch [200/230]: loss 0.7210, auc 0.4756, ap 0.5033
2024-01-10 22:01:27,124 - GAugM EPNet train, Epoch [201/230]: loss 0.7209, auc 0.4122, ap 0.4514
2024-01-10 22:01:27,205 - GAugM EPNet train, Epoch [202/230]: loss 0.7210, auc 0.5194, ap 0.5676
2024-01-10 22:01:27,285 - GAugM EPNet train, Epoch [203/230]: loss 0.7210, auc 0.4527, ap 0.5023
2024-01-10 22:01:27,363 - GAugM EPNet train, Epoch [204/230]: loss 0.7209, auc 0.4680, ap 0.4725
2024-01-10 22:01:27,447 - GAugM EPNet train, Epoch [205/230]: loss 0.7209, auc 0.5141, ap 0.5482
2024-01-10 22:01:27,538 - GAugM EPNet train, Epoch [206/230]: loss 0.7209, auc 0.4329, ap 0.4635
2024-01-10 22:01:27,629 - GAugM EPNet train, Epoch [207/230]: loss 0.7210, auc 0.4769, ap 0.4940
2024-01-10 22:01:27,720 - GAugM EPNet train, Epoch [208/230]: loss 0.7209, auc 0.5219, ap 0.5730
2024-01-10 22:01:27,801 - GAugM EPNet train, Epoch [209/230]: loss 0.7210, auc 0.6219, ap 0.6534
2024-01-10 22:01:27,884 - GAugM EPNet train, Epoch [210/230]: loss 0.7209, auc 0.5233, ap 0.5198
2024-01-10 22:01:27,961 - GAugM EPNet train, Epoch [211/230]: loss 0.7210, auc 0.5228, ap 0.5381
2024-01-10 22:01:28,040 - GAugM EPNet train, Epoch [212/230]: loss 0.7210, auc 0.5096, ap 0.5595
2024-01-10 22:01:28,116 - GAugM EPNet train, Epoch [213/230]: loss 0.7208, auc 0.6136, ap 0.6371
2024-01-10 22:01:28,198 - GAugM EPNet train, Epoch [214/230]: loss 0.7210, auc 0.5335, ap 0.5304
2024-01-10 22:01:28,274 - GAugM EPNet train, Epoch [215/230]: loss 0.7210, auc 0.4231, ap 0.4940
2024-01-10 22:01:28,363 - GAugM EPNet train, Epoch [216/230]: loss 0.7209, auc 0.5100, ap 0.5340
2024-01-10 22:01:28,457 - GAugM EPNet train, Epoch [217/230]: loss 0.7209, auc 0.5347, ap 0.5722
2024-01-10 22:01:28,544 - GAugM EPNet train, Epoch [218/230]: loss 0.7209, auc 0.4868, ap 0.5322
2024-01-10 22:01:28,632 - GAugM EPNet train, Epoch [219/230]: loss 0.7208, auc 0.4240, ap 0.4704
2024-01-10 22:01:28,731 - GAugM EPNet train, Epoch [220/230]: loss 0.7210, auc 0.4155, ap 0.4990
2024-01-10 22:01:28,820 - GAugM EPNet train, Epoch [221/230]: loss 0.7209, auc 0.5306, ap 0.5340
2024-01-10 22:01:28,914 - GAugM EPNet train, Epoch [222/230]: loss 0.7209, auc 0.4580, ap 0.4861
2024-01-10 22:01:29,003 - GAugM EPNet train, Epoch [223/230]: loss 0.7209, auc 0.5032, ap 0.5523
2024-01-10 22:01:29,097 - GAugM EPNet train, Epoch [224/230]: loss 0.7210, auc 0.4785, ap 0.5009
2024-01-10 22:01:29,187 - GAugM EPNet train, Epoch [225/230]: loss 0.7209, auc 0.5048, ap 0.4939
2024-01-10 22:01:29,283 - GAugM EPNet train, Epoch [226/230]: loss 0.7210, auc 0.5281, ap 0.5359
2024-01-10 22:01:29,373 - GAugM EPNet train, Epoch [227/230]: loss 0.7210, auc 0.5660, ap 0.5647
2024-01-10 22:01:29,460 - GAugM EPNet train, Epoch [228/230]: loss 0.7209, auc 0.4181, ap 0.4524
2024-01-10 22:01:29,552 - GAugM EPNet train, Epoch [229/230]: loss 0.7209, auc 0.5069, ap 0.5216
2024-01-10 22:01:29,643 - GAugM EPNet train, Epoch [230/230]: loss 0.7209, auc 0.4972, ap 0.5209
2024-01-10 22:01:29,651 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa0158d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:01:30,419 - GAugM EPNet train, Epoch [  1/230]: loss 0.7210, auc 0.4179, ap 0.4511
2024-01-10 22:01:30,510 - GAugM EPNet train, Epoch [  2/230]: loss 0.7210, auc 0.4849, ap 0.4934
2024-01-10 22:01:30,604 - GAugM EPNet train, Epoch [  3/230]: loss 0.7209, auc 0.5495, ap 0.5508
2024-01-10 22:01:30,697 - GAugM EPNet train, Epoch [  4/230]: loss 0.7209, auc 0.4849, ap 0.5430
2024-01-10 22:01:30,791 - GAugM EPNet train, Epoch [  5/230]: loss 0.7209, auc 0.5968, ap 0.6067
2024-01-10 22:01:30,879 - GAugM EPNet train, Epoch [  6/230]: loss 0.7209, auc 0.5240, ap 0.5342
2024-01-10 22:01:30,969 - GAugM EPNet train, Epoch [  7/230]: loss 0.7209, auc 0.3863, ap 0.4274
2024-01-10 22:01:31,053 - GAugM EPNet train, Epoch [  8/230]: loss 0.7210, auc 0.4512, ap 0.4714
2024-01-10 22:01:31,138 - GAugM EPNet train, Epoch [  9/230]: loss 0.7209, auc 0.4783, ap 0.4988
2024-01-10 22:01:31,222 - GAugM EPNet train, Epoch [ 10/230]: loss 0.7208, auc 0.4583, ap 0.4703
2024-01-10 22:01:31,312 - GAugM EPNet train, Epoch [ 11/230]: loss 0.7209, auc 0.5641, ap 0.6058
2024-01-10 22:01:31,399 - GAugM EPNet train, Epoch [ 12/230]: loss 0.7210, auc 0.4484, ap 0.4635
2024-01-10 22:01:31,491 - GAugM EPNet train, Epoch [ 13/230]: loss 0.7209, auc 0.5466, ap 0.5630
2024-01-10 22:01:31,578 - GAugM EPNet train, Epoch [ 14/230]: loss 0.7209, auc 0.5546, ap 0.5661
2024-01-10 22:01:31,672 - GAugM EPNet train, Epoch [ 15/230]: loss 0.7210, auc 0.3562, ap 0.4175
2024-01-10 22:01:31,759 - GAugM EPNet train, Epoch [ 16/230]: loss 0.7209, auc 0.5157, ap 0.5255
2024-01-10 22:01:31,845 - GAugM EPNet train, Epoch [ 17/230]: loss 0.7210, auc 0.6027, ap 0.5774
2024-01-10 22:01:31,932 - GAugM EPNet train, Epoch [ 18/230]: loss 0.7210, auc 0.5379, ap 0.5677
2024-01-10 22:01:32,019 - GAugM EPNet train, Epoch [ 19/230]: loss 0.7209, auc 0.5342, ap 0.5241
2024-01-10 22:01:32,106 - GAugM EPNet train, Epoch [ 20/230]: loss 0.7210, auc 0.4834, ap 0.4915
2024-01-10 22:01:32,194 - GAugM EPNet train, Epoch [ 21/230]: loss 0.7209, auc 0.4626, ap 0.4630
2024-01-10 22:01:32,281 - GAugM EPNet train, Epoch [ 22/230]: loss 0.7210, auc 0.3973, ap 0.4580
2024-01-10 22:01:32,370 - GAugM EPNet train, Epoch [ 23/230]: loss 0.7208, auc 0.5319, ap 0.5359
2024-01-10 22:01:32,457 - GAugM EPNet train, Epoch [ 24/230]: loss 0.7209, auc 0.5434, ap 0.5729
2024-01-10 22:01:32,544 - GAugM EPNet train, Epoch [ 25/230]: loss 0.7209, auc 0.4256, ap 0.4799
2024-01-10 22:01:32,635 - GAugM EPNet train, Epoch [ 26/230]: loss 0.7210, auc 0.6378, ap 0.6175
2024-01-10 22:01:32,728 - GAugM EPNet train, Epoch [ 27/230]: loss 0.7209, auc 0.4544, ap 0.5421
2024-01-10 22:01:32,820 - GAugM EPNet train, Epoch [ 28/230]: loss 0.7209, auc 0.6004, ap 0.6135
2024-01-10 22:01:32,911 - GAugM EPNet train, Epoch [ 29/230]: loss 0.7210, auc 0.4938, ap 0.4950
2024-01-10 22:01:33,000 - GAugM EPNet train, Epoch [ 30/230]: loss 0.7209, auc 0.4913, ap 0.5184
2024-01-10 22:01:33,090 - GAugM EPNet train, Epoch [ 31/230]: loss 0.7208, auc 0.4891, ap 0.4937
2024-01-10 22:01:33,177 - GAugM EPNet train, Epoch [ 32/230]: loss 0.7210, auc 0.5990, ap 0.5707
2024-01-10 22:01:33,265 - GAugM EPNet train, Epoch [ 33/230]: loss 0.7209, auc 0.4676, ap 0.4907
2024-01-10 22:01:33,352 - GAugM EPNet train, Epoch [ 34/230]: loss 0.7209, auc 0.4632, ap 0.4919
2024-01-10 22:01:33,440 - GAugM EPNet train, Epoch [ 35/230]: loss 0.7209, auc 0.5447, ap 0.5302
2024-01-10 22:01:33,534 - GAugM EPNet train, Epoch [ 36/230]: loss 0.7209, auc 0.5931, ap 0.6014
2024-01-10 22:01:33,619 - GAugM EPNet train, Epoch [ 37/230]: loss 0.7209, auc 0.5078, ap 0.5263
2024-01-10 22:01:33,698 - GAugM EPNet train, Epoch [ 38/230]: loss 0.7209, auc 0.5247, ap 0.5053
2024-01-10 22:01:33,776 - GAugM EPNet train, Epoch [ 39/230]: loss 0.7208, auc 0.4178, ap 0.4738
2024-01-10 22:01:33,858 - GAugM EPNet train, Epoch [ 40/230]: loss 0.7210, auc 0.5701, ap 0.5434
2024-01-10 22:01:33,937 - GAugM EPNet train, Epoch [ 41/230]: loss 0.7210, auc 0.5548, ap 0.5670
2024-01-10 22:01:34,018 - GAugM EPNet train, Epoch [ 42/230]: loss 0.7209, auc 0.5840, ap 0.5849
2024-01-10 22:01:34,097 - GAugM EPNet train, Epoch [ 43/230]: loss 0.7208, auc 0.4639, ap 0.5055
2024-01-10 22:01:34,185 - GAugM EPNet train, Epoch [ 44/230]: loss 0.7208, auc 0.3387, ap 0.4051
2024-01-10 22:01:34,274 - GAugM EPNet train, Epoch [ 45/230]: loss 0.7209, auc 0.4738, ap 0.5087
2024-01-10 22:01:34,366 - GAugM EPNet train, Epoch [ 46/230]: loss 0.7209, auc 0.4112, ap 0.4531
2024-01-10 22:01:34,457 - GAugM EPNet train, Epoch [ 47/230]: loss 0.7210, auc 0.5331, ap 0.5424
2024-01-10 22:01:34,547 - GAugM EPNet train, Epoch [ 48/230]: loss 0.7210, auc 0.5700, ap 0.5955
2024-01-10 22:01:34,634 - GAugM EPNet train, Epoch [ 49/230]: loss 0.7209, auc 0.5315, ap 0.5390
2024-01-10 22:01:34,724 - GAugM EPNet train, Epoch [ 50/230]: loss 0.7210, auc 0.4692, ap 0.4899
2024-01-10 22:01:34,809 - GAugM EPNet train, Epoch [ 51/230]: loss 0.7210, auc 0.4907, ap 0.5051
2024-01-10 22:01:34,900 - GAugM EPNet train, Epoch [ 52/230]: loss 0.7209, auc 0.4183, ap 0.4896
2024-01-10 22:01:34,993 - GAugM EPNet train, Epoch [ 53/230]: loss 0.7209, auc 0.5550, ap 0.5980
2024-01-10 22:01:35,084 - GAugM EPNet train, Epoch [ 54/230]: loss 0.7211, auc 0.5716, ap 0.5628
2024-01-10 22:01:35,170 - GAugM EPNet train, Epoch [ 55/230]: loss 0.7209, auc 0.5605, ap 0.5632
2024-01-10 22:01:35,259 - GAugM EPNet train, Epoch [ 56/230]: loss 0.7208, auc 0.4316, ap 0.4524
2024-01-10 22:01:35,350 - GAugM EPNet train, Epoch [ 57/230]: loss 0.7209, auc 0.5112, ap 0.4952
2024-01-10 22:01:35,438 - GAugM EPNet train, Epoch [ 58/230]: loss 0.7210, auc 0.4519, ap 0.5161
2024-01-10 22:01:35,525 - GAugM EPNet train, Epoch [ 59/230]: loss 0.7211, auc 0.5027, ap 0.5275
2024-01-10 22:01:35,613 - GAugM EPNet train, Epoch [ 60/230]: loss 0.7210, auc 0.4388, ap 0.4538
2024-01-10 22:01:35,704 - GAugM EPNet train, Epoch [ 61/230]: loss 0.7209, auc 0.5050, ap 0.5001
2024-01-10 22:01:35,789 - GAugM EPNet train, Epoch [ 62/230]: loss 0.7210, auc 0.5247, ap 0.5514
2024-01-10 22:01:35,877 - GAugM EPNet train, Epoch [ 63/230]: loss 0.7208, auc 0.4315, ap 0.4503
2024-01-10 22:01:35,964 - GAugM EPNet train, Epoch [ 64/230]: loss 0.7208, auc 0.3921, ap 0.4677
2024-01-10 22:01:36,050 - GAugM EPNet train, Epoch [ 65/230]: loss 0.7208, auc 0.5920, ap 0.6059
2024-01-10 22:01:36,140 - GAugM EPNet train, Epoch [ 66/230]: loss 0.7209, auc 0.4160, ap 0.4593
2024-01-10 22:01:36,227 - GAugM EPNet train, Epoch [ 67/230]: loss 0.7209, auc 0.4856, ap 0.5205
2024-01-10 22:01:36,315 - GAugM EPNet train, Epoch [ 68/230]: loss 0.7210, auc 0.5164, ap 0.5671
2024-01-10 22:01:36,412 - GAugM EPNet train, Epoch [ 69/230]: loss 0.7210, auc 0.5201, ap 0.5542
2024-01-10 22:01:36,498 - GAugM EPNet train, Epoch [ 70/230]: loss 0.7210, auc 0.4680, ap 0.4757
2024-01-10 22:01:36,583 - GAugM EPNet train, Epoch [ 71/230]: loss 0.7210, auc 0.4662, ap 0.4770
2024-01-10 22:01:36,670 - GAugM EPNet train, Epoch [ 72/230]: loss 0.7210, auc 0.4518, ap 0.5152
2024-01-10 22:01:36,762 - GAugM EPNet train, Epoch [ 73/230]: loss 0.7209, auc 0.5965, ap 0.5548
2024-01-10 22:01:36,847 - GAugM EPNet train, Epoch [ 74/230]: loss 0.7209, auc 0.4676, ap 0.5091
2024-01-10 22:01:36,931 - GAugM EPNet train, Epoch [ 75/230]: loss 0.7210, auc 0.5256, ap 0.5360
2024-01-10 22:01:37,016 - GAugM EPNet train, Epoch [ 76/230]: loss 0.7209, auc 0.4888, ap 0.5110
2024-01-10 22:01:37,104 - GAugM EPNet train, Epoch [ 77/230]: loss 0.7208, auc 0.5548, ap 0.5582
2024-01-10 22:01:37,190 - GAugM EPNet train, Epoch [ 78/230]: loss 0.7209, auc 0.5061, ap 0.5083
2024-01-10 22:01:37,276 - GAugM EPNet train, Epoch [ 79/230]: loss 0.7208, auc 0.5271, ap 0.5547
2024-01-10 22:01:37,365 - GAugM EPNet train, Epoch [ 80/230]: loss 0.7209, auc 0.6228, ap 0.5769
2024-01-10 22:01:37,456 - GAugM EPNet train, Epoch [ 81/230]: loss 0.7209, auc 0.4112, ap 0.4467
2024-01-10 22:01:37,542 - GAugM EPNet train, Epoch [ 82/230]: loss 0.7210, auc 0.6020, ap 0.5658
2024-01-10 22:01:37,630 - GAugM EPNet train, Epoch [ 83/230]: loss 0.7209, auc 0.4446, ap 0.4827
2024-01-10 22:01:37,721 - GAugM EPNet train, Epoch [ 84/230]: loss 0.7209, auc 0.4322, ap 0.4470
2024-01-10 22:01:37,809 - GAugM EPNet train, Epoch [ 85/230]: loss 0.7210, auc 0.4274, ap 0.5018
2024-01-10 22:01:37,896 - GAugM EPNet train, Epoch [ 86/230]: loss 0.7208, auc 0.4717, ap 0.4845
2024-01-10 22:01:37,980 - GAugM EPNet train, Epoch [ 87/230]: loss 0.7209, auc 0.5443, ap 0.5003
2024-01-10 22:01:38,073 - GAugM EPNet train, Epoch [ 88/230]: loss 0.7210, auc 0.4724, ap 0.5355
2024-01-10 22:01:38,162 - GAugM EPNet train, Epoch [ 89/230]: loss 0.7210, auc 0.4721, ap 0.4946
2024-01-10 22:01:38,253 - GAugM EPNet train, Epoch [ 90/230]: loss 0.7209, auc 0.4555, ap 0.4758
2024-01-10 22:01:38,337 - GAugM EPNet train, Epoch [ 91/230]: loss 0.7208, auc 0.5449, ap 0.5205
2024-01-10 22:01:38,424 - GAugM EPNet train, Epoch [ 92/230]: loss 0.7209, auc 0.6209, ap 0.6076
2024-01-10 22:01:38,509 - GAugM EPNet train, Epoch [ 93/230]: loss 0.7209, auc 0.4308, ap 0.4655
2024-01-10 22:01:38,601 - GAugM EPNet train, Epoch [ 94/230]: loss 0.7210, auc 0.4197, ap 0.4822
2024-01-10 22:01:38,685 - GAugM EPNet train, Epoch [ 95/230]: loss 0.7210, auc 0.4459, ap 0.5004
2024-01-10 22:01:38,773 - GAugM EPNet train, Epoch [ 96/230]: loss 0.7209, auc 0.5278, ap 0.5382
2024-01-10 22:01:38,860 - GAugM EPNet train, Epoch [ 97/230]: loss 0.7209, auc 0.4667, ap 0.5002
2024-01-10 22:01:38,942 - GAugM EPNet train, Epoch [ 98/230]: loss 0.7209, auc 0.4763, ap 0.4780
2024-01-10 22:01:39,028 - GAugM EPNet train, Epoch [ 99/230]: loss 0.7209, auc 0.3604, ap 0.4485
2024-01-10 22:01:39,114 - GAugM EPNet train, Epoch [100/230]: loss 0.7210, auc 0.5080, ap 0.5499
2024-01-10 22:01:39,198 - GAugM EPNet train, Epoch [101/230]: loss 0.7210, auc 0.5342, ap 0.5951
2024-01-10 22:01:39,293 - GAugM EPNet train, Epoch [102/230]: loss 0.7209, auc 0.4288, ap 0.4753
2024-01-10 22:01:39,377 - GAugM EPNet train, Epoch [103/230]: loss 0.7209, auc 0.4414, ap 0.5108
2024-01-10 22:01:39,460 - GAugM EPNet train, Epoch [104/230]: loss 0.7209, auc 0.4477, ap 0.5009
2024-01-10 22:01:39,543 - GAugM EPNet train, Epoch [105/230]: loss 0.7209, auc 0.3895, ap 0.4299
2024-01-10 22:01:39,629 - GAugM EPNet train, Epoch [106/230]: loss 0.7210, auc 0.4986, ap 0.4980
2024-01-10 22:01:39,712 - GAugM EPNet train, Epoch [107/230]: loss 0.7210, auc 0.4637, ap 0.5347
2024-01-10 22:01:39,803 - GAugM EPNet train, Epoch [108/230]: loss 0.7208, auc 0.5653, ap 0.5604
2024-01-10 22:01:39,889 - GAugM EPNet train, Epoch [109/230]: loss 0.7210, auc 0.4632, ap 0.4738
2024-01-10 22:01:39,973 - GAugM EPNet train, Epoch [110/230]: loss 0.7209, auc 0.5452, ap 0.5652
2024-01-10 22:01:40,057 - GAugM EPNet train, Epoch [111/230]: loss 0.7210, auc 0.5176, ap 0.5461
2024-01-10 22:01:40,143 - GAugM EPNet train, Epoch [112/230]: loss 0.7209, auc 0.5146, ap 0.5244
2024-01-10 22:01:40,227 - GAugM EPNet train, Epoch [113/230]: loss 0.7210, auc 0.4539, ap 0.5049
2024-01-10 22:01:40,316 - GAugM EPNet train, Epoch [114/230]: loss 0.7209, auc 0.4806, ap 0.4890
2024-01-10 22:01:40,402 - GAugM EPNet train, Epoch [115/230]: loss 0.7210, auc 0.5096, ap 0.5456
2024-01-10 22:01:40,485 - GAugM EPNet train, Epoch [116/230]: loss 0.7209, auc 0.5619, ap 0.5750
2024-01-10 22:01:40,576 - GAugM EPNet train, Epoch [117/230]: loss 0.7208, auc 0.4507, ap 0.4920
2024-01-10 22:01:40,662 - GAugM EPNet train, Epoch [118/230]: loss 0.7209, auc 0.4356, ap 0.4530
2024-01-10 22:01:40,746 - GAugM EPNet train, Epoch [119/230]: loss 0.7209, auc 0.5762, ap 0.6069
2024-01-10 22:01:40,835 - GAugM EPNet train, Epoch [120/230]: loss 0.7210, auc 0.3994, ap 0.4406
2024-01-10 22:01:40,920 - GAugM EPNet train, Epoch [121/230]: loss 0.7210, auc 0.4662, ap 0.4830
2024-01-10 22:01:41,002 - GAugM EPNet train, Epoch [122/230]: loss 0.7209, auc 0.4802, ap 0.4888
2024-01-10 22:01:41,088 - GAugM EPNet train, Epoch [123/230]: loss 0.7209, auc 0.5281, ap 0.5972
2024-01-10 22:01:41,171 - GAugM EPNet train, Epoch [124/230]: loss 0.7210, auc 0.4920, ap 0.4871
2024-01-10 22:01:41,257 - GAugM EPNet train, Epoch [125/230]: loss 0.7209, auc 0.4785, ap 0.5131
2024-01-10 22:01:41,344 - GAugM EPNet train, Epoch [126/230]: loss 0.7210, auc 0.4705, ap 0.4824
2024-01-10 22:01:41,428 - GAugM EPNet train, Epoch [127/230]: loss 0.7209, auc 0.4907, ap 0.4907
2024-01-10 22:01:41,518 - GAugM EPNet train, Epoch [128/230]: loss 0.7210, auc 0.5983, ap 0.6058
2024-01-10 22:01:41,604 - GAugM EPNet train, Epoch [129/230]: loss 0.7208, auc 0.4028, ap 0.4502
2024-01-10 22:01:41,691 - GAugM EPNet train, Epoch [130/230]: loss 0.7210, auc 0.5352, ap 0.5318
2024-01-10 22:01:41,777 - GAugM EPNet train, Epoch [131/230]: loss 0.7210, auc 0.5130, ap 0.5417
2024-01-10 22:01:41,861 - GAugM EPNet train, Epoch [132/230]: loss 0.7209, auc 0.5945, ap 0.5537
2024-01-10 22:01:41,952 - GAugM EPNet train, Epoch [133/230]: loss 0.7209, auc 0.5125, ap 0.5623
2024-01-10 22:01:42,037 - GAugM EPNet train, Epoch [134/230]: loss 0.7210, auc 0.4671, ap 0.4978
2024-01-10 22:01:42,122 - GAugM EPNet train, Epoch [135/230]: loss 0.7209, auc 0.3932, ap 0.4338
2024-01-10 22:01:42,207 - GAugM EPNet train, Epoch [136/230]: loss 0.7209, auc 0.5146, ap 0.5034
2024-01-10 22:01:42,293 - GAugM EPNet train, Epoch [137/230]: loss 0.7210, auc 0.4496, ap 0.4817
2024-01-10 22:01:42,379 - GAugM EPNet train, Epoch [138/230]: loss 0.7210, auc 0.4874, ap 0.4988
2024-01-10 22:01:42,465 - GAugM EPNet train, Epoch [139/230]: loss 0.7210, auc 0.5411, ap 0.5623
2024-01-10 22:01:42,550 - GAugM EPNet train, Epoch [140/230]: loss 0.7209, auc 0.5354, ap 0.5885
2024-01-10 22:01:42,636 - GAugM EPNet train, Epoch [141/230]: loss 0.7209, auc 0.4505, ap 0.4719
2024-01-10 22:01:42,723 - GAugM EPNet train, Epoch [142/230]: loss 0.7209, auc 0.4872, ap 0.5283
2024-01-10 22:01:42,808 - GAugM EPNet train, Epoch [143/230]: loss 0.7209, auc 0.4179, ap 0.4592
2024-01-10 22:01:42,891 - GAugM EPNet train, Epoch [144/230]: loss 0.7209, auc 0.4544, ap 0.4607
2024-01-10 22:01:42,974 - GAugM EPNet train, Epoch [145/230]: loss 0.7209, auc 0.4683, ap 0.5025
2024-01-10 22:01:43,056 - GAugM EPNet train, Epoch [146/230]: loss 0.7209, auc 0.5344, ap 0.5344
2024-01-10 22:01:43,140 - GAugM EPNet train, Epoch [147/230]: loss 0.7209, auc 0.6045, ap 0.6344
2024-01-10 22:01:43,225 - GAugM EPNet train, Epoch [148/230]: loss 0.7209, auc 0.4993, ap 0.5220
2024-01-10 22:01:43,308 - GAugM EPNet train, Epoch [149/230]: loss 0.7208, auc 0.5262, ap 0.5396
2024-01-10 22:01:43,392 - GAugM EPNet train, Epoch [150/230]: loss 0.7209, auc 0.5274, ap 0.5565
2024-01-10 22:01:43,480 - GAugM EPNet train, Epoch [151/230]: loss 0.7209, auc 0.5477, ap 0.5124
2024-01-10 22:01:43,563 - GAugM EPNet train, Epoch [152/230]: loss 0.7209, auc 0.5810, ap 0.5608
2024-01-10 22:01:43,651 - GAugM EPNet train, Epoch [153/230]: loss 0.7209, auc 0.4977, ap 0.5322
2024-01-10 22:01:43,734 - GAugM EPNet train, Epoch [154/230]: loss 0.7209, auc 0.5440, ap 0.5616
2024-01-10 22:01:43,818 - GAugM EPNet train, Epoch [155/230]: loss 0.7209, auc 0.5837, ap 0.5753
2024-01-10 22:01:43,908 - GAugM EPNet train, Epoch [156/230]: loss 0.7209, auc 0.4272, ap 0.4496
2024-01-10 22:01:43,992 - GAugM EPNet train, Epoch [157/230]: loss 0.7209, auc 0.5253, ap 0.5157
2024-01-10 22:01:44,075 - GAugM EPNet train, Epoch [158/230]: loss 0.7208, auc 0.4381, ap 0.4626
2024-01-10 22:01:44,158 - GAugM EPNet train, Epoch [159/230]: loss 0.7208, auc 0.4893, ap 0.5100
2024-01-10 22:01:44,246 - GAugM EPNet train, Epoch [160/230]: loss 0.7209, auc 0.5578, ap 0.5512
2024-01-10 22:01:44,331 - GAugM EPNet train, Epoch [161/230]: loss 0.7209, auc 0.5762, ap 0.5842
2024-01-10 22:01:44,415 - GAugM EPNet train, Epoch [162/230]: loss 0.7209, auc 0.4138, ap 0.4383
2024-01-10 22:01:44,498 - GAugM EPNet train, Epoch [163/230]: loss 0.7209, auc 0.4197, ap 0.4422
2024-01-10 22:01:44,581 - GAugM EPNet train, Epoch [164/230]: loss 0.7211, auc 0.5520, ap 0.5501
2024-01-10 22:01:44,679 - GAugM EPNet train, Epoch [165/230]: loss 0.7210, auc 0.4206, ap 0.4758
2024-01-10 22:01:44,764 - GAugM EPNet train, Epoch [166/230]: loss 0.7208, auc 0.5233, ap 0.5498
2024-01-10 22:01:44,846 - GAugM EPNet train, Epoch [167/230]: loss 0.7209, auc 0.4181, ap 0.4658
2024-01-10 22:01:44,928 - GAugM EPNet train, Epoch [168/230]: loss 0.7209, auc 0.4680, ap 0.5230
2024-01-10 22:01:45,010 - GAugM EPNet train, Epoch [169/230]: loss 0.7209, auc 0.5310, ap 0.5535
2024-01-10 22:01:45,093 - GAugM EPNet train, Epoch [170/230]: loss 0.7210, auc 0.4338, ap 0.4506
2024-01-10 22:01:45,176 - GAugM EPNet train, Epoch [171/230]: loss 0.7209, auc 0.4334, ap 0.4711
2024-01-10 22:01:45,259 - GAugM EPNet train, Epoch [172/230]: loss 0.7208, auc 0.4272, ap 0.4709
2024-01-10 22:01:45,344 - GAugM EPNet train, Epoch [173/230]: loss 0.7209, auc 0.4607, ap 0.4676
2024-01-10 22:01:45,432 - GAugM EPNet train, Epoch [174/230]: loss 0.7209, auc 0.4583, ap 0.4788
2024-01-10 22:01:45,516 - GAugM EPNet train, Epoch [175/230]: loss 0.7209, auc 0.5705, ap 0.5593
2024-01-10 22:01:45,599 - GAugM EPNet train, Epoch [176/230]: loss 0.7209, auc 0.4872, ap 0.5009
2024-01-10 22:01:45,681 - GAugM EPNet train, Epoch [177/230]: loss 0.7210, auc 0.4950, ap 0.5028
2024-01-10 22:01:45,766 - GAugM EPNet train, Epoch [178/230]: loss 0.7210, auc 0.5643, ap 0.6028
2024-01-10 22:01:45,849 - GAugM EPNet train, Epoch [179/230]: loss 0.7210, auc 0.3839, ap 0.4624
2024-01-10 22:01:45,932 - GAugM EPNet train, Epoch [180/230]: loss 0.7210, auc 0.5096, ap 0.5713
2024-01-10 22:01:46,020 - GAugM EPNet train, Epoch [181/230]: loss 0.7209, auc 0.4701, ap 0.4821
2024-01-10 22:01:46,105 - GAugM EPNet train, Epoch [182/230]: loss 0.7209, auc 0.4119, ap 0.4701
2024-01-10 22:01:46,191 - GAugM EPNet train, Epoch [183/230]: loss 0.7210, auc 0.5749, ap 0.5888
2024-01-10 22:01:46,274 - GAugM EPNet train, Epoch [184/230]: loss 0.7209, auc 0.4389, ap 0.4641
2024-01-10 22:01:46,357 - GAugM EPNet train, Epoch [185/230]: loss 0.7209, auc 0.4772, ap 0.5131
2024-01-10 22:01:46,446 - GAugM EPNet train, Epoch [186/230]: loss 0.7208, auc 0.4792, ap 0.5222
2024-01-10 22:01:46,528 - GAugM EPNet train, Epoch [187/230]: loss 0.7209, auc 0.4879, ap 0.5153
2024-01-10 22:01:46,611 - GAugM EPNet train, Epoch [188/230]: loss 0.7209, auc 0.4160, ap 0.4590
2024-01-10 22:01:46,694 - GAugM EPNet train, Epoch [189/230]: loss 0.7209, auc 0.6257, ap 0.6207
2024-01-10 22:01:46,776 - GAugM EPNet train, Epoch [190/230]: loss 0.7209, auc 0.4939, ap 0.5128
2024-01-10 22:01:46,867 - GAugM EPNet train, Epoch [191/230]: loss 0.7209, auc 0.5491, ap 0.5495
2024-01-10 22:01:46,950 - GAugM EPNet train, Epoch [192/230]: loss 0.7209, auc 0.5459, ap 0.4931
2024-01-10 22:01:47,036 - GAugM EPNet train, Epoch [193/230]: loss 0.7209, auc 0.5139, ap 0.5114
2024-01-10 22:01:47,120 - GAugM EPNet train, Epoch [194/230]: loss 0.7209, auc 0.5404, ap 0.5651
2024-01-10 22:01:47,206 - GAugM EPNet train, Epoch [195/230]: loss 0.7209, auc 0.4779, ap 0.4746
2024-01-10 22:01:47,290 - GAugM EPNet train, Epoch [196/230]: loss 0.7208, auc 0.4973, ap 0.5011
2024-01-10 22:01:47,373 - GAugM EPNet train, Epoch [197/230]: loss 0.7210, auc 0.4776, ap 0.4891
2024-01-10 22:01:47,462 - GAugM EPNet train, Epoch [198/230]: loss 0.7210, auc 0.5518, ap 0.5578
2024-01-10 22:01:47,550 - GAugM EPNet train, Epoch [199/230]: loss 0.7209, auc 0.5386, ap 0.5461
2024-01-10 22:01:47,634 - GAugM EPNet train, Epoch [200/230]: loss 0.7210, auc 0.5488, ap 0.5212
2024-01-10 22:01:47,719 - GAugM EPNet train, Epoch [201/230]: loss 0.7209, auc 0.4884, ap 0.5087
2024-01-10 22:01:47,805 - GAugM EPNet train, Epoch [202/230]: loss 0.7210, auc 0.5878, ap 0.5986
2024-01-10 22:01:47,893 - GAugM EPNet train, Epoch [203/230]: loss 0.7210, auc 0.5559, ap 0.5850
2024-01-10 22:01:47,977 - GAugM EPNet train, Epoch [204/230]: loss 0.7209, auc 0.4544, ap 0.4696
2024-01-10 22:01:48,062 - GAugM EPNet train, Epoch [205/230]: loss 0.7209, auc 0.4429, ap 0.4984
2024-01-10 22:01:48,144 - GAugM EPNet train, Epoch [206/230]: loss 0.7209, auc 0.4397, ap 0.4772
2024-01-10 22:01:48,231 - GAugM EPNet train, Epoch [207/230]: loss 0.7210, auc 0.4217, ap 0.4717
2024-01-10 22:01:48,313 - GAugM EPNet train, Epoch [208/230]: loss 0.7209, auc 0.4769, ap 0.5564
2024-01-10 22:01:48,394 - GAugM EPNet train, Epoch [209/230]: loss 0.7210, auc 0.6299, ap 0.6333
2024-01-10 22:01:48,478 - GAugM EPNet train, Epoch [210/230]: loss 0.7209, auc 0.5393, ap 0.5197
2024-01-10 22:01:48,561 - GAugM EPNet train, Epoch [211/230]: loss 0.7210, auc 0.5255, ap 0.5328
2024-01-10 22:01:48,644 - GAugM EPNet train, Epoch [212/230]: loss 0.7210, auc 0.5057, ap 0.5289
2024-01-10 22:01:48,727 - GAugM EPNet train, Epoch [213/230]: loss 0.7208, auc 0.5676, ap 0.5713
2024-01-10 22:01:48,815 - GAugM EPNet train, Epoch [214/230]: loss 0.7210, auc 0.4639, ap 0.4808
2024-01-10 22:01:48,898 - GAugM EPNet train, Epoch [215/230]: loss 0.7210, auc 0.5101, ap 0.5217
2024-01-10 22:01:48,982 - GAugM EPNet train, Epoch [216/230]: loss 0.7209, auc 0.5344, ap 0.5489
2024-01-10 22:01:49,066 - GAugM EPNet train, Epoch [217/230]: loss 0.7209, auc 0.5239, ap 0.5869
2024-01-10 22:01:49,151 - GAugM EPNet train, Epoch [218/230]: loss 0.7209, auc 0.5044, ap 0.5469
2024-01-10 22:01:49,240 - GAugM EPNet train, Epoch [219/230]: loss 0.7208, auc 0.4580, ap 0.4789
2024-01-10 22:01:49,323 - GAugM EPNet train, Epoch [220/230]: loss 0.7210, auc 0.4224, ap 0.4696
2024-01-10 22:01:49,405 - GAugM EPNet train, Epoch [221/230]: loss 0.7209, auc 0.5135, ap 0.5031
2024-01-10 22:01:49,489 - GAugM EPNet train, Epoch [222/230]: loss 0.7209, auc 0.5089, ap 0.5152
2024-01-10 22:01:49,577 - GAugM EPNet train, Epoch [223/230]: loss 0.7209, auc 0.5901, ap 0.6019
2024-01-10 22:01:49,672 - GAugM EPNet train, Epoch [224/230]: loss 0.7210, auc 0.4834, ap 0.4828
2024-01-10 22:01:49,755 - GAugM EPNet train, Epoch [225/230]: loss 0.7209, auc 0.4110, ap 0.4492
2024-01-10 22:01:49,837 - GAugM EPNet train, Epoch [226/230]: loss 0.7210, auc 0.3984, ap 0.4531
2024-01-10 22:01:49,919 - GAugM EPNet train, Epoch [227/230]: loss 0.7210, auc 0.4541, ap 0.4684
2024-01-10 22:01:50,001 - GAugM EPNet train, Epoch [228/230]: loss 0.7209, auc 0.4811, ap 0.5128
2024-01-10 22:01:50,083 - GAugM EPNet train, Epoch [229/230]: loss 0.7209, auc 0.6015, ap 0.6325
2024-01-10 22:01:50,167 - GAugM EPNet train, Epoch [230/230]: loss 0.7209, auc 0.4502, ap 0.4876
2024-01-10 22:01:50,167 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0dd5a0bc50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:01:50,892 - GAugM EPNet train, Epoch [  1/230]: loss 0.7210, auc 0.5044, ap 0.4926
2024-01-10 22:01:50,978 - GAugM EPNet train, Epoch [  2/230]: loss 0.7210, auc 0.4818, ap 0.4778
2024-01-10 22:01:51,065 - GAugM EPNet train, Epoch [  3/230]: loss 0.7209, auc 0.5899, ap 0.5979
2024-01-10 22:01:51,156 - GAugM EPNet train, Epoch [  4/230]: loss 0.7209, auc 0.5150, ap 0.5450
2024-01-10 22:01:51,240 - GAugM EPNet train, Epoch [  5/230]: loss 0.7209, auc 0.5817, ap 0.5542
2024-01-10 22:01:51,327 - GAugM EPNet train, Epoch [  6/230]: loss 0.7209, auc 0.4300, ap 0.4884
2024-01-10 22:01:51,412 - GAugM EPNet train, Epoch [  7/230]: loss 0.7209, auc 0.4986, ap 0.4753
2024-01-10 22:01:51,498 - GAugM EPNet train, Epoch [  8/230]: loss 0.7210, auc 0.5886, ap 0.5463
2024-01-10 22:01:51,590 - GAugM EPNet train, Epoch [  9/230]: loss 0.7209, auc 0.4745, ap 0.4734
2024-01-10 22:01:51,674 - GAugM EPNet train, Epoch [ 10/230]: loss 0.7208, auc 0.4902, ap 0.4904
2024-01-10 22:01:51,758 - GAugM EPNet train, Epoch [ 11/230]: loss 0.7209, auc 0.4870, ap 0.4885
2024-01-10 22:01:51,843 - GAugM EPNet train, Epoch [ 12/230]: loss 0.7210, auc 0.5139, ap 0.5193
2024-01-10 22:01:51,927 - GAugM EPNet train, Epoch [ 13/230]: loss 0.7209, auc 0.6016, ap 0.5792
2024-01-10 22:01:52,015 - GAugM EPNet train, Epoch [ 14/230]: loss 0.7209, auc 0.4890, ap 0.4715
2024-01-10 22:01:52,102 - GAugM EPNet train, Epoch [ 15/230]: loss 0.7210, auc 0.3485, ap 0.4294
2024-01-10 22:01:52,190 - GAugM EPNet train, Epoch [ 16/230]: loss 0.7209, auc 0.5281, ap 0.5184
2024-01-10 22:01:52,275 - GAugM EPNet train, Epoch [ 17/230]: loss 0.7210, auc 0.5411, ap 0.5065
2024-01-10 22:01:52,365 - GAugM EPNet train, Epoch [ 18/230]: loss 0.7210, auc 0.6493, ap 0.6058
2024-01-10 22:01:52,448 - GAugM EPNet train, Epoch [ 19/230]: loss 0.7209, auc 0.5911, ap 0.5419
2024-01-10 22:01:52,537 - GAugM EPNet train, Epoch [ 20/230]: loss 0.7210, auc 0.4849, ap 0.5061
2024-01-10 22:01:52,622 - GAugM EPNet train, Epoch [ 21/230]: loss 0.7209, auc 0.4770, ap 0.4688
2024-01-10 22:01:52,710 - GAugM EPNet train, Epoch [ 22/230]: loss 0.7210, auc 0.4098, ap 0.4400
2024-01-10 22:01:52,795 - GAugM EPNet train, Epoch [ 23/230]: loss 0.7208, auc 0.5351, ap 0.5038
2024-01-10 22:01:52,880 - GAugM EPNet train, Epoch [ 24/230]: loss 0.7209, auc 0.5591, ap 0.5194
2024-01-10 22:01:52,969 - GAugM EPNet train, Epoch [ 25/230]: loss 0.7209, auc 0.4781, ap 0.4987
2024-01-10 22:01:53,054 - GAugM EPNet train, Epoch [ 26/230]: loss 0.7210, auc 0.4891, ap 0.4879
2024-01-10 22:01:53,142 - GAugM EPNet train, Epoch [ 27/230]: loss 0.7209, auc 0.4211, ap 0.4618
2024-01-10 22:01:53,230 - GAugM EPNet train, Epoch [ 28/230]: loss 0.7209, auc 0.6171, ap 0.6309
2024-01-10 22:01:53,326 - GAugM EPNet train, Epoch [ 29/230]: loss 0.7210, auc 0.4785, ap 0.4795
2024-01-10 22:01:53,411 - GAugM EPNet train, Epoch [ 30/230]: loss 0.7209, auc 0.5078, ap 0.4997
2024-01-10 22:01:53,500 - GAugM EPNet train, Epoch [ 31/230]: loss 0.7208, auc 0.4968, ap 0.4955
2024-01-10 22:01:53,588 - GAugM EPNet train, Epoch [ 32/230]: loss 0.7210, auc 0.5918, ap 0.5512
2024-01-10 22:01:53,682 - GAugM EPNet train, Epoch [ 33/230]: loss 0.7209, auc 0.5924, ap 0.5700
2024-01-10 22:01:53,765 - GAugM EPNet train, Epoch [ 34/230]: loss 0.7209, auc 0.4546, ap 0.4745
2024-01-10 22:01:53,850 - GAugM EPNet train, Epoch [ 35/230]: loss 0.7209, auc 0.5783, ap 0.5399
2024-01-10 22:01:53,934 - GAugM EPNet train, Epoch [ 36/230]: loss 0.7209, auc 0.5361, ap 0.5344
2024-01-10 22:01:54,022 - GAugM EPNet train, Epoch [ 37/230]: loss 0.7209, auc 0.4283, ap 0.4561
2024-01-10 22:01:54,107 - GAugM EPNet train, Epoch [ 38/230]: loss 0.7209, auc 0.4489, ap 0.4529
2024-01-10 22:01:54,190 - GAugM EPNet train, Epoch [ 39/230]: loss 0.7208, auc 0.4455, ap 0.4828
2024-01-10 22:01:54,280 - GAugM EPNet train, Epoch [ 40/230]: loss 0.7210, auc 0.6070, ap 0.5700
2024-01-10 22:01:54,370 - GAugM EPNet train, Epoch [ 41/230]: loss 0.7210, auc 0.4236, ap 0.4486
2024-01-10 22:01:54,463 - GAugM EPNet train, Epoch [ 42/230]: loss 0.7209, auc 0.5386, ap 0.5384
2024-01-10 22:01:54,555 - GAugM EPNet train, Epoch [ 43/230]: loss 0.7208, auc 0.5062, ap 0.5059
2024-01-10 22:01:54,644 - GAugM EPNet train, Epoch [ 44/230]: loss 0.7208, auc 0.3820, ap 0.4448
2024-01-10 22:01:54,739 - GAugM EPNet train, Epoch [ 45/230]: loss 0.7209, auc 0.5235, ap 0.5168
2024-01-10 22:01:54,827 - GAugM EPNet train, Epoch [ 46/230]: loss 0.7209, auc 0.4701, ap 0.4968
2024-01-10 22:01:54,916 - GAugM EPNet train, Epoch [ 47/230]: loss 0.7210, auc 0.4920, ap 0.4962
2024-01-10 22:01:55,004 - GAugM EPNet train, Epoch [ 48/230]: loss 0.7210, auc 0.5602, ap 0.5581
2024-01-10 22:01:55,092 - GAugM EPNet train, Epoch [ 49/230]: loss 0.7209, auc 0.5262, ap 0.5292
2024-01-10 22:01:55,176 - GAugM EPNet train, Epoch [ 50/230]: loss 0.7210, auc 0.5803, ap 0.5583
2024-01-10 22:01:55,264 - GAugM EPNet train, Epoch [ 51/230]: loss 0.7210, auc 0.4993, ap 0.4976
2024-01-10 22:01:55,351 - GAugM EPNet train, Epoch [ 52/230]: loss 0.7209, auc 0.4473, ap 0.4696
2024-01-10 22:01:55,438 - GAugM EPNet train, Epoch [ 53/230]: loss 0.7209, auc 0.5037, ap 0.5204
2024-01-10 22:01:55,527 - GAugM EPNet train, Epoch [ 54/230]: loss 0.7211, auc 0.5543, ap 0.5399
2024-01-10 22:01:55,619 - GAugM EPNet train, Epoch [ 55/230]: loss 0.7209, auc 0.6331, ap 0.5953
2024-01-10 22:01:55,707 - GAugM EPNet train, Epoch [ 56/230]: loss 0.7208, auc 0.4737, ap 0.4721
2024-01-10 22:01:55,799 - GAugM EPNet train, Epoch [ 57/230]: loss 0.7209, auc 0.4760, ap 0.4584
2024-01-10 22:01:55,885 - GAugM EPNet train, Epoch [ 58/230]: loss 0.7210, auc 0.4284, ap 0.4916
2024-01-10 22:01:55,972 - GAugM EPNet train, Epoch [ 59/230]: loss 0.7211, auc 0.5299, ap 0.5222
2024-01-10 22:01:56,065 - GAugM EPNet train, Epoch [ 60/230]: loss 0.7210, auc 0.5651, ap 0.5432
2024-01-10 22:01:56,160 - GAugM EPNet train, Epoch [ 61/230]: loss 0.7209, auc 0.5279, ap 0.5319
2024-01-10 22:01:56,250 - GAugM EPNet train, Epoch [ 62/230]: loss 0.7210, auc 0.5999, ap 0.6096
2024-01-10 22:01:56,349 - GAugM EPNet train, Epoch [ 63/230]: loss 0.7208, auc 0.4591, ap 0.4502
2024-01-10 22:01:56,441 - GAugM EPNet train, Epoch [ 64/230]: loss 0.7208, auc 0.4671, ap 0.5029
2024-01-10 22:01:56,535 - GAugM EPNet train, Epoch [ 65/230]: loss 0.7208, auc 0.5347, ap 0.5516
2024-01-10 22:01:56,630 - GAugM EPNet train, Epoch [ 66/230]: loss 0.7209, auc 0.4375, ap 0.4640
2024-01-10 22:01:56,721 - GAugM EPNet train, Epoch [ 67/230]: loss 0.7209, auc 0.5584, ap 0.5236
2024-01-10 22:01:56,809 - GAugM EPNet train, Epoch [ 68/230]: loss 0.7210, auc 0.4941, ap 0.5134
2024-01-10 22:01:56,901 - GAugM EPNet train, Epoch [ 69/230]: loss 0.7210, auc 0.4393, ap 0.4452
2024-01-10 22:01:56,990 - GAugM EPNet train, Epoch [ 70/230]: loss 0.7210, auc 0.5233, ap 0.4993
2024-01-10 22:01:57,086 - GAugM EPNet train, Epoch [ 71/230]: loss 0.7210, auc 0.5543, ap 0.5269
2024-01-10 22:01:57,177 - GAugM EPNet train, Epoch [ 72/230]: loss 0.7210, auc 0.4089, ap 0.4512
2024-01-10 22:01:57,266 - GAugM EPNet train, Epoch [ 73/230]: loss 0.7209, auc 0.5429, ap 0.5023
2024-01-10 22:01:57,356 - GAugM EPNet train, Epoch [ 74/230]: loss 0.7209, auc 0.5532, ap 0.5741
2024-01-10 22:01:57,444 - GAugM EPNet train, Epoch [ 75/230]: loss 0.7210, auc 0.4293, ap 0.4827
2024-01-10 22:01:57,536 - GAugM EPNet train, Epoch [ 76/230]: loss 0.7209, auc 0.5358, ap 0.4982
2024-01-10 22:01:57,624 - GAugM EPNet train, Epoch [ 77/230]: loss 0.7208, auc 0.5109, ap 0.5190
2024-01-10 22:01:57,714 - GAugM EPNet train, Epoch [ 78/230]: loss 0.7209, auc 0.5352, ap 0.5318
2024-01-10 22:01:57,807 - GAugM EPNet train, Epoch [ 79/230]: loss 0.7208, auc 0.4872, ap 0.4745
2024-01-10 22:01:57,897 - GAugM EPNet train, Epoch [ 80/230]: loss 0.7209, auc 0.5354, ap 0.5112
2024-01-10 22:01:57,980 - GAugM EPNet train, Epoch [ 81/230]: loss 0.7209, auc 0.4452, ap 0.4511
2024-01-10 22:01:58,069 - GAugM EPNet train, Epoch [ 82/230]: loss 0.7210, auc 0.5039, ap 0.4891
2024-01-10 22:01:58,161 - GAugM EPNet train, Epoch [ 83/230]: loss 0.7209, auc 0.5091, ap 0.5188
2024-01-10 22:01:58,255 - GAugM EPNet train, Epoch [ 84/230]: loss 0.7209, auc 0.4122, ap 0.4378
2024-01-10 22:01:58,349 - GAugM EPNet train, Epoch [ 85/230]: loss 0.7210, auc 0.4352, ap 0.4500
2024-01-10 22:01:58,444 - GAugM EPNet train, Epoch [ 86/230]: loss 0.7208, auc 0.5037, ap 0.5150
2024-01-10 22:01:58,526 - GAugM EPNet train, Epoch [ 87/230]: loss 0.7209, auc 0.5660, ap 0.5491
2024-01-10 22:01:58,612 - GAugM EPNet train, Epoch [ 88/230]: loss 0.7210, auc 0.5297, ap 0.5024
2024-01-10 22:01:58,709 - GAugM EPNet train, Epoch [ 89/230]: loss 0.7210, auc 0.4443, ap 0.4558
2024-01-10 22:01:58,804 - GAugM EPNet train, Epoch [ 90/230]: loss 0.7209, auc 0.4329, ap 0.5218
2024-01-10 22:01:58,901 - GAugM EPNet train, Epoch [ 91/230]: loss 0.7208, auc 0.4941, ap 0.5020
2024-01-10 22:01:59,000 - GAugM EPNet train, Epoch [ 92/230]: loss 0.7209, auc 0.6488, ap 0.6047
2024-01-10 22:01:59,092 - GAugM EPNet train, Epoch [ 93/230]: loss 0.7209, auc 0.4311, ap 0.4771
2024-01-10 22:01:59,182 - GAugM EPNet train, Epoch [ 94/230]: loss 0.7210, auc 0.4019, ap 0.4566
2024-01-10 22:01:59,274 - GAugM EPNet train, Epoch [ 95/230]: loss 0.7210, auc 0.4980, ap 0.5128
2024-01-10 22:01:59,363 - GAugM EPNet train, Epoch [ 96/230]: loss 0.7209, auc 0.5749, ap 0.5492
2024-01-10 22:01:59,450 - GAugM EPNet train, Epoch [ 97/230]: loss 0.7209, auc 0.4300, ap 0.4548
2024-01-10 22:01:59,540 - GAugM EPNet train, Epoch [ 98/230]: loss 0.7209, auc 0.4491, ap 0.4735
2024-01-10 22:01:59,630 - GAugM EPNet train, Epoch [ 99/230]: loss 0.7209, auc 0.4457, ap 0.4941
2024-01-10 22:01:59,718 - GAugM EPNet train, Epoch [100/230]: loss 0.7210, auc 0.5041, ap 0.5107
2024-01-10 22:01:59,809 - GAugM EPNet train, Epoch [101/230]: loss 0.7210, auc 0.4247, ap 0.5081
2024-01-10 22:01:59,903 - GAugM EPNet train, Epoch [102/230]: loss 0.7209, auc 0.4430, ap 0.4598
2024-01-10 22:01:59,994 - GAugM EPNet train, Epoch [103/230]: loss 0.7209, auc 0.4980, ap 0.5340
2024-01-10 22:02:00,084 - GAugM EPNet train, Epoch [104/230]: loss 0.7209, auc 0.4607, ap 0.4823
2024-01-10 22:02:00,179 - GAugM EPNet train, Epoch [105/230]: loss 0.7209, auc 0.4179, ap 0.4416
2024-01-10 22:02:00,268 - GAugM EPNet train, Epoch [106/230]: loss 0.7210, auc 0.4667, ap 0.4601
2024-01-10 22:02:00,357 - GAugM EPNet train, Epoch [107/230]: loss 0.7210, auc 0.4749, ap 0.4941
2024-01-10 22:02:00,448 - GAugM EPNet train, Epoch [108/230]: loss 0.7208, auc 0.5422, ap 0.5339
2024-01-10 22:02:00,538 - GAugM EPNet train, Epoch [109/230]: loss 0.7210, auc 0.4370, ap 0.4576
2024-01-10 22:02:00,627 - GAugM EPNet train, Epoch [110/230]: loss 0.7209, auc 0.5100, ap 0.5016
2024-01-10 22:02:00,725 - GAugM EPNet train, Epoch [111/230]: loss 0.7210, auc 0.4649, ap 0.4669
2024-01-10 22:02:00,819 - GAugM EPNet train, Epoch [112/230]: loss 0.7209, auc 0.5011, ap 0.5065
2024-01-10 22:02:00,905 - GAugM EPNet train, Epoch [113/230]: loss 0.7210, auc 0.4699, ap 0.5174
2024-01-10 22:02:00,997 - GAugM EPNet train, Epoch [114/230]: loss 0.7209, auc 0.4792, ap 0.4637
2024-01-10 22:02:01,089 - GAugM EPNet train, Epoch [115/230]: loss 0.7210, auc 0.4781, ap 0.4630
2024-01-10 22:02:01,181 - GAugM EPNet train, Epoch [116/230]: loss 0.7209, auc 0.5310, ap 0.5293
2024-01-10 22:02:01,272 - GAugM EPNet train, Epoch [117/230]: loss 0.7208, auc 0.4265, ap 0.4566
2024-01-10 22:02:01,360 - GAugM EPNet train, Epoch [118/230]: loss 0.7209, auc 0.5182, ap 0.5237
2024-01-10 22:02:01,452 - GAugM EPNet train, Epoch [119/230]: loss 0.7209, auc 0.5281, ap 0.5602
2024-01-10 22:02:01,542 - GAugM EPNet train, Epoch [120/230]: loss 0.7210, auc 0.5055, ap 0.5029
2024-01-10 22:02:01,632 - GAugM EPNet train, Epoch [121/230]: loss 0.7210, auc 0.4801, ap 0.4946
2024-01-10 22:02:01,722 - GAugM EPNet train, Epoch [122/230]: loss 0.7209, auc 0.4963, ap 0.4883
2024-01-10 22:02:01,813 - GAugM EPNet train, Epoch [123/230]: loss 0.7209, auc 0.5586, ap 0.5842
2024-01-10 22:02:01,910 - GAugM EPNet train, Epoch [124/230]: loss 0.7210, auc 0.4327, ap 0.4522
2024-01-10 22:02:02,007 - GAugM EPNet train, Epoch [125/230]: loss 0.7209, auc 0.4737, ap 0.4989
2024-01-10 22:02:02,102 - GAugM EPNet train, Epoch [126/230]: loss 0.7210, auc 0.5427, ap 0.5358
2024-01-10 22:02:02,191 - GAugM EPNet train, Epoch [127/230]: loss 0.7209, auc 0.4808, ap 0.4713
2024-01-10 22:02:02,281 - GAugM EPNet train, Epoch [128/230]: loss 0.7210, auc 0.4973, ap 0.4890
2024-01-10 22:02:02,372 - GAugM EPNet train, Epoch [129/230]: loss 0.7208, auc 0.3918, ap 0.4282
2024-01-10 22:02:02,467 - GAugM EPNet train, Epoch [130/230]: loss 0.7210, auc 0.5319, ap 0.5408
2024-01-10 22:02:02,559 - GAugM EPNet train, Epoch [131/230]: loss 0.7210, auc 0.4672, ap 0.4887
2024-01-10 22:02:02,655 - GAugM EPNet train, Epoch [132/230]: loss 0.7209, auc 0.5190, ap 0.5164
2024-01-10 22:02:02,750 - GAugM EPNet train, Epoch [133/230]: loss 0.7209, auc 0.5128, ap 0.5407
2024-01-10 22:02:02,842 - GAugM EPNet train, Epoch [134/230]: loss 0.7210, auc 0.4988, ap 0.5309
2024-01-10 22:02:02,941 - GAugM EPNet train, Epoch [135/230]: loss 0.7209, auc 0.3877, ap 0.4286
2024-01-10 22:02:03,030 - GAugM EPNet train, Epoch [136/230]: loss 0.7209, auc 0.4320, ap 0.4501
2024-01-10 22:02:03,123 - GAugM EPNet train, Epoch [137/230]: loss 0.7210, auc 0.4656, ap 0.4825
2024-01-10 22:02:03,214 - GAugM EPNet train, Epoch [138/230]: loss 0.7210, auc 0.5500, ap 0.5412
2024-01-10 22:02:03,304 - GAugM EPNet train, Epoch [139/230]: loss 0.7210, auc 0.4735, ap 0.4821
2024-01-10 22:02:03,395 - GAugM EPNet train, Epoch [140/230]: loss 0.7209, auc 0.5468, ap 0.5617
2024-01-10 22:02:03,494 - GAugM EPNet train, Epoch [141/230]: loss 0.7209, auc 0.5279, ap 0.5194
2024-01-10 22:02:03,585 - GAugM EPNet train, Epoch [142/230]: loss 0.7209, auc 0.5554, ap 0.5382
2024-01-10 22:02:03,679 - GAugM EPNet train, Epoch [143/230]: loss 0.7209, auc 0.3980, ap 0.4248
2024-01-10 22:02:03,776 - GAugM EPNet train, Epoch [144/230]: loss 0.7209, auc 0.4413, ap 0.4489
2024-01-10 22:02:03,866 - GAugM EPNet train, Epoch [145/230]: loss 0.7209, auc 0.4256, ap 0.4655
2024-01-10 22:02:03,960 - GAugM EPNet train, Epoch [146/230]: loss 0.7209, auc 0.4774, ap 0.5297
2024-01-10 22:02:04,050 - GAugM EPNet train, Epoch [147/230]: loss 0.7209, auc 0.5155, ap 0.5131
2024-01-10 22:02:04,143 - GAugM EPNet train, Epoch [148/230]: loss 0.7209, auc 0.4984, ap 0.5008
2024-01-10 22:02:04,235 - GAugM EPNet train, Epoch [149/230]: loss 0.7208, auc 0.4802, ap 0.4706
2024-01-10 22:02:04,326 - GAugM EPNet train, Epoch [150/230]: loss 0.7209, auc 0.4986, ap 0.5035
2024-01-10 22:02:04,423 - GAugM EPNet train, Epoch [151/230]: loss 0.7209, auc 0.5518, ap 0.5263
2024-01-10 22:02:04,512 - GAugM EPNet train, Epoch [152/230]: loss 0.7209, auc 0.5500, ap 0.5223
2024-01-10 22:02:04,601 - GAugM EPNet train, Epoch [153/230]: loss 0.7209, auc 0.4854, ap 0.5386
2024-01-10 22:02:04,690 - GAugM EPNet train, Epoch [154/230]: loss 0.7209, auc 0.5878, ap 0.6123
2024-01-10 22:02:04,785 - GAugM EPNet train, Epoch [155/230]: loss 0.7209, auc 0.4833, ap 0.4853
2024-01-10 22:02:04,875 - GAugM EPNet train, Epoch [156/230]: loss 0.7209, auc 0.4010, ap 0.4348
2024-01-10 22:02:04,964 - GAugM EPNet train, Epoch [157/230]: loss 0.7209, auc 0.5721, ap 0.5365
2024-01-10 22:02:05,053 - GAugM EPNet train, Epoch [158/230]: loss 0.7208, auc 0.4407, ap 0.4528
2024-01-10 22:02:05,151 - GAugM EPNet train, Epoch [159/230]: loss 0.7208, auc 0.4204, ap 0.4394
2024-01-10 22:02:05,242 - GAugM EPNet train, Epoch [160/230]: loss 0.7209, auc 0.4998, ap 0.5200
2024-01-10 22:02:05,333 - GAugM EPNet train, Epoch [161/230]: loss 0.7209, auc 0.5295, ap 0.5255
2024-01-10 22:02:05,427 - GAugM EPNet train, Epoch [162/230]: loss 0.7209, auc 0.4336, ap 0.4474
2024-01-10 22:02:05,514 - GAugM EPNet train, Epoch [163/230]: loss 0.7209, auc 0.4792, ap 0.4928
2024-01-10 22:02:05,605 - GAugM EPNet train, Epoch [164/230]: loss 0.7211, auc 0.5117, ap 0.5066
2024-01-10 22:02:05,695 - GAugM EPNet train, Epoch [165/230]: loss 0.7210, auc 0.4244, ap 0.4612
2024-01-10 22:02:05,781 - GAugM EPNet train, Epoch [166/230]: loss 0.7208, auc 0.5429, ap 0.5505
2024-01-10 22:02:05,872 - GAugM EPNet train, Epoch [167/230]: loss 0.7209, auc 0.3412, ap 0.4075
2024-01-10 22:02:05,962 - GAugM EPNet train, Epoch [168/230]: loss 0.7209, auc 0.4333, ap 0.4840
2024-01-10 22:02:06,051 - GAugM EPNet train, Epoch [169/230]: loss 0.7209, auc 0.4931, ap 0.5444
2024-01-10 22:02:06,147 - GAugM EPNet train, Epoch [170/230]: loss 0.7210, auc 0.5110, ap 0.4794
2024-01-10 22:02:06,235 - GAugM EPNet train, Epoch [171/230]: loss 0.7209, auc 0.4804, ap 0.4735
2024-01-10 22:02:06,326 - GAugM EPNet train, Epoch [172/230]: loss 0.7208, auc 0.4288, ap 0.4471
2024-01-10 22:02:06,416 - GAugM EPNet train, Epoch [173/230]: loss 0.7209, auc 0.5030, ap 0.4833
2024-01-10 22:02:06,515 - GAugM EPNet train, Epoch [174/230]: loss 0.7209, auc 0.4366, ap 0.4704
2024-01-10 22:02:06,605 - GAugM EPNet train, Epoch [175/230]: loss 0.7209, auc 0.6041, ap 0.5617
2024-01-10 22:02:06,689 - GAugM EPNet train, Epoch [176/230]: loss 0.7209, auc 0.5094, ap 0.4889
2024-01-10 22:02:06,781 - GAugM EPNet train, Epoch [177/230]: loss 0.7210, auc 0.5137, ap 0.4929
2024-01-10 22:02:06,874 - GAugM EPNet train, Epoch [178/230]: loss 0.7210, auc 0.5002, ap 0.5560
2024-01-10 22:02:06,956 - GAugM EPNet train, Epoch [179/230]: loss 0.7210, auc 0.3920, ap 0.4478
2024-01-10 22:02:07,054 - GAugM EPNet train, Epoch [180/230]: loss 0.7210, auc 0.5472, ap 0.5834
2024-01-10 22:02:07,150 - GAugM EPNet train, Epoch [181/230]: loss 0.7209, auc 0.4085, ap 0.4647
2024-01-10 22:02:07,243 - GAugM EPNet train, Epoch [182/230]: loss 0.7209, auc 0.4918, ap 0.5139
2024-01-10 22:02:07,337 - GAugM EPNet train, Epoch [183/230]: loss 0.7210, auc 0.5680, ap 0.5352
2024-01-10 22:02:07,429 - GAugM EPNet train, Epoch [184/230]: loss 0.7209, auc 0.5114, ap 0.5243
2024-01-10 22:02:07,525 - GAugM EPNet train, Epoch [185/230]: loss 0.7209, auc 0.5311, ap 0.5470
2024-01-10 22:02:07,614 - GAugM EPNet train, Epoch [186/230]: loss 0.7208, auc 0.4454, ap 0.4602
2024-01-10 22:02:07,699 - GAugM EPNet train, Epoch [187/230]: loss 0.7209, auc 0.5440, ap 0.5353
2024-01-10 22:02:07,793 - GAugM EPNet train, Epoch [188/230]: loss 0.7209, auc 0.4906, ap 0.4727
2024-01-10 22:02:07,881 - GAugM EPNet train, Epoch [189/230]: loss 0.7209, auc 0.5555, ap 0.5691
2024-01-10 22:02:07,963 - GAugM EPNet train, Epoch [190/230]: loss 0.7209, auc 0.3813, ap 0.4319
2024-01-10 22:02:08,057 - GAugM EPNet train, Epoch [191/230]: loss 0.7209, auc 0.4790, ap 0.4874
2024-01-10 22:02:08,157 - GAugM EPNet train, Epoch [192/230]: loss 0.7209, auc 0.4772, ap 0.4545
2024-01-10 22:02:08,249 - GAugM EPNet train, Epoch [193/230]: loss 0.7209, auc 0.5675, ap 0.5341
2024-01-10 22:02:08,336 - GAugM EPNet train, Epoch [194/230]: loss 0.7209, auc 0.4977, ap 0.4843
2024-01-10 22:02:08,426 - GAugM EPNet train, Epoch [195/230]: loss 0.7209, auc 0.4941, ap 0.5385
2024-01-10 22:02:08,524 - GAugM EPNet train, Epoch [196/230]: loss 0.7208, auc 0.5635, ap 0.5424
2024-01-10 22:02:08,622 - GAugM EPNet train, Epoch [197/230]: loss 0.7210, auc 0.4494, ap 0.4713
2024-01-10 22:02:08,717 - GAugM EPNet train, Epoch [198/230]: loss 0.7210, auc 0.5386, ap 0.5186
2024-01-10 22:02:08,809 - GAugM EPNet train, Epoch [199/230]: loss 0.7209, auc 0.4318, ap 0.4576
2024-01-10 22:02:08,901 - GAugM EPNet train, Epoch [200/230]: loss 0.7210, auc 0.4500, ap 0.4717
2024-01-10 22:02:08,989 - GAugM EPNet train, Epoch [201/230]: loss 0.7209, auc 0.5272, ap 0.5177
2024-01-10 22:02:09,069 - GAugM EPNet train, Epoch [202/230]: loss 0.7210, auc 0.5226, ap 0.5377
2024-01-10 22:02:09,149 - GAugM EPNet train, Epoch [203/230]: loss 0.7210, auc 0.5821, ap 0.5969
2024-01-10 22:02:09,232 - GAugM EPNet train, Epoch [204/230]: loss 0.7209, auc 0.4655, ap 0.4691
2024-01-10 22:02:09,311 - GAugM EPNet train, Epoch [205/230]: loss 0.7209, auc 0.4203, ap 0.4490
2024-01-10 22:02:09,395 - GAugM EPNet train, Epoch [206/230]: loss 0.7209, auc 0.4226, ap 0.4364
2024-01-10 22:02:09,471 - GAugM EPNet train, Epoch [207/230]: loss 0.7210, auc 0.4678, ap 0.4815
2024-01-10 22:02:09,551 - GAugM EPNet train, Epoch [208/230]: loss 0.7209, auc 0.4188, ap 0.4943
2024-01-10 22:02:09,643 - GAugM EPNet train, Epoch [209/230]: loss 0.7210, auc 0.5984, ap 0.5930
2024-01-10 22:02:09,742 - GAugM EPNet train, Epoch [210/230]: loss 0.7209, auc 0.4904, ap 0.5016
2024-01-10 22:02:09,839 - GAugM EPNet train, Epoch [211/230]: loss 0.7210, auc 0.5082, ap 0.5226
2024-01-10 22:02:09,928 - GAugM EPNet train, Epoch [212/230]: loss 0.7210, auc 0.4833, ap 0.4974
2024-01-10 22:02:10,021 - GAugM EPNet train, Epoch [213/230]: loss 0.7208, auc 0.5892, ap 0.5817
2024-01-10 22:02:10,117 - GAugM EPNet train, Epoch [214/230]: loss 0.7210, auc 0.4689, ap 0.4730
2024-01-10 22:02:10,199 - GAugM EPNet train, Epoch [215/230]: loss 0.7210, auc 0.4272, ap 0.4521
2024-01-10 22:02:10,279 - GAugM EPNet train, Epoch [216/230]: loss 0.7209, auc 0.5062, ap 0.5095
2024-01-10 22:02:10,369 - GAugM EPNet train, Epoch [217/230]: loss 0.7209, auc 0.5708, ap 0.5836
2024-01-10 22:02:10,469 - GAugM EPNet train, Epoch [218/230]: loss 0.7209, auc 0.5463, ap 0.5490
2024-01-10 22:02:10,570 - GAugM EPNet train, Epoch [219/230]: loss 0.7208, auc 0.4628, ap 0.4922
2024-01-10 22:02:10,664 - GAugM EPNet train, Epoch [220/230]: loss 0.7210, auc 0.4521, ap 0.4602
2024-01-10 22:02:10,752 - GAugM EPNet train, Epoch [221/230]: loss 0.7209, auc 0.5174, ap 0.5000
2024-01-10 22:02:10,843 - GAugM EPNet train, Epoch [222/230]: loss 0.7209, auc 0.4843, ap 0.4953
2024-01-10 22:02:10,933 - GAugM EPNet train, Epoch [223/230]: loss 0.7209, auc 0.5571, ap 0.5532
2024-01-10 22:02:11,010 - GAugM EPNet train, Epoch [224/230]: loss 0.7210, auc 0.5064, ap 0.5057
2024-01-10 22:02:11,102 - GAugM EPNet train, Epoch [225/230]: loss 0.7209, auc 0.4820, ap 0.4860
2024-01-10 22:02:11,196 - GAugM EPNet train, Epoch [226/230]: loss 0.7210, auc 0.5171, ap 0.5174
2024-01-10 22:02:11,291 - GAugM EPNet train, Epoch [227/230]: loss 0.7210, auc 0.5276, ap 0.5436
2024-01-10 22:02:11,385 - GAugM EPNet train, Epoch [228/230]: loss 0.7209, auc 0.5224, ap 0.5167
2024-01-10 22:02:11,484 - GAugM EPNet train, Epoch [229/230]: loss 0.7209, auc 0.5194, ap 0.5428
2024-01-10 22:02:11,582 - GAugM EPNet train, Epoch [230/230]: loss 0.7209, auc 0.5119, ap 0.5122
2024-01-10 22:02:11,587 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa0d4050>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:02:12,345 - GAugM EPNet train, Epoch [  1/230]: loss 0.7210, auc 0.4464, ap 0.4666
2024-01-10 22:02:12,440 - GAugM EPNet train, Epoch [  2/230]: loss 0.7210, auc 0.5121, ap 0.5085
2024-01-10 22:02:12,532 - GAugM EPNet train, Epoch [  3/230]: loss 0.7209, auc 0.5595, ap 0.5493
2024-01-10 22:02:12,634 - GAugM EPNet train, Epoch [  4/230]: loss 0.7209, auc 0.3836, ap 0.4327
2024-01-10 22:02:12,725 - GAugM EPNet train, Epoch [  5/230]: loss 0.7209, auc 0.5160, ap 0.5197
2024-01-10 22:02:12,811 - GAugM EPNet train, Epoch [  6/230]: loss 0.7209, auc 0.5002, ap 0.5044
2024-01-10 22:02:12,893 - GAugM EPNet train, Epoch [  7/230]: loss 0.7209, auc 0.4181, ap 0.4339
2024-01-10 22:02:12,983 - GAugM EPNet train, Epoch [  8/230]: loss 0.7210, auc 0.4831, ap 0.4786
2024-01-10 22:02:13,074 - GAugM EPNet train, Epoch [  9/230]: loss 0.7209, auc 0.4619, ap 0.4856
2024-01-10 22:02:13,166 - GAugM EPNet train, Epoch [ 10/230]: loss 0.7208, auc 0.5466, ap 0.5376
2024-01-10 22:02:13,261 - GAugM EPNet train, Epoch [ 11/230]: loss 0.7209, auc 0.5110, ap 0.5361
2024-01-10 22:02:13,351 - GAugM EPNet train, Epoch [ 12/230]: loss 0.7210, auc 0.4674, ap 0.4884
2024-01-10 22:02:13,441 - GAugM EPNet train, Epoch [ 13/230]: loss 0.7209, auc 0.5317, ap 0.5209
2024-01-10 22:02:13,536 - GAugM EPNet train, Epoch [ 14/230]: loss 0.7209, auc 0.5740, ap 0.5785
2024-01-10 22:02:13,630 - GAugM EPNet train, Epoch [ 15/230]: loss 0.7210, auc 0.4441, ap 0.4875
2024-01-10 22:02:13,720 - GAugM EPNet train, Epoch [ 16/230]: loss 0.7209, auc 0.5799, ap 0.5945
2024-01-10 22:02:13,807 - GAugM EPNet train, Epoch [ 17/230]: loss 0.7210, auc 0.5354, ap 0.5137
2024-01-10 22:02:13,902 - GAugM EPNet train, Epoch [ 18/230]: loss 0.7210, auc 0.6084, ap 0.5895
2024-01-10 22:02:13,990 - GAugM EPNet train, Epoch [ 19/230]: loss 0.7209, auc 0.5125, ap 0.4910
2024-01-10 22:02:14,079 - GAugM EPNet train, Epoch [ 20/230]: loss 0.7210, auc 0.5173, ap 0.5297
2024-01-10 22:02:14,170 - GAugM EPNet train, Epoch [ 21/230]: loss 0.7209, auc 0.4729, ap 0.4795
2024-01-10 22:02:14,262 - GAugM EPNet train, Epoch [ 22/230]: loss 0.7210, auc 0.3752, ap 0.4265
2024-01-10 22:02:14,355 - GAugM EPNet train, Epoch [ 23/230]: loss 0.7208, auc 0.4970, ap 0.5191
2024-01-10 22:02:14,443 - GAugM EPNet train, Epoch [ 24/230]: loss 0.7209, auc 0.5233, ap 0.5025
2024-01-10 22:02:14,536 - GAugM EPNet train, Epoch [ 25/230]: loss 0.7209, auc 0.4349, ap 0.4643
2024-01-10 22:02:14,622 - GAugM EPNet train, Epoch [ 26/230]: loss 0.7210, auc 0.5457, ap 0.5295
2024-01-10 22:02:14,710 - GAugM EPNet train, Epoch [ 27/230]: loss 0.7209, auc 0.4131, ap 0.4577
2024-01-10 22:02:14,797 - GAugM EPNet train, Epoch [ 28/230]: loss 0.7209, auc 0.5671, ap 0.5635
2024-01-10 22:02:14,888 - GAugM EPNet train, Epoch [ 29/230]: loss 0.7210, auc 0.5158, ap 0.5159
2024-01-10 22:02:14,980 - GAugM EPNet train, Epoch [ 30/230]: loss 0.7209, auc 0.4591, ap 0.4866
2024-01-10 22:02:15,067 - GAugM EPNet train, Epoch [ 31/230]: loss 0.7208, auc 0.5655, ap 0.5821
2024-01-10 22:02:15,155 - GAugM EPNet train, Epoch [ 32/230]: loss 0.7210, auc 0.5365, ap 0.5428
2024-01-10 22:02:15,244 - GAugM EPNet train, Epoch [ 33/230]: loss 0.7209, auc 0.6356, ap 0.6055
2024-01-10 22:02:15,338 - GAugM EPNet train, Epoch [ 34/230]: loss 0.7209, auc 0.4681, ap 0.4886
2024-01-10 22:02:15,425 - GAugM EPNet train, Epoch [ 35/230]: loss 0.7209, auc 0.5427, ap 0.5203
2024-01-10 22:02:15,514 - GAugM EPNet train, Epoch [ 36/230]: loss 0.7209, auc 0.5635, ap 0.5881
2024-01-10 22:02:15,601 - GAugM EPNet train, Epoch [ 37/230]: loss 0.7209, auc 0.4865, ap 0.4867
2024-01-10 22:02:15,695 - GAugM EPNet train, Epoch [ 38/230]: loss 0.7209, auc 0.4130, ap 0.4376
2024-01-10 22:02:15,788 - GAugM EPNet train, Epoch [ 39/230]: loss 0.7208, auc 0.4126, ap 0.4445
2024-01-10 22:02:15,876 - GAugM EPNet train, Epoch [ 40/230]: loss 0.7210, auc 0.5502, ap 0.5420
2024-01-10 22:02:15,963 - GAugM EPNet train, Epoch [ 41/230]: loss 0.7210, auc 0.4601, ap 0.5127
2024-01-10 22:02:16,058 - GAugM EPNet train, Epoch [ 42/230]: loss 0.7209, auc 0.5587, ap 0.5890
2024-01-10 22:02:16,145 - GAugM EPNet train, Epoch [ 43/230]: loss 0.7208, auc 0.3499, ap 0.4112
2024-01-10 22:02:16,241 - GAugM EPNet train, Epoch [ 44/230]: loss 0.7208, auc 0.4534, ap 0.4741
2024-01-10 22:02:16,328 - GAugM EPNet train, Epoch [ 45/230]: loss 0.7209, auc 0.6089, ap 0.5902
2024-01-10 22:02:16,417 - GAugM EPNet train, Epoch [ 46/230]: loss 0.7209, auc 0.4576, ap 0.4935
2024-01-10 22:02:16,507 - GAugM EPNet train, Epoch [ 47/230]: loss 0.7210, auc 0.4950, ap 0.5098
2024-01-10 22:02:16,593 - GAugM EPNet train, Epoch [ 48/230]: loss 0.7210, auc 0.5872, ap 0.6002
2024-01-10 22:02:16,687 - GAugM EPNet train, Epoch [ 49/230]: loss 0.7209, auc 0.5155, ap 0.5187
2024-01-10 22:02:16,774 - GAugM EPNet train, Epoch [ 50/230]: loss 0.7210, auc 0.4493, ap 0.4670
2024-01-10 22:02:16,868 - GAugM EPNet train, Epoch [ 51/230]: loss 0.7210, auc 0.4696, ap 0.5024
2024-01-10 22:02:16,957 - GAugM EPNet train, Epoch [ 52/230]: loss 0.7209, auc 0.5328, ap 0.5621
2024-01-10 22:02:17,048 - GAugM EPNet train, Epoch [ 53/230]: loss 0.7209, auc 0.6045, ap 0.5825
2024-01-10 22:02:17,137 - GAugM EPNet train, Epoch [ 54/230]: loss 0.7211, auc 0.5374, ap 0.5492
2024-01-10 22:02:17,224 - GAugM EPNet train, Epoch [ 55/230]: loss 0.7209, auc 0.5379, ap 0.5693
2024-01-10 22:02:17,320 - GAugM EPNet train, Epoch [ 56/230]: loss 0.7208, auc 0.5465, ap 0.5314
2024-01-10 22:02:17,408 - GAugM EPNet train, Epoch [ 57/230]: loss 0.7209, auc 0.4948, ap 0.4978
2024-01-10 22:02:17,497 - GAugM EPNet train, Epoch [ 58/230]: loss 0.7210, auc 0.5433, ap 0.5995
2024-01-10 22:02:17,595 - GAugM EPNet train, Epoch [ 59/230]: loss 0.7211, auc 0.4566, ap 0.4683
2024-01-10 22:02:17,683 - GAugM EPNet train, Epoch [ 60/230]: loss 0.7210, auc 0.5511, ap 0.5266
2024-01-10 22:02:17,775 - GAugM EPNet train, Epoch [ 61/230]: loss 0.7209, auc 0.5609, ap 0.5702
2024-01-10 22:02:17,867 - GAugM EPNet train, Epoch [ 62/230]: loss 0.7210, auc 0.4692, ap 0.5138
2024-01-10 22:02:17,956 - GAugM EPNet train, Epoch [ 63/230]: loss 0.7208, auc 0.4890, ap 0.4740
2024-01-10 22:02:18,054 - GAugM EPNet train, Epoch [ 64/230]: loss 0.7208, auc 0.4616, ap 0.4660
2024-01-10 22:02:18,142 - GAugM EPNet train, Epoch [ 65/230]: loss 0.7208, auc 0.5126, ap 0.5414
2024-01-10 22:02:18,231 - GAugM EPNet train, Epoch [ 66/230]: loss 0.7209, auc 0.4972, ap 0.5098
2024-01-10 22:02:18,317 - GAugM EPNet train, Epoch [ 67/230]: loss 0.7209, auc 0.5025, ap 0.4934
2024-01-10 22:02:18,409 - GAugM EPNet train, Epoch [ 68/230]: loss 0.7210, auc 0.5360, ap 0.5558
2024-01-10 22:02:18,497 - GAugM EPNet train, Epoch [ 69/230]: loss 0.7210, auc 0.5433, ap 0.5775
2024-01-10 22:02:18,585 - GAugM EPNet train, Epoch [ 70/230]: loss 0.7210, auc 0.4580, ap 0.4757
2024-01-10 22:02:18,674 - GAugM EPNet train, Epoch [ 71/230]: loss 0.7210, auc 0.5484, ap 0.5217
2024-01-10 22:02:18,762 - GAugM EPNet train, Epoch [ 72/230]: loss 0.7210, auc 0.5185, ap 0.5389
2024-01-10 22:02:18,854 - GAugM EPNet train, Epoch [ 73/230]: loss 0.7209, auc 0.4950, ap 0.5113
2024-01-10 22:02:18,946 - GAugM EPNet train, Epoch [ 74/230]: loss 0.7209, auc 0.5865, ap 0.5545
2024-01-10 22:02:19,035 - GAugM EPNet train, Epoch [ 75/230]: loss 0.7210, auc 0.4388, ap 0.4831
2024-01-10 22:02:19,127 - GAugM EPNet train, Epoch [ 76/230]: loss 0.7209, auc 0.4432, ap 0.4500
2024-01-10 22:02:19,214 - GAugM EPNet train, Epoch [ 77/230]: loss 0.7208, auc 0.6214, ap 0.5873
2024-01-10 22:02:19,301 - GAugM EPNet train, Epoch [ 78/230]: loss 0.7209, auc 0.5144, ap 0.4969
2024-01-10 22:02:19,395 - GAugM EPNet train, Epoch [ 79/230]: loss 0.7208, auc 0.4671, ap 0.5028
2024-01-10 22:02:19,482 - GAugM EPNet train, Epoch [ 80/230]: loss 0.7209, auc 0.5844, ap 0.5657
2024-01-10 22:02:19,571 - GAugM EPNet train, Epoch [ 81/230]: loss 0.7209, auc 0.5548, ap 0.5244
2024-01-10 22:02:19,662 - GAugM EPNet train, Epoch [ 82/230]: loss 0.7210, auc 0.4939, ap 0.4838
2024-01-10 22:02:19,751 - GAugM EPNet train, Epoch [ 83/230]: loss 0.7209, auc 0.4582, ap 0.5059
2024-01-10 22:02:19,846 - GAugM EPNet train, Epoch [ 84/230]: loss 0.7209, auc 0.4368, ap 0.5002
2024-01-10 22:02:19,936 - GAugM EPNet train, Epoch [ 85/230]: loss 0.7210, auc 0.4667, ap 0.4923
2024-01-10 22:02:20,023 - GAugM EPNet train, Epoch [ 86/230]: loss 0.7208, auc 0.4834, ap 0.5023
2024-01-10 22:02:20,112 - GAugM EPNet train, Epoch [ 87/230]: loss 0.7209, auc 0.5344, ap 0.5245
2024-01-10 22:02:20,206 - GAugM EPNet train, Epoch [ 88/230]: loss 0.7210, auc 0.4923, ap 0.5242
2024-01-10 22:02:20,294 - GAugM EPNet train, Epoch [ 89/230]: loss 0.7210, auc 0.5678, ap 0.5601
2024-01-10 22:02:20,383 - GAugM EPNet train, Epoch [ 90/230]: loss 0.7209, auc 0.4587, ap 0.4910
2024-01-10 22:02:20,473 - GAugM EPNet train, Epoch [ 91/230]: loss 0.7208, auc 0.5488, ap 0.5189
2024-01-10 22:02:20,560 - GAugM EPNet train, Epoch [ 92/230]: loss 0.7209, auc 0.5894, ap 0.5902
2024-01-10 22:02:20,647 - GAugM EPNet train, Epoch [ 93/230]: loss 0.7209, auc 0.4361, ap 0.4733
2024-01-10 22:02:20,737 - GAugM EPNet train, Epoch [ 94/230]: loss 0.7210, auc 0.4094, ap 0.4637
2024-01-10 22:02:20,832 - GAugM EPNet train, Epoch [ 95/230]: loss 0.7210, auc 0.5160, ap 0.5046
2024-01-10 22:02:20,919 - GAugM EPNet train, Epoch [ 96/230]: loss 0.7209, auc 0.4690, ap 0.5080
2024-01-10 22:02:21,006 - GAugM EPNet train, Epoch [ 97/230]: loss 0.7209, auc 0.5311, ap 0.5839
2024-01-10 22:02:21,098 - GAugM EPNet train, Epoch [ 98/230]: loss 0.7209, auc 0.4459, ap 0.4713
2024-01-10 22:02:21,185 - GAugM EPNet train, Epoch [ 99/230]: loss 0.7209, auc 0.4569, ap 0.4721
2024-01-10 22:02:21,276 - GAugM EPNet train, Epoch [100/230]: loss 0.7210, auc 0.5194, ap 0.5473
2024-01-10 22:02:21,361 - GAugM EPNet train, Epoch [101/230]: loss 0.7210, auc 0.5028, ap 0.5422
2024-01-10 22:02:21,449 - GAugM EPNet train, Epoch [102/230]: loss 0.7209, auc 0.4923, ap 0.5116
2024-01-10 22:02:21,537 - GAugM EPNet train, Epoch [103/230]: loss 0.7209, auc 0.4155, ap 0.4927
2024-01-10 22:02:21,626 - GAugM EPNet train, Epoch [104/230]: loss 0.7209, auc 0.4761, ap 0.4622
2024-01-10 22:02:21,714 - GAugM EPNet train, Epoch [105/230]: loss 0.7209, auc 0.4728, ap 0.4728
2024-01-10 22:02:21,808 - GAugM EPNet train, Epoch [106/230]: loss 0.7210, auc 0.4608, ap 0.4937
2024-01-10 22:02:21,896 - GAugM EPNet train, Epoch [107/230]: loss 0.7210, auc 0.4694, ap 0.5118
2024-01-10 22:02:21,986 - GAugM EPNet train, Epoch [108/230]: loss 0.7208, auc 0.5258, ap 0.5284
2024-01-10 22:02:22,075 - GAugM EPNet train, Epoch [109/230]: loss 0.7210, auc 0.4377, ap 0.4758
2024-01-10 22:02:22,166 - GAugM EPNet train, Epoch [110/230]: loss 0.7209, auc 0.5030, ap 0.5297
2024-01-10 22:02:22,255 - GAugM EPNet train, Epoch [111/230]: loss 0.7210, auc 0.5169, ap 0.5258
2024-01-10 22:02:22,342 - GAugM EPNet train, Epoch [112/230]: loss 0.7209, auc 0.4749, ap 0.5007
2024-01-10 22:02:22,436 - GAugM EPNet train, Epoch [113/230]: loss 0.7210, auc 0.5415, ap 0.5737
2024-01-10 22:02:22,521 - GAugM EPNet train, Epoch [114/230]: loss 0.7209, auc 0.4026, ap 0.4326
2024-01-10 22:02:22,608 - GAugM EPNet train, Epoch [115/230]: loss 0.7210, auc 0.5021, ap 0.4870
2024-01-10 22:02:22,702 - GAugM EPNet train, Epoch [116/230]: loss 0.7209, auc 0.5386, ap 0.5598
2024-01-10 22:02:22,792 - GAugM EPNet train, Epoch [117/230]: loss 0.7208, auc 0.4276, ap 0.4530
2024-01-10 22:02:22,886 - GAugM EPNet train, Epoch [118/230]: loss 0.7209, auc 0.4311, ap 0.4760
2024-01-10 22:02:22,973 - GAugM EPNet train, Epoch [119/230]: loss 0.7209, auc 0.5486, ap 0.5742
2024-01-10 22:02:23,062 - GAugM EPNet train, Epoch [120/230]: loss 0.7210, auc 0.4745, ap 0.5016
2024-01-10 22:02:23,151 - GAugM EPNet train, Epoch [121/230]: loss 0.7210, auc 0.4514, ap 0.4626
2024-01-10 22:02:23,238 - GAugM EPNet train, Epoch [122/230]: loss 0.7209, auc 0.5012, ap 0.5197
2024-01-10 22:02:23,336 - GAugM EPNet train, Epoch [123/230]: loss 0.7209, auc 0.4854, ap 0.5285
2024-01-10 22:02:23,426 - GAugM EPNet train, Epoch [124/230]: loss 0.7210, auc 0.4689, ap 0.4759
2024-01-10 22:02:23,517 - GAugM EPNet train, Epoch [125/230]: loss 0.7209, auc 0.5014, ap 0.5196
2024-01-10 22:02:23,606 - GAugM EPNet train, Epoch [126/230]: loss 0.7210, auc 0.5130, ap 0.5139
2024-01-10 22:02:23,693 - GAugM EPNet train, Epoch [127/230]: loss 0.7209, auc 0.5091, ap 0.5073
2024-01-10 22:02:23,788 - GAugM EPNet train, Epoch [128/230]: loss 0.7210, auc 0.5399, ap 0.5257
2024-01-10 22:02:23,878 - GAugM EPNet train, Epoch [129/230]: loss 0.7208, auc 0.4137, ap 0.4469
2024-01-10 22:02:23,965 - GAugM EPNet train, Epoch [130/230]: loss 0.7210, auc 0.4398, ap 0.4666
2024-01-10 22:02:24,060 - GAugM EPNet train, Epoch [131/230]: loss 0.7210, auc 0.5965, ap 0.5950
2024-01-10 22:02:24,150 - GAugM EPNet train, Epoch [132/230]: loss 0.7209, auc 0.5322, ap 0.5283
2024-01-10 22:02:24,236 - GAugM EPNet train, Epoch [133/230]: loss 0.7209, auc 0.4745, ap 0.5227
2024-01-10 22:02:24,323 - GAugM EPNet train, Epoch [134/230]: loss 0.7210, auc 0.4824, ap 0.4986
2024-01-10 22:02:24,410 - GAugM EPNet train, Epoch [135/230]: loss 0.7209, auc 0.4049, ap 0.4439
2024-01-10 22:02:24,500 - GAugM EPNet train, Epoch [136/230]: loss 0.7209, auc 0.4560, ap 0.4759
2024-01-10 22:02:24,588 - GAugM EPNet train, Epoch [137/230]: loss 0.7210, auc 0.5226, ap 0.5253
2024-01-10 22:02:24,676 - GAugM EPNet train, Epoch [138/230]: loss 0.7210, auc 0.5055, ap 0.5013
2024-01-10 22:02:24,771 - GAugM EPNet train, Epoch [139/230]: loss 0.7210, auc 0.4357, ap 0.4459
2024-01-10 22:02:24,860 - GAugM EPNet train, Epoch [140/230]: loss 0.7209, auc 0.4703, ap 0.5137
2024-01-10 22:02:24,948 - GAugM EPNet train, Epoch [141/230]: loss 0.7209, auc 0.5096, ap 0.4754
2024-01-10 22:02:25,037 - GAugM EPNet train, Epoch [142/230]: loss 0.7209, auc 0.4690, ap 0.4971
2024-01-10 22:02:25,126 - GAugM EPNet train, Epoch [143/230]: loss 0.7209, auc 0.4560, ap 0.4598
2024-01-10 22:02:25,212 - GAugM EPNet train, Epoch [144/230]: loss 0.7209, auc 0.4909, ap 0.4964
2024-01-10 22:02:25,301 - GAugM EPNet train, Epoch [145/230]: loss 0.7209, auc 0.4681, ap 0.5151
2024-01-10 22:02:25,394 - GAugM EPNet train, Epoch [146/230]: loss 0.7209, auc 0.5482, ap 0.5523
2024-01-10 22:02:25,483 - GAugM EPNet train, Epoch [147/230]: loss 0.7209, auc 0.5732, ap 0.6064
2024-01-10 22:02:25,570 - GAugM EPNet train, Epoch [148/230]: loss 0.7209, auc 0.4811, ap 0.5204
2024-01-10 22:02:25,659 - GAugM EPNet train, Epoch [149/230]: loss 0.7208, auc 0.5536, ap 0.5463
2024-01-10 22:02:25,746 - GAugM EPNet train, Epoch [150/230]: loss 0.7209, auc 0.4724, ap 0.4829
2024-01-10 22:02:25,833 - GAugM EPNet train, Epoch [151/230]: loss 0.7209, auc 0.5388, ap 0.5406
2024-01-10 22:02:25,920 - GAugM EPNet train, Epoch [152/230]: loss 0.7209, auc 0.5860, ap 0.5960
2024-01-10 22:02:26,009 - GAugM EPNet train, Epoch [153/230]: loss 0.7209, auc 0.4576, ap 0.5013
2024-01-10 22:02:26,094 - GAugM EPNet train, Epoch [154/230]: loss 0.7209, auc 0.4998, ap 0.4903
2024-01-10 22:02:26,186 - GAugM EPNet train, Epoch [155/230]: loss 0.7209, auc 0.5514, ap 0.5501
2024-01-10 22:02:26,273 - GAugM EPNet train, Epoch [156/230]: loss 0.7209, auc 0.4025, ap 0.4407
2024-01-10 22:02:26,362 - GAugM EPNet train, Epoch [157/230]: loss 0.7209, auc 0.5619, ap 0.5397
2024-01-10 22:02:26,449 - GAugM EPNet train, Epoch [158/230]: loss 0.7208, auc 0.4074, ap 0.4629
2024-01-10 22:02:26,537 - GAugM EPNet train, Epoch [159/230]: loss 0.7208, auc 0.5011, ap 0.4932
2024-01-10 22:02:26,627 - GAugM EPNet train, Epoch [160/230]: loss 0.7209, auc 0.5158, ap 0.5177
2024-01-10 22:02:26,715 - GAugM EPNet train, Epoch [161/230]: loss 0.7209, auc 0.5578, ap 0.5378
2024-01-10 22:02:26,804 - GAugM EPNet train, Epoch [162/230]: loss 0.7209, auc 0.5242, ap 0.5053
2024-01-10 22:02:26,892 - GAugM EPNet train, Epoch [163/230]: loss 0.7209, auc 0.4760, ap 0.4648
2024-01-10 22:02:26,977 - GAugM EPNet train, Epoch [164/230]: loss 0.7211, auc 0.5176, ap 0.5074
2024-01-10 22:02:27,065 - GAugM EPNet train, Epoch [165/230]: loss 0.7210, auc 0.3936, ap 0.4553
2024-01-10 22:02:27,153 - GAugM EPNet train, Epoch [166/230]: loss 0.7208, auc 0.5411, ap 0.5039
2024-01-10 22:02:27,238 - GAugM EPNet train, Epoch [167/230]: loss 0.7209, auc 0.4288, ap 0.4526
2024-01-10 22:02:27,324 - GAugM EPNet train, Epoch [168/230]: loss 0.7209, auc 0.4836, ap 0.5259
2024-01-10 22:02:27,410 - GAugM EPNet train, Epoch [169/230]: loss 0.7209, auc 0.5395, ap 0.5347
2024-01-10 22:02:27,498 - GAugM EPNet train, Epoch [170/230]: loss 0.7210, auc 0.5529, ap 0.5138
2024-01-10 22:02:27,583 - GAugM EPNet train, Epoch [171/230]: loss 0.7209, auc 0.4215, ap 0.4509
2024-01-10 22:02:27,674 - GAugM EPNet train, Epoch [172/230]: loss 0.7208, auc 0.4754, ap 0.4938
2024-01-10 22:02:27,760 - GAugM EPNet train, Epoch [173/230]: loss 0.7209, auc 0.5311, ap 0.5217
2024-01-10 22:02:27,847 - GAugM EPNet train, Epoch [174/230]: loss 0.7209, auc 0.4681, ap 0.4946
2024-01-10 22:02:27,932 - GAugM EPNet train, Epoch [175/230]: loss 0.7209, auc 0.6228, ap 0.5976
2024-01-10 22:02:28,019 - GAugM EPNet train, Epoch [176/230]: loss 0.7209, auc 0.5221, ap 0.5310
2024-01-10 22:02:28,107 - GAugM EPNet train, Epoch [177/230]: loss 0.7210, auc 0.5032, ap 0.5140
2024-01-10 22:02:28,192 - GAugM EPNet train, Epoch [178/230]: loss 0.7210, auc 0.5931, ap 0.5966
2024-01-10 22:02:28,279 - GAugM EPNet train, Epoch [179/230]: loss 0.7210, auc 0.4089, ap 0.4531
2024-01-10 22:02:28,365 - GAugM EPNet train, Epoch [180/230]: loss 0.7210, auc 0.5125, ap 0.5421
2024-01-10 22:02:28,453 - GAugM EPNet train, Epoch [181/230]: loss 0.7209, auc 0.3855, ap 0.4160
2024-01-10 22:02:28,540 - GAugM EPNet train, Epoch [182/230]: loss 0.7209, auc 0.4555, ap 0.4975
2024-01-10 22:02:28,627 - GAugM EPNet train, Epoch [183/230]: loss 0.7210, auc 0.5299, ap 0.5509
2024-01-10 22:02:28,712 - GAugM EPNet train, Epoch [184/230]: loss 0.7209, auc 0.4786, ap 0.4883
2024-01-10 22:02:28,800 - GAugM EPNet train, Epoch [185/230]: loss 0.7209, auc 0.4174, ap 0.4579
2024-01-10 22:02:28,892 - GAugM EPNet train, Epoch [186/230]: loss 0.7208, auc 0.4913, ap 0.5458
2024-01-10 22:02:28,979 - GAugM EPNet train, Epoch [187/230]: loss 0.7209, auc 0.5028, ap 0.5315
2024-01-10 22:02:29,065 - GAugM EPNet train, Epoch [188/230]: loss 0.7209, auc 0.3747, ap 0.4150
2024-01-10 22:02:29,152 - GAugM EPNet train, Epoch [189/230]: loss 0.7209, auc 0.5162, ap 0.5703
2024-01-10 22:02:29,238 - GAugM EPNet train, Epoch [190/230]: loss 0.7209, auc 0.4025, ap 0.4402
2024-01-10 22:02:29,325 - GAugM EPNet train, Epoch [191/230]: loss 0.7209, auc 0.4286, ap 0.4831
2024-01-10 22:02:29,413 - GAugM EPNet train, Epoch [192/230]: loss 0.7209, auc 0.4813, ap 0.4606
2024-01-10 22:02:29,498 - GAugM EPNet train, Epoch [193/230]: loss 0.7209, auc 0.5951, ap 0.5853
2024-01-10 22:02:29,583 - GAugM EPNet train, Epoch [194/230]: loss 0.7209, auc 0.4560, ap 0.4772
2024-01-10 22:02:29,670 - GAugM EPNet train, Epoch [195/230]: loss 0.7209, auc 0.5050, ap 0.5111
2024-01-10 22:02:29,755 - GAugM EPNet train, Epoch [196/230]: loss 0.7208, auc 0.5842, ap 0.5657
2024-01-10 22:02:29,845 - GAugM EPNet train, Epoch [197/230]: loss 0.7210, auc 0.4870, ap 0.4854
2024-01-10 22:02:29,934 - GAugM EPNet train, Epoch [198/230]: loss 0.7210, auc 0.4731, ap 0.4815
2024-01-10 22:02:30,023 - GAugM EPNet train, Epoch [199/230]: loss 0.7209, auc 0.5411, ap 0.5583
2024-01-10 22:02:30,113 - GAugM EPNet train, Epoch [200/230]: loss 0.7210, auc 0.4972, ap 0.5139
2024-01-10 22:02:30,202 - GAugM EPNet train, Epoch [201/230]: loss 0.7209, auc 0.4735, ap 0.4844
2024-01-10 22:02:30,290 - GAugM EPNet train, Epoch [202/230]: loss 0.7210, auc 0.4973, ap 0.5131
2024-01-10 22:02:30,380 - GAugM EPNet train, Epoch [203/230]: loss 0.7210, auc 0.5206, ap 0.5372
2024-01-10 22:02:30,472 - GAugM EPNet train, Epoch [204/230]: loss 0.7209, auc 0.4703, ap 0.4863
2024-01-10 22:02:30,563 - GAugM EPNet train, Epoch [205/230]: loss 0.7209, auc 0.4872, ap 0.5221
2024-01-10 22:02:30,650 - GAugM EPNet train, Epoch [206/230]: loss 0.7209, auc 0.4496, ap 0.4684
2024-01-10 22:02:30,736 - GAugM EPNet train, Epoch [207/230]: loss 0.7210, auc 0.4797, ap 0.4996
2024-01-10 22:02:30,825 - GAugM EPNet train, Epoch [208/230]: loss 0.7209, auc 0.3888, ap 0.4449
2024-01-10 22:02:30,914 - GAugM EPNet train, Epoch [209/230]: loss 0.7210, auc 0.5424, ap 0.5458
2024-01-10 22:02:31,002 - GAugM EPNet train, Epoch [210/230]: loss 0.7209, auc 0.3658, ap 0.4230
2024-01-10 22:02:31,086 - GAugM EPNet train, Epoch [211/230]: loss 0.7210, auc 0.4979, ap 0.5278
2024-01-10 22:02:31,171 - GAugM EPNet train, Epoch [212/230]: loss 0.7210, auc 0.4518, ap 0.4964
2024-01-10 22:02:31,257 - GAugM EPNet train, Epoch [213/230]: loss 0.7208, auc 0.6235, ap 0.6380
2024-01-10 22:02:31,341 - GAugM EPNet train, Epoch [214/230]: loss 0.7210, auc 0.5269, ap 0.5221
2024-01-10 22:02:31,428 - GAugM EPNet train, Epoch [215/230]: loss 0.7210, auc 0.5493, ap 0.5247
2024-01-10 22:02:31,513 - GAugM EPNet train, Epoch [216/230]: loss 0.7209, auc 0.5176, ap 0.5224
2024-01-10 22:02:31,600 - GAugM EPNet train, Epoch [217/230]: loss 0.7209, auc 0.5838, ap 0.6230
2024-01-10 22:02:31,685 - GAugM EPNet train, Epoch [218/230]: loss 0.7209, auc 0.5317, ap 0.5846
2024-01-10 22:02:31,776 - GAugM EPNet train, Epoch [219/230]: loss 0.7208, auc 0.3597, ap 0.4056
2024-01-10 22:02:31,860 - GAugM EPNet train, Epoch [220/230]: loss 0.7210, auc 0.5046, ap 0.5509
2024-01-10 22:02:31,944 - GAugM EPNet train, Epoch [221/230]: loss 0.7209, auc 0.5069, ap 0.5201
2024-01-10 22:02:32,031 - GAugM EPNet train, Epoch [222/230]: loss 0.7209, auc 0.5020, ap 0.4935
2024-01-10 22:02:32,117 - GAugM EPNet train, Epoch [223/230]: loss 0.7209, auc 0.5516, ap 0.5643
2024-01-10 22:02:32,202 - GAugM EPNet train, Epoch [224/230]: loss 0.7210, auc 0.3932, ap 0.4362
2024-01-10 22:02:32,291 - GAugM EPNet train, Epoch [225/230]: loss 0.7209, auc 0.4633, ap 0.4660
2024-01-10 22:02:32,376 - GAugM EPNet train, Epoch [226/230]: loss 0.7210, auc 0.4665, ap 0.5033
2024-01-10 22:02:32,462 - GAugM EPNet train, Epoch [227/230]: loss 0.7210, auc 0.5951, ap 0.6092
2024-01-10 22:02:32,549 - GAugM EPNet train, Epoch [228/230]: loss 0.7209, auc 0.4329, ap 0.4627
2024-01-10 22:02:32,640 - GAugM EPNet train, Epoch [229/230]: loss 0.7209, auc 0.4904, ap 0.4962
2024-01-10 22:02:32,727 - GAugM EPNet train, Epoch [230/230]: loss 0.7209, auc 0.5110, ap 0.5280
2024-01-10 22:02:32,727 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9e13050>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:02:33,453 - GAugM EPNet train, Epoch [  1/230]: loss 0.7210, auc 0.4653, ap 0.4662
2024-01-10 22:02:33,542 - GAugM EPNet train, Epoch [  2/230]: loss 0.7210, auc 0.5927, ap 0.5655
2024-01-10 22:02:33,633 - GAugM EPNet train, Epoch [  3/230]: loss 0.7209, auc 0.5171, ap 0.5081
2024-01-10 22:02:33,724 - GAugM EPNet train, Epoch [  4/230]: loss 0.7209, auc 0.4535, ap 0.4682
2024-01-10 22:02:33,814 - GAugM EPNet train, Epoch [  5/230]: loss 0.7209, auc 0.5854, ap 0.6010
2024-01-10 22:02:33,898 - GAugM EPNet train, Epoch [  6/230]: loss 0.7209, auc 0.5253, ap 0.5350
2024-01-10 22:02:33,977 - GAugM EPNet train, Epoch [  7/230]: loss 0.7209, auc 0.4804, ap 0.4738
2024-01-10 22:02:34,057 - GAugM EPNet train, Epoch [  8/230]: loss 0.7210, auc 0.5142, ap 0.5073
2024-01-10 22:02:34,136 - GAugM EPNet train, Epoch [  9/230]: loss 0.7209, auc 0.4583, ap 0.4642
2024-01-10 22:02:34,212 - GAugM EPNet train, Epoch [ 10/230]: loss 0.7208, auc 0.5192, ap 0.4974
2024-01-10 22:02:34,288 - GAugM EPNet train, Epoch [ 11/230]: loss 0.7209, auc 0.4961, ap 0.5105
2024-01-10 22:02:34,365 - GAugM EPNet train, Epoch [ 12/230]: loss 0.7210, auc 0.5272, ap 0.5144
2024-01-10 22:02:34,445 - GAugM EPNet train, Epoch [ 13/230]: loss 0.7209, auc 0.5331, ap 0.5605
2024-01-10 22:02:34,522 - GAugM EPNet train, Epoch [ 14/230]: loss 0.7209, auc 0.5028, ap 0.4981
2024-01-10 22:02:34,600 - GAugM EPNet train, Epoch [ 15/230]: loss 0.7210, auc 0.3809, ap 0.4507
2024-01-10 22:02:34,678 - GAugM EPNet train, Epoch [ 16/230]: loss 0.7209, auc 0.4087, ap 0.4452
2024-01-10 22:02:34,757 - GAugM EPNet train, Epoch [ 17/230]: loss 0.7210, auc 0.5582, ap 0.5467
2024-01-10 22:02:34,834 - GAugM EPNet train, Epoch [ 18/230]: loss 0.7210, auc 0.6314, ap 0.6118
2024-01-10 22:02:34,914 - GAugM EPNet train, Epoch [ 19/230]: loss 0.7209, auc 0.5082, ap 0.5147
2024-01-10 22:02:34,996 - GAugM EPNet train, Epoch [ 20/230]: loss 0.7210, auc 0.4740, ap 0.5154
2024-01-10 22:02:35,074 - GAugM EPNet train, Epoch [ 21/230]: loss 0.7209, auc 0.4400, ap 0.4667
2024-01-10 22:02:35,157 - GAugM EPNet train, Epoch [ 22/230]: loss 0.7210, auc 0.3432, ap 0.4239
2024-01-10 22:02:35,235 - GAugM EPNet train, Epoch [ 23/230]: loss 0.7208, auc 0.4888, ap 0.4948
2024-01-10 22:02:35,312 - GAugM EPNet train, Epoch [ 24/230]: loss 0.7209, auc 0.4226, ap 0.4389
2024-01-10 22:02:35,391 - GAugM EPNet train, Epoch [ 25/230]: loss 0.7209, auc 0.4694, ap 0.4774
2024-01-10 22:02:35,469 - GAugM EPNet train, Epoch [ 26/230]: loss 0.7210, auc 0.5180, ap 0.5194
2024-01-10 22:02:35,546 - GAugM EPNet train, Epoch [ 27/230]: loss 0.7209, auc 0.4192, ap 0.4730
2024-01-10 22:02:35,626 - GAugM EPNet train, Epoch [ 28/230]: loss 0.7209, auc 0.5039, ap 0.5024
2024-01-10 22:02:35,702 - GAugM EPNet train, Epoch [ 29/230]: loss 0.7210, auc 0.5498, ap 0.5679
2024-01-10 22:02:35,781 - GAugM EPNet train, Epoch [ 30/230]: loss 0.7209, auc 0.5541, ap 0.5547
2024-01-10 22:02:35,859 - GAugM EPNet train, Epoch [ 31/230]: loss 0.7208, auc 0.4995, ap 0.4986
2024-01-10 22:02:35,935 - GAugM EPNet train, Epoch [ 32/230]: loss 0.7210, auc 0.5447, ap 0.5319
2024-01-10 22:02:36,012 - GAugM EPNet train, Epoch [ 33/230]: loss 0.7209, auc 0.5417, ap 0.5579
2024-01-10 22:02:36,089 - GAugM EPNet train, Epoch [ 34/230]: loss 0.7209, auc 0.4404, ap 0.4524
2024-01-10 22:02:36,165 - GAugM EPNet train, Epoch [ 35/230]: loss 0.7209, auc 0.5886, ap 0.5773
2024-01-10 22:02:36,244 - GAugM EPNet train, Epoch [ 36/230]: loss 0.7209, auc 0.5628, ap 0.5551
2024-01-10 22:02:36,322 - GAugM EPNet train, Epoch [ 37/230]: loss 0.7209, auc 0.4454, ap 0.4846
2024-01-10 22:02:36,398 - GAugM EPNet train, Epoch [ 38/230]: loss 0.7209, auc 0.5187, ap 0.5126
2024-01-10 22:02:36,473 - GAugM EPNet train, Epoch [ 39/230]: loss 0.7208, auc 0.4811, ap 0.5216
2024-01-10 22:02:36,549 - GAugM EPNet train, Epoch [ 40/230]: loss 0.7210, auc 0.5860, ap 0.5450
2024-01-10 22:02:36,624 - GAugM EPNet train, Epoch [ 41/230]: loss 0.7210, auc 0.4534, ap 0.4851
2024-01-10 22:02:36,700 - GAugM EPNet train, Epoch [ 42/230]: loss 0.7209, auc 0.5466, ap 0.5559
2024-01-10 22:02:36,776 - GAugM EPNet train, Epoch [ 43/230]: loss 0.7208, auc 0.4478, ap 0.4694
2024-01-10 22:02:36,854 - GAugM EPNet train, Epoch [ 44/230]: loss 0.7208, auc 0.3781, ap 0.4295
2024-01-10 22:02:36,928 - GAugM EPNet train, Epoch [ 45/230]: loss 0.7209, auc 0.5457, ap 0.5303
2024-01-10 22:02:37,003 - GAugM EPNet train, Epoch [ 46/230]: loss 0.7209, auc 0.4644, ap 0.5031
2024-01-10 22:02:37,082 - GAugM EPNet train, Epoch [ 47/230]: loss 0.7210, auc 0.4911, ap 0.4855
2024-01-10 22:02:37,159 - GAugM EPNet train, Epoch [ 48/230]: loss 0.7210, auc 0.5498, ap 0.5632
2024-01-10 22:02:37,235 - GAugM EPNet train, Epoch [ 49/230]: loss 0.7209, auc 0.4655, ap 0.4850
2024-01-10 22:02:37,315 - GAugM EPNet train, Epoch [ 50/230]: loss 0.7210, auc 0.5999, ap 0.5713
2024-01-10 22:02:37,392 - GAugM EPNet train, Epoch [ 51/230]: loss 0.7210, auc 0.4705, ap 0.5153
2024-01-10 22:02:37,468 - GAugM EPNet train, Epoch [ 52/230]: loss 0.7209, auc 0.4117, ap 0.4641
2024-01-10 22:02:37,546 - GAugM EPNet train, Epoch [ 53/230]: loss 0.7209, auc 0.5335, ap 0.5530
2024-01-10 22:02:37,622 - GAugM EPNet train, Epoch [ 54/230]: loss 0.7211, auc 0.5933, ap 0.5613
2024-01-10 22:02:37,698 - GAugM EPNet train, Epoch [ 55/230]: loss 0.7209, auc 0.5915, ap 0.5984
2024-01-10 22:02:37,775 - GAugM EPNet train, Epoch [ 56/230]: loss 0.7208, auc 0.5292, ap 0.4999
2024-01-10 22:02:37,851 - GAugM EPNet train, Epoch [ 57/230]: loss 0.7209, auc 0.4665, ap 0.4591
2024-01-10 22:02:37,925 - GAugM EPNet train, Epoch [ 58/230]: loss 0.7210, auc 0.4356, ap 0.4756
2024-01-10 22:02:38,003 - GAugM EPNet train, Epoch [ 59/230]: loss 0.7211, auc 0.5262, ap 0.5015
2024-01-10 22:02:38,084 - GAugM EPNet train, Epoch [ 60/230]: loss 0.7210, auc 0.5351, ap 0.5460
2024-01-10 22:02:38,163 - GAugM EPNet train, Epoch [ 61/230]: loss 0.7209, auc 0.5475, ap 0.5363
2024-01-10 22:02:38,237 - GAugM EPNet train, Epoch [ 62/230]: loss 0.7210, auc 0.4502, ap 0.4647
2024-01-10 22:02:38,320 - GAugM EPNet train, Epoch [ 63/230]: loss 0.7208, auc 0.4582, ap 0.4815
2024-01-10 22:02:38,395 - GAugM EPNet train, Epoch [ 64/230]: loss 0.7208, auc 0.4642, ap 0.4993
2024-01-10 22:02:38,470 - GAugM EPNet train, Epoch [ 65/230]: loss 0.7208, auc 0.5986, ap 0.5615
2024-01-10 22:02:38,546 - GAugM EPNet train, Epoch [ 66/230]: loss 0.7209, auc 0.4163, ap 0.4471
2024-01-10 22:02:38,624 - GAugM EPNet train, Epoch [ 67/230]: loss 0.7209, auc 0.4963, ap 0.5043
2024-01-10 22:02:38,701 - GAugM EPNet train, Epoch [ 68/230]: loss 0.7210, auc 0.4601, ap 0.5318
2024-01-10 22:02:38,777 - GAugM EPNet train, Epoch [ 69/230]: loss 0.7210, auc 0.5212, ap 0.5243
2024-01-10 22:02:38,854 - GAugM EPNet train, Epoch [ 70/230]: loss 0.7210, auc 0.4439, ap 0.4515
2024-01-10 22:02:38,930 - GAugM EPNet train, Epoch [ 71/230]: loss 0.7210, auc 0.5157, ap 0.5134
2024-01-10 22:02:39,006 - GAugM EPNet train, Epoch [ 72/230]: loss 0.7210, auc 0.4603, ap 0.4941
2024-01-10 22:02:39,081 - GAugM EPNet train, Epoch [ 73/230]: loss 0.7209, auc 0.5278, ap 0.5221
2024-01-10 22:02:39,157 - GAugM EPNet train, Epoch [ 74/230]: loss 0.7209, auc 0.5021, ap 0.4936
2024-01-10 22:02:39,232 - GAugM EPNet train, Epoch [ 75/230]: loss 0.7210, auc 0.3743, ap 0.4163
2024-01-10 22:02:39,311 - GAugM EPNet train, Epoch [ 76/230]: loss 0.7209, auc 0.4758, ap 0.4969
2024-01-10 22:02:39,390 - GAugM EPNet train, Epoch [ 77/230]: loss 0.7208, auc 0.5441, ap 0.5680
2024-01-10 22:02:39,466 - GAugM EPNet train, Epoch [ 78/230]: loss 0.7209, auc 0.5125, ap 0.5158
2024-01-10 22:02:39,541 - GAugM EPNet train, Epoch [ 79/230]: loss 0.7208, auc 0.5146, ap 0.5257
2024-01-10 22:02:39,620 - GAugM EPNet train, Epoch [ 80/230]: loss 0.7209, auc 0.5473, ap 0.5211
2024-01-10 22:02:39,696 - GAugM EPNet train, Epoch [ 81/230]: loss 0.7209, auc 0.4712, ap 0.4749
2024-01-10 22:02:39,773 - GAugM EPNet train, Epoch [ 82/230]: loss 0.7210, auc 0.5433, ap 0.5184
2024-01-10 22:02:39,851 - GAugM EPNet train, Epoch [ 83/230]: loss 0.7209, auc 0.4956, ap 0.5265
2024-01-10 22:02:39,926 - GAugM EPNet train, Epoch [ 84/230]: loss 0.7209, auc 0.4229, ap 0.4495
2024-01-10 22:02:40,003 - GAugM EPNet train, Epoch [ 85/230]: loss 0.7210, auc 0.4484, ap 0.5043
2024-01-10 22:02:40,080 - GAugM EPNet train, Epoch [ 86/230]: loss 0.7208, auc 0.5290, ap 0.5436
2024-01-10 22:02:40,155 - GAugM EPNet train, Epoch [ 87/230]: loss 0.7209, auc 0.5908, ap 0.5532
2024-01-10 22:02:40,230 - GAugM EPNet train, Epoch [ 88/230]: loss 0.7210, auc 0.4817, ap 0.5034
2024-01-10 22:02:40,306 - GAugM EPNet train, Epoch [ 89/230]: loss 0.7210, auc 0.5185, ap 0.5832
2024-01-10 22:02:40,382 - GAugM EPNet train, Epoch [ 90/230]: loss 0.7209, auc 0.4530, ap 0.4646
2024-01-10 22:02:40,464 - GAugM EPNet train, Epoch [ 91/230]: loss 0.7208, auc 0.4909, ap 0.4809
2024-01-10 22:02:40,540 - GAugM EPNet train, Epoch [ 92/230]: loss 0.7209, auc 0.5917, ap 0.5716
2024-01-10 22:02:40,616 - GAugM EPNet train, Epoch [ 93/230]: loss 0.7209, auc 0.3839, ap 0.4379
2024-01-10 22:02:40,694 - GAugM EPNet train, Epoch [ 94/230]: loss 0.7210, auc 0.3891, ap 0.4435
2024-01-10 22:02:40,771 - GAugM EPNet train, Epoch [ 95/230]: loss 0.7210, auc 0.4414, ap 0.4580
2024-01-10 22:02:40,847 - GAugM EPNet train, Epoch [ 96/230]: loss 0.7209, auc 0.5614, ap 0.5762
2024-01-10 22:02:40,923 - GAugM EPNet train, Epoch [ 97/230]: loss 0.7209, auc 0.4519, ap 0.4679
2024-01-10 22:02:41,004 - GAugM EPNet train, Epoch [ 98/230]: loss 0.7209, auc 0.4530, ap 0.4696
2024-01-10 22:02:41,081 - GAugM EPNet train, Epoch [ 99/230]: loss 0.7209, auc 0.4391, ap 0.4615
2024-01-10 22:02:41,156 - GAugM EPNet train, Epoch [100/230]: loss 0.7210, auc 0.5055, ap 0.5431
2024-01-10 22:02:41,234 - GAugM EPNet train, Epoch [101/230]: loss 0.7210, auc 0.4966, ap 0.5315
2024-01-10 22:02:41,311 - GAugM EPNet train, Epoch [102/230]: loss 0.7209, auc 0.4881, ap 0.5021
2024-01-10 22:02:41,386 - GAugM EPNet train, Epoch [103/230]: loss 0.7209, auc 0.4213, ap 0.4823
2024-01-10 22:02:41,461 - GAugM EPNet train, Epoch [104/230]: loss 0.7209, auc 0.4108, ap 0.4467
2024-01-10 22:02:41,538 - GAugM EPNet train, Epoch [105/230]: loss 0.7209, auc 0.4751, ap 0.4776
2024-01-10 22:02:41,613 - GAugM EPNet train, Epoch [106/230]: loss 0.7210, auc 0.5278, ap 0.5138
2024-01-10 22:02:41,688 - GAugM EPNet train, Epoch [107/230]: loss 0.7210, auc 0.4270, ap 0.4843
2024-01-10 22:02:41,769 - GAugM EPNet train, Epoch [108/230]: loss 0.7208, auc 0.4822, ap 0.4970
2024-01-10 22:02:41,846 - GAugM EPNet train, Epoch [109/230]: loss 0.7210, auc 0.4658, ap 0.4815
2024-01-10 22:02:41,923 - GAugM EPNet train, Epoch [110/230]: loss 0.7209, auc 0.5059, ap 0.5087
2024-01-10 22:02:41,999 - GAugM EPNet train, Epoch [111/230]: loss 0.7210, auc 0.4890, ap 0.5319
2024-01-10 22:02:42,076 - GAugM EPNet train, Epoch [112/230]: loss 0.7209, auc 0.4721, ap 0.4964
2024-01-10 22:02:42,153 - GAugM EPNet train, Epoch [113/230]: loss 0.7210, auc 0.5511, ap 0.5773
2024-01-10 22:02:42,233 - GAugM EPNet train, Epoch [114/230]: loss 0.7209, auc 0.4473, ap 0.4561
2024-01-10 22:02:42,309 - GAugM EPNet train, Epoch [115/230]: loss 0.7210, auc 0.5612, ap 0.5362
2024-01-10 22:02:42,385 - GAugM EPNet train, Epoch [116/230]: loss 0.7209, auc 0.4956, ap 0.4983
2024-01-10 22:02:42,463 - GAugM EPNet train, Epoch [117/230]: loss 0.7208, auc 0.3950, ap 0.4326
2024-01-10 22:02:42,538 - GAugM EPNet train, Epoch [118/230]: loss 0.7209, auc 0.5000, ap 0.5212
2024-01-10 22:02:42,612 - GAugM EPNet train, Epoch [119/230]: loss 0.7209, auc 0.5739, ap 0.5860
2024-01-10 22:02:42,687 - GAugM EPNet train, Epoch [120/230]: loss 0.7210, auc 0.4459, ap 0.4658
2024-01-10 22:02:42,763 - GAugM EPNet train, Epoch [121/230]: loss 0.7210, auc 0.4448, ap 0.4722
2024-01-10 22:02:42,840 - GAugM EPNet train, Epoch [122/230]: loss 0.7209, auc 0.5135, ap 0.5222
2024-01-10 22:02:42,917 - GAugM EPNet train, Epoch [123/230]: loss 0.7209, auc 0.5189, ap 0.5483
2024-01-10 22:02:42,994 - GAugM EPNet train, Epoch [124/230]: loss 0.7210, auc 0.5203, ap 0.5227
2024-01-10 22:02:43,070 - GAugM EPNet train, Epoch [125/230]: loss 0.7209, auc 0.4692, ap 0.5091
2024-01-10 22:02:43,148 - GAugM EPNet train, Epoch [126/230]: loss 0.7210, auc 0.4555, ap 0.4599
2024-01-10 22:02:43,225 - GAugM EPNet train, Epoch [127/230]: loss 0.7209, auc 0.5607, ap 0.5293
2024-01-10 22:02:43,301 - GAugM EPNet train, Epoch [128/230]: loss 0.7210, auc 0.4733, ap 0.4774
2024-01-10 22:02:43,379 - GAugM EPNet train, Epoch [129/230]: loss 0.7208, auc 0.4142, ap 0.4513
2024-01-10 22:02:43,457 - GAugM EPNet train, Epoch [130/230]: loss 0.7210, auc 0.4705, ap 0.4957
2024-01-10 22:02:43,534 - GAugM EPNet train, Epoch [131/230]: loss 0.7210, auc 0.5466, ap 0.5542
2024-01-10 22:02:43,618 - GAugM EPNet train, Epoch [132/230]: loss 0.7209, auc 0.5130, ap 0.5306
2024-01-10 22:02:43,696 - GAugM EPNet train, Epoch [133/230]: loss 0.7209, auc 0.4208, ap 0.4901
2024-01-10 22:02:43,773 - GAugM EPNet train, Epoch [134/230]: loss 0.7210, auc 0.5167, ap 0.5414
2024-01-10 22:02:43,850 - GAugM EPNet train, Epoch [135/230]: loss 0.7209, auc 0.3806, ap 0.4464
2024-01-10 22:02:43,936 - GAugM EPNet train, Epoch [136/230]: loss 0.7209, auc 0.4815, ap 0.5067
2024-01-10 22:02:44,011 - GAugM EPNet train, Epoch [137/230]: loss 0.7210, auc 0.4699, ap 0.4917
2024-01-10 22:02:44,085 - GAugM EPNet train, Epoch [138/230]: loss 0.7210, auc 0.5552, ap 0.5597
2024-01-10 22:02:44,164 - GAugM EPNet train, Epoch [139/230]: loss 0.7210, auc 0.4356, ap 0.4593
2024-01-10 22:02:44,240 - GAugM EPNet train, Epoch [140/230]: loss 0.7209, auc 0.4822, ap 0.5068
2024-01-10 22:02:44,316 - GAugM EPNet train, Epoch [141/230]: loss 0.7209, auc 0.4900, ap 0.4887
2024-01-10 22:02:44,392 - GAugM EPNet train, Epoch [142/230]: loss 0.7209, auc 0.5383, ap 0.5435
2024-01-10 22:02:44,467 - GAugM EPNet train, Epoch [143/230]: loss 0.7209, auc 0.4528, ap 0.4649
2024-01-10 22:02:44,544 - GAugM EPNet train, Epoch [144/230]: loss 0.7209, auc 0.4608, ap 0.4818
2024-01-10 22:02:44,621 - GAugM EPNet train, Epoch [145/230]: loss 0.7209, auc 0.4938, ap 0.5061
2024-01-10 22:02:44,698 - GAugM EPNet train, Epoch [146/230]: loss 0.7209, auc 0.4956, ap 0.5257
2024-01-10 22:02:44,777 - GAugM EPNet train, Epoch [147/230]: loss 0.7209, auc 0.5858, ap 0.5919
2024-01-10 22:02:44,853 - GAugM EPNet train, Epoch [148/230]: loss 0.7209, auc 0.5117, ap 0.5056
2024-01-10 22:02:44,928 - GAugM EPNet train, Epoch [149/230]: loss 0.7208, auc 0.4932, ap 0.5015
2024-01-10 22:02:45,004 - GAugM EPNet train, Epoch [150/230]: loss 0.7209, auc 0.4721, ap 0.4784
2024-01-10 22:02:45,080 - GAugM EPNet train, Epoch [151/230]: loss 0.7209, auc 0.5438, ap 0.5432
2024-01-10 22:02:45,160 - GAugM EPNet train, Epoch [152/230]: loss 0.7209, auc 0.5564, ap 0.5666
2024-01-10 22:02:45,236 - GAugM EPNet train, Epoch [153/230]: loss 0.7209, auc 0.4758, ap 0.5010
2024-01-10 22:02:45,315 - GAugM EPNet train, Epoch [154/230]: loss 0.7209, auc 0.5103, ap 0.5607
2024-01-10 22:02:45,390 - GAugM EPNet train, Epoch [155/230]: loss 0.7209, auc 0.4913, ap 0.4888
2024-01-10 22:02:45,465 - GAugM EPNet train, Epoch [156/230]: loss 0.7209, auc 0.4142, ap 0.4679
2024-01-10 22:02:45,546 - GAugM EPNet train, Epoch [157/230]: loss 0.7209, auc 0.4950, ap 0.4997
2024-01-10 22:02:45,621 - GAugM EPNet train, Epoch [158/230]: loss 0.7208, auc 0.3615, ap 0.4168
2024-01-10 22:02:45,697 - GAugM EPNet train, Epoch [159/230]: loss 0.7208, auc 0.5189, ap 0.5268
2024-01-10 22:02:45,775 - GAugM EPNet train, Epoch [160/230]: loss 0.7209, auc 0.5406, ap 0.5558
2024-01-10 22:02:45,860 - GAugM EPNet train, Epoch [161/230]: loss 0.7209, auc 0.5237, ap 0.5427
2024-01-10 22:02:45,936 - GAugM EPNet train, Epoch [162/230]: loss 0.7209, auc 0.4530, ap 0.4694
2024-01-10 22:02:46,013 - GAugM EPNet train, Epoch [163/230]: loss 0.7209, auc 0.5379, ap 0.5259
2024-01-10 22:02:46,088 - GAugM EPNet train, Epoch [164/230]: loss 0.7211, auc 0.5150, ap 0.5185
2024-01-10 22:02:46,164 - GAugM EPNet train, Epoch [165/230]: loss 0.7210, auc 0.4947, ap 0.5166
2024-01-10 22:02:46,241 - GAugM EPNet train, Epoch [166/230]: loss 0.7208, auc 0.5869, ap 0.5931
2024-01-10 22:02:46,316 - GAugM EPNet train, Epoch [167/230]: loss 0.7209, auc 0.4427, ap 0.4662
2024-01-10 22:02:46,393 - GAugM EPNet train, Epoch [168/230]: loss 0.7209, auc 0.4432, ap 0.4870
2024-01-10 22:02:46,470 - GAugM EPNet train, Epoch [169/230]: loss 0.7209, auc 0.5691, ap 0.5869
2024-01-10 22:02:46,547 - GAugM EPNet train, Epoch [170/230]: loss 0.7210, auc 0.4939, ap 0.4938
2024-01-10 22:02:46,624 - GAugM EPNet train, Epoch [171/230]: loss 0.7209, auc 0.4813, ap 0.4951
2024-01-10 22:02:46,706 - GAugM EPNet train, Epoch [172/230]: loss 0.7208, auc 0.4747, ap 0.4829
2024-01-10 22:02:46,782 - GAugM EPNet train, Epoch [173/230]: loss 0.7209, auc 0.4712, ap 0.5153
2024-01-10 22:02:46,858 - GAugM EPNet train, Epoch [174/230]: loss 0.7209, auc 0.4925, ap 0.5028
2024-01-10 22:02:46,935 - GAugM EPNet train, Epoch [175/230]: loss 0.7209, auc 0.6410, ap 0.6302
2024-01-10 22:02:47,011 - GAugM EPNet train, Epoch [176/230]: loss 0.7209, auc 0.5148, ap 0.4982
2024-01-10 22:02:47,099 - GAugM EPNet train, Epoch [177/230]: loss 0.7210, auc 0.4957, ap 0.4976
2024-01-10 22:02:47,175 - GAugM EPNet train, Epoch [178/230]: loss 0.7210, auc 0.5534, ap 0.5580
2024-01-10 22:02:47,253 - GAugM EPNet train, Epoch [179/230]: loss 0.7210, auc 0.3571, ap 0.4241
2024-01-10 22:02:47,330 - GAugM EPNet train, Epoch [180/230]: loss 0.7210, auc 0.5336, ap 0.5691
2024-01-10 22:02:47,412 - GAugM EPNet train, Epoch [181/230]: loss 0.7209, auc 0.4434, ap 0.4647
2024-01-10 22:02:47,489 - GAugM EPNet train, Epoch [182/230]: loss 0.7209, auc 0.4899, ap 0.5485
2024-01-10 22:02:47,565 - GAugM EPNet train, Epoch [183/230]: loss 0.7210, auc 0.5046, ap 0.5105
2024-01-10 22:02:47,642 - GAugM EPNet train, Epoch [184/230]: loss 0.7209, auc 0.4795, ap 0.4880
2024-01-10 22:02:47,718 - GAugM EPNet train, Epoch [185/230]: loss 0.7209, auc 0.4432, ap 0.4639
2024-01-10 22:02:47,796 - GAugM EPNet train, Epoch [186/230]: loss 0.7208, auc 0.4471, ap 0.5316
2024-01-10 22:02:47,872 - GAugM EPNet train, Epoch [187/230]: loss 0.7209, auc 0.5399, ap 0.5292
2024-01-10 22:02:47,948 - GAugM EPNet train, Epoch [188/230]: loss 0.7209, auc 0.5425, ap 0.5259
2024-01-10 22:02:48,025 - GAugM EPNet train, Epoch [189/230]: loss 0.7209, auc 0.6057, ap 0.6154
2024-01-10 22:02:48,100 - GAugM EPNet train, Epoch [190/230]: loss 0.7209, auc 0.4409, ap 0.4571
2024-01-10 22:02:48,176 - GAugM EPNet train, Epoch [191/230]: loss 0.7209, auc 0.4352, ap 0.4752
2024-01-10 22:02:48,251 - GAugM EPNet train, Epoch [192/230]: loss 0.7209, auc 0.5342, ap 0.4986
2024-01-10 22:02:48,327 - GAugM EPNet train, Epoch [193/230]: loss 0.7209, auc 0.5199, ap 0.5062
2024-01-10 22:02:48,404 - GAugM EPNet train, Epoch [194/230]: loss 0.7209, auc 0.4539, ap 0.4874
2024-01-10 22:02:48,482 - GAugM EPNet train, Epoch [195/230]: loss 0.7209, auc 0.4418, ap 0.4714
2024-01-10 22:02:48,557 - GAugM EPNet train, Epoch [196/230]: loss 0.7208, auc 0.5137, ap 0.5016
2024-01-10 22:02:48,631 - GAugM EPNet train, Epoch [197/230]: loss 0.7210, auc 0.4354, ap 0.4496
2024-01-10 22:02:48,707 - GAugM EPNet train, Epoch [198/230]: loss 0.7210, auc 0.5148, ap 0.5136
2024-01-10 22:02:48,789 - GAugM EPNet train, Epoch [199/230]: loss 0.7209, auc 0.4612, ap 0.4826
2024-01-10 22:02:48,866 - GAugM EPNet train, Epoch [200/230]: loss 0.7210, auc 0.5137, ap 0.5112
2024-01-10 22:02:48,947 - GAugM EPNet train, Epoch [201/230]: loss 0.7209, auc 0.4744, ap 0.4844
2024-01-10 22:02:49,022 - GAugM EPNet train, Epoch [202/230]: loss 0.7210, auc 0.5041, ap 0.5668
2024-01-10 22:02:49,100 - GAugM EPNet train, Epoch [203/230]: loss 0.7210, auc 0.4391, ap 0.4666
2024-01-10 22:02:49,178 - GAugM EPNet train, Epoch [204/230]: loss 0.7209, auc 0.3697, ap 0.4158
2024-01-10 22:02:49,255 - GAugM EPNet train, Epoch [205/230]: loss 0.7209, auc 0.4706, ap 0.4757
2024-01-10 22:02:49,336 - GAugM EPNet train, Epoch [206/230]: loss 0.7209, auc 0.3539, ap 0.4068
2024-01-10 22:02:49,414 - GAugM EPNet train, Epoch [207/230]: loss 0.7210, auc 0.4509, ap 0.4893
2024-01-10 22:02:49,488 - GAugM EPNet train, Epoch [208/230]: loss 0.7209, auc 0.4662, ap 0.5222
2024-01-10 22:02:49,565 - GAugM EPNet train, Epoch [209/230]: loss 0.7210, auc 0.5481, ap 0.5576
2024-01-10 22:02:49,644 - GAugM EPNet train, Epoch [210/230]: loss 0.7209, auc 0.4224, ap 0.4482
2024-01-10 22:02:49,722 - GAugM EPNet train, Epoch [211/230]: loss 0.7210, auc 0.4936, ap 0.5163
2024-01-10 22:02:49,797 - GAugM EPNet train, Epoch [212/230]: loss 0.7210, auc 0.4713, ap 0.5113
2024-01-10 22:02:49,874 - GAugM EPNet train, Epoch [213/230]: loss 0.7208, auc 0.6022, ap 0.6458
2024-01-10 22:02:49,951 - GAugM EPNet train, Epoch [214/230]: loss 0.7210, auc 0.4712, ap 0.4861
2024-01-10 22:02:50,027 - GAugM EPNet train, Epoch [215/230]: loss 0.7210, auc 0.5231, ap 0.5039
2024-01-10 22:02:50,103 - GAugM EPNet train, Epoch [216/230]: loss 0.7209, auc 0.5669, ap 0.5458
2024-01-10 22:02:50,179 - GAugM EPNet train, Epoch [217/230]: loss 0.7209, auc 0.5838, ap 0.6317
2024-01-10 22:02:50,255 - GAugM EPNet train, Epoch [218/230]: loss 0.7209, auc 0.5267, ap 0.5825
2024-01-10 22:02:50,334 - GAugM EPNet train, Epoch [219/230]: loss 0.7208, auc 0.5098, ap 0.5252
2024-01-10 22:02:50,415 - GAugM EPNet train, Epoch [220/230]: loss 0.7210, auc 0.4347, ap 0.4585
2024-01-10 22:02:50,493 - GAugM EPNet train, Epoch [221/230]: loss 0.7209, auc 0.5048, ap 0.5003
2024-01-10 22:02:50,570 - GAugM EPNet train, Epoch [222/230]: loss 0.7209, auc 0.5278, ap 0.5157
2024-01-10 22:02:50,646 - GAugM EPNet train, Epoch [223/230]: loss 0.7209, auc 0.5199, ap 0.5163
2024-01-10 22:02:50,722 - GAugM EPNet train, Epoch [224/230]: loss 0.7210, auc 0.3875, ap 0.4306
2024-01-10 22:02:50,799 - GAugM EPNet train, Epoch [225/230]: loss 0.7209, auc 0.4603, ap 0.4778
2024-01-10 22:02:50,878 - GAugM EPNet train, Epoch [226/230]: loss 0.7210, auc 0.4758, ap 0.4948
2024-01-10 22:02:50,956 - GAugM EPNet train, Epoch [227/230]: loss 0.7210, auc 0.4829, ap 0.4944
2024-01-10 22:02:51,033 - GAugM EPNet train, Epoch [228/230]: loss 0.7209, auc 0.5064, ap 0.4992
2024-01-10 22:02:51,110 - GAugM EPNet train, Epoch [229/230]: loss 0.7209, auc 0.4986, ap 0.5075
2024-01-10 22:02:51,185 - GAugM EPNet train, Epoch [230/230]: loss 0.7209, auc 0.4482, ap 0.4721
2024-01-10 22:02:51,186 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9e21850>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:02:51,916 - GAugM EPNet train, Epoch [  1/230]: loss 0.7210, auc 0.5091, ap 0.4874
2024-01-10 22:02:52,006 - GAugM EPNet train, Epoch [  2/230]: loss 0.7210, auc 0.4696, ap 0.4717
2024-01-10 22:02:52,092 - GAugM EPNet train, Epoch [  3/230]: loss 0.7209, auc 0.6166, ap 0.5923
2024-01-10 22:02:52,179 - GAugM EPNet train, Epoch [  4/230]: loss 0.7209, auc 0.5148, ap 0.5110
2024-01-10 22:02:52,266 - GAugM EPNet train, Epoch [  5/230]: loss 0.7209, auc 0.5589, ap 0.5710
2024-01-10 22:02:52,355 - GAugM EPNet train, Epoch [  6/230]: loss 0.7209, auc 0.4781, ap 0.4733
2024-01-10 22:02:52,440 - GAugM EPNet train, Epoch [  7/230]: loss 0.7209, auc 0.5183, ap 0.5017
2024-01-10 22:02:52,519 - GAugM EPNet train, Epoch [  8/230]: loss 0.7210, auc 0.4834, ap 0.5040
2024-01-10 22:02:52,597 - GAugM EPNet train, Epoch [  9/230]: loss 0.7209, auc 0.3859, ap 0.4341
2024-01-10 22:02:52,673 - GAugM EPNet train, Epoch [ 10/230]: loss 0.7208, auc 0.5073, ap 0.5096
2024-01-10 22:02:52,753 - GAugM EPNet train, Epoch [ 11/230]: loss 0.7209, auc 0.4774, ap 0.4880
2024-01-10 22:02:52,830 - GAugM EPNet train, Epoch [ 12/230]: loss 0.7210, auc 0.4788, ap 0.4849
2024-01-10 22:02:52,907 - GAugM EPNet train, Epoch [ 13/230]: loss 0.7209, auc 0.5575, ap 0.5704
2024-01-10 22:02:52,983 - GAugM EPNet train, Epoch [ 14/230]: loss 0.7209, auc 0.5440, ap 0.5171
2024-01-10 22:02:53,060 - GAugM EPNet train, Epoch [ 15/230]: loss 0.7210, auc 0.4831, ap 0.5480
2024-01-10 22:02:53,137 - GAugM EPNet train, Epoch [ 16/230]: loss 0.7209, auc 0.4738, ap 0.4828
2024-01-10 22:02:53,212 - GAugM EPNet train, Epoch [ 17/230]: loss 0.7210, auc 0.6006, ap 0.5533
2024-01-10 22:02:53,294 - GAugM EPNet train, Epoch [ 18/230]: loss 0.7210, auc 0.6070, ap 0.5987
2024-01-10 22:02:53,370 - GAugM EPNet train, Epoch [ 19/230]: loss 0.7209, auc 0.5593, ap 0.5444
2024-01-10 22:02:53,446 - GAugM EPNet train, Epoch [ 20/230]: loss 0.7210, auc 0.4735, ap 0.5297
2024-01-10 22:02:53,524 - GAugM EPNet train, Epoch [ 21/230]: loss 0.7209, auc 0.4738, ap 0.4743
2024-01-10 22:02:53,602 - GAugM EPNet train, Epoch [ 22/230]: loss 0.7210, auc 0.3749, ap 0.4432
2024-01-10 22:02:53,681 - GAugM EPNet train, Epoch [ 23/230]: loss 0.7208, auc 0.4507, ap 0.4647
2024-01-10 22:02:53,759 - GAugM EPNet train, Epoch [ 24/230]: loss 0.7209, auc 0.5144, ap 0.5315
2024-01-10 22:02:53,835 - GAugM EPNet train, Epoch [ 25/230]: loss 0.7209, auc 0.3702, ap 0.4194
2024-01-10 22:02:53,910 - GAugM EPNet train, Epoch [ 26/230]: loss 0.7210, auc 0.5717, ap 0.5489
2024-01-10 22:02:53,987 - GAugM EPNet train, Epoch [ 27/230]: loss 0.7209, auc 0.4297, ap 0.4636
2024-01-10 22:02:54,063 - GAugM EPNet train, Epoch [ 28/230]: loss 0.7209, auc 0.5269, ap 0.5370
2024-01-10 22:02:54,138 - GAugM EPNet train, Epoch [ 29/230]: loss 0.7210, auc 0.4528, ap 0.4779
2024-01-10 22:02:54,217 - GAugM EPNet train, Epoch [ 30/230]: loss 0.7209, auc 0.5390, ap 0.5776
2024-01-10 22:02:54,294 - GAugM EPNet train, Epoch [ 31/230]: loss 0.7208, auc 0.5269, ap 0.5400
2024-01-10 22:02:54,370 - GAugM EPNet train, Epoch [ 32/230]: loss 0.7210, auc 0.5557, ap 0.5417
2024-01-10 22:02:54,447 - GAugM EPNet train, Epoch [ 33/230]: loss 0.7209, auc 0.5048, ap 0.5152
2024-01-10 22:02:54,525 - GAugM EPNet train, Epoch [ 34/230]: loss 0.7209, auc 0.4653, ap 0.4754
2024-01-10 22:02:54,602 - GAugM EPNet train, Epoch [ 35/230]: loss 0.7209, auc 0.5198, ap 0.5128
2024-01-10 22:02:54,680 - GAugM EPNet train, Epoch [ 36/230]: loss 0.7209, auc 0.5368, ap 0.5182
2024-01-10 22:02:54,754 - GAugM EPNet train, Epoch [ 37/230]: loss 0.7209, auc 0.4706, ap 0.4902
2024-01-10 22:02:54,834 - GAugM EPNet train, Epoch [ 38/230]: loss 0.7209, auc 0.5166, ap 0.5131
2024-01-10 22:02:54,912 - GAugM EPNet train, Epoch [ 39/230]: loss 0.7208, auc 0.4468, ap 0.4925
2024-01-10 22:02:54,989 - GAugM EPNet train, Epoch [ 40/230]: loss 0.7210, auc 0.5532, ap 0.5294
2024-01-10 22:02:55,068 - GAugM EPNet train, Epoch [ 41/230]: loss 0.7210, auc 0.4881, ap 0.4772
2024-01-10 22:02:55,147 - GAugM EPNet train, Epoch [ 42/230]: loss 0.7209, auc 0.5767, ap 0.5844
2024-01-10 22:02:55,225 - GAugM EPNet train, Epoch [ 43/230]: loss 0.7208, auc 0.4646, ap 0.4900
2024-01-10 22:02:55,304 - GAugM EPNet train, Epoch [ 44/230]: loss 0.7208, auc 0.4026, ap 0.4507
2024-01-10 22:02:55,379 - GAugM EPNet train, Epoch [ 45/230]: loss 0.7209, auc 0.4639, ap 0.4652
2024-01-10 22:02:55,458 - GAugM EPNet train, Epoch [ 46/230]: loss 0.7209, auc 0.5158, ap 0.5259
2024-01-10 22:02:55,535 - GAugM EPNet train, Epoch [ 47/230]: loss 0.7210, auc 0.4856, ap 0.5018
2024-01-10 22:02:55,612 - GAugM EPNet train, Epoch [ 48/230]: loss 0.7210, auc 0.5931, ap 0.5826
2024-01-10 22:02:55,690 - GAugM EPNet train, Epoch [ 49/230]: loss 0.7209, auc 0.5618, ap 0.5591
2024-01-10 22:02:55,765 - GAugM EPNet train, Epoch [ 50/230]: loss 0.7210, auc 0.5105, ap 0.5153
2024-01-10 22:02:55,844 - GAugM EPNet train, Epoch [ 51/230]: loss 0.7210, auc 0.4119, ap 0.4536
2024-01-10 22:02:55,921 - GAugM EPNet train, Epoch [ 52/230]: loss 0.7209, auc 0.5582, ap 0.5873
2024-01-10 22:02:55,999 - GAugM EPNet train, Epoch [ 53/230]: loss 0.7209, auc 0.5347, ap 0.5161
2024-01-10 22:02:56,077 - GAugM EPNet train, Epoch [ 54/230]: loss 0.7211, auc 0.5568, ap 0.5322
2024-01-10 22:02:56,152 - GAugM EPNet train, Epoch [ 55/230]: loss 0.7209, auc 0.5237, ap 0.5412
2024-01-10 22:02:56,228 - GAugM EPNet train, Epoch [ 56/230]: loss 0.7208, auc 0.4959, ap 0.5089
2024-01-10 22:02:56,304 - GAugM EPNet train, Epoch [ 57/230]: loss 0.7209, auc 0.5084, ap 0.4943
2024-01-10 22:02:56,380 - GAugM EPNet train, Epoch [ 58/230]: loss 0.7210, auc 0.4340, ap 0.4862
2024-01-10 22:02:56,457 - GAugM EPNet train, Epoch [ 59/230]: loss 0.7211, auc 0.5034, ap 0.5015
2024-01-10 22:02:56,535 - GAugM EPNet train, Epoch [ 60/230]: loss 0.7210, auc 0.4567, ap 0.4688
2024-01-10 22:02:56,617 - GAugM EPNet train, Epoch [ 61/230]: loss 0.7209, auc 0.5767, ap 0.5661
2024-01-10 22:02:56,694 - GAugM EPNet train, Epoch [ 62/230]: loss 0.7210, auc 0.4503, ap 0.5155
2024-01-10 22:02:56,772 - GAugM EPNet train, Epoch [ 63/230]: loss 0.7208, auc 0.4372, ap 0.4589
2024-01-10 22:02:56,851 - GAugM EPNet train, Epoch [ 64/230]: loss 0.7208, auc 0.4393, ap 0.4738
2024-01-10 22:02:56,933 - GAugM EPNet train, Epoch [ 65/230]: loss 0.7208, auc 0.6187, ap 0.6248
2024-01-10 22:02:57,008 - GAugM EPNet train, Epoch [ 66/230]: loss 0.7209, auc 0.4279, ap 0.4507
2024-01-10 22:02:57,084 - GAugM EPNet train, Epoch [ 67/230]: loss 0.7209, auc 0.6038, ap 0.5534
2024-01-10 22:02:57,161 - GAugM EPNet train, Epoch [ 68/230]: loss 0.7210, auc 0.5586, ap 0.6015
2024-01-10 22:02:57,240 - GAugM EPNet train, Epoch [ 69/230]: loss 0.7210, auc 0.4567, ap 0.4904
2024-01-10 22:02:57,320 - GAugM EPNet train, Epoch [ 70/230]: loss 0.7210, auc 0.4678, ap 0.4684
2024-01-10 22:02:57,397 - GAugM EPNet train, Epoch [ 71/230]: loss 0.7210, auc 0.5678, ap 0.5339
2024-01-10 22:02:57,475 - GAugM EPNet train, Epoch [ 72/230]: loss 0.7210, auc 0.4176, ap 0.4869
2024-01-10 22:02:57,550 - GAugM EPNet train, Epoch [ 73/230]: loss 0.7209, auc 0.5016, ap 0.5006
2024-01-10 22:02:57,636 - GAugM EPNet train, Epoch [ 74/230]: loss 0.7209, auc 0.5465, ap 0.5476
2024-01-10 22:02:57,712 - GAugM EPNet train, Epoch [ 75/230]: loss 0.7210, auc 0.5240, ap 0.5112
2024-01-10 22:02:57,788 - GAugM EPNet train, Epoch [ 76/230]: loss 0.7209, auc 0.3418, ap 0.4315
2024-01-10 22:02:57,865 - GAugM EPNet train, Epoch [ 77/230]: loss 0.7208, auc 0.5700, ap 0.5775
2024-01-10 22:02:57,941 - GAugM EPNet train, Epoch [ 78/230]: loss 0.7209, auc 0.5301, ap 0.5147
2024-01-10 22:02:58,016 - GAugM EPNet train, Epoch [ 79/230]: loss 0.7208, auc 0.4970, ap 0.4998
2024-01-10 22:02:58,091 - GAugM EPNet train, Epoch [ 80/230]: loss 0.7209, auc 0.5799, ap 0.5499
2024-01-10 22:02:58,171 - GAugM EPNet train, Epoch [ 81/230]: loss 0.7209, auc 0.4632, ap 0.4688
2024-01-10 22:02:58,256 - GAugM EPNet train, Epoch [ 82/230]: loss 0.7210, auc 0.5411, ap 0.5518
2024-01-10 22:02:58,332 - GAugM EPNet train, Epoch [ 83/230]: loss 0.7209, auc 0.5173, ap 0.5392
2024-01-10 22:02:58,410 - GAugM EPNet train, Epoch [ 84/230]: loss 0.7209, auc 0.3628, ap 0.4081
2024-01-10 22:02:58,491 - GAugM EPNet train, Epoch [ 85/230]: loss 0.7210, auc 0.4920, ap 0.5397
2024-01-10 22:02:58,568 - GAugM EPNet train, Epoch [ 86/230]: loss 0.7208, auc 0.4334, ap 0.4693
2024-01-10 22:02:58,643 - GAugM EPNet train, Epoch [ 87/230]: loss 0.7209, auc 0.5155, ap 0.5286
2024-01-10 22:02:58,720 - GAugM EPNet train, Epoch [ 88/230]: loss 0.7210, auc 0.4745, ap 0.5290
2024-01-10 22:02:58,796 - GAugM EPNet train, Epoch [ 89/230]: loss 0.7210, auc 0.4251, ap 0.4741
2024-01-10 22:02:58,873 - GAugM EPNet train, Epoch [ 90/230]: loss 0.7209, auc 0.4849, ap 0.4906
2024-01-10 22:02:58,951 - GAugM EPNet train, Epoch [ 91/230]: loss 0.7208, auc 0.5710, ap 0.5405
2024-01-10 22:02:59,029 - GAugM EPNet train, Epoch [ 92/230]: loss 0.7209, auc 0.6134, ap 0.6020
2024-01-10 22:02:59,107 - GAugM EPNet train, Epoch [ 93/230]: loss 0.7209, auc 0.3923, ap 0.4341
2024-01-10 22:02:59,184 - GAugM EPNet train, Epoch [ 94/230]: loss 0.7210, auc 0.4379, ap 0.4411
2024-01-10 22:02:59,261 - GAugM EPNet train, Epoch [ 95/230]: loss 0.7210, auc 0.5133, ap 0.5018
2024-01-10 22:02:59,338 - GAugM EPNet train, Epoch [ 96/230]: loss 0.7209, auc 0.5486, ap 0.5725
2024-01-10 22:02:59,421 - GAugM EPNet train, Epoch [ 97/230]: loss 0.7209, auc 0.5005, ap 0.5576
2024-01-10 22:02:59,497 - GAugM EPNet train, Epoch [ 98/230]: loss 0.7209, auc 0.4995, ap 0.4965
2024-01-10 22:02:59,576 - GAugM EPNet train, Epoch [ 99/230]: loss 0.7209, auc 0.3966, ap 0.4442
2024-01-10 22:02:59,653 - GAugM EPNet train, Epoch [100/230]: loss 0.7210, auc 0.4931, ap 0.5014
2024-01-10 22:02:59,729 - GAugM EPNet train, Epoch [101/230]: loss 0.7210, auc 0.4728, ap 0.4874
2024-01-10 22:02:59,812 - GAugM EPNet train, Epoch [102/230]: loss 0.7209, auc 0.4941, ap 0.5387
2024-01-10 22:02:59,889 - GAugM EPNet train, Epoch [103/230]: loss 0.7209, auc 0.4980, ap 0.5221
2024-01-10 22:02:59,966 - GAugM EPNet train, Epoch [104/230]: loss 0.7209, auc 0.5101, ap 0.5250
2024-01-10 22:03:00,043 - GAugM EPNet train, Epoch [105/230]: loss 0.7209, auc 0.4913, ap 0.4990
2024-01-10 22:03:00,117 - GAugM EPNet train, Epoch [106/230]: loss 0.7210, auc 0.4863, ap 0.4923
2024-01-10 22:03:00,198 - GAugM EPNet train, Epoch [107/230]: loss 0.7210, auc 0.4610, ap 0.4906
2024-01-10 22:03:00,273 - GAugM EPNet train, Epoch [108/230]: loss 0.7208, auc 0.4820, ap 0.4851
2024-01-10 22:03:00,348 - GAugM EPNet train, Epoch [109/230]: loss 0.7210, auc 0.4300, ap 0.4452
2024-01-10 22:03:00,425 - GAugM EPNet train, Epoch [110/230]: loss 0.7209, auc 0.4788, ap 0.5112
2024-01-10 22:03:00,502 - GAugM EPNet train, Epoch [111/230]: loss 0.7210, auc 0.4984, ap 0.4926
2024-01-10 22:03:00,579 - GAugM EPNet train, Epoch [112/230]: loss 0.7209, auc 0.4468, ap 0.4632
2024-01-10 22:03:00,653 - GAugM EPNet train, Epoch [113/230]: loss 0.7210, auc 0.5016, ap 0.5264
2024-01-10 22:03:00,731 - GAugM EPNet train, Epoch [114/230]: loss 0.7209, auc 0.4788, ap 0.4727
2024-01-10 22:03:00,808 - GAugM EPNet train, Epoch [115/230]: loss 0.7210, auc 0.5525, ap 0.5440
2024-01-10 22:03:00,885 - GAugM EPNet train, Epoch [116/230]: loss 0.7209, auc 0.5625, ap 0.5409
2024-01-10 22:03:00,962 - GAugM EPNet train, Epoch [117/230]: loss 0.7208, auc 0.4276, ap 0.4623
2024-01-10 22:03:01,038 - GAugM EPNet train, Epoch [118/230]: loss 0.7209, auc 0.4318, ap 0.4830
2024-01-10 22:03:01,117 - GAugM EPNet train, Epoch [119/230]: loss 0.7209, auc 0.5379, ap 0.5463
2024-01-10 22:03:01,202 - GAugM EPNet train, Epoch [120/230]: loss 0.7210, auc 0.4187, ap 0.4530
2024-01-10 22:03:01,281 - GAugM EPNet train, Epoch [121/230]: loss 0.7210, auc 0.4165, ap 0.4521
2024-01-10 22:03:01,358 - GAugM EPNet train, Epoch [122/230]: loss 0.7209, auc 0.4681, ap 0.5015
2024-01-10 22:03:01,440 - GAugM EPNet train, Epoch [123/230]: loss 0.7209, auc 0.5194, ap 0.5321
2024-01-10 22:03:01,517 - GAugM EPNet train, Epoch [124/230]: loss 0.7210, auc 0.4667, ap 0.5019
2024-01-10 22:03:01,599 - GAugM EPNet train, Epoch [125/230]: loss 0.7209, auc 0.4998, ap 0.5226
2024-01-10 22:03:01,677 - GAugM EPNet train, Epoch [126/230]: loss 0.7210, auc 0.5212, ap 0.5233
2024-01-10 22:03:01,758 - GAugM EPNet train, Epoch [127/230]: loss 0.7209, auc 0.5301, ap 0.5165
2024-01-10 22:03:01,834 - GAugM EPNet train, Epoch [128/230]: loss 0.7210, auc 0.5507, ap 0.5349
2024-01-10 22:03:01,911 - GAugM EPNet train, Epoch [129/230]: loss 0.7208, auc 0.4258, ap 0.4470
2024-01-10 22:03:01,988 - GAugM EPNet train, Epoch [130/230]: loss 0.7210, auc 0.4194, ap 0.4605
2024-01-10 22:03:02,065 - GAugM EPNet train, Epoch [131/230]: loss 0.7210, auc 0.6369, ap 0.6188
2024-01-10 22:03:02,142 - GAugM EPNet train, Epoch [132/230]: loss 0.7209, auc 0.4956, ap 0.4994
2024-01-10 22:03:02,219 - GAugM EPNet train, Epoch [133/230]: loss 0.7209, auc 0.4603, ap 0.4743
2024-01-10 22:03:02,303 - GAugM EPNet train, Epoch [134/230]: loss 0.7210, auc 0.4404, ap 0.4685
2024-01-10 22:03:02,380 - GAugM EPNet train, Epoch [135/230]: loss 0.7209, auc 0.3784, ap 0.4381
2024-01-10 22:03:02,458 - GAugM EPNet train, Epoch [136/230]: loss 0.7209, auc 0.5593, ap 0.5516
2024-01-10 22:03:02,535 - GAugM EPNet train, Epoch [137/230]: loss 0.7210, auc 0.4824, ap 0.5007
2024-01-10 22:03:02,610 - GAugM EPNet train, Epoch [138/230]: loss 0.7210, auc 0.5247, ap 0.5276
2024-01-10 22:03:02,689 - GAugM EPNet train, Epoch [139/230]: loss 0.7210, auc 0.4624, ap 0.5199
2024-01-10 22:03:02,767 - GAugM EPNet train, Epoch [140/230]: loss 0.7209, auc 0.4450, ap 0.4900
2024-01-10 22:03:02,844 - GAugM EPNet train, Epoch [141/230]: loss 0.7209, auc 0.5543, ap 0.5073
2024-01-10 22:03:02,921 - GAugM EPNet train, Epoch [142/230]: loss 0.7209, auc 0.5027, ap 0.4983
2024-01-10 22:03:02,999 - GAugM EPNet train, Epoch [143/230]: loss 0.7209, auc 0.3884, ap 0.4385
2024-01-10 22:03:03,075 - GAugM EPNet train, Epoch [144/230]: loss 0.7209, auc 0.4706, ap 0.4760
2024-01-10 22:03:03,152 - GAugM EPNet train, Epoch [145/230]: loss 0.7209, auc 0.4329, ap 0.4717
2024-01-10 22:03:03,230 - GAugM EPNet train, Epoch [146/230]: loss 0.7209, auc 0.4461, ap 0.5050
2024-01-10 22:03:03,306 - GAugM EPNet train, Epoch [147/230]: loss 0.7209, auc 0.5710, ap 0.5961
2024-01-10 22:03:03,383 - GAugM EPNet train, Epoch [148/230]: loss 0.7209, auc 0.4471, ap 0.4587
2024-01-10 22:03:03,461 - GAugM EPNet train, Epoch [149/230]: loss 0.7208, auc 0.4710, ap 0.4989
2024-01-10 22:03:03,537 - GAugM EPNet train, Epoch [150/230]: loss 0.7209, auc 0.5230, ap 0.5237
2024-01-10 22:03:03,614 - GAugM EPNet train, Epoch [151/230]: loss 0.7209, auc 0.4980, ap 0.5050
2024-01-10 22:03:03,691 - GAugM EPNet train, Epoch [152/230]: loss 0.7209, auc 0.5913, ap 0.5858
2024-01-10 22:03:03,768 - GAugM EPNet train, Epoch [153/230]: loss 0.7209, auc 0.5368, ap 0.5422
2024-01-10 22:03:03,843 - GAugM EPNet train, Epoch [154/230]: loss 0.7209, auc 0.5774, ap 0.5941
2024-01-10 22:03:03,922 - GAugM EPNet train, Epoch [155/230]: loss 0.7209, auc 0.4592, ap 0.5041
2024-01-10 22:03:04,004 - GAugM EPNet train, Epoch [156/230]: loss 0.7209, auc 0.4649, ap 0.4929
2024-01-10 22:03:04,081 - GAugM EPNet train, Epoch [157/230]: loss 0.7209, auc 0.5233, ap 0.5035
2024-01-10 22:03:04,159 - GAugM EPNet train, Epoch [158/230]: loss 0.7208, auc 0.4450, ap 0.4625
2024-01-10 22:03:04,235 - GAugM EPNet train, Epoch [159/230]: loss 0.7208, auc 0.5105, ap 0.5112
2024-01-10 22:03:04,313 - GAugM EPNet train, Epoch [160/230]: loss 0.7209, auc 0.5091, ap 0.5228
2024-01-10 22:03:04,391 - GAugM EPNet train, Epoch [161/230]: loss 0.7209, auc 0.5778, ap 0.5724
2024-01-10 22:03:04,473 - GAugM EPNet train, Epoch [162/230]: loss 0.7209, auc 0.4090, ap 0.4358
2024-01-10 22:03:04,549 - GAugM EPNet train, Epoch [163/230]: loss 0.7209, auc 0.5390, ap 0.5259
2024-01-10 22:03:04,627 - GAugM EPNet train, Epoch [164/230]: loss 0.7211, auc 0.5276, ap 0.4985
2024-01-10 22:03:04,702 - GAugM EPNet train, Epoch [165/230]: loss 0.7210, auc 0.4101, ap 0.4308
2024-01-10 22:03:04,779 - GAugM EPNet train, Epoch [166/230]: loss 0.7208, auc 0.5304, ap 0.5534
2024-01-10 22:03:04,864 - GAugM EPNet train, Epoch [167/230]: loss 0.7209, auc 0.3421, ap 0.3993
2024-01-10 22:03:04,941 - GAugM EPNet train, Epoch [168/230]: loss 0.7209, auc 0.4432, ap 0.4879
2024-01-10 22:03:05,019 - GAugM EPNet train, Epoch [169/230]: loss 0.7209, auc 0.5376, ap 0.5729
2024-01-10 22:03:05,095 - GAugM EPNet train, Epoch [170/230]: loss 0.7210, auc 0.5016, ap 0.4803
2024-01-10 22:03:05,172 - GAugM EPNet train, Epoch [171/230]: loss 0.7209, auc 0.4254, ap 0.4586
2024-01-10 22:03:05,248 - GAugM EPNet train, Epoch [172/230]: loss 0.7208, auc 0.3806, ap 0.4252
2024-01-10 22:03:05,326 - GAugM EPNet train, Epoch [173/230]: loss 0.7209, auc 0.4592, ap 0.5166
2024-01-10 22:03:05,403 - GAugM EPNet train, Epoch [174/230]: loss 0.7209, auc 0.4550, ap 0.4634
2024-01-10 22:03:05,482 - GAugM EPNet train, Epoch [175/230]: loss 0.7209, auc 0.5258, ap 0.5122
2024-01-10 22:03:05,560 - GAugM EPNet train, Epoch [176/230]: loss 0.7209, auc 0.4820, ap 0.4759
2024-01-10 22:03:05,636 - GAugM EPNet train, Epoch [177/230]: loss 0.7210, auc 0.5838, ap 0.5463
2024-01-10 22:03:05,714 - GAugM EPNet train, Epoch [178/230]: loss 0.7210, auc 0.5454, ap 0.5832
2024-01-10 22:03:05,788 - GAugM EPNet train, Epoch [179/230]: loss 0.7210, auc 0.4973, ap 0.5111
2024-01-10 22:03:05,866 - GAugM EPNet train, Epoch [180/230]: loss 0.7210, auc 0.5020, ap 0.5296
2024-01-10 22:03:05,944 - GAugM EPNet train, Epoch [181/230]: loss 0.7209, auc 0.4489, ap 0.4738
2024-01-10 22:03:06,021 - GAugM EPNet train, Epoch [182/230]: loss 0.7209, auc 0.5461, ap 0.5579
2024-01-10 22:03:06,097 - GAugM EPNet train, Epoch [183/230]: loss 0.7210, auc 0.4813, ap 0.4806
2024-01-10 22:03:06,173 - GAugM EPNet train, Epoch [184/230]: loss 0.7209, auc 0.5041, ap 0.5075
2024-01-10 22:03:06,249 - GAugM EPNet train, Epoch [185/230]: loss 0.7209, auc 0.4802, ap 0.5221
2024-01-10 22:03:06,330 - GAugM EPNet train, Epoch [186/230]: loss 0.7208, auc 0.4870, ap 0.5071
2024-01-10 22:03:06,408 - GAugM EPNet train, Epoch [187/230]: loss 0.7209, auc 0.5354, ap 0.5603
2024-01-10 22:03:06,484 - GAugM EPNet train, Epoch [188/230]: loss 0.7209, auc 0.5119, ap 0.4931
2024-01-10 22:03:06,565 - GAugM EPNet train, Epoch [189/230]: loss 0.7209, auc 0.5105, ap 0.5431
2024-01-10 22:03:06,643 - GAugM EPNet train, Epoch [190/230]: loss 0.7209, auc 0.4226, ap 0.4460
2024-01-10 22:03:06,718 - GAugM EPNet train, Epoch [191/230]: loss 0.7209, auc 0.4340, ap 0.4836
2024-01-10 22:03:06,794 - GAugM EPNet train, Epoch [192/230]: loss 0.7209, auc 0.4699, ap 0.4602
2024-01-10 22:03:06,870 - GAugM EPNet train, Epoch [193/230]: loss 0.7209, auc 0.5461, ap 0.5249
2024-01-10 22:03:06,946 - GAugM EPNet train, Epoch [194/230]: loss 0.7209, auc 0.4991, ap 0.5212
2024-01-10 22:03:07,021 - GAugM EPNet train, Epoch [195/230]: loss 0.7209, auc 0.4436, ap 0.4874
2024-01-10 22:03:07,098 - GAugM EPNet train, Epoch [196/230]: loss 0.7208, auc 0.5105, ap 0.4878
2024-01-10 22:03:07,174 - GAugM EPNet train, Epoch [197/230]: loss 0.7210, auc 0.4863, ap 0.4909
2024-01-10 22:03:07,251 - GAugM EPNet train, Epoch [198/230]: loss 0.7210, auc 0.5376, ap 0.5592
2024-01-10 22:03:07,327 - GAugM EPNet train, Epoch [199/230]: loss 0.7209, auc 0.4397, ap 0.4726
2024-01-10 22:03:07,407 - GAugM EPNet train, Epoch [200/230]: loss 0.7210, auc 0.4923, ap 0.4994
2024-01-10 22:03:07,483 - GAugM EPNet train, Epoch [201/230]: loss 0.7209, auc 0.4365, ap 0.4561
2024-01-10 22:03:07,563 - GAugM EPNet train, Epoch [202/230]: loss 0.7210, auc 0.5803, ap 0.6058
2024-01-10 22:03:07,647 - GAugM EPNet train, Epoch [203/230]: loss 0.7210, auc 0.4884, ap 0.5033
2024-01-10 22:03:07,724 - GAugM EPNet train, Epoch [204/230]: loss 0.7209, auc 0.4162, ap 0.4441
2024-01-10 22:03:07,801 - GAugM EPNet train, Epoch [205/230]: loss 0.7209, auc 0.4877, ap 0.5281
2024-01-10 22:03:07,878 - GAugM EPNet train, Epoch [206/230]: loss 0.7209, auc 0.4404, ap 0.4507
2024-01-10 22:03:07,960 - GAugM EPNet train, Epoch [207/230]: loss 0.7210, auc 0.4646, ap 0.4665
2024-01-10 22:03:08,039 - GAugM EPNet train, Epoch [208/230]: loss 0.7209, auc 0.4187, ap 0.4732
2024-01-10 22:03:08,115 - GAugM EPNet train, Epoch [209/230]: loss 0.7210, auc 0.6241, ap 0.6199
2024-01-10 22:03:08,192 - GAugM EPNet train, Epoch [210/230]: loss 0.7209, auc 0.4689, ap 0.4741
2024-01-10 22:03:08,270 - GAugM EPNet train, Epoch [211/230]: loss 0.7210, auc 0.5632, ap 0.5465
2024-01-10 22:03:08,350 - GAugM EPNet train, Epoch [212/230]: loss 0.7210, auc 0.5066, ap 0.5481
2024-01-10 22:03:08,427 - GAugM EPNet train, Epoch [213/230]: loss 0.7208, auc 0.5906, ap 0.5943
2024-01-10 22:03:08,504 - GAugM EPNet train, Epoch [214/230]: loss 0.7210, auc 0.5187, ap 0.5090
2024-01-10 22:03:08,585 - GAugM EPNet train, Epoch [215/230]: loss 0.7210, auc 0.4439, ap 0.4784
2024-01-10 22:03:08,663 - GAugM EPNet train, Epoch [216/230]: loss 0.7209, auc 0.4785, ap 0.4793
2024-01-10 22:03:08,740 - GAugM EPNet train, Epoch [217/230]: loss 0.7209, auc 0.4891, ap 0.5395
2024-01-10 22:03:08,816 - GAugM EPNet train, Epoch [218/230]: loss 0.7209, auc 0.5069, ap 0.5256
2024-01-10 22:03:08,896 - GAugM EPNet train, Epoch [219/230]: loss 0.7208, auc 0.5059, ap 0.5076
2024-01-10 22:03:08,982 - GAugM EPNet train, Epoch [220/230]: loss 0.7210, auc 0.3937, ap 0.4472
2024-01-10 22:03:09,060 - GAugM EPNet train, Epoch [221/230]: loss 0.7209, auc 0.5643, ap 0.5444
2024-01-10 22:03:09,144 - GAugM EPNet train, Epoch [222/230]: loss 0.7209, auc 0.4557, ap 0.4695
2024-01-10 22:03:09,221 - GAugM EPNet train, Epoch [223/230]: loss 0.7209, auc 0.5137, ap 0.5046
2024-01-10 22:03:09,299 - GAugM EPNet train, Epoch [224/230]: loss 0.7210, auc 0.4642, ap 0.4985
2024-01-10 22:03:09,375 - GAugM EPNet train, Epoch [225/230]: loss 0.7209, auc 0.5144, ap 0.5306
2024-01-10 22:03:09,452 - GAugM EPNet train, Epoch [226/230]: loss 0.7210, auc 0.5358, ap 0.5344
2024-01-10 22:03:09,534 - GAugM EPNet train, Epoch [227/230]: loss 0.7210, auc 0.5308, ap 0.5165
2024-01-10 22:03:09,612 - GAugM EPNet train, Epoch [228/230]: loss 0.7209, auc 0.4119, ap 0.4408
2024-01-10 22:03:09,687 - GAugM EPNet train, Epoch [229/230]: loss 0.7209, auc 0.5344, ap 0.5085
2024-01-10 22:03:09,765 - GAugM EPNet train, Epoch [230/230]: loss 0.7209, auc 0.4475, ap 0.4652
2024-01-10 22:03:09,766 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9e1cfd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:03:10,483 - GAugM EPNet train, Epoch [  1/230]: loss 0.7210, auc 0.4500, ap 0.4564
2024-01-10 22:03:10,586 - GAugM EPNet train, Epoch [  2/230]: loss 0.7210, auc 0.5578, ap 0.5484
2024-01-10 22:03:10,675 - GAugM EPNet train, Epoch [  3/230]: loss 0.7209, auc 0.5883, ap 0.5893
2024-01-10 22:03:10,756 - GAugM EPNet train, Epoch [  4/230]: loss 0.7209, auc 0.5618, ap 0.5556
2024-01-10 22:03:10,839 - GAugM EPNet train, Epoch [  5/230]: loss 0.7209, auc 0.6107, ap 0.5951
2024-01-10 22:03:10,925 - GAugM EPNet train, Epoch [  6/230]: loss 0.7209, auc 0.5246, ap 0.5164
2024-01-10 22:03:11,015 - GAugM EPNet train, Epoch [  7/230]: loss 0.7209, auc 0.4731, ap 0.4974
2024-01-10 22:03:11,105 - GAugM EPNet train, Epoch [  8/230]: loss 0.7210, auc 0.4441, ap 0.4586
2024-01-10 22:03:11,183 - GAugM EPNet train, Epoch [  9/230]: loss 0.7209, auc 0.4505, ap 0.4776
2024-01-10 22:03:11,266 - GAugM EPNet train, Epoch [ 10/230]: loss 0.7208, auc 0.4811, ap 0.5062
2024-01-10 22:03:11,350 - GAugM EPNet train, Epoch [ 11/230]: loss 0.7209, auc 0.4633, ap 0.5031
2024-01-10 22:03:11,428 - GAugM EPNet train, Epoch [ 12/230]: loss 0.7210, auc 0.5522, ap 0.5183
2024-01-10 22:03:11,514 - GAugM EPNet train, Epoch [ 13/230]: loss 0.7209, auc 0.5392, ap 0.5509
2024-01-10 22:03:11,603 - GAugM EPNet train, Epoch [ 14/230]: loss 0.7209, auc 0.5239, ap 0.5324
2024-01-10 22:03:11,687 - GAugM EPNet train, Epoch [ 15/230]: loss 0.7210, auc 0.4240, ap 0.4736
2024-01-10 22:03:11,770 - GAugM EPNet train, Epoch [ 16/230]: loss 0.7209, auc 0.4525, ap 0.5107
2024-01-10 22:03:11,864 - GAugM EPNet train, Epoch [ 17/230]: loss 0.7210, auc 0.5792, ap 0.5573
2024-01-10 22:03:11,945 - GAugM EPNet train, Epoch [ 18/230]: loss 0.7210, auc 0.5632, ap 0.5592
2024-01-10 22:03:12,029 - GAugM EPNet train, Epoch [ 19/230]: loss 0.7209, auc 0.5342, ap 0.5270
2024-01-10 22:03:12,112 - GAugM EPNet train, Epoch [ 20/230]: loss 0.7210, auc 0.4441, ap 0.4970
2024-01-10 22:03:12,203 - GAugM EPNet train, Epoch [ 21/230]: loss 0.7209, auc 0.5304, ap 0.5234
2024-01-10 22:03:12,283 - GAugM EPNet train, Epoch [ 22/230]: loss 0.7210, auc 0.4137, ap 0.4657
2024-01-10 22:03:12,364 - GAugM EPNet train, Epoch [ 23/230]: loss 0.7208, auc 0.4749, ap 0.5133
2024-01-10 22:03:12,451 - GAugM EPNet train, Epoch [ 24/230]: loss 0.7209, auc 0.5621, ap 0.5604
2024-01-10 22:03:12,535 - GAugM EPNet train, Epoch [ 25/230]: loss 0.7209, auc 0.4356, ap 0.4772
2024-01-10 22:03:12,611 - GAugM EPNet train, Epoch [ 26/230]: loss 0.7210, auc 0.5150, ap 0.5350
2024-01-10 22:03:12,695 - GAugM EPNet train, Epoch [ 27/230]: loss 0.7209, auc 0.5399, ap 0.5492
2024-01-10 22:03:12,780 - GAugM EPNet train, Epoch [ 28/230]: loss 0.7209, auc 0.5014, ap 0.5223
2024-01-10 22:03:12,864 - GAugM EPNet train, Epoch [ 29/230]: loss 0.7210, auc 0.4829, ap 0.5238
2024-01-10 22:03:12,946 - GAugM EPNet train, Epoch [ 30/230]: loss 0.7209, auc 0.5431, ap 0.5644
2024-01-10 22:03:13,027 - GAugM EPNet train, Epoch [ 31/230]: loss 0.7208, auc 0.4945, ap 0.5274
2024-01-10 22:03:13,103 - GAugM EPNet train, Epoch [ 32/230]: loss 0.7210, auc 0.6095, ap 0.5963
2024-01-10 22:03:13,192 - GAugM EPNet train, Epoch [ 33/230]: loss 0.7209, auc 0.4890, ap 0.5154
2024-01-10 22:03:13,269 - GAugM EPNet train, Epoch [ 34/230]: loss 0.7209, auc 0.4183, ap 0.4635
2024-01-10 22:03:13,352 - GAugM EPNet train, Epoch [ 35/230]: loss 0.7209, auc 0.5595, ap 0.5378
2024-01-10 22:03:13,439 - GAugM EPNet train, Epoch [ 36/230]: loss 0.7209, auc 0.5838, ap 0.5815
2024-01-10 22:03:13,518 - GAugM EPNet train, Epoch [ 37/230]: loss 0.7209, auc 0.4813, ap 0.5014
2024-01-10 22:03:13,598 - GAugM EPNet train, Epoch [ 38/230]: loss 0.7209, auc 0.4365, ap 0.4504
2024-01-10 22:03:13,694 - GAugM EPNet train, Epoch [ 39/230]: loss 0.7208, auc 0.4961, ap 0.5488
2024-01-10 22:03:13,777 - GAugM EPNet train, Epoch [ 40/230]: loss 0.7210, auc 0.5386, ap 0.5335
2024-01-10 22:03:13,857 - GAugM EPNet train, Epoch [ 41/230]: loss 0.7210, auc 0.5036, ap 0.5258
2024-01-10 22:03:13,946 - GAugM EPNet train, Epoch [ 42/230]: loss 0.7209, auc 0.5146, ap 0.5660
2024-01-10 22:03:14,028 - GAugM EPNet train, Epoch [ 43/230]: loss 0.7208, auc 0.4393, ap 0.5118
2024-01-10 22:03:14,107 - GAugM EPNet train, Epoch [ 44/230]: loss 0.7208, auc 0.3564, ap 0.4167
2024-01-10 22:03:14,192 - GAugM EPNet train, Epoch [ 45/230]: loss 0.7209, auc 0.5315, ap 0.5451
2024-01-10 22:03:14,275 - GAugM EPNet train, Epoch [ 46/230]: loss 0.7209, auc 0.4633, ap 0.4856
2024-01-10 22:03:14,353 - GAugM EPNet train, Epoch [ 47/230]: loss 0.7210, auc 0.4694, ap 0.4871
2024-01-10 22:03:14,439 - GAugM EPNet train, Epoch [ 48/230]: loss 0.7210, auc 0.6161, ap 0.6470
2024-01-10 22:03:14,517 - GAugM EPNet train, Epoch [ 49/230]: loss 0.7209, auc 0.5093, ap 0.5205
2024-01-10 22:03:14,594 - GAugM EPNet train, Epoch [ 50/230]: loss 0.7210, auc 0.5055, ap 0.5154
2024-01-10 22:03:14,679 - GAugM EPNet train, Epoch [ 51/230]: loss 0.7210, auc 0.4160, ap 0.4592
2024-01-10 22:03:14,757 - GAugM EPNet train, Epoch [ 52/230]: loss 0.7209, auc 0.4701, ap 0.4922
2024-01-10 22:03:14,835 - GAugM EPNet train, Epoch [ 53/230]: loss 0.7209, auc 0.5061, ap 0.5537
2024-01-10 22:03:14,915 - GAugM EPNet train, Epoch [ 54/230]: loss 0.7211, auc 0.6068, ap 0.5844
2024-01-10 22:03:14,991 - GAugM EPNet train, Epoch [ 55/230]: loss 0.7209, auc 0.6075, ap 0.6181
2024-01-10 22:03:15,079 - GAugM EPNet train, Epoch [ 56/230]: loss 0.7208, auc 0.4530, ap 0.4778
2024-01-10 22:03:15,168 - GAugM EPNet train, Epoch [ 57/230]: loss 0.7209, auc 0.4847, ap 0.4733
2024-01-10 22:03:15,256 - GAugM EPNet train, Epoch [ 58/230]: loss 0.7210, auc 0.4772, ap 0.5215
2024-01-10 22:03:15,338 - GAugM EPNet train, Epoch [ 59/230]: loss 0.7211, auc 0.5073, ap 0.4882
2024-01-10 22:03:15,423 - GAugM EPNet train, Epoch [ 60/230]: loss 0.7210, auc 0.5443, ap 0.5554
2024-01-10 22:03:15,503 - GAugM EPNet train, Epoch [ 61/230]: loss 0.7209, auc 0.5308, ap 0.5626
2024-01-10 22:03:15,588 - GAugM EPNet train, Epoch [ 62/230]: loss 0.7210, auc 0.5869, ap 0.6236
2024-01-10 22:03:15,673 - GAugM EPNet train, Epoch [ 63/230]: loss 0.7208, auc 0.3827, ap 0.4370
2024-01-10 22:03:15,754 - GAugM EPNet train, Epoch [ 64/230]: loss 0.7208, auc 0.4436, ap 0.5231
2024-01-10 22:03:15,834 - GAugM EPNet train, Epoch [ 65/230]: loss 0.7208, auc 0.6680, ap 0.7023
2024-01-10 22:03:15,916 - GAugM EPNet train, Epoch [ 66/230]: loss 0.7209, auc 0.4672, ap 0.5008
2024-01-10 22:03:15,995 - GAugM EPNet train, Epoch [ 67/230]: loss 0.7209, auc 0.5244, ap 0.5168
2024-01-10 22:03:16,073 - GAugM EPNet train, Epoch [ 68/230]: loss 0.7210, auc 0.4712, ap 0.5081
2024-01-10 22:03:16,155 - GAugM EPNet train, Epoch [ 69/230]: loss 0.7210, auc 0.5130, ap 0.5550
2024-01-10 22:03:16,242 - GAugM EPNet train, Epoch [ 70/230]: loss 0.7210, auc 0.5023, ap 0.4908
2024-01-10 22:03:16,325 - GAugM EPNet train, Epoch [ 71/230]: loss 0.7210, auc 0.5153, ap 0.5189
2024-01-10 22:03:16,405 - GAugM EPNet train, Epoch [ 72/230]: loss 0.7210, auc 0.4671, ap 0.5193
2024-01-10 22:03:16,482 - GAugM EPNet train, Epoch [ 73/230]: loss 0.7209, auc 0.5452, ap 0.5284
2024-01-10 22:03:16,561 - GAugM EPNet train, Epoch [ 74/230]: loss 0.7209, auc 0.5217, ap 0.5691
2024-01-10 22:03:16,657 - GAugM EPNet train, Epoch [ 75/230]: loss 0.7210, auc 0.4519, ap 0.4720
2024-01-10 22:03:16,737 - GAugM EPNet train, Epoch [ 76/230]: loss 0.7209, auc 0.4633, ap 0.5152
2024-01-10 22:03:16,820 - GAugM EPNet train, Epoch [ 77/230]: loss 0.7208, auc 0.5897, ap 0.6065
2024-01-10 22:03:16,903 - GAugM EPNet train, Epoch [ 78/230]: loss 0.7209, auc 0.5303, ap 0.5404
2024-01-10 22:03:16,984 - GAugM EPNet train, Epoch [ 79/230]: loss 0.7208, auc 0.5068, ap 0.5307
2024-01-10 22:03:17,065 - GAugM EPNet train, Epoch [ 80/230]: loss 0.7209, auc 0.5773, ap 0.5761
2024-01-10 22:03:17,141 - GAugM EPNet train, Epoch [ 81/230]: loss 0.7209, auc 0.4996, ap 0.5004
2024-01-10 22:03:17,221 - GAugM EPNet train, Epoch [ 82/230]: loss 0.7210, auc 0.4845, ap 0.5035
2024-01-10 22:03:17,309 - GAugM EPNet train, Epoch [ 83/230]: loss 0.7209, auc 0.5276, ap 0.5488
2024-01-10 22:03:17,397 - GAugM EPNet train, Epoch [ 84/230]: loss 0.7209, auc 0.4219, ap 0.4825
2024-01-10 22:03:17,485 - GAugM EPNet train, Epoch [ 85/230]: loss 0.7210, auc 0.4658, ap 0.5094
2024-01-10 22:03:17,575 - GAugM EPNet train, Epoch [ 86/230]: loss 0.7208, auc 0.4891, ap 0.5389
2024-01-10 22:03:17,654 - GAugM EPNet train, Epoch [ 87/230]: loss 0.7209, auc 0.5263, ap 0.5414
2024-01-10 22:03:17,734 - GAugM EPNet train, Epoch [ 88/230]: loss 0.7210, auc 0.3820, ap 0.4801
2024-01-10 22:03:17,818 - GAugM EPNet train, Epoch [ 89/230]: loss 0.7210, auc 0.4715, ap 0.5201
2024-01-10 22:03:17,898 - GAugM EPNet train, Epoch [ 90/230]: loss 0.7209, auc 0.3790, ap 0.4262
2024-01-10 22:03:17,976 - GAugM EPNet train, Epoch [ 91/230]: loss 0.7208, auc 0.5568, ap 0.5185
2024-01-10 22:03:18,060 - GAugM EPNet train, Epoch [ 92/230]: loss 0.7209, auc 0.5717, ap 0.5890
2024-01-10 22:03:18,141 - GAugM EPNet train, Epoch [ 93/230]: loss 0.7209, auc 0.4779, ap 0.4926
2024-01-10 22:03:18,216 - GAugM EPNet train, Epoch [ 94/230]: loss 0.7210, auc 0.4333, ap 0.4570
2024-01-10 22:03:18,298 - GAugM EPNet train, Epoch [ 95/230]: loss 0.7210, auc 0.5279, ap 0.5666
2024-01-10 22:03:18,375 - GAugM EPNet train, Epoch [ 96/230]: loss 0.7209, auc 0.5009, ap 0.5390
2024-01-10 22:03:18,466 - GAugM EPNet train, Epoch [ 97/230]: loss 0.7209, auc 0.4847, ap 0.5313
2024-01-10 22:03:18,552 - GAugM EPNet train, Epoch [ 98/230]: loss 0.7209, auc 0.4324, ap 0.4737
2024-01-10 22:03:18,633 - GAugM EPNet train, Epoch [ 99/230]: loss 0.7209, auc 0.4516, ap 0.4760
2024-01-10 22:03:18,719 - GAugM EPNet train, Epoch [100/230]: loss 0.7210, auc 0.4361, ap 0.4618
2024-01-10 22:03:18,806 - GAugM EPNet train, Epoch [101/230]: loss 0.7210, auc 0.4194, ap 0.4730
2024-01-10 22:03:18,886 - GAugM EPNet train, Epoch [102/230]: loss 0.7209, auc 0.5543, ap 0.5667
2024-01-10 22:03:18,973 - GAugM EPNet train, Epoch [103/230]: loss 0.7209, auc 0.4922, ap 0.5382
2024-01-10 22:03:19,055 - GAugM EPNet train, Epoch [104/230]: loss 0.7209, auc 0.3685, ap 0.4318
2024-01-10 22:03:19,140 - GAugM EPNet train, Epoch [105/230]: loss 0.7209, auc 0.3690, ap 0.4250
2024-01-10 22:03:19,220 - GAugM EPNet train, Epoch [106/230]: loss 0.7210, auc 0.4918, ap 0.4812
2024-01-10 22:03:19,300 - GAugM EPNet train, Epoch [107/230]: loss 0.7210, auc 0.4530, ap 0.5143
2024-01-10 22:03:19,386 - GAugM EPNet train, Epoch [108/230]: loss 0.7208, auc 0.5032, ap 0.4951
2024-01-10 22:03:19,467 - GAugM EPNet train, Epoch [109/230]: loss 0.7210, auc 0.4612, ap 0.4888
2024-01-10 22:03:19,558 - GAugM EPNet train, Epoch [110/230]: loss 0.7209, auc 0.4051, ap 0.4587
2024-01-10 22:03:19,640 - GAugM EPNet train, Epoch [111/230]: loss 0.7210, auc 0.4911, ap 0.5134
2024-01-10 22:03:19,718 - GAugM EPNet train, Epoch [112/230]: loss 0.7209, auc 0.4019, ap 0.4604
2024-01-10 22:03:19,802 - GAugM EPNet train, Epoch [113/230]: loss 0.7210, auc 0.4785, ap 0.5138
2024-01-10 22:03:19,884 - GAugM EPNet train, Epoch [114/230]: loss 0.7209, auc 0.4861, ap 0.5100
2024-01-10 22:03:19,963 - GAugM EPNet train, Epoch [115/230]: loss 0.7210, auc 0.4729, ap 0.4983
2024-01-10 22:03:20,050 - GAugM EPNet train, Epoch [116/230]: loss 0.7209, auc 0.4511, ap 0.4860
2024-01-10 22:03:20,132 - GAugM EPNet train, Epoch [117/230]: loss 0.7208, auc 0.4922, ap 0.5144
2024-01-10 22:03:20,222 - GAugM EPNet train, Epoch [118/230]: loss 0.7209, auc 0.4413, ap 0.5050
2024-01-10 22:03:20,306 - GAugM EPNet train, Epoch [119/230]: loss 0.7209, auc 0.5066, ap 0.5648
2024-01-10 22:03:20,388 - GAugM EPNet train, Epoch [120/230]: loss 0.7210, auc 0.4306, ap 0.4429
2024-01-10 22:03:20,468 - GAugM EPNet train, Epoch [121/230]: loss 0.7210, auc 0.4448, ap 0.4908
2024-01-10 22:03:20,554 - GAugM EPNet train, Epoch [122/230]: loss 0.7209, auc 0.5178, ap 0.5379
2024-01-10 22:03:20,635 - GAugM EPNet train, Epoch [123/230]: loss 0.7209, auc 0.4986, ap 0.5104
2024-01-10 22:03:20,713 - GAugM EPNet train, Epoch [124/230]: loss 0.7210, auc 0.4632, ap 0.4734
2024-01-10 22:03:20,801 - GAugM EPNet train, Epoch [125/230]: loss 0.7209, auc 0.5276, ap 0.5562
2024-01-10 22:03:20,887 - GAugM EPNet train, Epoch [126/230]: loss 0.7210, auc 0.5114, ap 0.5258
2024-01-10 22:03:20,974 - GAugM EPNet train, Epoch [127/230]: loss 0.7209, auc 0.5564, ap 0.5455
2024-01-10 22:03:21,055 - GAugM EPNet train, Epoch [128/230]: loss 0.7210, auc 0.5733, ap 0.5532
2024-01-10 22:03:21,134 - GAugM EPNet train, Epoch [129/230]: loss 0.7208, auc 0.3224, ap 0.4085
2024-01-10 22:03:21,214 - GAugM EPNet train, Epoch [130/230]: loss 0.7210, auc 0.4964, ap 0.5128
2024-01-10 22:03:21,304 - GAugM EPNet train, Epoch [131/230]: loss 0.7210, auc 0.5182, ap 0.5813
2024-01-10 22:03:21,392 - GAugM EPNet train, Epoch [132/230]: loss 0.7209, auc 0.5351, ap 0.5523
2024-01-10 22:03:21,475 - GAugM EPNet train, Epoch [133/230]: loss 0.7209, auc 0.5180, ap 0.5410
2024-01-10 22:03:21,559 - GAugM EPNet train, Epoch [134/230]: loss 0.7210, auc 0.5473, ap 0.5662
2024-01-10 22:03:21,639 - GAugM EPNet train, Epoch [135/230]: loss 0.7209, auc 0.4446, ap 0.4732
2024-01-10 22:03:21,726 - GAugM EPNet train, Epoch [136/230]: loss 0.7209, auc 0.4929, ap 0.4940
2024-01-10 22:03:21,806 - GAugM EPNet train, Epoch [137/230]: loss 0.7210, auc 0.5091, ap 0.5326
2024-01-10 22:03:21,890 - GAugM EPNet train, Epoch [138/230]: loss 0.7210, auc 0.5449, ap 0.5390
2024-01-10 22:03:21,976 - GAugM EPNet train, Epoch [139/230]: loss 0.7210, auc 0.5135, ap 0.5214
2024-01-10 22:03:22,056 - GAugM EPNet train, Epoch [140/230]: loss 0.7209, auc 0.5160, ap 0.5634
2024-01-10 22:03:22,137 - GAugM EPNet train, Epoch [141/230]: loss 0.7209, auc 0.5256, ap 0.5444
2024-01-10 22:03:22,219 - GAugM EPNet train, Epoch [142/230]: loss 0.7209, auc 0.4575, ap 0.4670
2024-01-10 22:03:22,305 - GAugM EPNet train, Epoch [143/230]: loss 0.7209, auc 0.4802, ap 0.4878
2024-01-10 22:03:22,395 - GAugM EPNet train, Epoch [144/230]: loss 0.7209, auc 0.5025, ap 0.4823
2024-01-10 22:03:22,479 - GAugM EPNet train, Epoch [145/230]: loss 0.7209, auc 0.4557, ap 0.5252
2024-01-10 22:03:22,561 - GAugM EPNet train, Epoch [146/230]: loss 0.7209, auc 0.5454, ap 0.5722
2024-01-10 22:03:22,642 - GAugM EPNet train, Epoch [147/230]: loss 0.7209, auc 0.6143, ap 0.6461
2024-01-10 22:03:22,717 - GAugM EPNet train, Epoch [148/230]: loss 0.7209, auc 0.5712, ap 0.5740
2024-01-10 22:03:22,797 - GAugM EPNet train, Epoch [149/230]: loss 0.7208, auc 0.5004, ap 0.5168
2024-01-10 22:03:22,877 - GAugM EPNet train, Epoch [150/230]: loss 0.7209, auc 0.5607, ap 0.5546
2024-01-10 22:03:22,956 - GAugM EPNet train, Epoch [151/230]: loss 0.7209, auc 0.4808, ap 0.4989
2024-01-10 22:03:23,045 - GAugM EPNet train, Epoch [152/230]: loss 0.7209, auc 0.6148, ap 0.6198
2024-01-10 22:03:23,125 - GAugM EPNet train, Epoch [153/230]: loss 0.7209, auc 0.4188, ap 0.4876
2024-01-10 22:03:23,210 - GAugM EPNet train, Epoch [154/230]: loss 0.7209, auc 0.5068, ap 0.5452
2024-01-10 22:03:23,290 - GAugM EPNet train, Epoch [155/230]: loss 0.7209, auc 0.4877, ap 0.4903
2024-01-10 22:03:23,376 - GAugM EPNet train, Epoch [156/230]: loss 0.7209, auc 0.4441, ap 0.4718
2024-01-10 22:03:23,458 - GAugM EPNet train, Epoch [157/230]: loss 0.7209, auc 0.4875, ap 0.4939
2024-01-10 22:03:23,540 - GAugM EPNet train, Epoch [158/230]: loss 0.7208, auc 0.4092, ap 0.4599
2024-01-10 22:03:23,619 - GAugM EPNet train, Epoch [159/230]: loss 0.7208, auc 0.4733, ap 0.4788
2024-01-10 22:03:23,699 - GAugM EPNet train, Epoch [160/230]: loss 0.7209, auc 0.5320, ap 0.5496
2024-01-10 22:03:23,781 - GAugM EPNet train, Epoch [161/230]: loss 0.7209, auc 0.4696, ap 0.5053
2024-01-10 22:03:23,859 - GAugM EPNet train, Epoch [162/230]: loss 0.7209, auc 0.4519, ap 0.4519
2024-01-10 22:03:23,946 - GAugM EPNet train, Epoch [163/230]: loss 0.7209, auc 0.5842, ap 0.5584
2024-01-10 22:03:24,028 - GAugM EPNet train, Epoch [164/230]: loss 0.7211, auc 0.5384, ap 0.5216
2024-01-10 22:03:24,110 - GAugM EPNet train, Epoch [165/230]: loss 0.7210, auc 0.4267, ap 0.4584
2024-01-10 22:03:24,194 - GAugM EPNet train, Epoch [166/230]: loss 0.7208, auc 0.6193, ap 0.5877
2024-01-10 22:03:24,272 - GAugM EPNet train, Epoch [167/230]: loss 0.7209, auc 0.4370, ap 0.4679
2024-01-10 22:03:24,350 - GAugM EPNet train, Epoch [168/230]: loss 0.7209, auc 0.4795, ap 0.5038
2024-01-10 22:03:24,438 - GAugM EPNet train, Epoch [169/230]: loss 0.7209, auc 0.5598, ap 0.6110
2024-01-10 22:03:24,521 - GAugM EPNet train, Epoch [170/230]: loss 0.7210, auc 0.4637, ap 0.4705
2024-01-10 22:03:24,602 - GAugM EPNet train, Epoch [171/230]: loss 0.7209, auc 0.5190, ap 0.5243
2024-01-10 22:03:24,680 - GAugM EPNet train, Epoch [172/230]: loss 0.7208, auc 0.4171, ap 0.4568
2024-01-10 22:03:24,758 - GAugM EPNet train, Epoch [173/230]: loss 0.7209, auc 0.4690, ap 0.4912
2024-01-10 22:03:24,836 - GAugM EPNet train, Epoch [174/230]: loss 0.7209, auc 0.4669, ap 0.4818
2024-01-10 22:03:24,922 - GAugM EPNet train, Epoch [175/230]: loss 0.7209, auc 0.6015, ap 0.5971
2024-01-10 22:03:25,000 - GAugM EPNet train, Epoch [176/230]: loss 0.7209, auc 0.4970, ap 0.5135
2024-01-10 22:03:25,078 - GAugM EPNet train, Epoch [177/230]: loss 0.7210, auc 0.4416, ap 0.4672
2024-01-10 22:03:25,168 - GAugM EPNet train, Epoch [178/230]: loss 0.7210, auc 0.4801, ap 0.5187
2024-01-10 22:03:25,251 - GAugM EPNet train, Epoch [179/230]: loss 0.7210, auc 0.4496, ap 0.5279
2024-01-10 22:03:25,335 - GAugM EPNet train, Epoch [180/230]: loss 0.7210, auc 0.4895, ap 0.5416
2024-01-10 22:03:25,412 - GAugM EPNet train, Epoch [181/230]: loss 0.7209, auc 0.3423, ap 0.4160
2024-01-10 22:03:25,497 - GAugM EPNet train, Epoch [182/230]: loss 0.7209, auc 0.5546, ap 0.5957
2024-01-10 22:03:25,580 - GAugM EPNet train, Epoch [183/230]: loss 0.7210, auc 0.5360, ap 0.5274
2024-01-10 22:03:25,667 - GAugM EPNet train, Epoch [184/230]: loss 0.7209, auc 0.5522, ap 0.5708
2024-01-10 22:03:25,752 - GAugM EPNet train, Epoch [185/230]: loss 0.7209, auc 0.4345, ap 0.4687
2024-01-10 22:03:25,832 - GAugM EPNet train, Epoch [186/230]: loss 0.7208, auc 0.4315, ap 0.4953
2024-01-10 22:03:25,920 - GAugM EPNet train, Epoch [187/230]: loss 0.7209, auc 0.5495, ap 0.5783
2024-01-10 22:03:26,001 - GAugM EPNet train, Epoch [188/230]: loss 0.7209, auc 0.4813, ap 0.4836
2024-01-10 22:03:26,093 - GAugM EPNet train, Epoch [189/230]: loss 0.7209, auc 0.5922, ap 0.6321
2024-01-10 22:03:26,174 - GAugM EPNet train, Epoch [190/230]: loss 0.7209, auc 0.4235, ap 0.4412
2024-01-10 22:03:26,253 - GAugM EPNet train, Epoch [191/230]: loss 0.7209, auc 0.4583, ap 0.5479
2024-01-10 22:03:26,341 - GAugM EPNet train, Epoch [192/230]: loss 0.7209, auc 0.5004, ap 0.4793
2024-01-10 22:03:26,422 - GAugM EPNet train, Epoch [193/230]: loss 0.7209, auc 0.5271, ap 0.5199
2024-01-10 22:03:26,506 - GAugM EPNet train, Epoch [194/230]: loss 0.7209, auc 0.4863, ap 0.5071
2024-01-10 22:03:26,589 - GAugM EPNet train, Epoch [195/230]: loss 0.7209, auc 0.4710, ap 0.4845
2024-01-10 22:03:26,668 - GAugM EPNet train, Epoch [196/230]: loss 0.7208, auc 0.5098, ap 0.5160
2024-01-10 22:03:26,741 - GAugM EPNet train, Epoch [197/230]: loss 0.7210, auc 0.4966, ap 0.4909
2024-01-10 22:03:26,826 - GAugM EPNet train, Epoch [198/230]: loss 0.7210, auc 0.4952, ap 0.5027
2024-01-10 22:03:26,904 - GAugM EPNet train, Epoch [199/230]: loss 0.7209, auc 0.5858, ap 0.6148
2024-01-10 22:03:26,984 - GAugM EPNet train, Epoch [200/230]: loss 0.7210, auc 0.4891, ap 0.4999
2024-01-10 22:03:27,059 - GAugM EPNet train, Epoch [201/230]: loss 0.7209, auc 0.4534, ap 0.4777
2024-01-10 22:03:27,139 - GAugM EPNet train, Epoch [202/230]: loss 0.7210, auc 0.4575, ap 0.5267
2024-01-10 22:03:27,225 - GAugM EPNet train, Epoch [203/230]: loss 0.7210, auc 0.5555, ap 0.5874
2024-01-10 22:03:27,308 - GAugM EPNet train, Epoch [204/230]: loss 0.7209, auc 0.4480, ap 0.4737
2024-01-10 22:03:27,389 - GAugM EPNet train, Epoch [205/230]: loss 0.7209, auc 0.4614, ap 0.5100
2024-01-10 22:03:27,468 - GAugM EPNet train, Epoch [206/230]: loss 0.7209, auc 0.4696, ap 0.4931
2024-01-10 22:03:27,556 - GAugM EPNet train, Epoch [207/230]: loss 0.7210, auc 0.4644, ap 0.5283
2024-01-10 22:03:27,636 - GAugM EPNet train, Epoch [208/230]: loss 0.7209, auc 0.4737, ap 0.5233
2024-01-10 22:03:27,722 - GAugM EPNet train, Epoch [209/230]: loss 0.7210, auc 0.5513, ap 0.5577
2024-01-10 22:03:27,797 - GAugM EPNet train, Epoch [210/230]: loss 0.7209, auc 0.4591, ap 0.4867
2024-01-10 22:03:27,871 - GAugM EPNet train, Epoch [211/230]: loss 0.7210, auc 0.5142, ap 0.5496
2024-01-10 22:03:27,955 - GAugM EPNet train, Epoch [212/230]: loss 0.7210, auc 0.4774, ap 0.4919
2024-01-10 22:03:28,030 - GAugM EPNet train, Epoch [213/230]: loss 0.7208, auc 0.5943, ap 0.6322
2024-01-10 22:03:28,110 - GAugM EPNet train, Epoch [214/230]: loss 0.7210, auc 0.4569, ap 0.4883
2024-01-10 22:03:28,210 - GAugM EPNet train, Epoch [215/230]: loss 0.7210, auc 0.4900, ap 0.4777
2024-01-10 22:03:28,291 - GAugM EPNet train, Epoch [216/230]: loss 0.7209, auc 0.5025, ap 0.5257
2024-01-10 22:03:28,369 - GAugM EPNet train, Epoch [217/230]: loss 0.7209, auc 0.5895, ap 0.6657
2024-01-10 22:03:28,449 - GAugM EPNet train, Epoch [218/230]: loss 0.7209, auc 0.4939, ap 0.5622
2024-01-10 22:03:28,530 - GAugM EPNet train, Epoch [219/230]: loss 0.7208, auc 0.4247, ap 0.4713
2024-01-10 22:03:28,616 - GAugM EPNet train, Epoch [220/230]: loss 0.7210, auc 0.5315, ap 0.5741
2024-01-10 22:03:28,693 - GAugM EPNet train, Epoch [221/230]: loss 0.7209, auc 0.5664, ap 0.5732
2024-01-10 22:03:28,771 - GAugM EPNet train, Epoch [222/230]: loss 0.7209, auc 0.4648, ap 0.4923
2024-01-10 22:03:28,848 - GAugM EPNet train, Epoch [223/230]: loss 0.7209, auc 0.5117, ap 0.5568
2024-01-10 22:03:28,928 - GAugM EPNet train, Epoch [224/230]: loss 0.7210, auc 0.5121, ap 0.5175
2024-01-10 22:03:29,011 - GAugM EPNet train, Epoch [225/230]: loss 0.7209, auc 0.4810, ap 0.5233
2024-01-10 22:03:29,103 - GAugM EPNet train, Epoch [226/230]: loss 0.7210, auc 0.5470, ap 0.5509
2024-01-10 22:03:29,185 - GAugM EPNet train, Epoch [227/230]: loss 0.7210, auc 0.5530, ap 0.5751
2024-01-10 22:03:29,265 - GAugM EPNet train, Epoch [228/230]: loss 0.7209, auc 0.4648, ap 0.5013
2024-01-10 22:03:29,352 - GAugM EPNet train, Epoch [229/230]: loss 0.7209, auc 0.5726, ap 0.5892
2024-01-10 22:03:29,432 - GAugM EPNet train, Epoch [230/230]: loss 0.7209, auc 0.4952, ap 0.5208
2024-01-10 22:03:29,441 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d0386cb90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:03:30,163 - GAugM EPNet train, Epoch [  1/230]: loss 0.7210, auc 0.4393, ap 0.4659
2024-01-10 22:03:30,260 - GAugM EPNet train, Epoch [  2/230]: loss 0.7210, auc 0.4610, ap 0.4920
2024-01-10 22:03:30,355 - GAugM EPNet train, Epoch [  3/230]: loss 0.7209, auc 0.4792, ap 0.4839
2024-01-10 22:03:30,443 - GAugM EPNet train, Epoch [  4/230]: loss 0.7209, auc 0.5055, ap 0.5724
2024-01-10 22:03:30,532 - GAugM EPNet train, Epoch [  5/230]: loss 0.7209, auc 0.5550, ap 0.5946
2024-01-10 22:03:30,621 - GAugM EPNet train, Epoch [  6/230]: loss 0.7209, auc 0.4838, ap 0.4924
2024-01-10 22:03:30,706 - GAugM EPNet train, Epoch [  7/230]: loss 0.7209, auc 0.4770, ap 0.4785
2024-01-10 22:03:30,789 - GAugM EPNet train, Epoch [  8/230]: loss 0.7210, auc 0.4621, ap 0.4668
2024-01-10 22:03:30,873 - GAugM EPNet train, Epoch [  9/230]: loss 0.7209, auc 0.5158, ap 0.5119
2024-01-10 22:03:30,955 - GAugM EPNet train, Epoch [ 10/230]: loss 0.7208, auc 0.5272, ap 0.5280
2024-01-10 22:03:31,040 - GAugM EPNet train, Epoch [ 11/230]: loss 0.7209, auc 0.4468, ap 0.5015
2024-01-10 22:03:31,122 - GAugM EPNet train, Epoch [ 12/230]: loss 0.7210, auc 0.4735, ap 0.4974
2024-01-10 22:03:31,210 - GAugM EPNet train, Epoch [ 13/230]: loss 0.7209, auc 0.5507, ap 0.5732
2024-01-10 22:03:31,292 - GAugM EPNet train, Epoch [ 14/230]: loss 0.7209, auc 0.5358, ap 0.5245
2024-01-10 22:03:31,378 - GAugM EPNet train, Epoch [ 15/230]: loss 0.7210, auc 0.3257, ap 0.4081
2024-01-10 22:03:31,464 - GAugM EPNet train, Epoch [ 16/230]: loss 0.7209, auc 0.5753, ap 0.6122
2024-01-10 22:03:31,548 - GAugM EPNet train, Epoch [ 17/230]: loss 0.7210, auc 0.5457, ap 0.5550
2024-01-10 22:03:31,635 - GAugM EPNet train, Epoch [ 18/230]: loss 0.7210, auc 0.5546, ap 0.5713
2024-01-10 22:03:31,720 - GAugM EPNet train, Epoch [ 19/230]: loss 0.7209, auc 0.5255, ap 0.5177
2024-01-10 22:03:31,807 - GAugM EPNet train, Epoch [ 20/230]: loss 0.7210, auc 0.5055, ap 0.5565
2024-01-10 22:03:31,887 - GAugM EPNet train, Epoch [ 21/230]: loss 0.7209, auc 0.3795, ap 0.4520
2024-01-10 22:03:31,975 - GAugM EPNet train, Epoch [ 22/230]: loss 0.7210, auc 0.4030, ap 0.4647
2024-01-10 22:03:32,056 - GAugM EPNet train, Epoch [ 23/230]: loss 0.7208, auc 0.5219, ap 0.5314
2024-01-10 22:03:32,137 - GAugM EPNet train, Epoch [ 24/230]: loss 0.7209, auc 0.4678, ap 0.5066
2024-01-10 22:03:32,221 - GAugM EPNet train, Epoch [ 25/230]: loss 0.7209, auc 0.4692, ap 0.4948
2024-01-10 22:03:32,304 - GAugM EPNet train, Epoch [ 26/230]: loss 0.7210, auc 0.5853, ap 0.6127
2024-01-10 22:03:32,382 - GAugM EPNet train, Epoch [ 27/230]: loss 0.7209, auc 0.4336, ap 0.4919
2024-01-10 22:03:32,476 - GAugM EPNet train, Epoch [ 28/230]: loss 0.7209, auc 0.5393, ap 0.5962
2024-01-10 22:03:32,560 - GAugM EPNet train, Epoch [ 29/230]: loss 0.7210, auc 0.4603, ap 0.4724
2024-01-10 22:03:32,643 - GAugM EPNet train, Epoch [ 30/230]: loss 0.7209, auc 0.4311, ap 0.4806
2024-01-10 22:03:32,720 - GAugM EPNet train, Epoch [ 31/230]: loss 0.7208, auc 0.5077, ap 0.5411
2024-01-10 22:03:32,812 - GAugM EPNet train, Epoch [ 32/230]: loss 0.7210, auc 0.5643, ap 0.5577
2024-01-10 22:03:32,893 - GAugM EPNet train, Epoch [ 33/230]: loss 0.7209, auc 0.5158, ap 0.5425
2024-01-10 22:03:32,979 - GAugM EPNet train, Epoch [ 34/230]: loss 0.7209, auc 0.3930, ap 0.4295
2024-01-10 22:03:33,062 - GAugM EPNet train, Epoch [ 35/230]: loss 0.7209, auc 0.5643, ap 0.5721
2024-01-10 22:03:33,144 - GAugM EPNet train, Epoch [ 36/230]: loss 0.7209, auc 0.4792, ap 0.5315
2024-01-10 22:03:33,229 - GAugM EPNet train, Epoch [ 37/230]: loss 0.7209, auc 0.5101, ap 0.5227
2024-01-10 22:03:33,312 - GAugM EPNet train, Epoch [ 38/230]: loss 0.7209, auc 0.5208, ap 0.5067
2024-01-10 22:03:33,394 - GAugM EPNet train, Epoch [ 39/230]: loss 0.7208, auc 0.4642, ap 0.4913
2024-01-10 22:03:33,483 - GAugM EPNet train, Epoch [ 40/230]: loss 0.7210, auc 0.5322, ap 0.5208
2024-01-10 22:03:33,568 - GAugM EPNet train, Epoch [ 41/230]: loss 0.7210, auc 0.5596, ap 0.5862
2024-01-10 22:03:33,651 - GAugM EPNet train, Epoch [ 42/230]: loss 0.7209, auc 0.5799, ap 0.6452
2024-01-10 22:03:33,734 - GAugM EPNet train, Epoch [ 43/230]: loss 0.7208, auc 0.4365, ap 0.4671
2024-01-10 22:03:33,818 - GAugM EPNet train, Epoch [ 44/230]: loss 0.7208, auc 0.4176, ap 0.4960
2024-01-10 22:03:33,903 - GAugM EPNet train, Epoch [ 45/230]: loss 0.7209, auc 0.4891, ap 0.5052
2024-01-10 22:03:33,987 - GAugM EPNet train, Epoch [ 46/230]: loss 0.7209, auc 0.4343, ap 0.4874
2024-01-10 22:03:34,079 - GAugM EPNet train, Epoch [ 47/230]: loss 0.7210, auc 0.5041, ap 0.5452
2024-01-10 22:03:34,163 - GAugM EPNet train, Epoch [ 48/230]: loss 0.7210, auc 0.6458, ap 0.6714
2024-01-10 22:03:34,248 - GAugM EPNet train, Epoch [ 49/230]: loss 0.7209, auc 0.4642, ap 0.5149
2024-01-10 22:03:34,337 - GAugM EPNet train, Epoch [ 50/230]: loss 0.7210, auc 0.5080, ap 0.5262
2024-01-10 22:03:34,420 - GAugM EPNet train, Epoch [ 51/230]: loss 0.7210, auc 0.5162, ap 0.5431
2024-01-10 22:03:34,508 - GAugM EPNet train, Epoch [ 52/230]: loss 0.7209, auc 0.4664, ap 0.5087
2024-01-10 22:03:34,588 - GAugM EPNet train, Epoch [ 53/230]: loss 0.7209, auc 0.5436, ap 0.5610
2024-01-10 22:03:34,671 - GAugM EPNet train, Epoch [ 54/230]: loss 0.7211, auc 0.5853, ap 0.5854
2024-01-10 22:03:34,756 - GAugM EPNet train, Epoch [ 55/230]: loss 0.7209, auc 0.5208, ap 0.5631
2024-01-10 22:03:34,838 - GAugM EPNet train, Epoch [ 56/230]: loss 0.7208, auc 0.4553, ap 0.4641
2024-01-10 22:03:34,927 - GAugM EPNet train, Epoch [ 57/230]: loss 0.7209, auc 0.4575, ap 0.4657
2024-01-10 22:03:35,009 - GAugM EPNet train, Epoch [ 58/230]: loss 0.7210, auc 0.4774, ap 0.5600
2024-01-10 22:03:35,090 - GAugM EPNet train, Epoch [ 59/230]: loss 0.7211, auc 0.5675, ap 0.5812
2024-01-10 22:03:35,172 - GAugM EPNet train, Epoch [ 60/230]: loss 0.7210, auc 0.4838, ap 0.5018
2024-01-10 22:03:35,254 - GAugM EPNet train, Epoch [ 61/230]: loss 0.7209, auc 0.4998, ap 0.5372
2024-01-10 22:03:35,334 - GAugM EPNet train, Epoch [ 62/230]: loss 0.7210, auc 0.5489, ap 0.5819
2024-01-10 22:03:35,422 - GAugM EPNet train, Epoch [ 63/230]: loss 0.7208, auc 0.4575, ap 0.5079
2024-01-10 22:03:35,507 - GAugM EPNet train, Epoch [ 64/230]: loss 0.7208, auc 0.3692, ap 0.4286
2024-01-10 22:03:35,591 - GAugM EPNet train, Epoch [ 65/230]: loss 0.7208, auc 0.5297, ap 0.5636
2024-01-10 22:03:35,678 - GAugM EPNet train, Epoch [ 66/230]: loss 0.7209, auc 0.5194, ap 0.5296
2024-01-10 22:03:35,759 - GAugM EPNet train, Epoch [ 67/230]: loss 0.7209, auc 0.4756, ap 0.4909
2024-01-10 22:03:35,840 - GAugM EPNet train, Epoch [ 68/230]: loss 0.7210, auc 0.4956, ap 0.5379
2024-01-10 22:03:35,923 - GAugM EPNet train, Epoch [ 69/230]: loss 0.7210, auc 0.5116, ap 0.5675
2024-01-10 22:03:36,007 - GAugM EPNet train, Epoch [ 70/230]: loss 0.7210, auc 0.4913, ap 0.5221
2024-01-10 22:03:36,089 - GAugM EPNet train, Epoch [ 71/230]: loss 0.7210, auc 0.5678, ap 0.5442
2024-01-10 22:03:36,173 - GAugM EPNet train, Epoch [ 72/230]: loss 0.7210, auc 0.4443, ap 0.4814
2024-01-10 22:03:36,256 - GAugM EPNet train, Epoch [ 73/230]: loss 0.7209, auc 0.5860, ap 0.5559
2024-01-10 22:03:36,337 - GAugM EPNet train, Epoch [ 74/230]: loss 0.7209, auc 0.4742, ap 0.5189
2024-01-10 22:03:36,420 - GAugM EPNet train, Epoch [ 75/230]: loss 0.7210, auc 0.4009, ap 0.4923
2024-01-10 22:03:36,500 - GAugM EPNet train, Epoch [ 76/230]: loss 0.7209, auc 0.3781, ap 0.4209
2024-01-10 22:03:36,583 - GAugM EPNet train, Epoch [ 77/230]: loss 0.7208, auc 0.5012, ap 0.5466
2024-01-10 22:03:36,667 - GAugM EPNet train, Epoch [ 78/230]: loss 0.7209, auc 0.5069, ap 0.5248
2024-01-10 22:03:36,753 - GAugM EPNet train, Epoch [ 79/230]: loss 0.7208, auc 0.4927, ap 0.5266
2024-01-10 22:03:36,832 - GAugM EPNet train, Epoch [ 80/230]: loss 0.7209, auc 0.5166, ap 0.5327
2024-01-10 22:03:36,913 - GAugM EPNet train, Epoch [ 81/230]: loss 0.7209, auc 0.4831, ap 0.4858
2024-01-10 22:03:36,998 - GAugM EPNet train, Epoch [ 82/230]: loss 0.7210, auc 0.5308, ap 0.5415
2024-01-10 22:03:37,081 - GAugM EPNet train, Epoch [ 83/230]: loss 0.7209, auc 0.4318, ap 0.4954
2024-01-10 22:03:37,165 - GAugM EPNet train, Epoch [ 84/230]: loss 0.7209, auc 0.3809, ap 0.4223
2024-01-10 22:03:37,248 - GAugM EPNet train, Epoch [ 85/230]: loss 0.7210, auc 0.4083, ap 0.4570
2024-01-10 22:03:37,333 - GAugM EPNet train, Epoch [ 86/230]: loss 0.7208, auc 0.4906, ap 0.4873
2024-01-10 22:03:37,414 - GAugM EPNet train, Epoch [ 87/230]: loss 0.7209, auc 0.5568, ap 0.5630
2024-01-10 22:03:37,500 - GAugM EPNet train, Epoch [ 88/230]: loss 0.7210, auc 0.5112, ap 0.5422
2024-01-10 22:03:37,585 - GAugM EPNet train, Epoch [ 89/230]: loss 0.7210, auc 0.5735, ap 0.6057
2024-01-10 22:03:37,665 - GAugM EPNet train, Epoch [ 90/230]: loss 0.7209, auc 0.4293, ap 0.4732
2024-01-10 22:03:37,747 - GAugM EPNet train, Epoch [ 91/230]: loss 0.7208, auc 0.6251, ap 0.5969
2024-01-10 22:03:37,831 - GAugM EPNet train, Epoch [ 92/230]: loss 0.7209, auc 0.5970, ap 0.5793
2024-01-10 22:03:37,914 - GAugM EPNet train, Epoch [ 93/230]: loss 0.7209, auc 0.4062, ap 0.4713
2024-01-10 22:03:37,998 - GAugM EPNet train, Epoch [ 94/230]: loss 0.7210, auc 0.4834, ap 0.5425
2024-01-10 22:03:38,080 - GAugM EPNet train, Epoch [ 95/230]: loss 0.7210, auc 0.5123, ap 0.5212
2024-01-10 22:03:38,162 - GAugM EPNet train, Epoch [ 96/230]: loss 0.7209, auc 0.5408, ap 0.5468
2024-01-10 22:03:38,247 - GAugM EPNet train, Epoch [ 97/230]: loss 0.7209, auc 0.5400, ap 0.5750
2024-01-10 22:03:38,338 - GAugM EPNet train, Epoch [ 98/230]: loss 0.7209, auc 0.4778, ap 0.4854
2024-01-10 22:03:38,421 - GAugM EPNet train, Epoch [ 99/230]: loss 0.7209, auc 0.4817, ap 0.5046
2024-01-10 22:03:38,508 - GAugM EPNet train, Epoch [100/230]: loss 0.7210, auc 0.4610, ap 0.5191
2024-01-10 22:03:38,588 - GAugM EPNet train, Epoch [101/230]: loss 0.7210, auc 0.5500, ap 0.6314
2024-01-10 22:03:38,666 - GAugM EPNet train, Epoch [102/230]: loss 0.7209, auc 0.4411, ap 0.4749
2024-01-10 22:03:38,747 - GAugM EPNet train, Epoch [103/230]: loss 0.7209, auc 0.5589, ap 0.6158
2024-01-10 22:03:38,829 - GAugM EPNet train, Epoch [104/230]: loss 0.7209, auc 0.4977, ap 0.4763
2024-01-10 22:03:38,910 - GAugM EPNet train, Epoch [105/230]: loss 0.7209, auc 0.4813, ap 0.4836
2024-01-10 22:03:39,001 - GAugM EPNet train, Epoch [106/230]: loss 0.7210, auc 0.4087, ap 0.4404
2024-01-10 22:03:39,084 - GAugM EPNet train, Epoch [107/230]: loss 0.7210, auc 0.5340, ap 0.5502
2024-01-10 22:03:39,166 - GAugM EPNet train, Epoch [108/230]: loss 0.7208, auc 0.5030, ap 0.5335
2024-01-10 22:03:39,258 - GAugM EPNet train, Epoch [109/230]: loss 0.7210, auc 0.5265, ap 0.5621
2024-01-10 22:03:39,342 - GAugM EPNet train, Epoch [110/230]: loss 0.7209, auc 0.5344, ap 0.5583
2024-01-10 22:03:39,423 - GAugM EPNet train, Epoch [111/230]: loss 0.7210, auc 0.4530, ap 0.5011
2024-01-10 22:03:39,508 - GAugM EPNet train, Epoch [112/230]: loss 0.7209, auc 0.5372, ap 0.5445
2024-01-10 22:03:39,590 - GAugM EPNet train, Epoch [113/230]: loss 0.7210, auc 0.5016, ap 0.5448
2024-01-10 22:03:39,670 - GAugM EPNet train, Epoch [114/230]: loss 0.7209, auc 0.4393, ap 0.4638
2024-01-10 22:03:39,751 - GAugM EPNet train, Epoch [115/230]: loss 0.7210, auc 0.4913, ap 0.5453
2024-01-10 22:03:39,837 - GAugM EPNet train, Epoch [116/230]: loss 0.7209, auc 0.5742, ap 0.5947
2024-01-10 22:03:39,917 - GAugM EPNet train, Epoch [117/230]: loss 0.7208, auc 0.4916, ap 0.5028
2024-01-10 22:03:40,007 - GAugM EPNet train, Epoch [118/230]: loss 0.7209, auc 0.4493, ap 0.4806
2024-01-10 22:03:40,091 - GAugM EPNet train, Epoch [119/230]: loss 0.7209, auc 0.5283, ap 0.5585
2024-01-10 22:03:40,173 - GAugM EPNet train, Epoch [120/230]: loss 0.7210, auc 0.4272, ap 0.4739
2024-01-10 22:03:40,255 - GAugM EPNet train, Epoch [121/230]: loss 0.7210, auc 0.4454, ap 0.5039
2024-01-10 22:03:40,337 - GAugM EPNet train, Epoch [122/230]: loss 0.7209, auc 0.4489, ap 0.4961
2024-01-10 22:03:40,417 - GAugM EPNet train, Epoch [123/230]: loss 0.7209, auc 0.5187, ap 0.5566
2024-01-10 22:03:40,506 - GAugM EPNet train, Epoch [124/230]: loss 0.7210, auc 0.4368, ap 0.4576
2024-01-10 22:03:40,588 - GAugM EPNet train, Epoch [125/230]: loss 0.7209, auc 0.5212, ap 0.5318
2024-01-10 22:03:40,675 - GAugM EPNet train, Epoch [126/230]: loss 0.7210, auc 0.4824, ap 0.5412
2024-01-10 22:03:40,757 - GAugM EPNet train, Epoch [127/230]: loss 0.7209, auc 0.5180, ap 0.5202
2024-01-10 22:03:40,842 - GAugM EPNet train, Epoch [128/230]: loss 0.7210, auc 0.4902, ap 0.4860
2024-01-10 22:03:40,925 - GAugM EPNet train, Epoch [129/230]: loss 0.7208, auc 0.4187, ap 0.4502
2024-01-10 22:03:41,005 - GAugM EPNet train, Epoch [130/230]: loss 0.7210, auc 0.4386, ap 0.4690
2024-01-10 22:03:41,084 - GAugM EPNet train, Epoch [131/230]: loss 0.7210, auc 0.5219, ap 0.5499
2024-01-10 22:03:41,171 - GAugM EPNet train, Epoch [132/230]: loss 0.7209, auc 0.5333, ap 0.5659
2024-01-10 22:03:41,252 - GAugM EPNet train, Epoch [133/230]: loss 0.7209, auc 0.5030, ap 0.5402
2024-01-10 22:03:41,333 - GAugM EPNet train, Epoch [134/230]: loss 0.7210, auc 0.4995, ap 0.5127
2024-01-10 22:03:41,415 - GAugM EPNet train, Epoch [135/230]: loss 0.7209, auc 0.3745, ap 0.4323
2024-01-10 22:03:41,499 - GAugM EPNet train, Epoch [136/230]: loss 0.7209, auc 0.4446, ap 0.4735
2024-01-10 22:03:41,580 - GAugM EPNet train, Epoch [137/230]: loss 0.7210, auc 0.5358, ap 0.5621
2024-01-10 22:03:41,670 - GAugM EPNet train, Epoch [138/230]: loss 0.7210, auc 0.5201, ap 0.5267
2024-01-10 22:03:41,752 - GAugM EPNet train, Epoch [139/230]: loss 0.7210, auc 0.4692, ap 0.4984
2024-01-10 22:03:41,835 - GAugM EPNet train, Epoch [140/230]: loss 0.7209, auc 0.5493, ap 0.5858
2024-01-10 22:03:41,925 - GAugM EPNet train, Epoch [141/230]: loss 0.7209, auc 0.4802, ap 0.4950
2024-01-10 22:03:42,007 - GAugM EPNet train, Epoch [142/230]: loss 0.7209, auc 0.5148, ap 0.5513
2024-01-10 22:03:42,096 - GAugM EPNet train, Epoch [143/230]: loss 0.7209, auc 0.3834, ap 0.4375
2024-01-10 22:03:42,180 - GAugM EPNet train, Epoch [144/230]: loss 0.7209, auc 0.4528, ap 0.4681
2024-01-10 22:03:42,261 - GAugM EPNet train, Epoch [145/230]: loss 0.7209, auc 0.5091, ap 0.5140
2024-01-10 22:03:42,341 - GAugM EPNet train, Epoch [146/230]: loss 0.7209, auc 0.4799, ap 0.5166
2024-01-10 22:03:42,418 - GAugM EPNet train, Epoch [147/230]: loss 0.7209, auc 0.6750, ap 0.6959
2024-01-10 22:03:42,501 - GAugM EPNet train, Epoch [148/230]: loss 0.7209, auc 0.4749, ap 0.5102
2024-01-10 22:03:42,577 - GAugM EPNet train, Epoch [149/230]: loss 0.7208, auc 0.4721, ap 0.5166
2024-01-10 22:03:42,661 - GAugM EPNet train, Epoch [150/230]: loss 0.7209, auc 0.5728, ap 0.5658
2024-01-10 22:03:42,749 - GAugM EPNet train, Epoch [151/230]: loss 0.7209, auc 0.5041, ap 0.5244
2024-01-10 22:03:42,827 - GAugM EPNet train, Epoch [152/230]: loss 0.7209, auc 0.5440, ap 0.5670
2024-01-10 22:03:42,910 - GAugM EPNet train, Epoch [153/230]: loss 0.7209, auc 0.4325, ap 0.4659
2024-01-10 22:03:42,997 - GAugM EPNet train, Epoch [154/230]: loss 0.7209, auc 0.5760, ap 0.6377
2024-01-10 22:03:43,080 - GAugM EPNet train, Epoch [155/230]: loss 0.7209, auc 0.5044, ap 0.5549
2024-01-10 22:03:43,173 - GAugM EPNet train, Epoch [156/230]: loss 0.7209, auc 0.4607, ap 0.4831
2024-01-10 22:03:43,258 - GAugM EPNet train, Epoch [157/230]: loss 0.7209, auc 0.5119, ap 0.5311
2024-01-10 22:03:43,345 - GAugM EPNet train, Epoch [158/230]: loss 0.7208, auc 0.4980, ap 0.5125
2024-01-10 22:03:43,425 - GAugM EPNet train, Epoch [159/230]: loss 0.7208, auc 0.4546, ap 0.4776
2024-01-10 22:03:43,508 - GAugM EPNet train, Epoch [160/230]: loss 0.7209, auc 0.5778, ap 0.6157
2024-01-10 22:03:43,592 - GAugM EPNet train, Epoch [161/230]: loss 0.7209, auc 0.5564, ap 0.5530
2024-01-10 22:03:43,675 - GAugM EPNet train, Epoch [162/230]: loss 0.7209, auc 0.4678, ap 0.4878
2024-01-10 22:03:43,755 - GAugM EPNet train, Epoch [163/230]: loss 0.7209, auc 0.4240, ap 0.4406
2024-01-10 22:03:43,840 - GAugM EPNet train, Epoch [164/230]: loss 0.7211, auc 0.5091, ap 0.5186
2024-01-10 22:03:43,921 - GAugM EPNet train, Epoch [165/230]: loss 0.7210, auc 0.4208, ap 0.5156
2024-01-10 22:03:43,999 - GAugM EPNet train, Epoch [166/230]: loss 0.7208, auc 0.4454, ap 0.4789
2024-01-10 22:03:44,087 - GAugM EPNet train, Epoch [167/230]: loss 0.7209, auc 0.4557, ap 0.4882
2024-01-10 22:03:44,175 - GAugM EPNet train, Epoch [168/230]: loss 0.7209, auc 0.4507, ap 0.5075
2024-01-10 22:03:44,263 - GAugM EPNet train, Epoch [169/230]: loss 0.7209, auc 0.6515, ap 0.6803
2024-01-10 22:03:44,344 - GAugM EPNet train, Epoch [170/230]: loss 0.7210, auc 0.4450, ap 0.4645
2024-01-10 22:03:44,428 - GAugM EPNet train, Epoch [171/230]: loss 0.7209, auc 0.4607, ap 0.4914
2024-01-10 22:03:44,507 - GAugM EPNet train, Epoch [172/230]: loss 0.7208, auc 0.4315, ap 0.4660
2024-01-10 22:03:44,588 - GAugM EPNet train, Epoch [173/230]: loss 0.7209, auc 0.5813, ap 0.5851
2024-01-10 22:03:44,679 - GAugM EPNet train, Epoch [174/230]: loss 0.7209, auc 0.4215, ap 0.4567
2024-01-10 22:03:44,761 - GAugM EPNet train, Epoch [175/230]: loss 0.7209, auc 0.6294, ap 0.6055
2024-01-10 22:03:44,841 - GAugM EPNet train, Epoch [176/230]: loss 0.7209, auc 0.4525, ap 0.4676
2024-01-10 22:03:44,932 - GAugM EPNet train, Epoch [177/230]: loss 0.7210, auc 0.5892, ap 0.5709
2024-01-10 22:03:45,013 - GAugM EPNet train, Epoch [178/230]: loss 0.7210, auc 0.5347, ap 0.5582
2024-01-10 22:03:45,105 - GAugM EPNet train, Epoch [179/230]: loss 0.7210, auc 0.4058, ap 0.4934
2024-01-10 22:03:45,185 - GAugM EPNet train, Epoch [180/230]: loss 0.7210, auc 0.5176, ap 0.5903
2024-01-10 22:03:45,266 - GAugM EPNet train, Epoch [181/230]: loss 0.7209, auc 0.4806, ap 0.5047
2024-01-10 22:03:45,346 - GAugM EPNet train, Epoch [182/230]: loss 0.7209, auc 0.4347, ap 0.4729
2024-01-10 22:03:45,431 - GAugM EPNet train, Epoch [183/230]: loss 0.7210, auc 0.5621, ap 0.5759
2024-01-10 22:03:45,513 - GAugM EPNet train, Epoch [184/230]: loss 0.7209, auc 0.4614, ap 0.5133
2024-01-10 22:03:45,601 - GAugM EPNet train, Epoch [185/230]: loss 0.7209, auc 0.5475, ap 0.5948
2024-01-10 22:03:45,680 - GAugM EPNet train, Epoch [186/230]: loss 0.7208, auc 0.4500, ap 0.5208
2024-01-10 22:03:45,770 - GAugM EPNet train, Epoch [187/230]: loss 0.7209, auc 0.4988, ap 0.5232
2024-01-10 22:03:45,852 - GAugM EPNet train, Epoch [188/230]: loss 0.7209, auc 0.4728, ap 0.4749
2024-01-10 22:03:45,941 - GAugM EPNet train, Epoch [189/230]: loss 0.7209, auc 0.5554, ap 0.5877
2024-01-10 22:03:46,022 - GAugM EPNet train, Epoch [190/230]: loss 0.7209, auc 0.3859, ap 0.4505
2024-01-10 22:03:46,102 - GAugM EPNet train, Epoch [191/230]: loss 0.7209, auc 0.4710, ap 0.5482
2024-01-10 22:03:46,188 - GAugM EPNet train, Epoch [192/230]: loss 0.7209, auc 0.5251, ap 0.4978
2024-01-10 22:03:46,271 - GAugM EPNet train, Epoch [193/230]: loss 0.7209, auc 0.5774, ap 0.5658
2024-01-10 22:03:46,353 - GAugM EPNet train, Epoch [194/230]: loss 0.7209, auc 0.4393, ap 0.4912
2024-01-10 22:03:46,437 - GAugM EPNet train, Epoch [195/230]: loss 0.7209, auc 0.4799, ap 0.5375
2024-01-10 22:03:46,522 - GAugM EPNet train, Epoch [196/230]: loss 0.7208, auc 0.5639, ap 0.5357
2024-01-10 22:03:46,605 - GAugM EPNet train, Epoch [197/230]: loss 0.7210, auc 0.5411, ap 0.5485
2024-01-10 22:03:46,689 - GAugM EPNet train, Epoch [198/230]: loss 0.7210, auc 0.5133, ap 0.5395
2024-01-10 22:03:46,770 - GAugM EPNet train, Epoch [199/230]: loss 0.7209, auc 0.5262, ap 0.5568
2024-01-10 22:03:46,848 - GAugM EPNet train, Epoch [200/230]: loss 0.7210, auc 0.4738, ap 0.5158
2024-01-10 22:03:46,931 - GAugM EPNet train, Epoch [201/230]: loss 0.7209, auc 0.5632, ap 0.5763
2024-01-10 22:03:47,009 - GAugM EPNet train, Epoch [202/230]: loss 0.7210, auc 0.4685, ap 0.5056
2024-01-10 22:03:47,092 - GAugM EPNet train, Epoch [203/230]: loss 0.7210, auc 0.4778, ap 0.5048
2024-01-10 22:03:47,175 - GAugM EPNet train, Epoch [204/230]: loss 0.7209, auc 0.4845, ap 0.5070
2024-01-10 22:03:47,252 - GAugM EPNet train, Epoch [205/230]: loss 0.7209, auc 0.4261, ap 0.4739
2024-01-10 22:03:47,336 - GAugM EPNet train, Epoch [206/230]: loss 0.7209, auc 0.3898, ap 0.4609
2024-01-10 22:03:47,419 - GAugM EPNet train, Epoch [207/230]: loss 0.7210, auc 0.3816, ap 0.4561
2024-01-10 22:03:47,510 - GAugM EPNet train, Epoch [208/230]: loss 0.7209, auc 0.5169, ap 0.5882
2024-01-10 22:03:47,590 - GAugM EPNet train, Epoch [209/230]: loss 0.7210, auc 0.5436, ap 0.5745
2024-01-10 22:03:47,677 - GAugM EPNet train, Epoch [210/230]: loss 0.7209, auc 0.4624, ap 0.4712
2024-01-10 22:03:47,759 - GAugM EPNet train, Epoch [211/230]: loss 0.7210, auc 0.5450, ap 0.5680
2024-01-10 22:03:47,846 - GAugM EPNet train, Epoch [212/230]: loss 0.7210, auc 0.3991, ap 0.4391
2024-01-10 22:03:47,925 - GAugM EPNet train, Epoch [213/230]: loss 0.7208, auc 0.5390, ap 0.5711
2024-01-10 22:03:48,008 - GAugM EPNet train, Epoch [214/230]: loss 0.7210, auc 0.4753, ap 0.4885
2024-01-10 22:03:48,088 - GAugM EPNet train, Epoch [215/230]: loss 0.7210, auc 0.4941, ap 0.5111
2024-01-10 22:03:48,176 - GAugM EPNet train, Epoch [216/230]: loss 0.7209, auc 0.4770, ap 0.5000
2024-01-10 22:03:48,260 - GAugM EPNet train, Epoch [217/230]: loss 0.7209, auc 0.5562, ap 0.6101
2024-01-10 22:03:48,346 - GAugM EPNet train, Epoch [218/230]: loss 0.7209, auc 0.4785, ap 0.5132
2024-01-10 22:03:48,435 - GAugM EPNet train, Epoch [219/230]: loss 0.7208, auc 0.4308, ap 0.4713
2024-01-10 22:03:48,518 - GAugM EPNet train, Epoch [220/230]: loss 0.7210, auc 0.4724, ap 0.5210
2024-01-10 22:03:48,602 - GAugM EPNet train, Epoch [221/230]: loss 0.7209, auc 0.5230, ap 0.5534
2024-01-10 22:03:48,685 - GAugM EPNet train, Epoch [222/230]: loss 0.7209, auc 0.4699, ap 0.5013
2024-01-10 22:03:48,772 - GAugM EPNet train, Epoch [223/230]: loss 0.7209, auc 0.5126, ap 0.5530
2024-01-10 22:03:48,856 - GAugM EPNet train, Epoch [224/230]: loss 0.7210, auc 0.4066, ap 0.4300
2024-01-10 22:03:48,939 - GAugM EPNet train, Epoch [225/230]: loss 0.7209, auc 0.5411, ap 0.5637
2024-01-10 22:03:49,027 - GAugM EPNet train, Epoch [226/230]: loss 0.7210, auc 0.5205, ap 0.5676
2024-01-10 22:03:49,111 - GAugM EPNet train, Epoch [227/230]: loss 0.7210, auc 0.5675, ap 0.6082
2024-01-10 22:03:49,195 - GAugM EPNet train, Epoch [228/230]: loss 0.7209, auc 0.4788, ap 0.4916
2024-01-10 22:03:49,272 - GAugM EPNet train, Epoch [229/230]: loss 0.7209, auc 0.5425, ap 0.5836
2024-01-10 22:03:49,361 - GAugM EPNet train, Epoch [230/230]: loss 0.7209, auc 0.4824, ap 0.5334
2024-01-10 22:03:49,361 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035e0590>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:03:50,059 - GAugM EPNet train, Epoch [  1/230]: loss 0.7210, auc 0.4598, ap 0.4643
2024-01-10 22:03:50,145 - GAugM EPNet train, Epoch [  2/230]: loss 0.7210, auc 0.5061, ap 0.4958
2024-01-10 22:03:50,228 - GAugM EPNet train, Epoch [  3/230]: loss 0.7209, auc 0.5303, ap 0.5497
2024-01-10 22:03:50,318 - GAugM EPNet train, Epoch [  4/230]: loss 0.7209, auc 0.5096, ap 0.5258
2024-01-10 22:03:50,403 - GAugM EPNet train, Epoch [  5/230]: loss 0.7209, auc 0.5545, ap 0.5312
2024-01-10 22:03:50,497 - GAugM EPNet train, Epoch [  6/230]: loss 0.7209, auc 0.4870, ap 0.4848
2024-01-10 22:03:50,582 - GAugM EPNet train, Epoch [  7/230]: loss 0.7209, auc 0.4562, ap 0.4669
2024-01-10 22:03:50,666 - GAugM EPNet train, Epoch [  8/230]: loss 0.7210, auc 0.5089, ap 0.5220
2024-01-10 22:03:50,757 - GAugM EPNet train, Epoch [  9/230]: loss 0.7209, auc 0.4794, ap 0.4760
2024-01-10 22:03:50,843 - GAugM EPNet train, Epoch [ 10/230]: loss 0.7208, auc 0.4486, ap 0.4596
2024-01-10 22:03:50,929 - GAugM EPNet train, Epoch [ 11/230]: loss 0.7209, auc 0.5148, ap 0.4856
2024-01-10 22:03:51,012 - GAugM EPNet train, Epoch [ 12/230]: loss 0.7210, auc 0.4934, ap 0.4910
2024-01-10 22:03:51,098 - GAugM EPNet train, Epoch [ 13/230]: loss 0.7209, auc 0.5860, ap 0.5485
2024-01-10 22:03:51,187 - GAugM EPNet train, Epoch [ 14/230]: loss 0.7209, auc 0.5710, ap 0.5443
2024-01-10 22:03:51,275 - GAugM EPNet train, Epoch [ 15/230]: loss 0.7210, auc 0.3921, ap 0.4556
2024-01-10 22:03:51,357 - GAugM EPNet train, Epoch [ 16/230]: loss 0.7209, auc 0.5210, ap 0.5019
2024-01-10 22:03:51,440 - GAugM EPNet train, Epoch [ 17/230]: loss 0.7210, auc 0.4920, ap 0.4937
2024-01-10 22:03:51,522 - GAugM EPNet train, Epoch [ 18/230]: loss 0.7210, auc 0.6232, ap 0.6046
2024-01-10 22:03:51,612 - GAugM EPNet train, Epoch [ 19/230]: loss 0.7209, auc 0.4660, ap 0.4765
2024-01-10 22:03:51,697 - GAugM EPNet train, Epoch [ 20/230]: loss 0.7210, auc 0.5032, ap 0.5377
2024-01-10 22:03:51,780 - GAugM EPNet train, Epoch [ 21/230]: loss 0.7209, auc 0.4804, ap 0.4944
2024-01-10 22:03:51,859 - GAugM EPNet train, Epoch [ 22/230]: loss 0.7210, auc 0.4274, ap 0.4378
2024-01-10 22:03:51,952 - GAugM EPNet train, Epoch [ 23/230]: loss 0.7208, auc 0.5529, ap 0.5270
2024-01-10 22:03:52,038 - GAugM EPNet train, Epoch [ 24/230]: loss 0.7209, auc 0.5153, ap 0.5059
2024-01-10 22:03:52,122 - GAugM EPNet train, Epoch [ 25/230]: loss 0.7209, auc 0.3896, ap 0.4306
2024-01-10 22:03:52,213 - GAugM EPNet train, Epoch [ 26/230]: loss 0.7210, auc 0.5166, ap 0.5286
2024-01-10 22:03:52,294 - GAugM EPNet train, Epoch [ 27/230]: loss 0.7209, auc 0.4213, ap 0.4493
2024-01-10 22:03:52,379 - GAugM EPNet train, Epoch [ 28/230]: loss 0.7209, auc 0.5712, ap 0.5716
2024-01-10 22:03:52,462 - GAugM EPNet train, Epoch [ 29/230]: loss 0.7210, auc 0.5219, ap 0.5103
2024-01-10 22:03:52,550 - GAugM EPNet train, Epoch [ 30/230]: loss 0.7209, auc 0.5582, ap 0.5633
2024-01-10 22:03:52,636 - GAugM EPNet train, Epoch [ 31/230]: loss 0.7208, auc 0.5336, ap 0.5167
2024-01-10 22:03:52,717 - GAugM EPNet train, Epoch [ 32/230]: loss 0.7210, auc 0.5098, ap 0.4980
2024-01-10 22:03:52,797 - GAugM EPNet train, Epoch [ 33/230]: loss 0.7209, auc 0.5500, ap 0.5604
2024-01-10 22:03:52,885 - GAugM EPNet train, Epoch [ 34/230]: loss 0.7209, auc 0.4395, ap 0.4550
2024-01-10 22:03:52,970 - GAugM EPNet train, Epoch [ 35/230]: loss 0.7209, auc 0.4941, ap 0.4863
2024-01-10 22:03:53,048 - GAugM EPNet train, Epoch [ 36/230]: loss 0.7209, auc 0.5842, ap 0.5770
2024-01-10 22:03:53,138 - GAugM EPNet train, Epoch [ 37/230]: loss 0.7209, auc 0.3925, ap 0.4369
2024-01-10 22:03:53,217 - GAugM EPNet train, Epoch [ 38/230]: loss 0.7209, auc 0.4847, ap 0.4843
2024-01-10 22:03:53,298 - GAugM EPNet train, Epoch [ 39/230]: loss 0.7208, auc 0.5048, ap 0.5352
2024-01-10 22:03:53,381 - GAugM EPNet train, Epoch [ 40/230]: loss 0.7210, auc 0.5084, ap 0.4849
2024-01-10 22:03:53,472 - GAugM EPNet train, Epoch [ 41/230]: loss 0.7210, auc 0.5004, ap 0.5229
2024-01-10 22:03:53,557 - GAugM EPNet train, Epoch [ 42/230]: loss 0.7209, auc 0.4909, ap 0.5306
2024-01-10 22:03:53,637 - GAugM EPNet train, Epoch [ 43/230]: loss 0.7208, auc 0.3683, ap 0.4443
2024-01-10 22:03:53,723 - GAugM EPNet train, Epoch [ 44/230]: loss 0.7208, auc 0.3581, ap 0.4142
2024-01-10 22:03:53,803 - GAugM EPNet train, Epoch [ 45/230]: loss 0.7209, auc 0.4480, ap 0.5023
2024-01-10 22:03:53,888 - GAugM EPNet train, Epoch [ 46/230]: loss 0.7209, auc 0.4779, ap 0.4900
2024-01-10 22:03:53,970 - GAugM EPNet train, Epoch [ 47/230]: loss 0.7210, auc 0.4535, ap 0.4824
2024-01-10 22:03:54,052 - GAugM EPNet train, Epoch [ 48/230]: loss 0.7210, auc 0.5803, ap 0.5798
2024-01-10 22:03:54,142 - GAugM EPNet train, Epoch [ 49/230]: loss 0.7209, auc 0.4788, ap 0.4798
2024-01-10 22:03:54,226 - GAugM EPNet train, Epoch [ 50/230]: loss 0.7210, auc 0.5098, ap 0.5210
2024-01-10 22:03:54,309 - GAugM EPNet train, Epoch [ 51/230]: loss 0.7210, auc 0.4624, ap 0.4706
2024-01-10 22:03:54,388 - GAugM EPNet train, Epoch [ 52/230]: loss 0.7209, auc 0.4509, ap 0.4759
2024-01-10 22:03:54,469 - GAugM EPNet train, Epoch [ 53/230]: loss 0.7209, auc 0.5368, ap 0.5593
2024-01-10 22:03:54,555 - GAugM EPNet train, Epoch [ 54/230]: loss 0.7211, auc 0.5447, ap 0.5270
2024-01-10 22:03:54,640 - GAugM EPNet train, Epoch [ 55/230]: loss 0.7209, auc 0.5356, ap 0.5221
2024-01-10 22:03:54,722 - GAugM EPNet train, Epoch [ 56/230]: loss 0.7208, auc 0.4888, ap 0.4772
2024-01-10 22:03:54,807 - GAugM EPNet train, Epoch [ 57/230]: loss 0.7209, auc 0.5322, ap 0.5026
2024-01-10 22:03:54,886 - GAugM EPNet train, Epoch [ 58/230]: loss 0.7210, auc 0.4261, ap 0.4559
2024-01-10 22:03:54,962 - GAugM EPNet train, Epoch [ 59/230]: loss 0.7211, auc 0.4512, ap 0.4525
2024-01-10 22:03:55,050 - GAugM EPNet train, Epoch [ 60/230]: loss 0.7210, auc 0.5564, ap 0.5305
2024-01-10 22:03:55,132 - GAugM EPNet train, Epoch [ 61/230]: loss 0.7209, auc 0.5345, ap 0.5498
2024-01-10 22:03:55,217 - GAugM EPNet train, Epoch [ 62/230]: loss 0.7210, auc 0.5112, ap 0.5213
2024-01-10 22:03:55,308 - GAugM EPNet train, Epoch [ 63/230]: loss 0.7208, auc 0.4457, ap 0.4669
2024-01-10 22:03:55,389 - GAugM EPNet train, Epoch [ 64/230]: loss 0.7208, auc 0.5507, ap 0.5625
2024-01-10 22:03:55,471 - GAugM EPNet train, Epoch [ 65/230]: loss 0.7208, auc 0.6004, ap 0.5640
2024-01-10 22:03:55,553 - GAugM EPNet train, Epoch [ 66/230]: loss 0.7209, auc 0.4936, ap 0.5153
2024-01-10 22:03:55,646 - GAugM EPNet train, Epoch [ 67/230]: loss 0.7209, auc 0.6276, ap 0.6086
2024-01-10 22:03:55,727 - GAugM EPNet train, Epoch [ 68/230]: loss 0.7210, auc 0.5050, ap 0.5089
2024-01-10 22:03:55,813 - GAugM EPNet train, Epoch [ 69/230]: loss 0.7210, auc 0.4833, ap 0.4974
2024-01-10 22:03:55,895 - GAugM EPNet train, Epoch [ 70/230]: loss 0.7210, auc 0.4706, ap 0.4682
2024-01-10 22:03:55,976 - GAugM EPNet train, Epoch [ 71/230]: loss 0.7210, auc 0.5075, ap 0.5004
2024-01-10 22:03:56,060 - GAugM EPNet train, Epoch [ 72/230]: loss 0.7210, auc 0.4502, ap 0.4625
2024-01-10 22:03:56,149 - GAugM EPNet train, Epoch [ 73/230]: loss 0.7209, auc 0.5249, ap 0.5047
2024-01-10 22:03:56,234 - GAugM EPNet train, Epoch [ 74/230]: loss 0.7209, auc 0.5336, ap 0.5524
2024-01-10 22:03:56,316 - GAugM EPNet train, Epoch [ 75/230]: loss 0.7210, auc 0.5028, ap 0.5119
2024-01-10 22:03:56,407 - GAugM EPNet train, Epoch [ 76/230]: loss 0.7209, auc 0.5221, ap 0.5301
2024-01-10 22:03:56,489 - GAugM EPNet train, Epoch [ 77/230]: loss 0.7208, auc 0.5470, ap 0.5485
2024-01-10 22:03:56,569 - GAugM EPNet train, Epoch [ 78/230]: loss 0.7209, auc 0.4694, ap 0.4762
2024-01-10 22:03:56,656 - GAugM EPNet train, Epoch [ 79/230]: loss 0.7208, auc 0.5004, ap 0.5055
2024-01-10 22:03:56,737 - GAugM EPNet train, Epoch [ 80/230]: loss 0.7209, auc 0.5541, ap 0.5307
2024-01-10 22:03:56,818 - GAugM EPNet train, Epoch [ 81/230]: loss 0.7209, auc 0.5374, ap 0.5162
2024-01-10 22:03:56,903 - GAugM EPNet train, Epoch [ 82/230]: loss 0.7210, auc 0.5486, ap 0.5274
2024-01-10 22:03:56,984 - GAugM EPNet train, Epoch [ 83/230]: loss 0.7209, auc 0.4160, ap 0.4664
2024-01-10 22:03:57,068 - GAugM EPNet train, Epoch [ 84/230]: loss 0.7209, auc 0.4030, ap 0.4489
2024-01-10 22:03:57,157 - GAugM EPNet train, Epoch [ 85/230]: loss 0.7210, auc 0.4963, ap 0.5023
2024-01-10 22:03:57,242 - GAugM EPNet train, Epoch [ 86/230]: loss 0.7208, auc 0.5295, ap 0.5404
2024-01-10 22:03:57,329 - GAugM EPNet train, Epoch [ 87/230]: loss 0.7209, auc 0.5454, ap 0.5235
2024-01-10 22:03:57,408 - GAugM EPNet train, Epoch [ 88/230]: loss 0.7210, auc 0.4528, ap 0.4808
2024-01-10 22:03:57,490 - GAugM EPNet train, Epoch [ 89/230]: loss 0.7210, auc 0.4247, ap 0.4601
2024-01-10 22:03:57,570 - GAugM EPNet train, Epoch [ 90/230]: loss 0.7209, auc 0.4379, ap 0.4750
2024-01-10 22:03:57,647 - GAugM EPNet train, Epoch [ 91/230]: loss 0.7208, auc 0.5263, ap 0.5131
2024-01-10 22:03:57,729 - GAugM EPNet train, Epoch [ 92/230]: loss 0.7209, auc 0.5773, ap 0.5549
2024-01-10 22:03:57,824 - GAugM EPNet train, Epoch [ 93/230]: loss 0.7209, auc 0.3877, ap 0.4477
2024-01-10 22:03:57,907 - GAugM EPNet train, Epoch [ 94/230]: loss 0.7210, auc 0.4514, ap 0.4789
2024-01-10 22:03:57,988 - GAugM EPNet train, Epoch [ 95/230]: loss 0.7210, auc 0.4429, ap 0.4735
2024-01-10 22:03:58,068 - GAugM EPNet train, Epoch [ 96/230]: loss 0.7209, auc 0.5304, ap 0.5324
2024-01-10 22:03:58,146 - GAugM EPNet train, Epoch [ 97/230]: loss 0.7209, auc 0.4877, ap 0.5032
2024-01-10 22:03:58,233 - GAugM EPNet train, Epoch [ 98/230]: loss 0.7209, auc 0.5064, ap 0.4981
2024-01-10 22:03:58,315 - GAugM EPNet train, Epoch [ 99/230]: loss 0.7209, auc 0.4890, ap 0.5047
2024-01-10 22:03:58,396 - GAugM EPNet train, Epoch [100/230]: loss 0.7210, auc 0.4998, ap 0.4849
2024-01-10 22:03:58,481 - GAugM EPNet train, Epoch [101/230]: loss 0.7210, auc 0.5949, ap 0.6350
2024-01-10 22:03:58,564 - GAugM EPNet train, Epoch [102/230]: loss 0.7209, auc 0.4788, ap 0.4932
2024-01-10 22:03:58,644 - GAugM EPNet train, Epoch [103/230]: loss 0.7209, auc 0.4334, ap 0.4715
2024-01-10 22:03:58,726 - GAugM EPNet train, Epoch [104/230]: loss 0.7209, auc 0.4591, ap 0.4902
2024-01-10 22:03:58,809 - GAugM EPNet train, Epoch [105/230]: loss 0.7209, auc 0.5018, ap 0.4942
2024-01-10 22:03:58,891 - GAugM EPNet train, Epoch [106/230]: loss 0.7210, auc 0.4980, ap 0.5051
2024-01-10 22:03:58,969 - GAugM EPNet train, Epoch [107/230]: loss 0.7210, auc 0.5493, ap 0.5229
2024-01-10 22:03:59,057 - GAugM EPNet train, Epoch [108/230]: loss 0.7208, auc 0.5036, ap 0.4992
2024-01-10 22:03:59,139 - GAugM EPNet train, Epoch [109/230]: loss 0.7210, auc 0.4717, ap 0.4783
2024-01-10 22:03:59,221 - GAugM EPNet train, Epoch [110/230]: loss 0.7209, auc 0.4749, ap 0.4918
2024-01-10 22:03:59,300 - GAugM EPNet train, Epoch [111/230]: loss 0.7210, auc 0.4952, ap 0.5072
2024-01-10 22:03:59,381 - GAugM EPNet train, Epoch [112/230]: loss 0.7209, auc 0.5237, ap 0.5152
2024-01-10 22:03:59,458 - GAugM EPNet train, Epoch [113/230]: loss 0.7210, auc 0.4427, ap 0.4781
2024-01-10 22:03:59,552 - GAugM EPNet train, Epoch [114/230]: loss 0.7209, auc 0.4181, ap 0.4531
2024-01-10 22:03:59,635 - GAugM EPNet train, Epoch [115/230]: loss 0.7210, auc 0.4852, ap 0.4727
2024-01-10 22:03:59,718 - GAugM EPNet train, Epoch [116/230]: loss 0.7209, auc 0.4961, ap 0.4912
2024-01-10 22:03:59,809 - GAugM EPNet train, Epoch [117/230]: loss 0.7208, auc 0.5173, ap 0.5074
2024-01-10 22:03:59,890 - GAugM EPNet train, Epoch [118/230]: loss 0.7209, auc 0.4838, ap 0.5000
2024-01-10 22:03:59,968 - GAugM EPNet train, Epoch [119/230]: loss 0.7209, auc 0.5511, ap 0.5600
2024-01-10 22:04:00,052 - GAugM EPNet train, Epoch [120/230]: loss 0.7210, auc 0.4729, ap 0.4880
2024-01-10 22:04:00,132 - GAugM EPNet train, Epoch [121/230]: loss 0.7210, auc 0.4932, ap 0.4766
2024-01-10 22:04:00,210 - GAugM EPNet train, Epoch [122/230]: loss 0.7209, auc 0.5886, ap 0.5702
2024-01-10 22:04:00,297 - GAugM EPNet train, Epoch [123/230]: loss 0.7209, auc 0.4534, ap 0.4698
2024-01-10 22:04:00,379 - GAugM EPNet train, Epoch [124/230]: loss 0.7210, auc 0.4478, ap 0.4596
2024-01-10 22:04:00,470 - GAugM EPNet train, Epoch [125/230]: loss 0.7209, auc 0.4788, ap 0.4719
2024-01-10 22:04:00,556 - GAugM EPNet train, Epoch [126/230]: loss 0.7210, auc 0.4639, ap 0.4603
2024-01-10 22:04:00,642 - GAugM EPNet train, Epoch [127/230]: loss 0.7209, auc 0.4370, ap 0.4408
2024-01-10 22:04:00,724 - GAugM EPNet train, Epoch [128/230]: loss 0.7210, auc 0.4751, ap 0.4894
2024-01-10 22:04:00,810 - GAugM EPNet train, Epoch [129/230]: loss 0.7208, auc 0.4229, ap 0.4399
2024-01-10 22:04:00,893 - GAugM EPNet train, Epoch [130/230]: loss 0.7210, auc 0.4883, ap 0.4966
2024-01-10 22:04:00,974 - GAugM EPNet train, Epoch [131/230]: loss 0.7210, auc 0.5477, ap 0.5425
2024-01-10 22:04:01,058 - GAugM EPNet train, Epoch [132/230]: loss 0.7209, auc 0.5676, ap 0.5446
2024-01-10 22:04:01,143 - GAugM EPNet train, Epoch [133/230]: loss 0.7209, auc 0.4923, ap 0.5147
2024-01-10 22:04:01,227 - GAugM EPNet train, Epoch [134/230]: loss 0.7210, auc 0.5235, ap 0.5602
2024-01-10 22:04:01,311 - GAugM EPNet train, Epoch [135/230]: loss 0.7209, auc 0.4236, ap 0.4565
2024-01-10 22:04:01,387 - GAugM EPNet train, Epoch [136/230]: loss 0.7209, auc 0.5340, ap 0.5157
2024-01-10 22:04:01,474 - GAugM EPNet train, Epoch [137/230]: loss 0.7210, auc 0.4758, ap 0.4704
2024-01-10 22:04:01,557 - GAugM EPNet train, Epoch [138/230]: loss 0.7210, auc 0.5655, ap 0.5375
2024-01-10 22:04:01,639 - GAugM EPNet train, Epoch [139/230]: loss 0.7210, auc 0.4598, ap 0.4615
2024-01-10 22:04:01,720 - GAugM EPNet train, Epoch [140/230]: loss 0.7209, auc 0.4831, ap 0.5021
2024-01-10 22:04:01,806 - GAugM EPNet train, Epoch [141/230]: loss 0.7209, auc 0.5769, ap 0.5520
2024-01-10 22:04:01,892 - GAugM EPNet train, Epoch [142/230]: loss 0.7209, auc 0.4941, ap 0.4969
2024-01-10 22:04:01,975 - GAugM EPNet train, Epoch [143/230]: loss 0.7209, auc 0.4274, ap 0.4430
2024-01-10 22:04:02,055 - GAugM EPNet train, Epoch [144/230]: loss 0.7209, auc 0.4592, ap 0.4835
2024-01-10 22:04:02,138 - GAugM EPNet train, Epoch [145/230]: loss 0.7209, auc 0.4788, ap 0.4965
2024-01-10 22:04:02,216 - GAugM EPNet train, Epoch [146/230]: loss 0.7209, auc 0.4817, ap 0.4992
2024-01-10 22:04:02,302 - GAugM EPNet train, Epoch [147/230]: loss 0.7209, auc 0.6493, ap 0.6561
2024-01-10 22:04:02,390 - GAugM EPNet train, Epoch [148/230]: loss 0.7209, auc 0.5294, ap 0.5169
2024-01-10 22:04:02,469 - GAugM EPNet train, Epoch [149/230]: loss 0.7208, auc 0.5182, ap 0.5049
2024-01-10 22:04:02,550 - GAugM EPNet train, Epoch [150/230]: loss 0.7209, auc 0.4559, ap 0.4766
2024-01-10 22:04:02,631 - GAugM EPNet train, Epoch [151/230]: loss 0.7209, auc 0.5425, ap 0.5290
2024-01-10 22:04:02,714 - GAugM EPNet train, Epoch [152/230]: loss 0.7209, auc 0.5568, ap 0.5520
2024-01-10 22:04:02,802 - GAugM EPNet train, Epoch [153/230]: loss 0.7209, auc 0.3985, ap 0.4419
2024-01-10 22:04:02,884 - GAugM EPNet train, Epoch [154/230]: loss 0.7209, auc 0.5595, ap 0.5780
2024-01-10 22:04:02,965 - GAugM EPNet train, Epoch [155/230]: loss 0.7209, auc 0.5667, ap 0.5604
2024-01-10 22:04:03,048 - GAugM EPNet train, Epoch [156/230]: loss 0.7209, auc 0.4381, ap 0.4663
2024-01-10 22:04:03,127 - GAugM EPNet train, Epoch [157/230]: loss 0.7209, auc 0.4690, ap 0.4752
2024-01-10 22:04:03,215 - GAugM EPNet train, Epoch [158/230]: loss 0.7208, auc 0.4783, ap 0.4779
2024-01-10 22:04:03,291 - GAugM EPNet train, Epoch [159/230]: loss 0.7208, auc 0.5032, ap 0.4867
2024-01-10 22:04:03,375 - GAugM EPNet train, Epoch [160/230]: loss 0.7209, auc 0.5085, ap 0.5085
2024-01-10 22:04:03,456 - GAugM EPNet train, Epoch [161/230]: loss 0.7209, auc 0.5730, ap 0.5582
2024-01-10 22:04:03,544 - GAugM EPNet train, Epoch [162/230]: loss 0.7209, auc 0.4039, ap 0.4333
2024-01-10 22:04:03,625 - GAugM EPNet train, Epoch [163/230]: loss 0.7209, auc 0.5285, ap 0.5211
2024-01-10 22:04:03,705 - GAugM EPNet train, Epoch [164/230]: loss 0.7211, auc 0.5150, ap 0.4962
2024-01-10 22:04:03,785 - GAugM EPNet train, Epoch [165/230]: loss 0.7210, auc 0.4284, ap 0.4706
2024-01-10 22:04:03,875 - GAugM EPNet train, Epoch [166/230]: loss 0.7208, auc 0.5749, ap 0.5568
2024-01-10 22:04:03,955 - GAugM EPNet train, Epoch [167/230]: loss 0.7209, auc 0.5306, ap 0.5123
2024-01-10 22:04:04,033 - GAugM EPNet train, Epoch [168/230]: loss 0.7209, auc 0.4975, ap 0.5598
2024-01-10 22:04:04,117 - GAugM EPNet train, Epoch [169/230]: loss 0.7209, auc 0.6006, ap 0.6378
2024-01-10 22:04:04,201 - GAugM EPNet train, Epoch [170/230]: loss 0.7210, auc 0.4518, ap 0.4633
2024-01-10 22:04:04,283 - GAugM EPNet train, Epoch [171/230]: loss 0.7209, auc 0.4464, ap 0.4606
2024-01-10 22:04:04,364 - GAugM EPNet train, Epoch [172/230]: loss 0.7208, auc 0.4300, ap 0.4603
2024-01-10 22:04:04,447 - GAugM EPNet train, Epoch [173/230]: loss 0.7209, auc 0.4699, ap 0.4901
2024-01-10 22:04:04,527 - GAugM EPNet train, Epoch [174/230]: loss 0.7209, auc 0.5587, ap 0.5164
2024-01-10 22:04:04,610 - GAugM EPNet train, Epoch [175/230]: loss 0.7209, auc 0.6009, ap 0.5583
2024-01-10 22:04:04,688 - GAugM EPNet train, Epoch [176/230]: loss 0.7209, auc 0.4333, ap 0.4435
2024-01-10 22:04:04,775 - GAugM EPNet train, Epoch [177/230]: loss 0.7210, auc 0.4883, ap 0.4891
2024-01-10 22:04:04,863 - GAugM EPNet train, Epoch [178/230]: loss 0.7210, auc 0.5618, ap 0.5643
2024-01-10 22:04:04,941 - GAugM EPNet train, Epoch [179/230]: loss 0.7210, auc 0.4044, ap 0.4702
2024-01-10 22:04:05,024 - GAugM EPNet train, Epoch [180/230]: loss 0.7210, auc 0.4936, ap 0.5172
2024-01-10 22:04:05,109 - GAugM EPNet train, Epoch [181/230]: loss 0.7209, auc 0.4616, ap 0.4776
2024-01-10 22:04:05,192 - GAugM EPNet train, Epoch [182/230]: loss 0.7209, auc 0.5117, ap 0.5022
2024-01-10 22:04:05,276 - GAugM EPNet train, Epoch [183/230]: loss 0.7210, auc 0.4989, ap 0.5019
2024-01-10 22:04:05,358 - GAugM EPNet train, Epoch [184/230]: loss 0.7209, auc 0.4813, ap 0.5043
2024-01-10 22:04:05,438 - GAugM EPNet train, Epoch [185/230]: loss 0.7209, auc 0.4740, ap 0.5011
2024-01-10 22:04:05,520 - GAugM EPNet train, Epoch [186/230]: loss 0.7208, auc 0.4155, ap 0.4564
2024-01-10 22:04:05,604 - GAugM EPNet train, Epoch [187/230]: loss 0.7209, auc 0.4932, ap 0.4793
2024-01-10 22:04:05,688 - GAugM EPNet train, Epoch [188/230]: loss 0.7209, auc 0.4455, ap 0.4610
2024-01-10 22:04:05,775 - GAugM EPNet train, Epoch [189/230]: loss 0.7209, auc 0.6018, ap 0.5946
2024-01-10 22:04:05,862 - GAugM EPNet train, Epoch [190/230]: loss 0.7209, auc 0.4021, ap 0.4281
2024-01-10 22:04:05,944 - GAugM EPNet train, Epoch [191/230]: loss 0.7209, auc 0.4651, ap 0.5170
2024-01-10 22:04:06,023 - GAugM EPNet train, Epoch [192/230]: loss 0.7209, auc 0.4964, ap 0.5084
2024-01-10 22:04:06,109 - GAugM EPNet train, Epoch [193/230]: loss 0.7209, auc 0.5057, ap 0.4881
2024-01-10 22:04:06,193 - GAugM EPNet train, Epoch [194/230]: loss 0.7209, auc 0.5427, ap 0.5169
2024-01-10 22:04:06,274 - GAugM EPNet train, Epoch [195/230]: loss 0.7209, auc 0.4726, ap 0.4944
2024-01-10 22:04:06,363 - GAugM EPNet train, Epoch [196/230]: loss 0.7208, auc 0.5696, ap 0.5339
2024-01-10 22:04:06,446 - GAugM EPNet train, Epoch [197/230]: loss 0.7210, auc 0.4701, ap 0.4698
2024-01-10 22:04:06,532 - GAugM EPNet train, Epoch [198/230]: loss 0.7210, auc 0.4461, ap 0.4547
2024-01-10 22:04:06,615 - GAugM EPNet train, Epoch [199/230]: loss 0.7209, auc 0.4779, ap 0.4910
2024-01-10 22:04:06,697 - GAugM EPNet train, Epoch [200/230]: loss 0.7210, auc 0.5091, ap 0.5097
2024-01-10 22:04:06,785 - GAugM EPNet train, Epoch [201/230]: loss 0.7209, auc 0.4849, ap 0.5077
2024-01-10 22:04:06,863 - GAugM EPNet train, Epoch [202/230]: loss 0.7210, auc 0.5415, ap 0.5452
2024-01-10 22:04:06,943 - GAugM EPNet train, Epoch [203/230]: loss 0.7210, auc 0.5144, ap 0.5450
2024-01-10 22:04:07,031 - GAugM EPNet train, Epoch [204/230]: loss 0.7209, auc 0.4612, ap 0.4818
2024-01-10 22:04:07,119 - GAugM EPNet train, Epoch [205/230]: loss 0.7209, auc 0.5125, ap 0.5452
2024-01-10 22:04:07,201 - GAugM EPNet train, Epoch [206/230]: loss 0.7209, auc 0.4810, ap 0.4794
2024-01-10 22:04:07,294 - GAugM EPNet train, Epoch [207/230]: loss 0.7210, auc 0.5228, ap 0.5250
2024-01-10 22:04:07,374 - GAugM EPNet train, Epoch [208/230]: loss 0.7209, auc 0.4347, ap 0.4517
2024-01-10 22:04:07,457 - GAugM EPNet train, Epoch [209/230]: loss 0.7210, auc 0.5530, ap 0.5425
2024-01-10 22:04:07,536 - GAugM EPNet train, Epoch [210/230]: loss 0.7209, auc 0.4286, ap 0.4521
2024-01-10 22:04:07,618 - GAugM EPNet train, Epoch [211/230]: loss 0.7210, auc 0.4854, ap 0.5082
2024-01-10 22:04:07,702 - GAugM EPNet train, Epoch [212/230]: loss 0.7210, auc 0.4648, ap 0.4793
2024-01-10 22:04:07,782 - GAugM EPNet train, Epoch [213/230]: loss 0.7208, auc 0.6597, ap 0.6787
2024-01-10 22:04:07,868 - GAugM EPNet train, Epoch [214/230]: loss 0.7210, auc 0.5545, ap 0.5598
2024-01-10 22:04:07,952 - GAugM EPNet train, Epoch [215/230]: loss 0.7210, auc 0.5427, ap 0.5191
2024-01-10 22:04:08,035 - GAugM EPNet train, Epoch [216/230]: loss 0.7209, auc 0.5637, ap 0.5365
2024-01-10 22:04:08,117 - GAugM EPNet train, Epoch [217/230]: loss 0.7209, auc 0.6152, ap 0.6045
2024-01-10 22:04:08,207 - GAugM EPNet train, Epoch [218/230]: loss 0.7209, auc 0.4915, ap 0.5116
2024-01-10 22:04:08,291 - GAugM EPNet train, Epoch [219/230]: loss 0.7208, auc 0.4569, ap 0.4699
2024-01-10 22:04:08,372 - GAugM EPNet train, Epoch [220/230]: loss 0.7210, auc 0.4909, ap 0.5168
2024-01-10 22:04:08,451 - GAugM EPNet train, Epoch [221/230]: loss 0.7209, auc 0.5454, ap 0.5313
2024-01-10 22:04:08,532 - GAugM EPNet train, Epoch [222/230]: loss 0.7209, auc 0.4950, ap 0.4800
2024-01-10 22:04:08,615 - GAugM EPNet train, Epoch [223/230]: loss 0.7209, auc 0.6079, ap 0.5857
2024-01-10 22:04:08,695 - GAugM EPNet train, Epoch [224/230]: loss 0.7210, auc 0.5477, ap 0.5346
2024-01-10 22:04:08,774 - GAugM EPNet train, Epoch [225/230]: loss 0.7209, auc 0.4211, ap 0.4672
2024-01-10 22:04:08,860 - GAugM EPNet train, Epoch [226/230]: loss 0.7210, auc 0.4941, ap 0.5247
2024-01-10 22:04:08,946 - GAugM EPNet train, Epoch [227/230]: loss 0.7210, auc 0.5573, ap 0.5731
2024-01-10 22:04:09,025 - GAugM EPNet train, Epoch [228/230]: loss 0.7209, auc 0.4660, ap 0.4831
2024-01-10 22:04:09,107 - GAugM EPNet train, Epoch [229/230]: loss 0.7209, auc 0.4980, ap 0.5076
2024-01-10 22:04:09,189 - GAugM EPNet train, Epoch [230/230]: loss 0.7209, auc 0.4977, ap 0.5404
2024-01-10 22:04:09,195 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d0386cb90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:04:09,898 - GAugM EPNet train, Epoch [  1/230]: loss 0.7210, auc 0.4952, ap 0.4946
2024-01-10 22:04:09,990 - GAugM EPNet train, Epoch [  2/230]: loss 0.7210, auc 0.4922, ap 0.4868
2024-01-10 22:04:10,083 - GAugM EPNet train, Epoch [  3/230]: loss 0.7209, auc 0.5450, ap 0.5609
2024-01-10 22:04:10,175 - GAugM EPNet train, Epoch [  4/230]: loss 0.7209, auc 0.5182, ap 0.5632
2024-01-10 22:04:10,261 - GAugM EPNet train, Epoch [  5/230]: loss 0.7209, auc 0.5902, ap 0.5684
2024-01-10 22:04:10,350 - GAugM EPNet train, Epoch [  6/230]: loss 0.7209, auc 0.5155, ap 0.5103
2024-01-10 22:04:10,435 - GAugM EPNet train, Epoch [  7/230]: loss 0.7209, auc 0.4398, ap 0.4440
2024-01-10 22:04:10,521 - GAugM EPNet train, Epoch [  8/230]: loss 0.7210, auc 0.4948, ap 0.4942
2024-01-10 22:04:10,606 - GAugM EPNet train, Epoch [  9/230]: loss 0.7209, auc 0.4138, ap 0.4745
2024-01-10 22:04:10,692 - GAugM EPNet train, Epoch [ 10/230]: loss 0.7208, auc 0.5263, ap 0.5264
2024-01-10 22:04:10,777 - GAugM EPNet train, Epoch [ 11/230]: loss 0.7209, auc 0.4672, ap 0.4878
2024-01-10 22:04:10,865 - GAugM EPNet train, Epoch [ 12/230]: loss 0.7210, auc 0.4856, ap 0.4847
2024-01-10 22:04:10,950 - GAugM EPNet train, Epoch [ 13/230]: loss 0.7209, auc 0.5968, ap 0.5722
2024-01-10 22:04:11,042 - GAugM EPNet train, Epoch [ 14/230]: loss 0.7209, auc 0.5692, ap 0.5439
2024-01-10 22:04:11,130 - GAugM EPNet train, Epoch [ 15/230]: loss 0.7210, auc 0.3918, ap 0.4518
2024-01-10 22:04:11,217 - GAugM EPNet train, Epoch [ 16/230]: loss 0.7209, auc 0.4811, ap 0.4902
2024-01-10 22:04:11,303 - GAugM EPNet train, Epoch [ 17/230]: loss 0.7210, auc 0.5239, ap 0.5227
2024-01-10 22:04:11,387 - GAugM EPNet train, Epoch [ 18/230]: loss 0.7210, auc 0.5860, ap 0.5834
2024-01-10 22:04:11,478 - GAugM EPNet train, Epoch [ 19/230]: loss 0.7209, auc 0.5532, ap 0.5361
2024-01-10 22:04:11,565 - GAugM EPNet train, Epoch [ 20/230]: loss 0.7210, auc 0.4806, ap 0.5293
2024-01-10 22:04:11,650 - GAugM EPNet train, Epoch [ 21/230]: loss 0.7209, auc 0.4589, ap 0.4926
2024-01-10 22:04:11,736 - GAugM EPNet train, Epoch [ 22/230]: loss 0.7210, auc 0.4195, ap 0.4637
2024-01-10 22:04:11,817 - GAugM EPNet train, Epoch [ 23/230]: loss 0.7208, auc 0.5016, ap 0.5093
2024-01-10 22:04:11,899 - GAugM EPNet train, Epoch [ 24/230]: loss 0.7209, auc 0.5488, ap 0.5527
2024-01-10 22:04:11,990 - GAugM EPNet train, Epoch [ 25/230]: loss 0.7209, auc 0.4708, ap 0.4894
2024-01-10 22:04:12,071 - GAugM EPNet train, Epoch [ 26/230]: loss 0.7210, auc 0.4936, ap 0.5374
2024-01-10 22:04:12,164 - GAugM EPNet train, Epoch [ 27/230]: loss 0.7209, auc 0.4726, ap 0.5302
2024-01-10 22:04:12,246 - GAugM EPNet train, Epoch [ 28/230]: loss 0.7209, auc 0.6218, ap 0.6417
2024-01-10 22:04:12,331 - GAugM EPNet train, Epoch [ 29/230]: loss 0.7210, auc 0.5253, ap 0.5257
2024-01-10 22:04:12,417 - GAugM EPNet train, Epoch [ 30/230]: loss 0.7209, auc 0.5039, ap 0.5002
2024-01-10 22:04:12,502 - GAugM EPNet train, Epoch [ 31/230]: loss 0.7208, auc 0.5235, ap 0.5360
2024-01-10 22:04:12,590 - GAugM EPNet train, Epoch [ 32/230]: loss 0.7210, auc 0.5580, ap 0.5436
2024-01-10 22:04:12,677 - GAugM EPNet train, Epoch [ 33/230]: loss 0.7209, auc 0.5598, ap 0.5778
2024-01-10 22:04:12,761 - GAugM EPNet train, Epoch [ 34/230]: loss 0.7209, auc 0.3555, ap 0.4088
2024-01-10 22:04:12,842 - GAugM EPNet train, Epoch [ 35/230]: loss 0.7209, auc 0.5621, ap 0.5565
2024-01-10 22:04:12,929 - GAugM EPNet train, Epoch [ 36/230]: loss 0.7209, auc 0.6114, ap 0.6196
2024-01-10 22:04:13,018 - GAugM EPNet train, Epoch [ 37/230]: loss 0.7209, auc 0.5392, ap 0.5591
2024-01-10 22:04:13,102 - GAugM EPNet train, Epoch [ 38/230]: loss 0.7209, auc 0.4594, ap 0.4651
2024-01-10 22:04:13,186 - GAugM EPNet train, Epoch [ 39/230]: loss 0.7208, auc 0.4875, ap 0.5044
2024-01-10 22:04:13,277 - GAugM EPNet train, Epoch [ 40/230]: loss 0.7210, auc 0.5735, ap 0.5439
2024-01-10 22:04:13,365 - GAugM EPNet train, Epoch [ 41/230]: loss 0.7210, auc 0.4813, ap 0.5381
2024-01-10 22:04:13,444 - GAugM EPNet train, Epoch [ 42/230]: loss 0.7209, auc 0.5815, ap 0.5950
2024-01-10 22:04:13,536 - GAugM EPNet train, Epoch [ 43/230]: loss 0.7208, auc 0.4197, ap 0.4555
2024-01-10 22:04:13,621 - GAugM EPNet train, Epoch [ 44/230]: loss 0.7208, auc 0.4251, ap 0.4658
2024-01-10 22:04:13,701 - GAugM EPNet train, Epoch [ 45/230]: loss 0.7209, auc 0.5959, ap 0.6230
2024-01-10 22:04:13,792 - GAugM EPNet train, Epoch [ 46/230]: loss 0.7209, auc 0.4457, ap 0.4829
2024-01-10 22:04:13,879 - GAugM EPNet train, Epoch [ 47/230]: loss 0.7210, auc 0.4430, ap 0.4816
2024-01-10 22:04:13,963 - GAugM EPNet train, Epoch [ 48/230]: loss 0.7210, auc 0.5666, ap 0.5868
2024-01-10 22:04:14,053 - GAugM EPNet train, Epoch [ 49/230]: loss 0.7209, auc 0.5433, ap 0.5673
2024-01-10 22:04:14,140 - GAugM EPNet train, Epoch [ 50/230]: loss 0.7210, auc 0.4448, ap 0.4682
2024-01-10 22:04:14,226 - GAugM EPNet train, Epoch [ 51/230]: loss 0.7210, auc 0.5445, ap 0.5674
2024-01-10 22:04:14,318 - GAugM EPNet train, Epoch [ 52/230]: loss 0.7209, auc 0.4915, ap 0.5199
2024-01-10 22:04:14,407 - GAugM EPNet train, Epoch [ 53/230]: loss 0.7209, auc 0.6059, ap 0.5852
2024-01-10 22:04:14,493 - GAugM EPNet train, Epoch [ 54/230]: loss 0.7211, auc 0.6333, ap 0.6228
2024-01-10 22:04:14,576 - GAugM EPNet train, Epoch [ 55/230]: loss 0.7209, auc 0.5349, ap 0.5607
2024-01-10 22:04:14,654 - GAugM EPNet train, Epoch [ 56/230]: loss 0.7208, auc 0.5411, ap 0.5585
2024-01-10 22:04:14,736 - GAugM EPNet train, Epoch [ 57/230]: loss 0.7209, auc 0.4662, ap 0.4672
2024-01-10 22:04:14,821 - GAugM EPNet train, Epoch [ 58/230]: loss 0.7210, auc 0.4742, ap 0.5263
2024-01-10 22:04:14,902 - GAugM EPNet train, Epoch [ 59/230]: loss 0.7211, auc 0.5128, ap 0.5027
2024-01-10 22:04:14,995 - GAugM EPNet train, Epoch [ 60/230]: loss 0.7210, auc 0.5555, ap 0.5767
2024-01-10 22:04:15,080 - GAugM EPNet train, Epoch [ 61/230]: loss 0.7209, auc 0.5634, ap 0.5615
2024-01-10 22:04:15,168 - GAugM EPNet train, Epoch [ 62/230]: loss 0.7210, auc 0.4594, ap 0.4586
2024-01-10 22:04:15,254 - GAugM EPNet train, Epoch [ 63/230]: loss 0.7208, auc 0.4900, ap 0.4880
2024-01-10 22:04:15,340 - GAugM EPNet train, Epoch [ 64/230]: loss 0.7208, auc 0.4822, ap 0.5148
2024-01-10 22:04:15,423 - GAugM EPNet train, Epoch [ 65/230]: loss 0.7208, auc 0.4665, ap 0.4897
2024-01-10 22:04:15,509 - GAugM EPNet train, Epoch [ 66/230]: loss 0.7209, auc 0.4587, ap 0.5117
2024-01-10 22:04:15,595 - GAugM EPNet train, Epoch [ 67/230]: loss 0.7209, auc 0.5450, ap 0.5299
2024-01-10 22:04:15,682 - GAugM EPNet train, Epoch [ 68/230]: loss 0.7210, auc 0.5265, ap 0.5602
2024-01-10 22:04:15,766 - GAugM EPNet train, Epoch [ 69/230]: loss 0.7210, auc 0.4402, ap 0.4932
2024-01-10 22:04:15,850 - GAugM EPNet train, Epoch [ 70/230]: loss 0.7210, auc 0.4703, ap 0.4877
2024-01-10 22:04:15,933 - GAugM EPNet train, Epoch [ 71/230]: loss 0.7210, auc 0.5997, ap 0.5523
2024-01-10 22:04:16,021 - GAugM EPNet train, Epoch [ 72/230]: loss 0.7210, auc 0.5048, ap 0.5307
2024-01-10 22:04:16,109 - GAugM EPNet train, Epoch [ 73/230]: loss 0.7209, auc 0.5376, ap 0.5125
2024-01-10 22:04:16,193 - GAugM EPNet train, Epoch [ 74/230]: loss 0.7209, auc 0.5116, ap 0.5079
2024-01-10 22:04:16,275 - GAugM EPNet train, Epoch [ 75/230]: loss 0.7210, auc 0.5077, ap 0.5208
2024-01-10 22:04:16,361 - GAugM EPNet train, Epoch [ 76/230]: loss 0.7209, auc 0.5100, ap 0.5153
2024-01-10 22:04:16,449 - GAugM EPNet train, Epoch [ 77/230]: loss 0.7208, auc 0.5634, ap 0.5951
2024-01-10 22:04:16,533 - GAugM EPNet train, Epoch [ 78/230]: loss 0.7209, auc 0.5253, ap 0.5191
2024-01-10 22:04:16,619 - GAugM EPNet train, Epoch [ 79/230]: loss 0.7208, auc 0.4733, ap 0.5097
2024-01-10 22:04:16,702 - GAugM EPNet train, Epoch [ 80/230]: loss 0.7209, auc 0.5011, ap 0.5031
2024-01-10 22:04:16,785 - GAugM EPNet train, Epoch [ 81/230]: loss 0.7209, auc 0.4931, ap 0.4871
2024-01-10 22:04:16,869 - GAugM EPNet train, Epoch [ 82/230]: loss 0.7210, auc 0.5449, ap 0.5342
2024-01-10 22:04:16,959 - GAugM EPNet train, Epoch [ 83/230]: loss 0.7209, auc 0.5064, ap 0.5340
2024-01-10 22:04:17,047 - GAugM EPNet train, Epoch [ 84/230]: loss 0.7209, auc 0.3807, ap 0.4237
2024-01-10 22:04:17,131 - GAugM EPNet train, Epoch [ 85/230]: loss 0.7210, auc 0.4142, ap 0.4546
2024-01-10 22:04:17,217 - GAugM EPNet train, Epoch [ 86/230]: loss 0.7208, auc 0.5105, ap 0.5098
2024-01-10 22:04:17,299 - GAugM EPNet train, Epoch [ 87/230]: loss 0.7209, auc 0.6048, ap 0.5919
2024-01-10 22:04:17,383 - GAugM EPNet train, Epoch [ 88/230]: loss 0.7210, auc 0.4571, ap 0.4921
2024-01-10 22:04:17,468 - GAugM EPNet train, Epoch [ 89/230]: loss 0.7210, auc 0.4993, ap 0.5328
2024-01-10 22:04:17,559 - GAugM EPNet train, Epoch [ 90/230]: loss 0.7209, auc 0.3782, ap 0.4598
2024-01-10 22:04:17,647 - GAugM EPNet train, Epoch [ 91/230]: loss 0.7208, auc 0.5940, ap 0.5451
2024-01-10 22:04:17,728 - GAugM EPNet train, Epoch [ 92/230]: loss 0.7209, auc 0.5789, ap 0.5992
2024-01-10 22:04:17,816 - GAugM EPNet train, Epoch [ 93/230]: loss 0.7209, auc 0.3685, ap 0.4280
2024-01-10 22:04:17,898 - GAugM EPNet train, Epoch [ 94/230]: loss 0.7210, auc 0.4765, ap 0.5065
2024-01-10 22:04:17,985 - GAugM EPNet train, Epoch [ 95/230]: loss 0.7210, auc 0.5651, ap 0.5699
2024-01-10 22:04:18,068 - GAugM EPNet train, Epoch [ 96/230]: loss 0.7209, auc 0.4893, ap 0.5167
2024-01-10 22:04:18,152 - GAugM EPNet train, Epoch [ 97/230]: loss 0.7209, auc 0.5520, ap 0.5737
2024-01-10 22:04:18,240 - GAugM EPNet train, Epoch [ 98/230]: loss 0.7209, auc 0.4722, ap 0.4879
2024-01-10 22:04:18,326 - GAugM EPNet train, Epoch [ 99/230]: loss 0.7209, auc 0.4674, ap 0.4868
2024-01-10 22:04:18,412 - GAugM EPNet train, Epoch [100/230]: loss 0.7210, auc 0.5450, ap 0.5712
2024-01-10 22:04:18,502 - GAugM EPNet train, Epoch [101/230]: loss 0.7210, auc 0.4681, ap 0.5451
2024-01-10 22:04:18,584 - GAugM EPNet train, Epoch [102/230]: loss 0.7209, auc 0.4705, ap 0.5104
2024-01-10 22:04:18,673 - GAugM EPNet train, Epoch [103/230]: loss 0.7209, auc 0.4868, ap 0.5388
2024-01-10 22:04:18,758 - GAugM EPNet train, Epoch [104/230]: loss 0.7209, auc 0.4776, ap 0.4943
2024-01-10 22:04:18,843 - GAugM EPNet train, Epoch [105/230]: loss 0.7209, auc 0.5201, ap 0.5235
2024-01-10 22:04:18,925 - GAugM EPNet train, Epoch [106/230]: loss 0.7210, auc 0.5021, ap 0.5129
2024-01-10 22:04:19,017 - GAugM EPNet train, Epoch [107/230]: loss 0.7210, auc 0.4509, ap 0.4667
2024-01-10 22:04:19,103 - GAugM EPNet train, Epoch [108/230]: loss 0.7208, auc 0.5457, ap 0.5555
2024-01-10 22:04:19,190 - GAugM EPNet train, Epoch [109/230]: loss 0.7210, auc 0.4487, ap 0.4772
2024-01-10 22:04:19,276 - GAugM EPNet train, Epoch [110/230]: loss 0.7209, auc 0.4973, ap 0.4875
2024-01-10 22:04:19,361 - GAugM EPNet train, Epoch [111/230]: loss 0.7210, auc 0.4612, ap 0.4757
2024-01-10 22:04:19,444 - GAugM EPNet train, Epoch [112/230]: loss 0.7209, auc 0.4847, ap 0.4986
2024-01-10 22:04:19,523 - GAugM EPNet train, Epoch [113/230]: loss 0.7210, auc 0.4580, ap 0.4827
2024-01-10 22:04:19,607 - GAugM EPNet train, Epoch [114/230]: loss 0.7209, auc 0.4523, ap 0.4769
2024-01-10 22:04:19,693 - GAugM EPNet train, Epoch [115/230]: loss 0.7210, auc 0.4884, ap 0.5060
2024-01-10 22:04:19,776 - GAugM EPNet train, Epoch [116/230]: loss 0.7209, auc 0.5651, ap 0.6027
2024-01-10 22:04:19,859 - GAugM EPNet train, Epoch [117/230]: loss 0.7208, auc 0.4719, ap 0.4795
2024-01-10 22:04:19,941 - GAugM EPNet train, Epoch [118/230]: loss 0.7209, auc 0.4767, ap 0.4820
2024-01-10 22:04:20,025 - GAugM EPNet train, Epoch [119/230]: loss 0.7209, auc 0.5379, ap 0.5637
2024-01-10 22:04:20,110 - GAugM EPNet train, Epoch [120/230]: loss 0.7210, auc 0.5278, ap 0.5298
2024-01-10 22:04:20,199 - GAugM EPNet train, Epoch [121/230]: loss 0.7210, auc 0.4868, ap 0.5109
2024-01-10 22:04:20,281 - GAugM EPNet train, Epoch [122/230]: loss 0.7209, auc 0.4124, ap 0.4868
2024-01-10 22:04:20,365 - GAugM EPNet train, Epoch [123/230]: loss 0.7209, auc 0.4884, ap 0.5049
2024-01-10 22:04:20,451 - GAugM EPNet train, Epoch [124/230]: loss 0.7210, auc 0.4162, ap 0.4644
2024-01-10 22:04:20,535 - GAugM EPNet train, Epoch [125/230]: loss 0.7209, auc 0.5413, ap 0.5436
2024-01-10 22:04:20,617 - GAugM EPNet train, Epoch [126/230]: loss 0.7210, auc 0.4982, ap 0.5148
2024-01-10 22:04:20,702 - GAugM EPNet train, Epoch [127/230]: loss 0.7209, auc 0.4575, ap 0.4682
2024-01-10 22:04:20,784 - GAugM EPNet train, Epoch [128/230]: loss 0.7210, auc 0.4341, ap 0.4576
2024-01-10 22:04:20,876 - GAugM EPNet train, Epoch [129/230]: loss 0.7208, auc 0.3364, ap 0.4085
2024-01-10 22:04:20,957 - GAugM EPNet train, Epoch [130/230]: loss 0.7210, auc 0.4418, ap 0.4813
2024-01-10 22:04:21,039 - GAugM EPNet train, Epoch [131/230]: loss 0.7210, auc 0.5142, ap 0.5440
2024-01-10 22:04:21,135 - GAugM EPNet train, Epoch [132/230]: loss 0.7209, auc 0.5128, ap 0.5254
2024-01-10 22:04:21,216 - GAugM EPNet train, Epoch [133/230]: loss 0.7209, auc 0.4708, ap 0.5040
2024-01-10 22:04:21,298 - GAugM EPNet train, Epoch [134/230]: loss 0.7210, auc 0.5126, ap 0.5576
2024-01-10 22:04:21,382 - GAugM EPNet train, Epoch [135/230]: loss 0.7209, auc 0.3879, ap 0.4385
2024-01-10 22:04:21,459 - GAugM EPNet train, Epoch [136/230]: loss 0.7209, auc 0.5301, ap 0.5515
2024-01-10 22:04:21,548 - GAugM EPNet train, Epoch [137/230]: loss 0.7210, auc 0.4637, ap 0.4865
2024-01-10 22:04:21,629 - GAugM EPNet train, Epoch [138/230]: loss 0.7210, auc 0.4867, ap 0.4756
2024-01-10 22:04:21,711 - GAugM EPNet train, Epoch [139/230]: loss 0.7210, auc 0.4888, ap 0.5175
2024-01-10 22:04:21,791 - GAugM EPNet train, Epoch [140/230]: loss 0.7209, auc 0.4398, ap 0.4788
2024-01-10 22:04:21,872 - GAugM EPNet train, Epoch [141/230]: loss 0.7209, auc 0.5748, ap 0.5559
2024-01-10 22:04:21,944 - GAugM EPNet train, Epoch [142/230]: loss 0.7209, auc 0.5732, ap 0.5685
2024-01-10 22:04:22,022 - GAugM EPNet train, Epoch [143/230]: loss 0.7209, auc 0.4617, ap 0.4981
2024-01-10 22:04:22,103 - GAugM EPNet train, Epoch [144/230]: loss 0.7209, auc 0.3957, ap 0.4454
2024-01-10 22:04:22,185 - GAugM EPNet train, Epoch [145/230]: loss 0.7209, auc 0.5342, ap 0.5644
2024-01-10 22:04:22,269 - GAugM EPNet train, Epoch [146/230]: loss 0.7209, auc 0.5678, ap 0.6021
2024-01-10 22:04:22,354 - GAugM EPNet train, Epoch [147/230]: loss 0.7209, auc 0.6150, ap 0.6422
2024-01-10 22:04:22,438 - GAugM EPNet train, Epoch [148/230]: loss 0.7209, auc 0.5226, ap 0.5129
2024-01-10 22:04:22,521 - GAugM EPNet train, Epoch [149/230]: loss 0.7208, auc 0.5192, ap 0.5190
2024-01-10 22:04:22,604 - GAugM EPNet train, Epoch [150/230]: loss 0.7209, auc 0.4783, ap 0.4902
2024-01-10 22:04:22,691 - GAugM EPNet train, Epoch [151/230]: loss 0.7209, auc 0.5160, ap 0.5204
2024-01-10 22:04:22,780 - GAugM EPNet train, Epoch [152/230]: loss 0.7209, auc 0.5117, ap 0.5223
2024-01-10 22:04:22,863 - GAugM EPNet train, Epoch [153/230]: loss 0.7209, auc 0.4454, ap 0.4839
2024-01-10 22:04:22,944 - GAugM EPNet train, Epoch [154/230]: loss 0.7209, auc 0.5669, ap 0.5895
2024-01-10 22:04:23,026 - GAugM EPNet train, Epoch [155/230]: loss 0.7209, auc 0.5322, ap 0.5777
2024-01-10 22:04:23,112 - GAugM EPNet train, Epoch [156/230]: loss 0.7209, auc 0.5091, ap 0.5349
2024-01-10 22:04:23,196 - GAugM EPNet train, Epoch [157/230]: loss 0.7209, auc 0.5075, ap 0.5283
2024-01-10 22:04:23,279 - GAugM EPNet train, Epoch [158/230]: loss 0.7208, auc 0.4655, ap 0.4840
2024-01-10 22:04:23,360 - GAugM EPNet train, Epoch [159/230]: loss 0.7208, auc 0.4897, ap 0.4968
2024-01-10 22:04:23,442 - GAugM EPNet train, Epoch [160/230]: loss 0.7209, auc 0.5301, ap 0.5633
2024-01-10 22:04:23,528 - GAugM EPNet train, Epoch [161/230]: loss 0.7209, auc 0.4915, ap 0.5107
2024-01-10 22:04:23,618 - GAugM EPNet train, Epoch [162/230]: loss 0.7209, auc 0.4397, ap 0.4635
2024-01-10 22:04:23,702 - GAugM EPNet train, Epoch [163/230]: loss 0.7209, auc 0.5345, ap 0.5064
2024-01-10 22:04:23,785 - GAugM EPNet train, Epoch [164/230]: loss 0.7211, auc 0.5632, ap 0.5348
2024-01-10 22:04:23,868 - GAugM EPNet train, Epoch [165/230]: loss 0.7210, auc 0.4505, ap 0.4560
2024-01-10 22:04:23,948 - GAugM EPNet train, Epoch [166/230]: loss 0.7208, auc 0.5790, ap 0.5500
2024-01-10 22:04:24,032 - GAugM EPNet train, Epoch [167/230]: loss 0.7209, auc 0.4749, ap 0.4956
2024-01-10 22:04:24,113 - GAugM EPNet train, Epoch [168/230]: loss 0.7209, auc 0.5315, ap 0.5642
2024-01-10 22:04:24,197 - GAugM EPNet train, Epoch [169/230]: loss 0.7209, auc 0.5751, ap 0.6109
2024-01-10 22:04:24,280 - GAugM EPNet train, Epoch [170/230]: loss 0.7210, auc 0.4281, ap 0.4428
2024-01-10 22:04:24,365 - GAugM EPNet train, Epoch [171/230]: loss 0.7209, auc 0.4624, ap 0.5072
2024-01-10 22:04:24,448 - GAugM EPNet train, Epoch [172/230]: loss 0.7208, auc 0.5062, ap 0.5105
2024-01-10 22:04:24,539 - GAugM EPNet train, Epoch [173/230]: loss 0.7209, auc 0.5007, ap 0.5507
2024-01-10 22:04:24,633 - GAugM EPNet train, Epoch [174/230]: loss 0.7209, auc 0.4461, ap 0.4562
2024-01-10 22:04:24,717 - GAugM EPNet train, Epoch [175/230]: loss 0.7209, auc 0.5295, ap 0.5071
2024-01-10 22:04:24,806 - GAugM EPNet train, Epoch [176/230]: loss 0.7209, auc 0.5167, ap 0.5018
2024-01-10 22:04:24,893 - GAugM EPNet train, Epoch [177/230]: loss 0.7210, auc 0.5719, ap 0.5267
2024-01-10 22:04:24,984 - GAugM EPNet train, Epoch [178/230]: loss 0.7210, auc 0.5420, ap 0.5930
2024-01-10 22:04:25,071 - GAugM EPNet train, Epoch [179/230]: loss 0.7210, auc 0.3539, ap 0.4427
2024-01-10 22:04:25,160 - GAugM EPNet train, Epoch [180/230]: loss 0.7210, auc 0.5272, ap 0.5576
2024-01-10 22:04:25,248 - GAugM EPNet train, Epoch [181/230]: loss 0.7209, auc 0.4551, ap 0.4899
2024-01-10 22:04:25,333 - GAugM EPNet train, Epoch [182/230]: loss 0.7209, auc 0.5053, ap 0.5464
2024-01-10 22:04:25,418 - GAugM EPNet train, Epoch [183/230]: loss 0.7210, auc 0.5374, ap 0.5109
2024-01-10 22:04:25,505 - GAugM EPNet train, Epoch [184/230]: loss 0.7209, auc 0.5856, ap 0.6126
2024-01-10 22:04:25,589 - GAugM EPNet train, Epoch [185/230]: loss 0.7209, auc 0.5182, ap 0.5181
2024-01-10 22:04:25,671 - GAugM EPNet train, Epoch [186/230]: loss 0.7208, auc 0.4811, ap 0.5365
2024-01-10 22:04:25,755 - GAugM EPNet train, Epoch [187/230]: loss 0.7209, auc 0.6152, ap 0.6114
2024-01-10 22:04:25,843 - GAugM EPNet train, Epoch [188/230]: loss 0.7209, auc 0.4475, ap 0.4607
2024-01-10 22:04:25,923 - GAugM EPNet train, Epoch [189/230]: loss 0.7209, auc 0.6326, ap 0.6145
2024-01-10 22:04:26,003 - GAugM EPNet train, Epoch [190/230]: loss 0.7209, auc 0.4112, ap 0.4517
2024-01-10 22:04:26,087 - GAugM EPNet train, Epoch [191/230]: loss 0.7209, auc 0.4562, ap 0.4968
2024-01-10 22:04:26,171 - GAugM EPNet train, Epoch [192/230]: loss 0.7209, auc 0.4724, ap 0.4677
2024-01-10 22:04:26,251 - GAugM EPNet train, Epoch [193/230]: loss 0.7209, auc 0.5376, ap 0.5386
2024-01-10 22:04:26,339 - GAugM EPNet train, Epoch [194/230]: loss 0.7209, auc 0.4610, ap 0.5046
2024-01-10 22:04:26,426 - GAugM EPNet train, Epoch [195/230]: loss 0.7209, auc 0.4311, ap 0.4853
2024-01-10 22:04:26,508 - GAugM EPNet train, Epoch [196/230]: loss 0.7208, auc 0.6150, ap 0.5571
2024-01-10 22:04:26,591 - GAugM EPNet train, Epoch [197/230]: loss 0.7210, auc 0.4861, ap 0.5012
2024-01-10 22:04:26,674 - GAugM EPNet train, Epoch [198/230]: loss 0.7210, auc 0.6143, ap 0.5663
2024-01-10 22:04:26,756 - GAugM EPNet train, Epoch [199/230]: loss 0.7209, auc 0.5062, ap 0.5248
2024-01-10 22:04:26,838 - GAugM EPNet train, Epoch [200/230]: loss 0.7210, auc 0.4877, ap 0.4964
2024-01-10 22:04:26,922 - GAugM EPNet train, Epoch [201/230]: loss 0.7209, auc 0.5441, ap 0.5336
2024-01-10 22:04:27,003 - GAugM EPNet train, Epoch [202/230]: loss 0.7210, auc 0.5351, ap 0.5911
2024-01-10 22:04:27,085 - GAugM EPNet train, Epoch [203/230]: loss 0.7210, auc 0.5383, ap 0.5753
2024-01-10 22:04:27,166 - GAugM EPNet train, Epoch [204/230]: loss 0.7209, auc 0.4703, ap 0.4763
2024-01-10 22:04:27,250 - GAugM EPNet train, Epoch [205/230]: loss 0.7209, auc 0.4662, ap 0.4885
2024-01-10 22:04:27,332 - GAugM EPNet train, Epoch [206/230]: loss 0.7209, auc 0.3950, ap 0.4315
2024-01-10 22:04:27,409 - GAugM EPNet train, Epoch [207/230]: loss 0.7210, auc 0.4715, ap 0.4904
2024-01-10 22:04:27,501 - GAugM EPNet train, Epoch [208/230]: loss 0.7209, auc 0.5431, ap 0.5793
2024-01-10 22:04:27,583 - GAugM EPNet train, Epoch [209/230]: loss 0.7210, auc 0.5548, ap 0.5766
2024-01-10 22:04:27,671 - GAugM EPNet train, Epoch [210/230]: loss 0.7209, auc 0.4852, ap 0.4823
2024-01-10 22:04:27,753 - GAugM EPNet train, Epoch [211/230]: loss 0.7210, auc 0.5030, ap 0.5495
2024-01-10 22:04:27,835 - GAugM EPNet train, Epoch [212/230]: loss 0.7210, auc 0.4660, ap 0.4764
2024-01-10 22:04:27,921 - GAugM EPNet train, Epoch [213/230]: loss 0.7208, auc 0.6061, ap 0.6166
2024-01-10 22:04:28,002 - GAugM EPNet train, Epoch [214/230]: loss 0.7210, auc 0.5117, ap 0.5289
2024-01-10 22:04:28,076 - GAugM EPNet train, Epoch [215/230]: loss 0.7210, auc 0.5160, ap 0.5265
2024-01-10 22:04:28,167 - GAugM EPNet train, Epoch [216/230]: loss 0.7209, auc 0.5351, ap 0.5286
2024-01-10 22:04:28,247 - GAugM EPNet train, Epoch [217/230]: loss 0.7209, auc 0.5475, ap 0.5648
2024-01-10 22:04:28,336 - GAugM EPNet train, Epoch [218/230]: loss 0.7209, auc 0.5178, ap 0.5669
2024-01-10 22:04:28,420 - GAugM EPNet train, Epoch [219/230]: loss 0.7208, auc 0.4909, ap 0.5147
2024-01-10 22:04:28,503 - GAugM EPNet train, Epoch [220/230]: loss 0.7210, auc 0.4381, ap 0.4934
2024-01-10 22:04:28,594 - GAugM EPNet train, Epoch [221/230]: loss 0.7209, auc 0.5959, ap 0.5622
2024-01-10 22:04:28,677 - GAugM EPNet train, Epoch [222/230]: loss 0.7209, auc 0.4413, ap 0.4661
2024-01-10 22:04:28,759 - GAugM EPNet train, Epoch [223/230]: loss 0.7209, auc 0.5098, ap 0.5431
2024-01-10 22:04:28,843 - GAugM EPNet train, Epoch [224/230]: loss 0.7210, auc 0.4151, ap 0.4506
2024-01-10 22:04:28,924 - GAugM EPNet train, Epoch [225/230]: loss 0.7209, auc 0.5249, ap 0.5539
2024-01-10 22:04:29,010 - GAugM EPNet train, Epoch [226/230]: loss 0.7210, auc 0.5196, ap 0.5276
2024-01-10 22:04:29,100 - GAugM EPNet train, Epoch [227/230]: loss 0.7210, auc 0.5705, ap 0.6070
2024-01-10 22:04:29,202 - GAugM EPNet train, Epoch [228/230]: loss 0.7209, auc 0.4979, ap 0.5083
2024-01-10 22:04:29,292 - GAugM EPNet train, Epoch [229/230]: loss 0.7209, auc 0.5320, ap 0.5479
2024-01-10 22:04:29,383 - GAugM EPNet train, Epoch [230/230]: loss 0.7209, auc 0.3811, ap 0.4450
2024-01-10 22:04:29,386 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa02e390>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:04:30,115 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4272, ap 0.4641
2024-01-10 22:04:30,207 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5235, ap 0.5278
2024-01-10 22:04:30,297 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5687, ap 0.5476
2024-01-10 22:04:30,386 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4867, ap 0.4842
2024-01-10 22:04:30,477 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5420, ap 0.5468
2024-01-10 22:04:30,570 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.5338, ap 0.5181
2024-01-10 22:04:30,660 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4333, ap 0.4522
2024-01-10 22:04:30,740 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5117, ap 0.4957
2024-01-10 22:04:30,816 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4114, ap 0.4349
2024-01-10 22:04:30,894 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4681, ap 0.4737
2024-01-10 22:04:30,972 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4648, ap 0.4638
2024-01-10 22:04:31,052 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4494, ap 0.4538
2024-01-10 22:04:31,133 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5785, ap 0.6012
2024-01-10 22:04:31,210 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5215, ap 0.5078
2024-01-10 22:04:31,284 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.3994, ap 0.4505
2024-01-10 22:04:31,364 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5130, ap 0.5091
2024-01-10 22:04:31,448 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5758, ap 0.5423
2024-01-10 22:04:31,551 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5876, ap 0.5705
2024-01-10 22:04:31,650 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5687, ap 0.5501
2024-01-10 22:04:31,742 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.4870, ap 0.5291
2024-01-10 22:04:31,834 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.5190, ap 0.5097
2024-01-10 22:04:31,921 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.3585, ap 0.4409
2024-01-10 22:04:32,023 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5260, ap 0.5282
2024-01-10 22:04:32,113 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5121, ap 0.4913
2024-01-10 22:04:32,212 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4721, ap 0.4886
2024-01-10 22:04:32,298 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5694, ap 0.5759
2024-01-10 22:04:32,388 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4523, ap 0.4755
2024-01-10 22:04:32,481 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5678, ap 0.5811
2024-01-10 22:04:32,568 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.4564, ap 0.4728
2024-01-10 22:04:32,662 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.4302, ap 0.4481
2024-01-10 22:04:32,750 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.4587, ap 0.5004
2024-01-10 22:04:32,840 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5828, ap 0.5553
2024-01-10 22:04:32,935 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.4877, ap 0.5420
2024-01-10 22:04:33,029 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.3770, ap 0.4123
2024-01-10 22:04:33,118 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5151, ap 0.5125
2024-01-10 22:04:33,209 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5997, ap 0.5672
2024-01-10 22:04:33,298 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.5046, ap 0.4977
2024-01-10 22:04:33,389 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.4669, ap 0.4754
2024-01-10 22:04:33,487 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4361, ap 0.4565
2024-01-10 22:04:33,574 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5776, ap 0.5465
2024-01-10 22:04:33,666 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.5438, ap 0.5541
2024-01-10 22:04:33,748 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5066, ap 0.5085
2024-01-10 22:04:33,829 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4281, ap 0.4562
2024-01-10 22:04:33,912 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4074, ap 0.4526
2024-01-10 22:04:34,007 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5586, ap 0.5589
2024-01-10 22:04:34,097 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4639, ap 0.4971
2024-01-10 22:04:34,187 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4656, ap 0.4874
2024-01-10 22:04:34,273 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5767, ap 0.5853
2024-01-10 22:04:34,370 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5500, ap 0.5485
2024-01-10 22:04:34,465 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5376, ap 0.5383
2024-01-10 22:04:34,559 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4680, ap 0.4920
2024-01-10 22:04:34,654 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4820, ap 0.5042
2024-01-10 22:04:34,743 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5698, ap 0.5681
2024-01-10 22:04:34,836 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.6027, ap 0.5990
2024-01-10 22:04:34,932 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5799, ap 0.5685
2024-01-10 22:04:35,019 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.5071, ap 0.5219
2024-01-10 22:04:35,110 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4245, ap 0.4382
2024-01-10 22:04:35,196 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4706, ap 0.5212
2024-01-10 22:04:35,288 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4576, ap 0.4623
2024-01-10 22:04:35,379 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5279, ap 0.5208
2024-01-10 22:04:35,473 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5514, ap 0.5726
2024-01-10 22:04:35,563 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.4738, ap 0.5074
2024-01-10 22:04:35,662 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4217, ap 0.4368
2024-01-10 22:04:35,751 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4706, ap 0.5242
2024-01-10 22:04:35,841 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5126, ap 0.5144
2024-01-10 22:04:35,932 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.3895, ap 0.4496
2024-01-10 22:04:36,019 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5441, ap 0.5170
2024-01-10 22:04:36,109 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5326, ap 0.5211
2024-01-10 22:04:36,197 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4637, ap 0.5227
2024-01-10 22:04:36,288 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.5335, ap 0.5057
2024-01-10 22:04:36,383 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5655, ap 0.5317
2024-01-10 22:04:36,471 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4292, ap 0.4803
2024-01-10 22:04:36,562 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.4778, ap 0.4830
2024-01-10 22:04:36,651 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5504, ap 0.5269
2024-01-10 22:04:36,741 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4705, ap 0.5162
2024-01-10 22:04:36,831 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4404, ap 0.4703
2024-01-10 22:04:36,918 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5144, ap 0.5272
2024-01-10 22:04:37,008 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5263, ap 0.5355
2024-01-10 22:04:37,105 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5392, ap 0.5349
2024-01-10 22:04:37,191 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5335, ap 0.5319
2024-01-10 22:04:37,277 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.4813, ap 0.4840
2024-01-10 22:04:37,365 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5004, ap 0.5207
2024-01-10 22:04:37,452 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4486, ap 0.5034
2024-01-10 22:04:37,542 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4343, ap 0.4396
2024-01-10 22:04:37,636 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.3991, ap 0.4412
2024-01-10 22:04:37,724 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4681, ap 0.4861
2024-01-10 22:04:37,813 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5443, ap 0.5367
2024-01-10 22:04:37,895 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.5142, ap 0.5521
2024-01-10 22:04:37,975 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4850, ap 0.5369
2024-01-10 22:04:38,049 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4231, ap 0.4728
2024-01-10 22:04:38,051 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9fdcfd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:04:38,771 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4395, ap 0.4512
2024-01-10 22:04:38,873 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.4544, ap 0.4745
2024-01-10 22:04:38,979 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5247, ap 0.5120
2024-01-10 22:04:39,081 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.5730, ap 0.5716
2024-01-10 22:04:39,172 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5586, ap 0.5498
2024-01-10 22:04:39,258 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.4473, ap 0.4614
2024-01-10 22:04:39,337 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4284, ap 0.4420
2024-01-10 22:04:39,414 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.4329, ap 0.4766
2024-01-10 22:04:39,490 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.5103, ap 0.4904
2024-01-10 22:04:39,585 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4995, ap 0.5045
2024-01-10 22:04:39,665 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4776, ap 0.4732
2024-01-10 22:04:39,758 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4525, ap 0.4857
2024-01-10 22:04:39,853 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.6043, ap 0.6004
2024-01-10 22:04:39,944 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.4656, ap 0.4595
2024-01-10 22:04:40,033 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.5046, ap 0.5115
2024-01-10 22:04:40,123 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5901, ap 0.5683
2024-01-10 22:04:40,215 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5431, ap 0.5365
2024-01-10 22:04:40,310 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5043, ap 0.5197
2024-01-10 22:04:40,408 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.4370, ap 0.4681
2024-01-10 22:04:40,495 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.6011, ap 0.6076
2024-01-10 22:04:40,583 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4731, ap 0.5115
2024-01-10 22:04:40,675 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.3740, ap 0.4291
2024-01-10 22:04:40,762 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5803, ap 0.5541
2024-01-10 22:04:40,855 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5516, ap 0.5269
2024-01-10 22:04:40,940 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4850, ap 0.4787
2024-01-10 22:04:41,029 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5990, ap 0.5708
2024-01-10 22:04:41,114 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4537, ap 0.4737
2024-01-10 22:04:41,204 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5840, ap 0.6030
2024-01-10 22:04:41,293 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.4939, ap 0.4926
2024-01-10 22:04:41,389 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5356, ap 0.5499
2024-01-10 22:04:41,476 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.4452, ap 0.5083
2024-01-10 22:04:41,572 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5609, ap 0.5339
2024-01-10 22:04:41,661 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5189, ap 0.5356
2024-01-10 22:04:41,747 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4231, ap 0.4757
2024-01-10 22:04:41,836 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5258, ap 0.5010
2024-01-10 22:04:41,928 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.6257, ap 0.5987
2024-01-10 22:04:42,017 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4772, ap 0.5059
2024-01-10 22:04:42,103 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.3857, ap 0.4278
2024-01-10 22:04:42,193 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4345, ap 0.4658
2024-01-10 22:04:42,286 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5799, ap 0.5514
2024-01-10 22:04:42,379 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.5183, ap 0.5083
2024-01-10 22:04:42,465 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.4989, ap 0.5277
2024-01-10 22:04:42,560 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4557, ap 0.5000
2024-01-10 22:04:42,648 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4895, ap 0.5222
2024-01-10 22:04:42,735 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.6216, ap 0.6101
2024-01-10 22:04:42,824 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4074, ap 0.4586
2024-01-10 22:04:42,911 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4918, ap 0.5250
2024-01-10 22:04:43,007 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5578, ap 0.5683
2024-01-10 22:04:43,102 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5021, ap 0.5088
2024-01-10 22:04:43,191 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.4877, ap 0.4960
2024-01-10 22:04:43,285 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4672, ap 0.5150
2024-01-10 22:04:43,370 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.5078, ap 0.5090
2024-01-10 22:04:43,463 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5749, ap 0.5818
2024-01-10 22:04:43,554 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5393, ap 0.5164
2024-01-10 22:04:43,648 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.4918, ap 0.5010
2024-01-10 22:04:43,734 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.5329, ap 0.5271
2024-01-10 22:04:43,827 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4452, ap 0.4473
2024-01-10 22:04:43,914 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4760, ap 0.5205
2024-01-10 22:04:44,009 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.5292, ap 0.5132
2024-01-10 22:04:44,098 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5619, ap 0.5445
2024-01-10 22:04:44,184 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5174, ap 0.5332
2024-01-10 22:04:44,263 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.4804, ap 0.5090
2024-01-10 22:04:44,348 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4879, ap 0.4982
2024-01-10 22:04:44,432 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.5438, ap 0.5751
2024-01-10 22:04:44,508 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5363, ap 0.5522
2024-01-10 22:04:44,587 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.5288, ap 0.5426
2024-01-10 22:04:44,666 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5956, ap 0.5777
2024-01-10 22:04:44,745 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.4557, ap 0.4945
2024-01-10 22:04:44,828 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.5719, ap 0.5746
2024-01-10 22:04:44,914 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.5084, ap 0.5114
2024-01-10 22:04:44,997 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.6066, ap 0.5793
2024-01-10 22:04:45,076 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4486, ap 0.4666
2024-01-10 22:04:45,159 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5671, ap 0.5393
2024-01-10 22:04:45,236 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5504, ap 0.5355
2024-01-10 22:04:45,316 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.3870, ap 0.4360
2024-01-10 22:04:45,394 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4270, ap 0.4687
2024-01-10 22:04:45,484 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5920, ap 0.6122
2024-01-10 22:04:45,563 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5224, ap 0.5168
2024-01-10 22:04:45,643 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5242, ap 0.5293
2024-01-10 22:04:45,727 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5324, ap 0.5394
2024-01-10 22:04:45,809 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5543, ap 0.5335
2024-01-10 22:04:45,891 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.4555, ap 0.4721
2024-01-10 22:04:45,967 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4313, ap 0.4698
2024-01-10 22:04:46,059 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.5210, ap 0.5330
2024-01-10 22:04:46,143 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4740, ap 0.4898
2024-01-10 22:04:46,222 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4334, ap 0.4637
2024-01-10 22:04:46,300 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5774, ap 0.5529
2024-01-10 22:04:46,386 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.5080, ap 0.5420
2024-01-10 22:04:46,462 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4818, ap 0.4960
2024-01-10 22:04:46,540 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.3896, ap 0.4795
2024-01-10 22:04:46,565 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d039e6c50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:04:47,251 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4211, ap 0.4340
2024-01-10 22:04:47,355 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.4792, ap 0.4802
2024-01-10 22:04:47,444 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5822, ap 0.5507
2024-01-10 22:04:47,530 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4354, ap 0.4701
2024-01-10 22:04:47,621 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.6054, ap 0.6246
2024-01-10 22:04:47,708 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.4767, ap 0.4870
2024-01-10 22:04:47,791 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4877, ap 0.4724
2024-01-10 22:04:47,867 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5014, ap 0.5280
2024-01-10 22:04:47,950 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4121, ap 0.4404
2024-01-10 22:04:48,036 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.5267, ap 0.5465
2024-01-10 22:04:48,119 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4840, ap 0.5207
2024-01-10 22:04:48,199 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4900, ap 0.4937
2024-01-10 22:04:48,280 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.4929, ap 0.4779
2024-01-10 22:04:48,360 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5429, ap 0.5202
2024-01-10 22:04:48,447 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4381, ap 0.4851
2024-01-10 22:04:48,524 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.4858, ap 0.5346
2024-01-10 22:04:48,604 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5390, ap 0.5317
2024-01-10 22:04:48,698 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5995, ap 0.5780
2024-01-10 22:04:48,774 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.4920, ap 0.4947
2024-01-10 22:04:48,857 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.4778, ap 0.5436
2024-01-10 22:04:48,938 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4836, ap 0.4976
2024-01-10 22:04:49,022 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.4354, ap 0.4715
2024-01-10 22:04:49,106 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5454, ap 0.5376
2024-01-10 22:04:49,189 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5231, ap 0.4940
2024-01-10 22:04:49,267 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4573, ap 0.4772
2024-01-10 22:04:49,351 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.6022, ap 0.5806
2024-01-10 22:04:49,432 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4185, ap 0.4959
2024-01-10 22:04:49,513 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.6143, ap 0.6045
2024-01-10 22:04:49,592 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5287, ap 0.5504
2024-01-10 22:04:49,676 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.4571, ap 0.4957
2024-01-10 22:04:49,755 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.5379, ap 0.5477
2024-01-10 22:04:49,832 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5392, ap 0.5476
2024-01-10 22:04:49,915 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5381, ap 0.5291
2024-01-10 22:04:50,000 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4069, ap 0.4599
2024-01-10 22:04:50,089 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5308, ap 0.5206
2024-01-10 22:04:50,165 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5596, ap 0.5796
2024-01-10 22:04:50,251 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4363, ap 0.4843
2024-01-10 22:04:50,336 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.5009, ap 0.4931
2024-01-10 22:04:50,417 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.3932, ap 0.4448
2024-01-10 22:04:50,497 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5530, ap 0.5264
2024-01-10 22:04:50,579 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.4751, ap 0.4874
2024-01-10 22:04:50,661 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5160, ap 0.5514
2024-01-10 22:04:50,739 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4802, ap 0.5032
2024-01-10 22:04:50,825 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.3416, ap 0.4058
2024-01-10 22:04:50,915 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5276, ap 0.5654
2024-01-10 22:04:50,999 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.3831, ap 0.4378
2024-01-10 22:04:51,074 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4900, ap 0.5086
2024-01-10 22:04:51,152 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5988, ap 0.6069
2024-01-10 22:04:51,232 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5226, ap 0.5356
2024-01-10 22:04:51,326 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.4988, ap 0.5097
2024-01-10 22:04:51,407 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4665, ap 0.4805
2024-01-10 22:04:51,499 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4916, ap 0.5166
2024-01-10 22:04:51,577 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5194, ap 0.5289
2024-01-10 22:04:51,664 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5324, ap 0.5418
2024-01-10 22:04:51,743 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5701, ap 0.5837
2024-01-10 22:04:51,820 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4587, ap 0.4765
2024-01-10 22:04:51,904 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4603, ap 0.4527
2024-01-10 22:04:51,981 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.5481, ap 0.6019
2024-01-10 22:04:52,057 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4984, ap 0.5063
2024-01-10 22:04:52,140 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5367, ap 0.5163
2024-01-10 22:04:52,216 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.4993, ap 0.5301
2024-01-10 22:04:52,292 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.4902, ap 0.5274
2024-01-10 22:04:52,366 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4422, ap 0.4623
2024-01-10 22:04:52,440 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.5157, ap 0.5201
2024-01-10 22:04:52,523 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.6191, ap 0.5914
2024-01-10 22:04:52,602 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4359, ap 0.5038
2024-01-10 22:04:52,679 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.4774, ap 0.4874
2024-01-10 22:04:52,759 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5463, ap 0.5837
2024-01-10 22:04:52,841 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4553, ap 0.5147
2024-01-10 22:04:52,919 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.5295, ap 0.5107
2024-01-10 22:04:52,994 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5267, ap 0.5377
2024-01-10 22:04:53,085 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4624, ap 0.4845
2024-01-10 22:04:53,163 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.4840, ap 0.4998
2024-01-10 22:04:53,243 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5538, ap 0.5622
2024-01-10 22:04:53,325 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4651, ap 0.4901
2024-01-10 22:04:53,401 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.3987, ap 0.4374
2024-01-10 22:04:53,476 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5990, ap 0.5821
2024-01-10 22:04:53,557 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.4559, ap 0.4781
2024-01-10 22:04:53,639 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.4527, ap 0.4749
2024-01-10 22:04:53,724 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5847, ap 0.5660
2024-01-10 22:04:53,803 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5457, ap 0.5129
2024-01-10 22:04:53,880 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5870, ap 0.5798
2024-01-10 22:04:53,958 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4870, ap 0.5101
2024-01-10 22:04:54,032 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4496, ap 0.4640
2024-01-10 22:04:54,116 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4131, ap 0.4433
2024-01-10 22:04:54,191 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.5361, ap 0.5285
2024-01-10 22:04:54,266 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5344, ap 0.5472
2024-01-10 22:04:54,340 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4044, ap 0.4558
2024-01-10 22:04:54,418 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4699, ap 0.5034
2024-01-10 22:04:54,502 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.5036, ap 0.5006
2024-01-10 22:04:54,525 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0dd5a0bc50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:04:55,323 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.6047, ap 0.5859
2024-01-10 22:04:55,411 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5135, ap 0.5081
2024-01-10 22:04:55,499 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5578, ap 0.5608
2024-01-10 22:04:55,586 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4669, ap 0.4665
2024-01-10 22:04:55,673 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.4913, ap 0.5087
2024-01-10 22:04:55,756 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.4518, ap 0.4720
2024-01-10 22:04:55,841 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.3763, ap 0.4141
2024-01-10 22:04:55,919 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5457, ap 0.5291
2024-01-10 22:04:55,997 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4578, ap 0.4814
2024-01-10 22:04:56,072 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.5126, ap 0.5126
2024-01-10 22:04:56,153 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4902, ap 0.4763
2024-01-10 22:04:56,231 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4804, ap 0.4866
2024-01-10 22:04:56,309 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5265, ap 0.5367
2024-01-10 22:04:56,386 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5771, ap 0.5693
2024-01-10 22:04:56,472 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4320, ap 0.4777
2024-01-10 22:04:56,545 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5676, ap 0.5465
2024-01-10 22:04:56,621 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5345, ap 0.5246
2024-01-10 22:04:56,697 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5997, ap 0.6023
2024-01-10 22:04:56,774 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.4877, ap 0.4875
2024-01-10 22:04:56,849 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5194, ap 0.5812
2024-01-10 22:04:56,924 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.5050, ap 0.5464
2024-01-10 22:04:57,016 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.4281, ap 0.4622
2024-01-10 22:04:57,097 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5267, ap 0.5233
2024-01-10 22:04:57,172 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.4826, ap 0.4706
2024-01-10 22:04:57,247 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4290, ap 0.4446
2024-01-10 22:04:57,322 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5687, ap 0.5835
2024-01-10 22:04:57,402 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4069, ap 0.4851
2024-01-10 22:04:57,483 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5885, ap 0.6022
2024-01-10 22:04:57,560 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.4514, ap 0.4748
2024-01-10 22:04:57,637 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5062, ap 0.5180
2024-01-10 22:04:57,714 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.5100, ap 0.5268
2024-01-10 22:04:57,797 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5918, ap 0.5592
2024-01-10 22:04:57,884 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.4988, ap 0.5124
2024-01-10 22:04:57,962 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4623, ap 0.4563
2024-01-10 22:04:58,041 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.4881, ap 0.5027
2024-01-10 22:04:58,127 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.6100, ap 0.5821
2024-01-10 22:04:58,201 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.5036, ap 0.5457
2024-01-10 22:04:58,281 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.5085, ap 0.4984
2024-01-10 22:04:58,357 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.5094, ap 0.5369
2024-01-10 22:04:58,438 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5100, ap 0.4984
2024-01-10 22:04:58,512 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.4514, ap 0.5124
2024-01-10 22:04:58,585 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5133, ap 0.5647
2024-01-10 22:04:58,662 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4060, ap 0.4297
2024-01-10 22:04:58,733 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.3875, ap 0.4419
2024-01-10 22:04:58,814 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5491, ap 0.5795
2024-01-10 22:04:58,893 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4749, ap 0.5007
2024-01-10 22:04:58,970 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.3873, ap 0.4253
2024-01-10 22:04:59,052 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5340, ap 0.5487
2024-01-10 22:04:59,130 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5151, ap 0.5133
2024-01-10 22:04:59,205 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.4747, ap 0.5104
2024-01-10 22:04:59,282 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4721, ap 0.4968
2024-01-10 22:04:59,355 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4354, ap 0.4479
2024-01-10 22:04:59,431 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5251, ap 0.5464
2024-01-10 22:04:59,513 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.6230, ap 0.6080
2024-01-10 22:04:59,607 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5069, ap 0.5350
2024-01-10 22:04:59,693 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.5504, ap 0.5332
2024-01-10 22:04:59,776 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4674, ap 0.4773
2024-01-10 22:04:59,862 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.5137, ap 0.5518
2024-01-10 22:04:59,945 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4907, ap 0.4782
2024-01-10 22:05:00,033 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5384, ap 0.5382
2024-01-10 22:05:00,119 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5577, ap 0.5641
2024-01-10 22:05:00,204 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5425, ap 0.5622
2024-01-10 22:05:00,282 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4551, ap 0.4942
2024-01-10 22:05:00,364 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4968, ap 0.5148
2024-01-10 22:05:00,441 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5087, ap 0.5078
2024-01-10 22:05:00,519 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.3695, ap 0.4382
2024-01-10 22:05:00,596 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5773, ap 0.5775
2024-01-10 22:05:00,674 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5546, ap 0.5722
2024-01-10 22:05:00,751 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4640, ap 0.5095
2024-01-10 22:05:00,833 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4975, ap 0.4855
2024-01-10 22:05:00,911 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5792, ap 0.5554
2024-01-10 22:05:00,988 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4156, ap 0.4611
2024-01-10 22:05:01,062 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.4550, ap 0.4561
2024-01-10 22:05:01,135 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.4681, ap 0.4955
2024-01-10 22:05:01,206 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.5525, ap 0.5734
2024-01-10 22:05:01,284 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.5020, ap 0.5003
2024-01-10 22:05:01,364 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5650, ap 0.5737
2024-01-10 22:05:01,441 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.4781, ap 0.4802
2024-01-10 22:05:01,526 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5344, ap 0.5424
2024-01-10 22:05:01,605 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.4849, ap 0.4854
2024-01-10 22:05:01,683 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.4753, ap 0.4887
2024-01-10 22:05:01,766 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5644, ap 0.5589
2024-01-10 22:05:01,841 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4441, ap 0.5247
2024-01-10 22:05:01,914 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4003, ap 0.4311
2024-01-10 22:05:01,992 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4849, ap 0.4903
2024-01-10 22:05:02,068 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4815, ap 0.5397
2024-01-10 22:05:02,145 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5685, ap 0.5357
2024-01-10 22:05:02,225 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4712, ap 0.5051
2024-01-10 22:05:02,299 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4696, ap 0.5057
2024-01-10 22:05:02,373 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4439, ap 0.4668
2024-01-10 22:05:02,381 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d039d9dd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:05:03,112 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4165, ap 0.4504
2024-01-10 22:05:03,205 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.4713, ap 0.4769
2024-01-10 22:05:03,296 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.4708, ap 0.4872
2024-01-10 22:05:03,398 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4979, ap 0.5094
2024-01-10 22:05:03,491 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5769, ap 0.5659
2024-01-10 22:05:03,584 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.5422, ap 0.5324
2024-01-10 22:05:03,673 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4101, ap 0.4354
2024-01-10 22:05:03,766 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.4729, ap 0.4794
2024-01-10 22:05:03,857 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4183, ap 0.4526
2024-01-10 22:05:03,950 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4761, ap 0.4893
2024-01-10 22:05:04,038 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.5055, ap 0.5530
2024-01-10 22:05:04,134 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.5160, ap 0.5458
2024-01-10 22:05:04,222 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5399, ap 0.5587
2024-01-10 22:05:04,322 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5048, ap 0.5205
2024-01-10 22:05:04,411 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4149, ap 0.4613
2024-01-10 22:05:04,505 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5064, ap 0.5224
2024-01-10 22:05:04,593 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5440, ap 0.5376
2024-01-10 22:05:04,681 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5705, ap 0.5753
2024-01-10 22:05:04,770 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5552, ap 0.5371
2024-01-10 22:05:04,857 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5342, ap 0.5538
2024-01-10 22:05:04,948 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.5103, ap 0.5526
2024-01-10 22:05:05,036 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.4233, ap 0.4642
2024-01-10 22:05:05,126 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5091, ap 0.5118
2024-01-10 22:05:05,216 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.4744, ap 0.4622
2024-01-10 22:05:05,308 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4471, ap 0.4575
2024-01-10 22:05:05,400 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5509, ap 0.5209
2024-01-10 22:05:05,489 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.5603, ap 0.6023
2024-01-10 22:05:05,575 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.6210, ap 0.6035
2024-01-10 22:05:05,661 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5239, ap 0.5328
2024-01-10 22:05:05,747 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5028, ap 0.4989
2024-01-10 22:05:05,841 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.5322, ap 0.5802
2024-01-10 22:05:05,929 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5265, ap 0.5089
2024-01-10 22:05:06,017 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5424, ap 0.5546
2024-01-10 22:05:06,105 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4372, ap 0.4753
2024-01-10 22:05:06,197 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5055, ap 0.5151
2024-01-10 22:05:06,284 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5511, ap 0.5910
2024-01-10 22:05:06,372 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4530, ap 0.4910
2024-01-10 22:05:06,459 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.5408, ap 0.5155
2024-01-10 22:05:06,555 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4293, ap 0.4816
2024-01-10 22:05:06,642 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5555, ap 0.5319
2024-01-10 22:05:06,732 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.4516, ap 0.4793
2024-01-10 22:05:06,841 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5854, ap 0.6110
2024-01-10 22:05:06,933 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4619, ap 0.4935
2024-01-10 22:05:07,023 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4235, ap 0.4820
2024-01-10 22:05:07,124 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.4765, ap 0.5217
2024-01-10 22:05:07,212 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4525, ap 0.4895
2024-01-10 22:05:07,299 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4628, ap 0.5049
2024-01-10 22:05:07,387 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5666, ap 0.5771
2024-01-10 22:05:07,482 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.4722, ap 0.4827
2024-01-10 22:05:07,573 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.4708, ap 0.4947
2024-01-10 22:05:07,661 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.5666, ap 0.6171
2024-01-10 22:05:07,759 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4767, ap 0.5249
2024-01-10 22:05:07,859 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.6066, ap 0.5894
2024-01-10 22:05:07,947 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5698, ap 0.5611
2024-01-10 22:05:08,037 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5482, ap 0.5475
2024-01-10 22:05:08,127 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.5044, ap 0.5058
2024-01-10 22:05:08,216 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4648, ap 0.4738
2024-01-10 22:05:08,299 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4982, ap 0.5441
2024-01-10 22:05:08,391 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4980, ap 0.4884
2024-01-10 22:05:08,474 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.4672, ap 0.4923
2024-01-10 22:05:08,568 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5384, ap 0.5325
2024-01-10 22:05:08,658 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5409, ap 0.5721
2024-01-10 22:05:08,747 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.5098, ap 0.5143
2024-01-10 22:05:08,834 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.5269, ap 0.5095
2024-01-10 22:05:08,919 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.6461, ap 0.6176
2024-01-10 22:05:09,011 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4913, ap 0.5527
2024-01-10 22:05:09,099 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5721, ap 0.5525
2024-01-10 22:05:09,188 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5808, ap 0.6075
2024-01-10 22:05:09,276 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4842, ap 0.4817
2024-01-10 22:05:09,362 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4690, ap 0.4623
2024-01-10 22:05:09,451 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5027, ap 0.4851
2024-01-10 22:05:09,544 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4610, ap 0.4878
2024-01-10 22:05:09,638 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.4941, ap 0.4938
2024-01-10 22:05:09,726 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.4963, ap 0.5116
2024-01-10 22:05:09,818 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4478, ap 0.4899
2024-01-10 22:05:09,913 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.3825, ap 0.4466
2024-01-10 22:05:09,999 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.6184, ap 0.6356
2024-01-10 22:05:10,085 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.4674, ap 0.4923
2024-01-10 22:05:10,170 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5449, ap 0.5478
2024-01-10 22:05:10,255 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5685, ap 0.5440
2024-01-10 22:05:10,341 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5224, ap 0.5175
2024-01-10 22:05:10,428 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.4653, ap 0.4691
2024-01-10 22:05:10,517 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4393, ap 0.4802
2024-01-10 22:05:10,601 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4210, ap 0.4876
2024-01-10 22:05:10,686 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.3937, ap 0.4476
2024-01-10 22:05:10,773 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4761, ap 0.5147
2024-01-10 22:05:10,859 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5000, ap 0.5048
2024-01-10 22:05:10,946 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.5082, ap 0.5442
2024-01-10 22:05:11,030 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4681, ap 0.5217
2024-01-10 22:05:11,116 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4244, ap 0.4502
2024-01-10 22:05:11,117 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0dd5a0bc50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:05:11,738 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4797, ap 0.4734
2024-01-10 22:05:11,819 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5180, ap 0.5106
2024-01-10 22:05:11,911 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5564, ap 0.5364
2024-01-10 22:05:12,005 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.4347, ap 0.4755
2024-01-10 22:05:12,086 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.4498, ap 0.4702
2024-01-10 22:05:12,163 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.4441, ap 0.4666
2024-01-10 22:05:12,241 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4354, ap 0.4474
2024-01-10 22:05:12,330 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.4567, ap 0.4768
2024-01-10 22:05:12,408 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4852, ap 0.4765
2024-01-10 22:05:12,491 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4236, ap 0.4413
2024-01-10 22:05:12,600 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4810, ap 0.4949
2024-01-10 22:05:12,680 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.5459, ap 0.5086
2024-01-10 22:05:12,761 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5196, ap 0.5411
2024-01-10 22:05:12,837 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.6201, ap 0.5927
2024-01-10 22:05:12,913 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4567, ap 0.4840
2024-01-10 22:05:12,990 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.4751, ap 0.5093
2024-01-10 22:05:13,067 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5723, ap 0.5489
2024-01-10 22:05:13,160 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5803, ap 0.5721
2024-01-10 22:05:13,237 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5724, ap 0.5497
2024-01-10 22:05:13,318 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5384, ap 0.5706
2024-01-10 22:05:13,396 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4817, ap 0.5341
2024-01-10 22:05:13,474 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.4616, ap 0.4925
2024-01-10 22:05:13,556 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.4731, ap 0.4801
2024-01-10 22:05:13,633 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5231, ap 0.5070
2024-01-10 22:05:13,721 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4486, ap 0.4636
2024-01-10 22:05:13,813 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.6079, ap 0.6175
2024-01-10 22:05:13,890 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4179, ap 0.4612
2024-01-10 22:05:13,974 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5635, ap 0.5639
2024-01-10 22:05:14,052 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5514, ap 0.5680
2024-01-10 22:05:14,129 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.4961, ap 0.5299
2024-01-10 22:05:14,206 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.5094, ap 0.5380
2024-01-10 22:05:14,288 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5762, ap 0.5656
2024-01-10 22:05:14,364 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.4918, ap 0.4924
2024-01-10 22:05:14,440 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4033, ap 0.4447
2024-01-10 22:05:14,517 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5573, ap 0.5256
2024-01-10 22:05:14,593 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.6093, ap 0.6083
2024-01-10 22:05:14,678 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4491, ap 0.4563
2024-01-10 22:05:14,773 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.4754, ap 0.4693
2024-01-10 22:05:14,854 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4521, ap 0.5123
2024-01-10 22:05:14,938 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5639, ap 0.5430
2024-01-10 22:05:15,019 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.5126, ap 0.5492
2024-01-10 22:05:15,098 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5349, ap 0.5398
2024-01-10 22:05:15,174 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4612, ap 0.5054
2024-01-10 22:05:15,251 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4662, ap 0.4999
2024-01-10 22:05:15,327 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5126, ap 0.5514
2024-01-10 22:05:15,404 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.3845, ap 0.4166
2024-01-10 22:05:15,482 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4849, ap 0.5002
2024-01-10 22:05:15,560 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.6102, ap 0.6160
2024-01-10 22:05:15,643 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.4888, ap 0.5065
2024-01-10 22:05:15,718 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.4637, ap 0.5051
2024-01-10 22:05:15,795 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4740, ap 0.4901
2024-01-10 22:05:15,872 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4778, ap 0.4969
2024-01-10 22:05:15,949 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5347, ap 0.5367
2024-01-10 22:05:16,025 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5942, ap 0.5990
2024-01-10 22:05:16,101 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5815, ap 0.6034
2024-01-10 22:05:16,182 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4856, ap 0.4923
2024-01-10 22:05:16,261 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4742, ap 0.4729
2024-01-10 22:05:16,338 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4972, ap 0.5430
2024-01-10 22:05:16,415 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4818, ap 0.4730
2024-01-10 22:05:16,491 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5344, ap 0.5361
2024-01-10 22:05:16,567 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.6403, ap 0.6421
2024-01-10 22:05:16,648 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5303, ap 0.5596
2024-01-10 22:05:16,736 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4530, ap 0.4753
2024-01-10 22:05:16,812 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4754, ap 0.5104
2024-01-10 22:05:16,890 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.6040, ap 0.5847
2024-01-10 22:05:16,989 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4286, ap 0.4930
2024-01-10 22:05:17,070 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5276, ap 0.5250
2024-01-10 22:05:17,150 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.4292, ap 0.4917
2024-01-10 22:05:17,228 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.5205, ap 0.5467
2024-01-10 22:05:17,314 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4418, ap 0.4401
2024-01-10 22:05:17,393 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5570, ap 0.5391
2024-01-10 22:05:17,475 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4388, ap 0.4794
2024-01-10 22:05:17,562 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5208, ap 0.5334
2024-01-10 22:05:17,644 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5534, ap 0.5532
2024-01-10 22:05:17,721 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4820, ap 0.5289
2024-01-10 22:05:17,799 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4927, ap 0.4915
2024-01-10 22:05:17,874 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5701, ap 0.5820
2024-01-10 22:05:17,951 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.4683, ap 0.4859
2024-01-10 22:05:18,029 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5988, ap 0.5822
2024-01-10 22:05:18,105 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5650, ap 0.5489
2024-01-10 22:05:18,186 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5376, ap 0.5105
2024-01-10 22:05:18,262 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5641, ap 0.5427
2024-01-10 22:05:18,339 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4973, ap 0.5379
2024-01-10 22:05:18,421 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4188, ap 0.4566
2024-01-10 22:05:18,498 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4562, ap 0.5001
2024-01-10 22:05:18,577 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4740, ap 0.4920
2024-01-10 22:05:18,660 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5689, ap 0.5625
2024-01-10 22:05:18,737 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4379, ap 0.4806
2024-01-10 22:05:18,819 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.3960, ap 0.4548
2024-01-10 22:05:18,896 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.3896, ap 0.4476
2024-01-10 22:05:18,921 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03546110>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:05:19,684 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4573, ap 0.4809
2024-01-10 22:05:19,769 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5043, ap 0.4996
2024-01-10 22:05:19,849 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5886, ap 0.5778
2024-01-10 22:05:19,939 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.5135, ap 0.5026
2024-01-10 22:05:20,020 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.6127, ap 0.6001
2024-01-10 22:05:20,098 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.5235, ap 0.5406
2024-01-10 22:05:20,188 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4617, ap 0.4577
2024-01-10 22:05:20,266 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.4753, ap 0.4946
2024-01-10 22:05:20,343 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.3836, ap 0.4292
2024-01-10 22:05:20,423 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.5155, ap 0.5318
2024-01-10 22:05:20,505 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4658, ap 0.4851
2024-01-10 22:05:20,593 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4494, ap 0.4646
2024-01-10 22:05:20,673 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5883, ap 0.6046
2024-01-10 22:05:20,751 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5737, ap 0.5557
2024-01-10 22:05:20,832 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.3836, ap 0.4636
2024-01-10 22:05:20,917 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5417, ap 0.5373
2024-01-10 22:05:20,994 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5637, ap 0.5704
2024-01-10 22:05:21,079 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5568, ap 0.5831
2024-01-10 22:05:21,159 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.4874, ap 0.4953
2024-01-10 22:05:21,245 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5212, ap 0.5418
2024-01-10 22:05:21,323 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4605, ap 0.4755
2024-01-10 22:05:21,407 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.3414, ap 0.4081
2024-01-10 22:05:21,485 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.4818, ap 0.5110
2024-01-10 22:05:21,563 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5139, ap 0.5284
2024-01-10 22:05:21,643 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4082, ap 0.4527
2024-01-10 22:05:21,729 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5018, ap 0.5130
2024-01-10 22:05:21,811 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4847, ap 0.5569
2024-01-10 22:05:21,889 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5071, ap 0.5175
2024-01-10 22:05:21,977 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5089, ap 0.5193
2024-01-10 22:05:22,061 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5676, ap 0.5895
2024-01-10 22:05:22,139 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.4219, ap 0.4815
2024-01-10 22:05:22,220 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5146, ap 0.5059
2024-01-10 22:05:22,300 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5616, ap 0.5645
2024-01-10 22:05:22,384 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4438, ap 0.4842
2024-01-10 22:05:22,466 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5977, ap 0.5663
2024-01-10 22:05:22,545 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5728, ap 0.5518
2024-01-10 22:05:22,621 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4598, ap 0.4861
2024-01-10 22:05:22,704 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.5153, ap 0.5077
2024-01-10 22:05:22,790 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4219, ap 0.4859
2024-01-10 22:05:22,870 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5984, ap 0.5751
2024-01-10 22:05:22,952 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.4649, ap 0.5041
2024-01-10 22:05:23,036 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5879, ap 0.6222
2024-01-10 22:05:23,119 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4121, ap 0.4925
2024-01-10 22:05:23,196 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4405, ap 0.4712
2024-01-10 22:05:23,281 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5087, ap 0.5263
2024-01-10 22:05:23,358 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4745, ap 0.5122
2024-01-10 22:05:23,438 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.5044, ap 0.5355
2024-01-10 22:05:23,523 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5874, ap 0.6148
2024-01-10 22:05:23,603 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.4834, ap 0.5026
2024-01-10 22:05:23,688 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5653, ap 0.5572
2024-01-10 22:05:23,769 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4964, ap 0.5098
2024-01-10 22:05:23,846 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4500, ap 0.5054
2024-01-10 22:05:23,923 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5392, ap 0.5387
2024-01-10 22:05:24,005 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5794, ap 0.5778
2024-01-10 22:05:24,082 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5507, ap 0.5703
2024-01-10 22:05:24,174 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4573, ap 0.4781
2024-01-10 22:05:24,254 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4854, ap 0.5088
2024-01-10 22:05:24,331 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.5025, ap 0.5646
2024-01-10 22:05:24,413 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.5644, ap 0.5648
2024-01-10 22:05:24,491 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.4827, ap 0.5107
2024-01-10 22:05:24,567 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5292, ap 0.5304
2024-01-10 22:05:24,661 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5491, ap 0.5617
2024-01-10 22:05:24,738 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4140, ap 0.4673
2024-01-10 22:05:24,820 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.5199, ap 0.5478
2024-01-10 22:05:24,900 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.6182, ap 0.6304
2024-01-10 22:05:24,977 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4089, ap 0.4451
2024-01-10 22:05:25,057 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.5635, ap 0.5564
2024-01-10 22:05:25,135 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5388, ap 0.5621
2024-01-10 22:05:25,218 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.5322, ap 0.5682
2024-01-10 22:05:25,297 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4778, ap 0.4817
2024-01-10 22:05:25,383 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5418, ap 0.5265
2024-01-10 22:05:25,463 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.5087, ap 0.5465
2024-01-10 22:05:25,539 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5523, ap 0.5350
2024-01-10 22:05:25,616 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5121, ap 0.5304
2024-01-10 22:05:25,694 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4309, ap 0.4934
2024-01-10 22:05:25,771 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.3790, ap 0.4268
2024-01-10 22:05:25,860 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5315, ap 0.5306
2024-01-10 22:05:25,941 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5271, ap 0.5074
2024-01-10 22:05:26,035 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5239, ap 0.5377
2024-01-10 22:05:26,119 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5420, ap 0.5299
2024-01-10 22:05:26,204 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.5463, ap 0.5432
2024-01-10 22:05:26,283 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5313, ap 0.5170
2024-01-10 22:05:26,364 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4502, ap 0.4872
2024-01-10 22:05:26,449 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4713, ap 0.4903
2024-01-10 22:05:26,537 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4929, ap 0.4943
2024-01-10 22:05:26,616 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4583, ap 0.4805
2024-01-10 22:05:26,703 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5352, ap 0.5315
2024-01-10 22:05:26,788 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4573, ap 0.4709
2024-01-10 22:05:26,871 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.4722, ap 0.5103
2024-01-10 22:05:26,954 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4074, ap 0.4904
2024-01-10 22:05:26,968 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d06490b50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:05:27,638 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4701, ap 0.4711
2024-01-10 22:05:27,716 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.4427, ap 0.4524
2024-01-10 22:05:27,807 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5687, ap 0.5484
2024-01-10 22:05:27,885 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.5589, ap 0.5757
2024-01-10 22:05:27,962 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5137, ap 0.5388
2024-01-10 22:05:28,040 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.4735, ap 0.4949
2024-01-10 22:05:28,119 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4391, ap 0.4684
2024-01-10 22:05:28,198 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.5194, ap 0.5077
2024-01-10 22:05:28,280 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.5103, ap 0.5193
2024-01-10 22:05:28,366 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4404, ap 0.4656
2024-01-10 22:05:28,446 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4571, ap 0.5015
2024-01-10 22:05:28,525 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.5178, ap 0.5049
2024-01-10 22:05:28,606 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5534, ap 0.5633
2024-01-10 22:05:28,685 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5121, ap 0.5048
2024-01-10 22:05:28,767 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.3571, ap 0.4283
2024-01-10 22:05:28,847 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5336, ap 0.5236
2024-01-10 22:05:28,932 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5700, ap 0.5877
2024-01-10 22:05:29,009 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.6018, ap 0.5917
2024-01-10 22:05:29,091 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5226, ap 0.5280
2024-01-10 22:05:29,170 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.4468, ap 0.5040
2024-01-10 22:05:29,255 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.5089, ap 0.5276
2024-01-10 22:05:29,337 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.3284, ap 0.4119
2024-01-10 22:05:29,420 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.4480, ap 0.4819
2024-01-10 22:05:29,499 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5000, ap 0.5031
2024-01-10 22:05:29,576 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4329, ap 0.4513
2024-01-10 22:05:29,653 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5578, ap 0.5807
2024-01-10 22:05:29,730 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4690, ap 0.5502
2024-01-10 22:05:29,808 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5538, ap 0.5716
2024-01-10 22:05:29,884 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.4881, ap 0.5129
2024-01-10 22:05:29,962 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5449, ap 0.5614
2024-01-10 22:05:30,039 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.4829, ap 0.5180
2024-01-10 22:05:30,128 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.6004, ap 0.5674
2024-01-10 22:05:30,208 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5465, ap 0.5552
2024-01-10 22:05:30,288 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4535, ap 0.4858
2024-01-10 22:05:30,366 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5858, ap 0.5747
2024-01-10 22:05:30,443 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5538, ap 0.5870
2024-01-10 22:05:30,524 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4956, ap 0.5216
2024-01-10 22:05:30,605 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.4614, ap 0.4732
2024-01-10 22:05:30,682 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4461, ap 0.4880
2024-01-10 22:05:30,759 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5319, ap 0.5152
2024-01-10 22:05:30,844 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.5290, ap 0.5478
2024-01-10 22:05:30,922 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5376, ap 0.5931
2024-01-10 22:05:31,005 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4861, ap 0.5407
2024-01-10 22:05:31,087 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.3731, ap 0.4381
2024-01-10 22:05:31,165 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5826, ap 0.6144
2024-01-10 22:05:31,243 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4502, ap 0.4739
2024-01-10 22:05:31,320 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.5011, ap 0.5078
2024-01-10 22:05:31,406 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5429, ap 0.5683
2024-01-10 22:05:31,484 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5360, ap 0.5444
2024-01-10 22:05:31,567 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5796, ap 0.5572
2024-01-10 22:05:31,645 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.5148, ap 0.5490
2024-01-10 22:05:31,727 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4272, ap 0.4630
2024-01-10 22:05:31,806 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5433, ap 0.5712
2024-01-10 22:05:31,890 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.6091, ap 0.5889
2024-01-10 22:05:31,969 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5452, ap 0.5723
2024-01-10 22:05:32,046 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4708, ap 0.4875
2024-01-10 22:05:32,122 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4306, ap 0.4568
2024-01-10 22:05:32,202 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4605, ap 0.5229
2024-01-10 22:05:32,285 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4963, ap 0.5015
2024-01-10 22:05:32,363 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5265, ap 0.5395
2024-01-10 22:05:32,447 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.4824, ap 0.4944
2024-01-10 22:05:32,526 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5607, ap 0.5964
2024-01-10 22:05:32,603 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.5135, ap 0.4950
2024-01-10 22:05:32,685 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.3720, ap 0.4230
2024-01-10 22:05:32,768 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5917, ap 0.5953
2024-01-10 22:05:32,846 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4742, ap 0.5323
2024-01-10 22:05:32,925 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.6331, ap 0.6041
2024-01-10 22:05:33,002 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5443, ap 0.5901
2024-01-10 22:05:33,080 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4977, ap 0.5389
2024-01-10 22:05:33,157 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4080, ap 0.4352
2024-01-10 22:05:33,238 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5799, ap 0.5968
2024-01-10 22:05:33,316 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4254, ap 0.4592
2024-01-10 22:05:33,395 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.4715, ap 0.5109
2024-01-10 22:05:33,480 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5055, ap 0.5581
2024-01-10 22:05:33,559 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4603, ap 0.4770
2024-01-10 22:05:33,644 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4416, ap 0.4524
2024-01-10 22:05:33,722 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5717, ap 0.5865
2024-01-10 22:05:33,800 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.4770, ap 0.5017
2024-01-10 22:05:33,877 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.5744, ap 0.5481
2024-01-10 22:05:33,962 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.6093, ap 0.5780
2024-01-10 22:05:34,040 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.4427, ap 0.4655
2024-01-10 22:05:34,119 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5794, ap 0.5405
2024-01-10 22:05:34,201 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4651, ap 0.4800
2024-01-10 22:05:34,279 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4518, ap 0.4895
2024-01-10 22:05:34,355 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.4489, ap 0.4920
2024-01-10 22:05:34,436 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.5548, ap 0.5534
2024-01-10 22:05:34,525 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5678, ap 0.5489
2024-01-10 22:05:34,604 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4379, ap 0.4582
2024-01-10 22:05:34,684 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.5308, ap 0.5428
2024-01-10 22:05:34,763 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4585, ap 0.4835
2024-01-10 22:05:34,774 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d0359e090>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:05:35,467 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4881, ap 0.4769
2024-01-10 22:05:35,555 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5728, ap 0.5326
2024-01-10 22:05:35,641 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5714, ap 0.5448
2024-01-10 22:05:35,724 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.5094, ap 0.5446
2024-01-10 22:05:35,805 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.5806, ap 0.5823
2024-01-10 22:05:35,892 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.5326, ap 0.5032
2024-01-10 22:05:35,971 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4062, ap 0.4329
2024-01-10 22:05:36,058 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.4959, ap 0.5106
2024-01-10 22:05:36,138 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4297, ap 0.4784
2024-01-10 22:05:36,215 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.4357, ap 0.4658
2024-01-10 22:05:36,299 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.5287, ap 0.5482
2024-01-10 22:05:36,380 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4400, ap 0.4528
2024-01-10 22:05:36,457 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5561, ap 0.5529
2024-01-10 22:05:36,539 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.5425, ap 0.5253
2024-01-10 22:05:36,616 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4496, ap 0.5072
2024-01-10 22:05:36,695 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5198, ap 0.5132
2024-01-10 22:05:36,775 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5607, ap 0.5408
2024-01-10 22:05:36,852 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5689, ap 0.5680
2024-01-10 22:05:36,930 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.5185, ap 0.5042
2024-01-10 22:05:37,008 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.5044, ap 0.5180
2024-01-10 22:05:37,096 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.4607, ap 0.4778
2024-01-10 22:05:37,174 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.3895, ap 0.4325
2024-01-10 22:05:37,255 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5301, ap 0.5221
2024-01-10 22:05:37,333 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5493, ap 0.5375
2024-01-10 22:05:37,412 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4535, ap 0.4710
2024-01-10 22:05:37,493 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5226, ap 0.5231
2024-01-10 22:05:37,571 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4176, ap 0.4617
2024-01-10 22:05:37,651 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5418, ap 0.5489
2024-01-10 22:05:37,729 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.4817, ap 0.5051
2024-01-10 22:05:37,807 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5963, ap 0.5912
2024-01-10 22:05:37,893 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.4906, ap 0.5042
2024-01-10 22:05:37,971 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.6112, ap 0.5797
2024-01-10 22:05:38,049 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.4913, ap 0.4953
2024-01-10 22:05:38,128 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.3934, ap 0.4485
2024-01-10 22:05:38,206 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.4906, ap 0.4873
2024-01-10 22:05:38,284 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.5497, ap 0.5402
2024-01-10 22:05:38,361 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4639, ap 0.4780
2024-01-10 22:05:38,440 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.5212, ap 0.5010
2024-01-10 22:05:38,516 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.4464, ap 0.4879
2024-01-10 22:05:38,604 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5906, ap 0.5571
2024-01-10 22:05:38,683 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.4842, ap 0.5024
2024-01-10 22:05:38,767 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.4717, ap 0.4860
2024-01-10 22:05:38,852 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4375, ap 0.5079
2024-01-10 22:05:38,940 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.3467, ap 0.4176
2024-01-10 22:05:39,019 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5689, ap 0.5604
2024-01-10 22:05:39,097 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4393, ap 0.4652
2024-01-10 22:05:39,179 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.4849, ap 0.4921
2024-01-10 22:05:39,257 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5977, ap 0.5954
2024-01-10 22:05:39,333 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5226, ap 0.5198
2024-01-10 22:05:39,413 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.4948, ap 0.4911
2024-01-10 22:05:39,488 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4130, ap 0.4530
2024-01-10 22:05:39,563 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.5055, ap 0.5109
2024-01-10 22:05:39,640 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5347, ap 0.5544
2024-01-10 22:05:39,719 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5760, ap 0.5651
2024-01-10 22:05:39,795 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5671, ap 0.5550
2024-01-10 22:05:39,871 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4414, ap 0.4489
2024-01-10 22:05:39,946 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.4649, ap 0.4531
2024-01-10 22:05:40,028 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.5489, ap 0.5921
2024-01-10 22:05:40,103 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.4560, ap 0.4678
2024-01-10 22:05:40,177 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.5863, ap 0.5784
2024-01-10 22:05:40,254 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.5205, ap 0.5128
2024-01-10 22:05:40,330 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5885, ap 0.6128
2024-01-10 22:05:40,405 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.3991, ap 0.4265
2024-01-10 22:05:40,481 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.4414, ap 0.4973
2024-01-10 22:05:40,559 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.5112, ap 0.5363
2024-01-10 22:05:40,639 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.4546, ap 0.4765
2024-01-10 22:05:40,715 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.4938, ap 0.5051
2024-01-10 22:05:40,790 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.4820, ap 0.5138
2024-01-10 22:05:40,866 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.5333, ap 0.5522
2024-01-10 22:05:40,942 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4810, ap 0.4740
2024-01-10 22:05:41,017 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5885, ap 0.5657
2024-01-10 22:05:41,096 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4236, ap 0.4630
2024-01-10 22:05:41,169 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.4767, ap 0.4813
2024-01-10 22:05:41,250 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.5146, ap 0.5108
2024-01-10 22:05:41,330 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4439, ap 0.4709
2024-01-10 22:05:41,406 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.3937, ap 0.4330
2024-01-10 22:05:41,482 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5037, ap 0.5121
2024-01-10 22:05:41,558 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5454, ap 0.5201
2024-01-10 22:05:41,638 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.4503, ap 0.4704
2024-01-10 22:05:41,713 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.5023, ap 0.4988
2024-01-10 22:05:41,801 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.4831, ap 0.4764
2024-01-10 22:05:41,885 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5269, ap 0.5093
2024-01-10 22:05:41,963 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.5408, ap 0.5753
2024-01-10 22:05:42,039 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4471, ap 0.4685
2024-01-10 22:05:42,115 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.5052, ap 0.5313
2024-01-10 22:05:42,191 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.4265, ap 0.4467
2024-01-10 22:05:42,266 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5262, ap 0.5188
2024-01-10 22:05:42,347 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4977, ap 0.5246
2024-01-10 22:05:42,422 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.5002, ap 0.5238
2024-01-10 22:05:42,504 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4375, ap 0.4582
2024-01-10 22:05:42,504 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035b6890>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:05:43,190 - GAugM EPNet train, Epoch [  1/90]: loss 0.7210, auc 0.4466, ap 0.4701
2024-01-10 22:05:43,269 - GAugM EPNet train, Epoch [  2/90]: loss 0.7210, auc 0.5085, ap 0.4949
2024-01-10 22:05:43,356 - GAugM EPNet train, Epoch [  3/90]: loss 0.7209, auc 0.5904, ap 0.5767
2024-01-10 22:05:43,445 - GAugM EPNet train, Epoch [  4/90]: loss 0.7209, auc 0.5511, ap 0.5522
2024-01-10 22:05:43,535 - GAugM EPNet train, Epoch [  5/90]: loss 0.7209, auc 0.6040, ap 0.5975
2024-01-10 22:05:43,631 - GAugM EPNet train, Epoch [  6/90]: loss 0.7209, auc 0.5336, ap 0.5092
2024-01-10 22:05:43,721 - GAugM EPNet train, Epoch [  7/90]: loss 0.7209, auc 0.4295, ap 0.4379
2024-01-10 22:05:43,809 - GAugM EPNet train, Epoch [  8/90]: loss 0.7210, auc 0.4559, ap 0.4744
2024-01-10 22:05:43,901 - GAugM EPNet train, Epoch [  9/90]: loss 0.7209, auc 0.4466, ap 0.4661
2024-01-10 22:05:43,990 - GAugM EPNet train, Epoch [ 10/90]: loss 0.7208, auc 0.5586, ap 0.5234
2024-01-10 22:05:44,081 - GAugM EPNet train, Epoch [ 11/90]: loss 0.7209, auc 0.4459, ap 0.5032
2024-01-10 22:05:44,175 - GAugM EPNet train, Epoch [ 12/90]: loss 0.7210, auc 0.4427, ap 0.4654
2024-01-10 22:05:44,262 - GAugM EPNet train, Epoch [ 13/90]: loss 0.7209, auc 0.5164, ap 0.4946
2024-01-10 22:05:44,345 - GAugM EPNet train, Epoch [ 14/90]: loss 0.7209, auc 0.6223, ap 0.5825
2024-01-10 22:05:44,422 - GAugM EPNet train, Epoch [ 15/90]: loss 0.7210, auc 0.4671, ap 0.5048
2024-01-10 22:05:44,507 - GAugM EPNet train, Epoch [ 16/90]: loss 0.7209, auc 0.5756, ap 0.5839
2024-01-10 22:05:44,586 - GAugM EPNet train, Epoch [ 17/90]: loss 0.7210, auc 0.5404, ap 0.5115
2024-01-10 22:05:44,674 - GAugM EPNet train, Epoch [ 18/90]: loss 0.7210, auc 0.5924, ap 0.5722
2024-01-10 22:05:44,753 - GAugM EPNet train, Epoch [ 19/90]: loss 0.7209, auc 0.4891, ap 0.4869
2024-01-10 22:05:44,831 - GAugM EPNet train, Epoch [ 20/90]: loss 0.7210, auc 0.4696, ap 0.4830
2024-01-10 22:05:44,919 - GAugM EPNet train, Epoch [ 21/90]: loss 0.7209, auc 0.5285, ap 0.5382
2024-01-10 22:05:45,000 - GAugM EPNet train, Epoch [ 22/90]: loss 0.7210, auc 0.4583, ap 0.4699
2024-01-10 22:05:45,085 - GAugM EPNet train, Epoch [ 23/90]: loss 0.7208, auc 0.5427, ap 0.5439
2024-01-10 22:05:45,167 - GAugM EPNet train, Epoch [ 24/90]: loss 0.7209, auc 0.5130, ap 0.4942
2024-01-10 22:05:45,245 - GAugM EPNet train, Epoch [ 25/90]: loss 0.7209, auc 0.4534, ap 0.4648
2024-01-10 22:05:45,320 - GAugM EPNet train, Epoch [ 26/90]: loss 0.7210, auc 0.5664, ap 0.5634
2024-01-10 22:05:45,403 - GAugM EPNet train, Epoch [ 27/90]: loss 0.7209, auc 0.4626, ap 0.5005
2024-01-10 22:05:45,480 - GAugM EPNet train, Epoch [ 28/90]: loss 0.7209, auc 0.5484, ap 0.5309
2024-01-10 22:05:45,557 - GAugM EPNet train, Epoch [ 29/90]: loss 0.7210, auc 0.5020, ap 0.5059
2024-01-10 22:05:45,635 - GAugM EPNet train, Epoch [ 30/90]: loss 0.7209, auc 0.5408, ap 0.5531
2024-01-10 22:05:45,716 - GAugM EPNet train, Epoch [ 31/90]: loss 0.7208, auc 0.4916, ap 0.5109
2024-01-10 22:05:45,792 - GAugM EPNet train, Epoch [ 32/90]: loss 0.7210, auc 0.5644, ap 0.5497
2024-01-10 22:05:45,876 - GAugM EPNet train, Epoch [ 33/90]: loss 0.7209, auc 0.5297, ap 0.5586
2024-01-10 22:05:45,953 - GAugM EPNet train, Epoch [ 34/90]: loss 0.7209, auc 0.4551, ap 0.4760
2024-01-10 22:05:46,036 - GAugM EPNet train, Epoch [ 35/90]: loss 0.7209, auc 0.5420, ap 0.5264
2024-01-10 22:05:46,113 - GAugM EPNet train, Epoch [ 36/90]: loss 0.7209, auc 0.6292, ap 0.5985
2024-01-10 22:05:46,191 - GAugM EPNet train, Epoch [ 37/90]: loss 0.7209, auc 0.4195, ap 0.4651
2024-01-10 22:05:46,273 - GAugM EPNet train, Epoch [ 38/90]: loss 0.7209, auc 0.4847, ap 0.4736
2024-01-10 22:05:46,352 - GAugM EPNet train, Epoch [ 39/90]: loss 0.7208, auc 0.3761, ap 0.4378
2024-01-10 22:05:46,433 - GAugM EPNet train, Epoch [ 40/90]: loss 0.7210, auc 0.5714, ap 0.5345
2024-01-10 22:05:46,510 - GAugM EPNet train, Epoch [ 41/90]: loss 0.7210, auc 0.5306, ap 0.5292
2024-01-10 22:05:46,587 - GAugM EPNet train, Epoch [ 42/90]: loss 0.7209, auc 0.5653, ap 0.6052
2024-01-10 22:05:46,669 - GAugM EPNet train, Epoch [ 43/90]: loss 0.7208, auc 0.4811, ap 0.4917
2024-01-10 22:05:46,748 - GAugM EPNet train, Epoch [ 44/90]: loss 0.7208, auc 0.4199, ap 0.4700
2024-01-10 22:05:46,825 - GAugM EPNet train, Epoch [ 45/90]: loss 0.7209, auc 0.5482, ap 0.5596
2024-01-10 22:05:46,902 - GAugM EPNet train, Epoch [ 46/90]: loss 0.7209, auc 0.4400, ap 0.4552
2024-01-10 22:05:46,978 - GAugM EPNet train, Epoch [ 47/90]: loss 0.7210, auc 0.5114, ap 0.5311
2024-01-10 22:05:47,055 - GAugM EPNet train, Epoch [ 48/90]: loss 0.7210, auc 0.5797, ap 0.6010
2024-01-10 22:05:47,132 - GAugM EPNet train, Epoch [ 49/90]: loss 0.7209, auc 0.5481, ap 0.5393
2024-01-10 22:05:47,214 - GAugM EPNet train, Epoch [ 50/90]: loss 0.7210, auc 0.5166, ap 0.5113
2024-01-10 22:05:47,292 - GAugM EPNet train, Epoch [ 51/90]: loss 0.7210, auc 0.4614, ap 0.4968
2024-01-10 22:05:47,369 - GAugM EPNet train, Epoch [ 52/90]: loss 0.7209, auc 0.4299, ap 0.4890
2024-01-10 22:05:47,447 - GAugM EPNet train, Epoch [ 53/90]: loss 0.7209, auc 0.5308, ap 0.5451
2024-01-10 22:05:47,526 - GAugM EPNet train, Epoch [ 54/90]: loss 0.7211, auc 0.5751, ap 0.5801
2024-01-10 22:05:47,603 - GAugM EPNet train, Epoch [ 55/90]: loss 0.7209, auc 0.5541, ap 0.5781
2024-01-10 22:05:47,692 - GAugM EPNet train, Epoch [ 56/90]: loss 0.7208, auc 0.4744, ap 0.4673
2024-01-10 22:05:47,770 - GAugM EPNet train, Epoch [ 57/90]: loss 0.7209, auc 0.5194, ap 0.5128
2024-01-10 22:05:47,849 - GAugM EPNet train, Epoch [ 58/90]: loss 0.7210, auc 0.4842, ap 0.5155
2024-01-10 22:05:47,936 - GAugM EPNet train, Epoch [ 59/90]: loss 0.7211, auc 0.5466, ap 0.5311
2024-01-10 22:05:48,015 - GAugM EPNet train, Epoch [ 60/90]: loss 0.7210, auc 0.4874, ap 0.4951
2024-01-10 22:05:48,098 - GAugM EPNet train, Epoch [ 61/90]: loss 0.7209, auc 0.4740, ap 0.4691
2024-01-10 22:05:48,175 - GAugM EPNet train, Epoch [ 62/90]: loss 0.7210, auc 0.5368, ap 0.5581
2024-01-10 22:05:48,260 - GAugM EPNet train, Epoch [ 63/90]: loss 0.7208, auc 0.4457, ap 0.4505
2024-01-10 22:05:48,340 - GAugM EPNet train, Epoch [ 64/90]: loss 0.7208, auc 0.5409, ap 0.5305
2024-01-10 22:05:48,416 - GAugM EPNet train, Epoch [ 65/90]: loss 0.7208, auc 0.6488, ap 0.6335
2024-01-10 22:05:48,494 - GAugM EPNet train, Epoch [ 66/90]: loss 0.7209, auc 0.5158, ap 0.5025
2024-01-10 22:05:48,578 - GAugM EPNet train, Epoch [ 67/90]: loss 0.7209, auc 0.4906, ap 0.5149
2024-01-10 22:05:48,657 - GAugM EPNet train, Epoch [ 68/90]: loss 0.7210, auc 0.5087, ap 0.5617
2024-01-10 22:05:48,739 - GAugM EPNet train, Epoch [ 69/90]: loss 0.7210, auc 0.4722, ap 0.5020
2024-01-10 22:05:48,822 - GAugM EPNet train, Epoch [ 70/90]: loss 0.7210, auc 0.4630, ap 0.4680
2024-01-10 22:05:48,902 - GAugM EPNet train, Epoch [ 71/90]: loss 0.7210, auc 0.5630, ap 0.5587
2024-01-10 22:05:48,987 - GAugM EPNet train, Epoch [ 72/90]: loss 0.7210, auc 0.4886, ap 0.5250
2024-01-10 22:05:49,065 - GAugM EPNet train, Epoch [ 73/90]: loss 0.7209, auc 0.5258, ap 0.5125
2024-01-10 22:05:49,147 - GAugM EPNet train, Epoch [ 74/90]: loss 0.7209, auc 0.4235, ap 0.4513
2024-01-10 22:05:49,224 - GAugM EPNet train, Epoch [ 75/90]: loss 0.7210, auc 0.4219, ap 0.4516
2024-01-10 22:05:49,303 - GAugM EPNet train, Epoch [ 76/90]: loss 0.7209, auc 0.4464, ap 0.4773
2024-01-10 22:05:49,380 - GAugM EPNet train, Epoch [ 77/90]: loss 0.7208, auc 0.5441, ap 0.5291
2024-01-10 22:05:49,459 - GAugM EPNet train, Epoch [ 78/90]: loss 0.7209, auc 0.5025, ap 0.4855
2024-01-10 22:05:49,543 - GAugM EPNet train, Epoch [ 79/90]: loss 0.7208, auc 0.4405, ap 0.4618
2024-01-10 22:05:49,622 - GAugM EPNet train, Epoch [ 80/90]: loss 0.7209, auc 0.6032, ap 0.5595
2024-01-10 22:05:49,702 - GAugM EPNet train, Epoch [ 81/90]: loss 0.7209, auc 0.4745, ap 0.4689
2024-01-10 22:05:49,778 - GAugM EPNet train, Epoch [ 82/90]: loss 0.7210, auc 0.5968, ap 0.5644
2024-01-10 22:05:49,856 - GAugM EPNet train, Epoch [ 83/90]: loss 0.7209, auc 0.4176, ap 0.4631
2024-01-10 22:05:49,940 - GAugM EPNet train, Epoch [ 84/90]: loss 0.7209, auc 0.4608, ap 0.5120
2024-01-10 22:05:50,017 - GAugM EPNet train, Epoch [ 85/90]: loss 0.7210, auc 0.3952, ap 0.4404
2024-01-10 22:05:50,096 - GAugM EPNet train, Epoch [ 86/90]: loss 0.7208, auc 0.5053, ap 0.4926
2024-01-10 22:05:50,172 - GAugM EPNet train, Epoch [ 87/90]: loss 0.7209, auc 0.5310, ap 0.5205
2024-01-10 22:05:50,262 - GAugM EPNet train, Epoch [ 88/90]: loss 0.7210, auc 0.4308, ap 0.4581
2024-01-10 22:05:50,340 - GAugM EPNet train, Epoch [ 89/90]: loss 0.7210, auc 0.5580, ap 0.5662
2024-01-10 22:05:50,417 - GAugM EPNet train, Epoch [ 90/90]: loss 0.7209, auc 0.4500, ap 0.4831
2024-01-10 22:05:50,439 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035b7110>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:05:51,207 - GAugM EPNet train, Epoch [  1/70]: loss 0.7210, auc 0.5206, ap 0.5021
2024-01-10 22:05:51,302 - GAugM EPNet train, Epoch [  2/70]: loss 0.7210, auc 0.5242, ap 0.5130
2024-01-10 22:05:51,384 - GAugM EPNet train, Epoch [  3/70]: loss 0.7209, auc 0.6292, ap 0.5913
2024-01-10 22:05:51,479 - GAugM EPNet train, Epoch [  4/70]: loss 0.7209, auc 0.5171, ap 0.5459
2024-01-10 22:05:51,564 - GAugM EPNet train, Epoch [  5/70]: loss 0.7209, auc 0.5997, ap 0.5774
2024-01-10 22:05:51,643 - GAugM EPNet train, Epoch [  6/70]: loss 0.7209, auc 0.4911, ap 0.4998
2024-01-10 22:05:51,724 - GAugM EPNet train, Epoch [  7/70]: loss 0.7209, auc 0.4850, ap 0.4871
2024-01-10 22:05:51,803 - GAugM EPNet train, Epoch [  8/70]: loss 0.7210, auc 0.5765, ap 0.5642
2024-01-10 22:05:51,886 - GAugM EPNet train, Epoch [  9/70]: loss 0.7209, auc 0.4672, ap 0.4757
2024-01-10 22:05:51,973 - GAugM EPNet train, Epoch [ 10/70]: loss 0.7208, auc 0.4993, ap 0.5101
2024-01-10 22:05:52,052 - GAugM EPNet train, Epoch [ 11/70]: loss 0.7209, auc 0.5381, ap 0.5466
2024-01-10 22:05:52,135 - GAugM EPNet train, Epoch [ 12/70]: loss 0.7210, auc 0.4687, ap 0.4762
2024-01-10 22:05:52,211 - GAugM EPNet train, Epoch [ 13/70]: loss 0.7209, auc 0.5822, ap 0.5374
2024-01-10 22:05:52,304 - GAugM EPNet train, Epoch [ 14/70]: loss 0.7209, auc 0.5256, ap 0.5133
2024-01-10 22:05:52,385 - GAugM EPNet train, Epoch [ 15/70]: loss 0.7210, auc 0.4384, ap 0.5036
2024-01-10 22:05:52,462 - GAugM EPNet train, Epoch [ 16/70]: loss 0.7209, auc 0.5199, ap 0.5183
2024-01-10 22:05:52,544 - GAugM EPNet train, Epoch [ 17/70]: loss 0.7210, auc 0.5694, ap 0.5556
2024-01-10 22:05:52,626 - GAugM EPNet train, Epoch [ 18/70]: loss 0.7210, auc 0.6396, ap 0.6257
2024-01-10 22:05:52,711 - GAugM EPNet train, Epoch [ 19/70]: loss 0.7209, auc 0.5265, ap 0.5150
2024-01-10 22:05:52,791 - GAugM EPNet train, Epoch [ 20/70]: loss 0.7210, auc 0.4470, ap 0.4759
2024-01-10 22:05:52,870 - GAugM EPNet train, Epoch [ 21/70]: loss 0.7209, auc 0.5093, ap 0.5089
2024-01-10 22:05:52,953 - GAugM EPNet train, Epoch [ 22/70]: loss 0.7210, auc 0.3772, ap 0.4235
2024-01-10 22:05:53,034 - GAugM EPNet train, Epoch [ 23/70]: loss 0.7208, auc 0.5420, ap 0.5349
2024-01-10 22:05:53,120 - GAugM EPNet train, Epoch [ 24/70]: loss 0.7209, auc 0.5189, ap 0.5043
2024-01-10 22:05:53,200 - GAugM EPNet train, Epoch [ 25/70]: loss 0.7209, auc 0.4292, ap 0.4610
2024-01-10 22:05:53,277 - GAugM EPNet train, Epoch [ 26/70]: loss 0.7210, auc 0.5623, ap 0.5443
2024-01-10 22:05:53,365 - GAugM EPNet train, Epoch [ 27/70]: loss 0.7209, auc 0.4334, ap 0.4658
2024-01-10 22:05:53,443 - GAugM EPNet train, Epoch [ 28/70]: loss 0.7209, auc 0.5755, ap 0.5825
2024-01-10 22:05:53,521 - GAugM EPNet train, Epoch [ 29/70]: loss 0.7210, auc 0.5545, ap 0.5446
2024-01-10 22:05:53,600 - GAugM EPNet train, Epoch [ 30/70]: loss 0.7209, auc 0.4847, ap 0.5015
2024-01-10 22:05:53,676 - GAugM EPNet train, Epoch [ 31/70]: loss 0.7208, auc 0.5246, ap 0.5411
2024-01-10 22:05:53,754 - GAugM EPNet train, Epoch [ 32/70]: loss 0.7210, auc 0.5911, ap 0.5829
2024-01-10 22:05:53,845 - GAugM EPNet train, Epoch [ 33/70]: loss 0.7209, auc 0.5694, ap 0.5820
2024-01-10 22:05:53,922 - GAugM EPNet train, Epoch [ 34/70]: loss 0.7209, auc 0.4117, ap 0.4455
2024-01-10 22:05:53,998 - GAugM EPNet train, Epoch [ 35/70]: loss 0.7209, auc 0.4815, ap 0.4688
2024-01-10 22:05:54,074 - GAugM EPNet train, Epoch [ 36/70]: loss 0.7209, auc 0.5869, ap 0.6010
2024-01-10 22:05:54,152 - GAugM EPNet train, Epoch [ 37/70]: loss 0.7209, auc 0.3960, ap 0.4261
2024-01-10 22:05:54,228 - GAugM EPNet train, Epoch [ 38/70]: loss 0.7209, auc 0.5182, ap 0.5006
2024-01-10 22:05:54,313 - GAugM EPNet train, Epoch [ 39/70]: loss 0.7208, auc 0.4014, ap 0.4395
2024-01-10 22:05:54,390 - GAugM EPNet train, Epoch [ 40/70]: loss 0.7210, auc 0.5684, ap 0.5130
2024-01-10 22:05:54,465 - GAugM EPNet train, Epoch [ 41/70]: loss 0.7210, auc 0.4331, ap 0.4525
2024-01-10 22:05:54,547 - GAugM EPNet train, Epoch [ 42/70]: loss 0.7209, auc 0.5157, ap 0.5353
2024-01-10 22:05:54,621 - GAugM EPNet train, Epoch [ 43/70]: loss 0.7208, auc 0.3960, ap 0.4475
2024-01-10 22:05:54,699 - GAugM EPNet train, Epoch [ 44/70]: loss 0.7208, auc 0.4138, ap 0.4330
2024-01-10 22:05:54,776 - GAugM EPNet train, Epoch [ 45/70]: loss 0.7209, auc 0.5295, ap 0.5355
2024-01-10 22:05:54,854 - GAugM EPNet train, Epoch [ 46/70]: loss 0.7209, auc 0.4551, ap 0.4831
2024-01-10 22:05:54,938 - GAugM EPNet train, Epoch [ 47/70]: loss 0.7210, auc 0.4238, ap 0.4564
2024-01-10 22:05:55,017 - GAugM EPNet train, Epoch [ 48/70]: loss 0.7210, auc 0.5730, ap 0.5689
2024-01-10 22:05:55,091 - GAugM EPNet train, Epoch [ 49/70]: loss 0.7209, auc 0.4815, ap 0.5046
2024-01-10 22:05:55,169 - GAugM EPNet train, Epoch [ 50/70]: loss 0.7210, auc 0.5214, ap 0.5156
2024-01-10 22:05:55,252 - GAugM EPNet train, Epoch [ 51/70]: loss 0.7210, auc 0.4551, ap 0.4706
2024-01-10 22:05:55,328 - GAugM EPNet train, Epoch [ 52/70]: loss 0.7209, auc 0.4737, ap 0.5181
2024-01-10 22:05:55,406 - GAugM EPNet train, Epoch [ 53/70]: loss 0.7209, auc 0.5488, ap 0.5550
2024-01-10 22:05:55,484 - GAugM EPNet train, Epoch [ 54/70]: loss 0.7211, auc 0.5555, ap 0.5358
2024-01-10 22:05:55,559 - GAugM EPNet train, Epoch [ 55/70]: loss 0.7209, auc 0.5438, ap 0.5064
2024-01-10 22:05:55,634 - GAugM EPNet train, Epoch [ 56/70]: loss 0.7208, auc 0.5053, ap 0.4939
2024-01-10 22:05:55,725 - GAugM EPNet train, Epoch [ 57/70]: loss 0.7209, auc 0.4409, ap 0.4415
2024-01-10 22:05:55,804 - GAugM EPNet train, Epoch [ 58/70]: loss 0.7210, auc 0.5114, ap 0.5468
2024-01-10 22:05:55,882 - GAugM EPNet train, Epoch [ 59/70]: loss 0.7211, auc 0.5057, ap 0.5065
2024-01-10 22:05:55,962 - GAugM EPNet train, Epoch [ 60/70]: loss 0.7210, auc 0.5303, ap 0.5246
2024-01-10 22:05:56,052 - GAugM EPNet train, Epoch [ 61/70]: loss 0.7209, auc 0.5466, ap 0.5152
2024-01-10 22:05:56,130 - GAugM EPNet train, Epoch [ 62/70]: loss 0.7210, auc 0.4715, ap 0.4700
2024-01-10 22:05:56,208 - GAugM EPNet train, Epoch [ 63/70]: loss 0.7208, auc 0.4502, ap 0.4575
2024-01-10 22:05:56,288 - GAugM EPNet train, Epoch [ 64/70]: loss 0.7208, auc 0.4676, ap 0.5051
2024-01-10 22:05:56,371 - GAugM EPNet train, Epoch [ 65/70]: loss 0.7208, auc 0.5381, ap 0.5291
2024-01-10 22:05:56,449 - GAugM EPNet train, Epoch [ 66/70]: loss 0.7209, auc 0.4316, ap 0.4652
2024-01-10 22:05:56,522 - GAugM EPNet train, Epoch [ 67/70]: loss 0.7209, auc 0.5901, ap 0.5730
2024-01-10 22:05:56,599 - GAugM EPNet train, Epoch [ 68/70]: loss 0.7210, auc 0.5114, ap 0.5395
2024-01-10 22:05:56,677 - GAugM EPNet train, Epoch [ 69/70]: loss 0.7210, auc 0.5028, ap 0.5198
2024-01-10 22:05:56,752 - GAugM EPNet train, Epoch [ 70/70]: loss 0.7210, auc 0.4398, ap 0.4425
2024-01-10 22:05:56,753 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9e20a90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:05:57,426 - GAugM EPNet train, Epoch [  1/70]: loss 0.7210, auc 0.5244, ap 0.5023
2024-01-10 22:05:57,503 - GAugM EPNet train, Epoch [  2/70]: loss 0.7210, auc 0.4820, ap 0.5122
2024-01-10 22:05:57,581 - GAugM EPNet train, Epoch [  3/70]: loss 0.7209, auc 0.5418, ap 0.5433
2024-01-10 22:05:57,660 - GAugM EPNet train, Epoch [  4/70]: loss 0.7209, auc 0.5344, ap 0.5856
2024-01-10 22:05:57,736 - GAugM EPNet train, Epoch [  5/70]: loss 0.7209, auc 0.5607, ap 0.5679
2024-01-10 22:05:57,815 - GAugM EPNet train, Epoch [  6/70]: loss 0.7209, auc 0.5279, ap 0.5242
2024-01-10 22:05:57,891 - GAugM EPNet train, Epoch [  7/70]: loss 0.7209, auc 0.4147, ap 0.4351
2024-01-10 22:05:57,966 - GAugM EPNet train, Epoch [  8/70]: loss 0.7210, auc 0.4664, ap 0.4625
2024-01-10 22:05:58,042 - GAugM EPNet train, Epoch [  9/70]: loss 0.7209, auc 0.5205, ap 0.5243
2024-01-10 22:05:58,118 - GAugM EPNet train, Epoch [ 10/70]: loss 0.7208, auc 0.4802, ap 0.5274
2024-01-10 22:05:58,195 - GAugM EPNet train, Epoch [ 11/70]: loss 0.7209, auc 0.5443, ap 0.5751
2024-01-10 22:05:58,272 - GAugM EPNet train, Epoch [ 12/70]: loss 0.7210, auc 0.4632, ap 0.4928
2024-01-10 22:05:58,347 - GAugM EPNet train, Epoch [ 13/70]: loss 0.7209, auc 0.4820, ap 0.5184
2024-01-10 22:05:58,424 - GAugM EPNet train, Epoch [ 14/70]: loss 0.7209, auc 0.4838, ap 0.4868
2024-01-10 22:05:58,501 - GAugM EPNet train, Epoch [ 15/70]: loss 0.7210, auc 0.4183, ap 0.4491
2024-01-10 22:05:58,576 - GAugM EPNet train, Epoch [ 16/70]: loss 0.7209, auc 0.4336, ap 0.4748
2024-01-10 22:05:58,656 - GAugM EPNet train, Epoch [ 17/70]: loss 0.7210, auc 0.5472, ap 0.5416
2024-01-10 22:05:58,735 - GAugM EPNet train, Epoch [ 18/70]: loss 0.7210, auc 0.6451, ap 0.6034
2024-01-10 22:05:58,813 - GAugM EPNet train, Epoch [ 19/70]: loss 0.7209, auc 0.5066, ap 0.4930
2024-01-10 22:05:58,890 - GAugM EPNet train, Epoch [ 20/70]: loss 0.7210, auc 0.4731, ap 0.5302
2024-01-10 22:05:58,970 - GAugM EPNet train, Epoch [ 21/70]: loss 0.7209, auc 0.4980, ap 0.4925
2024-01-10 22:05:59,045 - GAugM EPNet train, Epoch [ 22/70]: loss 0.7210, auc 0.3200, ap 0.4180
2024-01-10 22:05:59,121 - GAugM EPNet train, Epoch [ 23/70]: loss 0.7208, auc 0.5507, ap 0.5249
2024-01-10 22:05:59,200 - GAugM EPNet train, Epoch [ 24/70]: loss 0.7209, auc 0.5799, ap 0.5458
2024-01-10 22:05:59,280 - GAugM EPNet train, Epoch [ 25/70]: loss 0.7209, auc 0.4048, ap 0.4408
2024-01-10 22:05:59,360 - GAugM EPNet train, Epoch [ 26/70]: loss 0.7210, auc 0.5774, ap 0.5767
2024-01-10 22:05:59,437 - GAugM EPNet train, Epoch [ 27/70]: loss 0.7209, auc 0.4528, ap 0.4809
2024-01-10 22:05:59,513 - GAugM EPNet train, Epoch [ 28/70]: loss 0.7209, auc 0.5486, ap 0.5822
2024-01-10 22:05:59,590 - GAugM EPNet train, Epoch [ 29/70]: loss 0.7210, auc 0.4721, ap 0.5078
2024-01-10 22:05:59,666 - GAugM EPNet train, Epoch [ 30/70]: loss 0.7209, auc 0.5475, ap 0.5489
2024-01-10 22:05:59,744 - GAugM EPNet train, Epoch [ 31/70]: loss 0.7208, auc 0.4632, ap 0.4732
2024-01-10 22:05:59,821 - GAugM EPNet train, Epoch [ 32/70]: loss 0.7210, auc 0.5593, ap 0.5347
2024-01-10 22:05:59,898 - GAugM EPNet train, Epoch [ 33/70]: loss 0.7209, auc 0.5244, ap 0.5288
2024-01-10 22:05:59,978 - GAugM EPNet train, Epoch [ 34/70]: loss 0.7209, auc 0.5052, ap 0.4974
2024-01-10 22:06:00,053 - GAugM EPNet train, Epoch [ 35/70]: loss 0.7209, auc 0.4973, ap 0.5143
2024-01-10 22:06:00,130 - GAugM EPNet train, Epoch [ 36/70]: loss 0.7209, auc 0.5433, ap 0.5257
2024-01-10 22:06:00,206 - GAugM EPNet train, Epoch [ 37/70]: loss 0.7209, auc 0.4617, ap 0.4998
2024-01-10 22:06:00,283 - GAugM EPNet train, Epoch [ 38/70]: loss 0.7209, auc 0.4852, ap 0.4757
2024-01-10 22:06:00,360 - GAugM EPNet train, Epoch [ 39/70]: loss 0.7208, auc 0.5091, ap 0.5120
2024-01-10 22:06:00,435 - GAugM EPNet train, Epoch [ 40/70]: loss 0.7210, auc 0.5208, ap 0.5080
2024-01-10 22:06:00,510 - GAugM EPNet train, Epoch [ 41/70]: loss 0.7210, auc 0.4357, ap 0.4765
2024-01-10 22:06:00,586 - GAugM EPNet train, Epoch [ 42/70]: loss 0.7209, auc 0.4603, ap 0.5140
2024-01-10 22:06:00,662 - GAugM EPNet train, Epoch [ 43/70]: loss 0.7208, auc 0.4429, ap 0.4498
2024-01-10 22:06:00,741 - GAugM EPNet train, Epoch [ 44/70]: loss 0.7208, auc 0.4621, ap 0.4806
2024-01-10 22:06:00,820 - GAugM EPNet train, Epoch [ 45/70]: loss 0.7209, auc 0.5344, ap 0.5334
2024-01-10 22:06:00,897 - GAugM EPNet train, Epoch [ 46/70]: loss 0.7209, auc 0.4934, ap 0.4818
2024-01-10 22:06:00,973 - GAugM EPNet train, Epoch [ 47/70]: loss 0.7210, auc 0.4781, ap 0.5072
2024-01-10 22:06:01,052 - GAugM EPNet train, Epoch [ 48/70]: loss 0.7210, auc 0.5500, ap 0.5866
2024-01-10 22:06:01,128 - GAugM EPNet train, Epoch [ 49/70]: loss 0.7209, auc 0.5105, ap 0.5446
2024-01-10 22:06:01,204 - GAugM EPNet train, Epoch [ 50/70]: loss 0.7210, auc 0.5732, ap 0.5461
2024-01-10 22:06:01,279 - GAugM EPNet train, Epoch [ 51/70]: loss 0.7210, auc 0.5593, ap 0.5591
2024-01-10 22:06:01,355 - GAugM EPNet train, Epoch [ 52/70]: loss 0.7209, auc 0.4938, ap 0.5237
2024-01-10 22:06:01,431 - GAugM EPNet train, Epoch [ 53/70]: loss 0.7209, auc 0.6166, ap 0.5718
2024-01-10 22:06:01,508 - GAugM EPNet train, Epoch [ 54/70]: loss 0.7211, auc 0.5457, ap 0.5393
2024-01-10 22:06:01,585 - GAugM EPNet train, Epoch [ 55/70]: loss 0.7209, auc 0.5628, ap 0.5727
2024-01-10 22:06:01,662 - GAugM EPNet train, Epoch [ 56/70]: loss 0.7208, auc 0.4480, ap 0.4579
2024-01-10 22:06:01,738 - GAugM EPNet train, Epoch [ 57/70]: loss 0.7209, auc 0.4169, ap 0.4315
2024-01-10 22:06:01,820 - GAugM EPNet train, Epoch [ 58/70]: loss 0.7210, auc 0.5190, ap 0.5507
2024-01-10 22:06:01,896 - GAugM EPNet train, Epoch [ 59/70]: loss 0.7211, auc 0.5739, ap 0.5671
2024-01-10 22:06:01,973 - GAugM EPNet train, Epoch [ 60/70]: loss 0.7210, auc 0.5198, ap 0.5103
2024-01-10 22:06:02,050 - GAugM EPNet train, Epoch [ 61/70]: loss 0.7209, auc 0.6273, ap 0.6413
2024-01-10 22:06:02,125 - GAugM EPNet train, Epoch [ 62/70]: loss 0.7210, auc 0.5272, ap 0.5500
2024-01-10 22:06:02,205 - GAugM EPNet train, Epoch [ 63/70]: loss 0.7208, auc 0.4375, ap 0.4443
2024-01-10 22:06:02,282 - GAugM EPNet train, Epoch [ 64/70]: loss 0.7208, auc 0.5500, ap 0.5638
2024-01-10 22:06:02,359 - GAugM EPNet train, Epoch [ 65/70]: loss 0.7208, auc 0.5692, ap 0.5536
2024-01-10 22:06:02,436 - GAugM EPNet train, Epoch [ 66/70]: loss 0.7209, auc 0.4753, ap 0.4817
2024-01-10 22:06:02,511 - GAugM EPNet train, Epoch [ 67/70]: loss 0.7209, auc 0.5301, ap 0.5263
2024-01-10 22:06:02,587 - GAugM EPNet train, Epoch [ 68/70]: loss 0.7210, auc 0.5710, ap 0.5681
2024-01-10 22:06:02,663 - GAugM EPNet train, Epoch [ 69/70]: loss 0.7210, auc 0.5390, ap 0.5564
2024-01-10 22:06:02,738 - GAugM EPNet train, Epoch [ 70/70]: loss 0.7210, auc 0.4279, ap 0.4343
2024-01-10 22:06:02,748 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035681d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:06:03,456 - GAugM EPNet train, Epoch [  1/70]: loss 0.7210, auc 0.4858, ap 0.4882
2024-01-10 22:06:03,533 - GAugM EPNet train, Epoch [  2/70]: loss 0.7210, auc 0.4797, ap 0.4751
2024-01-10 22:06:03,613 - GAugM EPNet train, Epoch [  3/70]: loss 0.7209, auc 0.5367, ap 0.5045
2024-01-10 22:06:03,704 - GAugM EPNet train, Epoch [  4/70]: loss 0.7209, auc 0.5064, ap 0.5006
2024-01-10 22:06:03,787 - GAugM EPNet train, Epoch [  5/70]: loss 0.7209, auc 0.5769, ap 0.5287
2024-01-10 22:06:03,866 - GAugM EPNet train, Epoch [  6/70]: loss 0.7209, auc 0.5114, ap 0.5023
2024-01-10 22:06:03,953 - GAugM EPNet train, Epoch [  7/70]: loss 0.7209, auc 0.4114, ap 0.4306
2024-01-10 22:06:04,033 - GAugM EPNet train, Epoch [  8/70]: loss 0.7210, auc 0.5160, ap 0.5018
2024-01-10 22:06:04,116 - GAugM EPNet train, Epoch [  9/70]: loss 0.7209, auc 0.4662, ap 0.4714
2024-01-10 22:06:04,198 - GAugM EPNet train, Epoch [ 10/70]: loss 0.7208, auc 0.4591, ap 0.4729
2024-01-10 22:06:04,276 - GAugM EPNet train, Epoch [ 11/70]: loss 0.7209, auc 0.4612, ap 0.5020
2024-01-10 22:06:04,353 - GAugM EPNet train, Epoch [ 12/70]: loss 0.7210, auc 0.4712, ap 0.4648
2024-01-10 22:06:04,429 - GAugM EPNet train, Epoch [ 13/70]: loss 0.7209, auc 0.5267, ap 0.4915
2024-01-10 22:06:04,504 - GAugM EPNet train, Epoch [ 14/70]: loss 0.7209, auc 0.5587, ap 0.5424
2024-01-10 22:06:04,580 - GAugM EPNet train, Epoch [ 15/70]: loss 0.7210, auc 0.3871, ap 0.4385
2024-01-10 22:06:04,660 - GAugM EPNet train, Epoch [ 16/70]: loss 0.7209, auc 0.5164, ap 0.5109
2024-01-10 22:06:04,737 - GAugM EPNet train, Epoch [ 17/70]: loss 0.7210, auc 0.5171, ap 0.5214
2024-01-10 22:06:04,820 - GAugM EPNet train, Epoch [ 18/70]: loss 0.7210, auc 0.6040, ap 0.5860
2024-01-10 22:06:04,898 - GAugM EPNet train, Epoch [ 19/70]: loss 0.7209, auc 0.5032, ap 0.4869
2024-01-10 22:06:04,973 - GAugM EPNet train, Epoch [ 20/70]: loss 0.7210, auc 0.5331, ap 0.5519
2024-01-10 22:06:05,048 - GAugM EPNet train, Epoch [ 21/70]: loss 0.7209, auc 0.5481, ap 0.5386
2024-01-10 22:06:05,127 - GAugM EPNet train, Epoch [ 22/70]: loss 0.7210, auc 0.3654, ap 0.4146
2024-01-10 22:06:05,205 - GAugM EPNet train, Epoch [ 23/70]: loss 0.7208, auc 0.4576, ap 0.4609
2024-01-10 22:06:05,285 - GAugM EPNet train, Epoch [ 24/70]: loss 0.7209, auc 0.4705, ap 0.4634
2024-01-10 22:06:05,361 - GAugM EPNet train, Epoch [ 25/70]: loss 0.7209, auc 0.5182, ap 0.4939
2024-01-10 22:06:05,440 - GAugM EPNet train, Epoch [ 26/70]: loss 0.7210, auc 0.5897, ap 0.5669
2024-01-10 22:06:05,521 - GAugM EPNet train, Epoch [ 27/70]: loss 0.7209, auc 0.4498, ap 0.4763
2024-01-10 22:06:05,598 - GAugM EPNet train, Epoch [ 28/70]: loss 0.7209, auc 0.5837, ap 0.5591
2024-01-10 22:06:05,682 - GAugM EPNet train, Epoch [ 29/70]: loss 0.7210, auc 0.5014, ap 0.5178
2024-01-10 22:06:05,760 - GAugM EPNet train, Epoch [ 30/70]: loss 0.7209, auc 0.5217, ap 0.5204
2024-01-10 22:06:05,846 - GAugM EPNet train, Epoch [ 31/70]: loss 0.7208, auc 0.4751, ap 0.4749
2024-01-10 22:06:05,929 - GAugM EPNet train, Epoch [ 32/70]: loss 0.7210, auc 0.5299, ap 0.5206
2024-01-10 22:06:06,009 - GAugM EPNet train, Epoch [ 33/70]: loss 0.7209, auc 0.5285, ap 0.5236
2024-01-10 22:06:06,091 - GAugM EPNet train, Epoch [ 34/70]: loss 0.7209, auc 0.4188, ap 0.4410
2024-01-10 22:06:06,168 - GAugM EPNet train, Epoch [ 35/70]: loss 0.7209, auc 0.5317, ap 0.5225
2024-01-10 22:06:06,244 - GAugM EPNet train, Epoch [ 36/70]: loss 0.7209, auc 0.5384, ap 0.5203
2024-01-10 22:06:06,322 - GAugM EPNet train, Epoch [ 37/70]: loss 0.7209, auc 0.4883, ap 0.4781
2024-01-10 22:06:06,407 - GAugM EPNet train, Epoch [ 38/70]: loss 0.7209, auc 0.5025, ap 0.4977
2024-01-10 22:06:06,492 - GAugM EPNet train, Epoch [ 39/70]: loss 0.7208, auc 0.4099, ap 0.4534
2024-01-10 22:06:06,571 - GAugM EPNet train, Epoch [ 40/70]: loss 0.7210, auc 0.5765, ap 0.5352
2024-01-10 22:06:06,649 - GAugM EPNet train, Epoch [ 41/70]: loss 0.7210, auc 0.4701, ap 0.4780
2024-01-10 22:06:06,725 - GAugM EPNet train, Epoch [ 42/70]: loss 0.7209, auc 0.5043, ap 0.5079
2024-01-10 22:06:06,800 - GAugM EPNet train, Epoch [ 43/70]: loss 0.7208, auc 0.4519, ap 0.4674
2024-01-10 22:06:06,880 - GAugM EPNet train, Epoch [ 44/70]: loss 0.7208, auc 0.4213, ap 0.4431
2024-01-10 22:06:06,962 - GAugM EPNet train, Epoch [ 45/70]: loss 0.7209, auc 0.5698, ap 0.5434
2024-01-10 22:06:07,046 - GAugM EPNet train, Epoch [ 46/70]: loss 0.7209, auc 0.4683, ap 0.4796
2024-01-10 22:06:07,123 - GAugM EPNet train, Epoch [ 47/70]: loss 0.7210, auc 0.4922, ap 0.5129
2024-01-10 22:06:07,199 - GAugM EPNet train, Epoch [ 48/70]: loss 0.7210, auc 0.6299, ap 0.6174
2024-01-10 22:06:07,275 - GAugM EPNet train, Epoch [ 49/70]: loss 0.7209, auc 0.5271, ap 0.5032
2024-01-10 22:06:07,350 - GAugM EPNet train, Epoch [ 50/70]: loss 0.7210, auc 0.5246, ap 0.5171
2024-01-10 22:06:07,432 - GAugM EPNet train, Epoch [ 51/70]: loss 0.7210, auc 0.4836, ap 0.5109
2024-01-10 22:06:07,524 - GAugM EPNet train, Epoch [ 52/70]: loss 0.7209, auc 0.4010, ap 0.4552
2024-01-10 22:06:07,615 - GAugM EPNet train, Epoch [ 53/70]: loss 0.7209, auc 0.5388, ap 0.5248
2024-01-10 22:06:07,714 - GAugM EPNet train, Epoch [ 54/70]: loss 0.7211, auc 0.4932, ap 0.4831
2024-01-10 22:06:07,805 - GAugM EPNet train, Epoch [ 55/70]: loss 0.7209, auc 0.5655, ap 0.5459
2024-01-10 22:06:07,905 - GAugM EPNet train, Epoch [ 56/70]: loss 0.7208, auc 0.4651, ap 0.4645
2024-01-10 22:06:07,997 - GAugM EPNet train, Epoch [ 57/70]: loss 0.7209, auc 0.4359, ap 0.4593
2024-01-10 22:06:08,089 - GAugM EPNet train, Epoch [ 58/70]: loss 0.7210, auc 0.4897, ap 0.5342
2024-01-10 22:06:08,187 - GAugM EPNet train, Epoch [ 59/70]: loss 0.7211, auc 0.5082, ap 0.5048
2024-01-10 22:06:08,278 - GAugM EPNet train, Epoch [ 60/70]: loss 0.7210, auc 0.5285, ap 0.5088
2024-01-10 22:06:08,369 - GAugM EPNet train, Epoch [ 61/70]: loss 0.7209, auc 0.5844, ap 0.5625
2024-01-10 22:06:08,464 - GAugM EPNet train, Epoch [ 62/70]: loss 0.7210, auc 0.5317, ap 0.5234
2024-01-10 22:06:08,553 - GAugM EPNet train, Epoch [ 63/70]: loss 0.7208, auc 0.4740, ap 0.4699
2024-01-10 22:06:08,646 - GAugM EPNet train, Epoch [ 64/70]: loss 0.7208, auc 0.5263, ap 0.5398
2024-01-10 22:06:08,735 - GAugM EPNet train, Epoch [ 65/70]: loss 0.7208, auc 0.6072, ap 0.5902
2024-01-10 22:06:08,829 - GAugM EPNet train, Epoch [ 66/70]: loss 0.7209, auc 0.4583, ap 0.4954
2024-01-10 22:06:08,923 - GAugM EPNet train, Epoch [ 67/70]: loss 0.7209, auc 0.5918, ap 0.5573
2024-01-10 22:06:09,012 - GAugM EPNet train, Epoch [ 68/70]: loss 0.7210, auc 0.5142, ap 0.5112
2024-01-10 22:06:09,101 - GAugM EPNet train, Epoch [ 69/70]: loss 0.7210, auc 0.5570, ap 0.5577
2024-01-10 22:06:09,190 - GAugM EPNet train, Epoch [ 70/70]: loss 0.7210, auc 0.5036, ap 0.4882
2024-01-10 22:06:09,203 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d06766b50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:06:09,938 - GAugM EPNet train, Epoch [  1/70]: loss 0.7210, auc 0.4578, ap 0.4641
2024-01-10 22:06:10,020 - GAugM EPNet train, Epoch [  2/70]: loss 0.7210, auc 0.5744, ap 0.5535
2024-01-10 22:06:10,103 - GAugM EPNet train, Epoch [  3/70]: loss 0.7209, auc 0.6056, ap 0.5555
2024-01-10 22:06:10,195 - GAugM EPNet train, Epoch [  4/70]: loss 0.7209, auc 0.5077, ap 0.4887
2024-01-10 22:06:10,285 - GAugM EPNet train, Epoch [  5/70]: loss 0.7209, auc 0.5721, ap 0.5547
2024-01-10 22:06:10,365 - GAugM EPNet train, Epoch [  6/70]: loss 0.7209, auc 0.5465, ap 0.5122
2024-01-10 22:06:10,444 - GAugM EPNet train, Epoch [  7/70]: loss 0.7209, auc 0.4813, ap 0.4738
2024-01-10 22:06:10,525 - GAugM EPNet train, Epoch [  8/70]: loss 0.7210, auc 0.5009, ap 0.5045
2024-01-10 22:06:10,623 - GAugM EPNet train, Epoch [  9/70]: loss 0.7209, auc 0.4137, ap 0.4287
2024-01-10 22:06:10,713 - GAugM EPNet train, Epoch [ 10/70]: loss 0.7208, auc 0.5228, ap 0.5041
2024-01-10 22:06:10,796 - GAugM EPNet train, Epoch [ 11/70]: loss 0.7209, auc 0.4393, ap 0.4835
2024-01-10 22:06:10,897 - GAugM EPNet train, Epoch [ 12/70]: loss 0.7210, auc 0.4991, ap 0.4849
2024-01-10 22:06:10,995 - GAugM EPNet train, Epoch [ 13/70]: loss 0.7209, auc 0.5899, ap 0.5525
2024-01-10 22:06:11,086 - GAugM EPNet train, Epoch [ 14/70]: loss 0.7209, auc 0.5963, ap 0.5682
2024-01-10 22:06:11,186 - GAugM EPNet train, Epoch [ 15/70]: loss 0.7210, auc 0.4470, ap 0.4897
2024-01-10 22:06:11,269 - GAugM EPNet train, Epoch [ 16/70]: loss 0.7209, auc 0.4785, ap 0.4995
2024-01-10 22:06:11,373 - GAugM EPNet train, Epoch [ 17/70]: loss 0.7210, auc 0.5340, ap 0.5187
2024-01-10 22:06:11,467 - GAugM EPNet train, Epoch [ 18/70]: loss 0.7210, auc 0.6219, ap 0.5976
2024-01-10 22:06:11,555 - GAugM EPNet train, Epoch [ 19/70]: loss 0.7209, auc 0.5224, ap 0.5129
2024-01-10 22:06:11,648 - GAugM EPNet train, Epoch [ 20/70]: loss 0.7210, auc 0.4379, ap 0.4794
2024-01-10 22:06:11,749 - GAugM EPNet train, Epoch [ 21/70]: loss 0.7209, auc 0.5522, ap 0.5789
2024-01-10 22:06:11,844 - GAugM EPNet train, Epoch [ 22/70]: loss 0.7210, auc 0.3111, ap 0.3894
2024-01-10 22:06:11,934 - GAugM EPNet train, Epoch [ 23/70]: loss 0.7208, auc 0.4826, ap 0.4910
2024-01-10 22:06:12,026 - GAugM EPNet train, Epoch [ 24/70]: loss 0.7209, auc 0.4888, ap 0.5033
2024-01-10 22:06:12,113 - GAugM EPNet train, Epoch [ 25/70]: loss 0.7209, auc 0.4087, ap 0.4360
2024-01-10 22:06:12,206 - GAugM EPNet train, Epoch [ 26/70]: loss 0.7210, auc 0.6112, ap 0.6098
2024-01-10 22:06:12,306 - GAugM EPNet train, Epoch [ 27/70]: loss 0.7209, auc 0.5030, ap 0.5302
2024-01-10 22:06:12,393 - GAugM EPNet train, Epoch [ 28/70]: loss 0.7209, auc 0.5294, ap 0.5398
2024-01-10 22:06:12,498 - GAugM EPNet train, Epoch [ 29/70]: loss 0.7210, auc 0.5105, ap 0.5231
2024-01-10 22:06:12,594 - GAugM EPNet train, Epoch [ 30/70]: loss 0.7209, auc 0.5116, ap 0.5135
2024-01-10 22:06:12,688 - GAugM EPNet train, Epoch [ 31/70]: loss 0.7208, auc 0.5415, ap 0.5380
2024-01-10 22:06:12,791 - GAugM EPNet train, Epoch [ 32/70]: loss 0.7210, auc 0.5972, ap 0.6067
2024-01-10 22:06:12,886 - GAugM EPNet train, Epoch [ 33/70]: loss 0.7209, auc 0.4980, ap 0.5216
2024-01-10 22:06:12,985 - GAugM EPNet train, Epoch [ 34/70]: loss 0.7209, auc 0.5027, ap 0.4867
2024-01-10 22:06:13,078 - GAugM EPNet train, Epoch [ 35/70]: loss 0.7209, auc 0.6013, ap 0.5604
2024-01-10 22:06:13,178 - GAugM EPNet train, Epoch [ 36/70]: loss 0.7209, auc 0.4829, ap 0.4844
2024-01-10 22:06:13,271 - GAugM EPNet train, Epoch [ 37/70]: loss 0.7209, auc 0.3855, ap 0.4271
2024-01-10 22:06:13,368 - GAugM EPNet train, Epoch [ 38/70]: loss 0.7209, auc 0.4899, ap 0.4737
2024-01-10 22:06:13,462 - GAugM EPNet train, Epoch [ 39/70]: loss 0.7208, auc 0.4827, ap 0.5093
2024-01-10 22:06:13,556 - GAugM EPNet train, Epoch [ 40/70]: loss 0.7210, auc 0.5641, ap 0.5268
2024-01-10 22:06:13,654 - GAugM EPNet train, Epoch [ 41/70]: loss 0.7210, auc 0.4658, ap 0.4953
2024-01-10 22:06:13,752 - GAugM EPNet train, Epoch [ 42/70]: loss 0.7209, auc 0.4888, ap 0.5142
2024-01-10 22:06:13,847 - GAugM EPNet train, Epoch [ 43/70]: loss 0.7208, auc 0.4094, ap 0.4766
2024-01-10 22:06:13,945 - GAugM EPNet train, Epoch [ 44/70]: loss 0.7208, auc 0.4664, ap 0.4755
2024-01-10 22:06:14,043 - GAugM EPNet train, Epoch [ 45/70]: loss 0.7209, auc 0.5865, ap 0.5622
2024-01-10 22:06:14,138 - GAugM EPNet train, Epoch [ 46/70]: loss 0.7209, auc 0.4806, ap 0.5081
2024-01-10 22:06:14,233 - GAugM EPNet train, Epoch [ 47/70]: loss 0.7210, auc 0.5189, ap 0.5186
2024-01-10 22:06:14,331 - GAugM EPNet train, Epoch [ 48/70]: loss 0.7210, auc 0.6210, ap 0.6032
2024-01-10 22:06:14,423 - GAugM EPNet train, Epoch [ 49/70]: loss 0.7209, auc 0.5482, ap 0.5561
2024-01-10 22:06:14,518 - GAugM EPNet train, Epoch [ 50/70]: loss 0.7210, auc 0.4763, ap 0.4792
2024-01-10 22:06:14,619 - GAugM EPNet train, Epoch [ 51/70]: loss 0.7210, auc 0.4557, ap 0.4915
2024-01-10 22:06:14,712 - GAugM EPNet train, Epoch [ 52/70]: loss 0.7209, auc 0.4432, ap 0.4432
2024-01-10 22:06:14,805 - GAugM EPNet train, Epoch [ 53/70]: loss 0.7209, auc 0.5514, ap 0.5207
2024-01-10 22:06:14,896 - GAugM EPNet train, Epoch [ 54/70]: loss 0.7211, auc 0.5235, ap 0.5155
2024-01-10 22:06:14,990 - GAugM EPNet train, Epoch [ 55/70]: loss 0.7209, auc 0.5532, ap 0.5364
2024-01-10 22:06:15,091 - GAugM EPNet train, Epoch [ 56/70]: loss 0.7208, auc 0.4900, ap 0.4716
2024-01-10 22:06:15,174 - GAugM EPNet train, Epoch [ 57/70]: loss 0.7209, auc 0.4267, ap 0.4339
2024-01-10 22:06:15,270 - GAugM EPNet train, Epoch [ 58/70]: loss 0.7210, auc 0.5125, ap 0.5471
2024-01-10 22:06:15,363 - GAugM EPNet train, Epoch [ 59/70]: loss 0.7211, auc 0.5000, ap 0.5122
2024-01-10 22:06:15,458 - GAugM EPNet train, Epoch [ 60/70]: loss 0.7210, auc 0.5194, ap 0.5145
2024-01-10 22:06:15,555 - GAugM EPNet train, Epoch [ 61/70]: loss 0.7209, auc 0.5639, ap 0.5633
2024-01-10 22:06:15,652 - GAugM EPNet train, Epoch [ 62/70]: loss 0.7210, auc 0.5634, ap 0.5753
2024-01-10 22:06:15,755 - GAugM EPNet train, Epoch [ 63/70]: loss 0.7208, auc 0.4929, ap 0.4846
2024-01-10 22:06:15,842 - GAugM EPNet train, Epoch [ 64/70]: loss 0.7208, auc 0.4021, ap 0.4338
2024-01-10 22:06:15,924 - GAugM EPNet train, Epoch [ 65/70]: loss 0.7208, auc 0.6365, ap 0.6178
2024-01-10 22:06:16,020 - GAugM EPNet train, Epoch [ 66/70]: loss 0.7209, auc 0.4325, ap 0.4480
2024-01-10 22:06:16,115 - GAugM EPNet train, Epoch [ 67/70]: loss 0.7209, auc 0.5628, ap 0.5329
2024-01-10 22:06:16,214 - GAugM EPNet train, Epoch [ 68/70]: loss 0.7210, auc 0.5482, ap 0.5487
2024-01-10 22:06:16,311 - GAugM EPNet train, Epoch [ 69/70]: loss 0.7210, auc 0.5358, ap 0.5482
2024-01-10 22:06:16,394 - GAugM EPNet train, Epoch [ 70/70]: loss 0.7210, auc 0.4461, ap 0.4438
2024-01-10 22:06:16,402 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035681d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:06:17,132 - GAugM EPNet train, Epoch [  1/70]: loss 0.7210, auc 0.5100, ap 0.5237
2024-01-10 22:06:17,226 - GAugM EPNet train, Epoch [  2/70]: loss 0.7210, auc 0.4840, ap 0.4919
2024-01-10 22:06:17,312 - GAugM EPNet train, Epoch [  3/70]: loss 0.7209, auc 0.5644, ap 0.5478
2024-01-10 22:06:17,401 - GAugM EPNet train, Epoch [  4/70]: loss 0.7209, auc 0.4672, ap 0.4968
2024-01-10 22:06:17,484 - GAugM EPNet train, Epoch [  5/70]: loss 0.7209, auc 0.5676, ap 0.5631
2024-01-10 22:06:17,565 - GAugM EPNet train, Epoch [  6/70]: loss 0.7209, auc 0.4573, ap 0.4676
2024-01-10 22:06:17,652 - GAugM EPNet train, Epoch [  7/70]: loss 0.7209, auc 0.4438, ap 0.4783
2024-01-10 22:06:17,738 - GAugM EPNet train, Epoch [  8/70]: loss 0.7210, auc 0.4583, ap 0.4728
2024-01-10 22:06:17,823 - GAugM EPNet train, Epoch [  9/70]: loss 0.7209, auc 0.4989, ap 0.5254
2024-01-10 22:06:17,904 - GAugM EPNet train, Epoch [ 10/70]: loss 0.7208, auc 0.5310, ap 0.5339
2024-01-10 22:06:18,007 - GAugM EPNet train, Epoch [ 11/70]: loss 0.7209, auc 0.4811, ap 0.4750
2024-01-10 22:06:18,107 - GAugM EPNet train, Epoch [ 12/70]: loss 0.7210, auc 0.4487, ap 0.4592
2024-01-10 22:06:18,208 - GAugM EPNet train, Epoch [ 13/70]: loss 0.7209, auc 0.4559, ap 0.4768
2024-01-10 22:06:18,306 - GAugM EPNet train, Epoch [ 14/70]: loss 0.7209, auc 0.5570, ap 0.5440
2024-01-10 22:06:18,404 - GAugM EPNet train, Epoch [ 15/70]: loss 0.7210, auc 0.4245, ap 0.4784
2024-01-10 22:06:18,500 - GAugM EPNet train, Epoch [ 16/70]: loss 0.7209, auc 0.5619, ap 0.5415
2024-01-10 22:06:18,581 - GAugM EPNet train, Epoch [ 17/70]: loss 0.7210, auc 0.5367, ap 0.5247
2024-01-10 22:06:18,669 - GAugM EPNet train, Epoch [ 18/70]: loss 0.7210, auc 0.5384, ap 0.5386
2024-01-10 22:06:18,765 - GAugM EPNet train, Epoch [ 19/70]: loss 0.7209, auc 0.4872, ap 0.4989
2024-01-10 22:06:18,864 - GAugM EPNet train, Epoch [ 20/70]: loss 0.7210, auc 0.5420, ap 0.5514
2024-01-10 22:06:18,959 - GAugM EPNet train, Epoch [ 21/70]: loss 0.7209, auc 0.5619, ap 0.5570
2024-01-10 22:06:19,053 - GAugM EPNet train, Epoch [ 22/70]: loss 0.7210, auc 0.3248, ap 0.4264
2024-01-10 22:06:19,146 - GAugM EPNet train, Epoch [ 23/70]: loss 0.7208, auc 0.4519, ap 0.4726
2024-01-10 22:06:19,240 - GAugM EPNet train, Epoch [ 24/70]: loss 0.7209, auc 0.5680, ap 0.5749
2024-01-10 22:06:19,337 - GAugM EPNet train, Epoch [ 25/70]: loss 0.7209, auc 0.4907, ap 0.4922
2024-01-10 22:06:19,428 - GAugM EPNet train, Epoch [ 26/70]: loss 0.7210, auc 0.4665, ap 0.5075
2024-01-10 22:06:19,521 - GAugM EPNet train, Epoch [ 27/70]: loss 0.7209, auc 0.4256, ap 0.4545
2024-01-10 22:06:19,617 - GAugM EPNet train, Epoch [ 28/70]: loss 0.7209, auc 0.5004, ap 0.5310
2024-01-10 22:06:19,701 - GAugM EPNet train, Epoch [ 29/70]: loss 0.7210, auc 0.4808, ap 0.4837
2024-01-10 22:06:19,782 - GAugM EPNet train, Epoch [ 30/70]: loss 0.7209, auc 0.5406, ap 0.5614
2024-01-10 22:06:19,865 - GAugM EPNet train, Epoch [ 31/70]: loss 0.7208, auc 0.4733, ap 0.5178
2024-01-10 22:06:19,944 - GAugM EPNet train, Epoch [ 32/70]: loss 0.7210, auc 0.5053, ap 0.5103
2024-01-10 22:06:20,029 - GAugM EPNet train, Epoch [ 33/70]: loss 0.7209, auc 0.5555, ap 0.5722
2024-01-10 22:06:20,124 - GAugM EPNet train, Epoch [ 34/70]: loss 0.7209, auc 0.5146, ap 0.4905
2024-01-10 22:06:20,214 - GAugM EPNet train, Epoch [ 35/70]: loss 0.7209, auc 0.6136, ap 0.5709
2024-01-10 22:06:20,306 - GAugM EPNet train, Epoch [ 36/70]: loss 0.7209, auc 0.5555, ap 0.5776
2024-01-10 22:06:20,396 - GAugM EPNet train, Epoch [ 37/70]: loss 0.7209, auc 0.5004, ap 0.5040
2024-01-10 22:06:20,485 - GAugM EPNet train, Epoch [ 38/70]: loss 0.7209, auc 0.4637, ap 0.4691
2024-01-10 22:06:20,581 - GAugM EPNet train, Epoch [ 39/70]: loss 0.7208, auc 0.4142, ap 0.4751
2024-01-10 22:06:20,671 - GAugM EPNet train, Epoch [ 40/70]: loss 0.7210, auc 0.6082, ap 0.5638
2024-01-10 22:06:20,764 - GAugM EPNet train, Epoch [ 41/70]: loss 0.7210, auc 0.5538, ap 0.5863
2024-01-10 22:06:20,854 - GAugM EPNet train, Epoch [ 42/70]: loss 0.7209, auc 0.5708, ap 0.5708
2024-01-10 22:06:20,943 - GAugM EPNet train, Epoch [ 43/70]: loss 0.7208, auc 0.4178, ap 0.4452
2024-01-10 22:06:21,042 - GAugM EPNet train, Epoch [ 44/70]: loss 0.7208, auc 0.4441, ap 0.4767
2024-01-10 22:06:21,131 - GAugM EPNet train, Epoch [ 45/70]: loss 0.7209, auc 0.5541, ap 0.5802
2024-01-10 22:06:21,218 - GAugM EPNet train, Epoch [ 46/70]: loss 0.7209, auc 0.4530, ap 0.4985
2024-01-10 22:06:21,310 - GAugM EPNet train, Epoch [ 47/70]: loss 0.7210, auc 0.4786, ap 0.4763
2024-01-10 22:06:21,399 - GAugM EPNet train, Epoch [ 48/70]: loss 0.7210, auc 0.5844, ap 0.5920
2024-01-10 22:06:21,489 - GAugM EPNet train, Epoch [ 49/70]: loss 0.7209, auc 0.5434, ap 0.5338
2024-01-10 22:06:21,585 - GAugM EPNet train, Epoch [ 50/70]: loss 0.7210, auc 0.4712, ap 0.4861
2024-01-10 22:06:21,674 - GAugM EPNet train, Epoch [ 51/70]: loss 0.7210, auc 0.5320, ap 0.5645
2024-01-10 22:06:21,764 - GAugM EPNet train, Epoch [ 52/70]: loss 0.7209, auc 0.4423, ap 0.5074
2024-01-10 22:06:21,853 - GAugM EPNet train, Epoch [ 53/70]: loss 0.7209, auc 0.5566, ap 0.5684
2024-01-10 22:06:21,951 - GAugM EPNet train, Epoch [ 54/70]: loss 0.7211, auc 0.5648, ap 0.5641
2024-01-10 22:06:22,041 - GAugM EPNet train, Epoch [ 55/70]: loss 0.7209, auc 0.6655, ap 0.6819
2024-01-10 22:06:22,131 - GAugM EPNet train, Epoch [ 56/70]: loss 0.7208, auc 0.5110, ap 0.5061
2024-01-10 22:06:22,219 - GAugM EPNet train, Epoch [ 57/70]: loss 0.7209, auc 0.4138, ap 0.4405
2024-01-10 22:06:22,310 - GAugM EPNet train, Epoch [ 58/70]: loss 0.7210, auc 0.5146, ap 0.5598
2024-01-10 22:06:22,407 - GAugM EPNet train, Epoch [ 59/70]: loss 0.7211, auc 0.4897, ap 0.5352
2024-01-10 22:06:22,496 - GAugM EPNet train, Epoch [ 60/70]: loss 0.7210, auc 0.4466, ap 0.4653
2024-01-10 22:06:22,586 - GAugM EPNet train, Epoch [ 61/70]: loss 0.7209, auc 0.5313, ap 0.5366
2024-01-10 22:06:22,675 - GAugM EPNet train, Epoch [ 62/70]: loss 0.7210, auc 0.4740, ap 0.5065
2024-01-10 22:06:22,765 - GAugM EPNet train, Epoch [ 63/70]: loss 0.7208, auc 0.4936, ap 0.5106
2024-01-10 22:06:22,858 - GAugM EPNet train, Epoch [ 64/70]: loss 0.7208, auc 0.5381, ap 0.5546
2024-01-10 22:06:22,947 - GAugM EPNet train, Epoch [ 65/70]: loss 0.7208, auc 0.5050, ap 0.5259
2024-01-10 22:06:23,036 - GAugM EPNet train, Epoch [ 66/70]: loss 0.7209, auc 0.4288, ap 0.4881
2024-01-10 22:06:23,123 - GAugM EPNet train, Epoch [ 67/70]: loss 0.7209, auc 0.5278, ap 0.5392
2024-01-10 22:06:23,215 - GAugM EPNet train, Epoch [ 68/70]: loss 0.7210, auc 0.5602, ap 0.5775
2024-01-10 22:06:23,303 - GAugM EPNet train, Epoch [ 69/70]: loss 0.7210, auc 0.4943, ap 0.5330
2024-01-10 22:06:23,390 - GAugM EPNet train, Epoch [ 70/70]: loss 0.7210, auc 0.4391, ap 0.4604
2024-01-10 22:06:23,398 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035e5350>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:06:24,118 - GAugM EPNet train, Epoch [  1/70]: loss 0.7210, auc 0.4404, ap 0.4564
2024-01-10 22:06:24,212 - GAugM EPNet train, Epoch [  2/70]: loss 0.7210, auc 0.5472, ap 0.5368
2024-01-10 22:06:24,303 - GAugM EPNet train, Epoch [  3/70]: loss 0.7209, auc 0.5402, ap 0.5609
2024-01-10 22:06:24,400 - GAugM EPNet train, Epoch [  4/70]: loss 0.7209, auc 0.5575, ap 0.5741
2024-01-10 22:06:24,491 - GAugM EPNet train, Epoch [  5/70]: loss 0.7209, auc 0.6175, ap 0.6134
2024-01-10 22:06:24,583 - GAugM EPNet train, Epoch [  6/70]: loss 0.7209, auc 0.4655, ap 0.4689
2024-01-10 22:06:24,662 - GAugM EPNet train, Epoch [  7/70]: loss 0.7209, auc 0.4320, ap 0.4653
2024-01-10 22:06:24,738 - GAugM EPNet train, Epoch [  8/70]: loss 0.7210, auc 0.5384, ap 0.5334
2024-01-10 22:06:24,815 - GAugM EPNet train, Epoch [  9/70]: loss 0.7209, auc 0.4502, ap 0.4767
2024-01-10 22:06:24,890 - GAugM EPNet train, Epoch [ 10/70]: loss 0.7208, auc 0.4879, ap 0.5013
2024-01-10 22:06:24,963 - GAugM EPNet train, Epoch [ 11/70]: loss 0.7209, auc 0.6040, ap 0.6022
2024-01-10 22:06:25,048 - GAugM EPNet train, Epoch [ 12/70]: loss 0.7210, auc 0.4194, ap 0.4612
2024-01-10 22:06:25,136 - GAugM EPNet train, Epoch [ 13/70]: loss 0.7209, auc 0.5274, ap 0.5370
2024-01-10 22:06:25,225 - GAugM EPNet train, Epoch [ 14/70]: loss 0.7209, auc 0.5125, ap 0.5427
2024-01-10 22:06:25,314 - GAugM EPNet train, Epoch [ 15/70]: loss 0.7210, auc 0.3475, ap 0.4286
2024-01-10 22:06:25,405 - GAugM EPNet train, Epoch [ 16/70]: loss 0.7209, auc 0.5365, ap 0.5391
2024-01-10 22:06:25,495 - GAugM EPNet train, Epoch [ 17/70]: loss 0.7210, auc 0.5646, ap 0.5642
2024-01-10 22:06:25,590 - GAugM EPNet train, Epoch [ 18/70]: loss 0.7210, auc 0.5611, ap 0.5687
2024-01-10 22:06:25,674 - GAugM EPNet train, Epoch [ 19/70]: loss 0.7209, auc 0.4648, ap 0.4723
2024-01-10 22:06:25,760 - GAugM EPNet train, Epoch [ 20/70]: loss 0.7210, auc 0.5064, ap 0.5640
2024-01-10 22:06:25,848 - GAugM EPNet train, Epoch [ 21/70]: loss 0.7209, auc 0.5269, ap 0.5059
2024-01-10 22:06:25,939 - GAugM EPNet train, Epoch [ 22/70]: loss 0.7210, auc 0.3532, ap 0.4110
2024-01-10 22:06:26,022 - GAugM EPNet train, Epoch [ 23/70]: loss 0.7208, auc 0.5012, ap 0.5218
2024-01-10 22:06:26,115 - GAugM EPNet train, Epoch [ 24/70]: loss 0.7209, auc 0.5336, ap 0.5150
2024-01-10 22:06:26,212 - GAugM EPNet train, Epoch [ 25/70]: loss 0.7209, auc 0.5142, ap 0.5116
2024-01-10 22:06:26,305 - GAugM EPNet train, Epoch [ 26/70]: loss 0.7210, auc 0.6205, ap 0.6242
2024-01-10 22:06:26,390 - GAugM EPNet train, Epoch [ 27/70]: loss 0.7209, auc 0.4722, ap 0.5350
2024-01-10 22:06:26,488 - GAugM EPNet train, Epoch [ 28/70]: loss 0.7209, auc 0.5947, ap 0.5705
2024-01-10 22:06:26,579 - GAugM EPNet train, Epoch [ 29/70]: loss 0.7210, auc 0.4918, ap 0.4961
2024-01-10 22:06:26,656 - GAugM EPNet train, Epoch [ 30/70]: loss 0.7209, auc 0.5555, ap 0.5582
2024-01-10 22:06:26,732 - GAugM EPNet train, Epoch [ 31/70]: loss 0.7208, auc 0.4824, ap 0.4907
2024-01-10 22:06:26,812 - GAugM EPNet train, Epoch [ 32/70]: loss 0.7210, auc 0.5746, ap 0.5502
2024-01-10 22:06:26,889 - GAugM EPNet train, Epoch [ 33/70]: loss 0.7209, auc 0.5032, ap 0.5002
2024-01-10 22:06:26,984 - GAugM EPNet train, Epoch [ 34/70]: loss 0.7209, auc 0.4991, ap 0.5576
2024-01-10 22:06:27,076 - GAugM EPNet train, Epoch [ 35/70]: loss 0.7209, auc 0.5780, ap 0.5365
2024-01-10 22:06:27,166 - GAugM EPNet train, Epoch [ 36/70]: loss 0.7209, auc 0.6020, ap 0.6076
2024-01-10 22:06:27,260 - GAugM EPNet train, Epoch [ 37/70]: loss 0.7209, auc 0.4827, ap 0.5174
2024-01-10 22:06:27,353 - GAugM EPNet train, Epoch [ 38/70]: loss 0.7209, auc 0.4450, ap 0.4552
2024-01-10 22:06:27,449 - GAugM EPNet train, Epoch [ 39/70]: loss 0.7208, auc 0.4605, ap 0.5113
2024-01-10 22:06:27,539 - GAugM EPNet train, Epoch [ 40/70]: loss 0.7210, auc 0.5326, ap 0.5265
2024-01-10 22:06:27,632 - GAugM EPNet train, Epoch [ 41/70]: loss 0.7210, auc 0.4551, ap 0.4789
2024-01-10 22:06:27,723 - GAugM EPNet train, Epoch [ 42/70]: loss 0.7209, auc 0.5057, ap 0.5299
2024-01-10 22:06:27,821 - GAugM EPNet train, Epoch [ 43/70]: loss 0.7208, auc 0.5269, ap 0.5728
2024-01-10 22:06:27,919 - GAugM EPNet train, Epoch [ 44/70]: loss 0.7208, auc 0.3464, ap 0.4204
2024-01-10 22:06:28,011 - GAugM EPNet train, Epoch [ 45/70]: loss 0.7209, auc 0.4906, ap 0.5121
2024-01-10 22:06:28,108 - GAugM EPNet train, Epoch [ 46/70]: loss 0.7209, auc 0.4377, ap 0.4588
2024-01-10 22:06:28,190 - GAugM EPNet train, Epoch [ 47/70]: loss 0.7210, auc 0.5135, ap 0.5121
2024-01-10 22:06:28,273 - GAugM EPNet train, Epoch [ 48/70]: loss 0.7210, auc 0.5552, ap 0.5702
2024-01-10 22:06:28,350 - GAugM EPNet train, Epoch [ 49/70]: loss 0.7209, auc 0.5555, ap 0.5365
2024-01-10 22:06:28,427 - GAugM EPNet train, Epoch [ 50/70]: loss 0.7210, auc 0.5269, ap 0.5218
2024-01-10 22:06:28,505 - GAugM EPNet train, Epoch [ 51/70]: loss 0.7210, auc 0.4986, ap 0.5313
2024-01-10 22:06:28,584 - GAugM EPNet train, Epoch [ 52/70]: loss 0.7209, auc 0.4103, ap 0.4342
2024-01-10 22:06:28,666 - GAugM EPNet train, Epoch [ 53/70]: loss 0.7209, auc 0.5808, ap 0.5817
2024-01-10 22:06:28,760 - GAugM EPNet train, Epoch [ 54/70]: loss 0.7211, auc 0.5449, ap 0.5575
2024-01-10 22:06:28,851 - GAugM EPNet train, Epoch [ 55/70]: loss 0.7209, auc 0.6239, ap 0.6277
2024-01-10 22:06:28,940 - GAugM EPNet train, Epoch [ 56/70]: loss 0.7208, auc 0.4705, ap 0.4645
2024-01-10 22:06:29,024 - GAugM EPNet train, Epoch [ 57/70]: loss 0.7209, auc 0.4103, ap 0.4312
2024-01-10 22:06:29,105 - GAugM EPNet train, Epoch [ 58/70]: loss 0.7210, auc 0.5534, ap 0.5712
2024-01-10 22:06:29,182 - GAugM EPNet train, Epoch [ 59/70]: loss 0.7211, auc 0.5073, ap 0.5352
2024-01-10 22:06:29,260 - GAugM EPNet train, Epoch [ 60/70]: loss 0.7210, auc 0.4557, ap 0.4725
2024-01-10 22:06:29,353 - GAugM EPNet train, Epoch [ 61/70]: loss 0.7209, auc 0.5639, ap 0.5516
2024-01-10 22:06:29,443 - GAugM EPNet train, Epoch [ 62/70]: loss 0.7210, auc 0.5260, ap 0.5708
2024-01-10 22:06:29,534 - GAugM EPNet train, Epoch [ 63/70]: loss 0.7208, auc 0.4610, ap 0.4647
2024-01-10 22:06:29,624 - GAugM EPNet train, Epoch [ 64/70]: loss 0.7208, auc 0.4639, ap 0.4830
2024-01-10 22:06:29,724 - GAugM EPNet train, Epoch [ 65/70]: loss 0.7208, auc 0.5345, ap 0.5257
2024-01-10 22:06:29,812 - GAugM EPNet train, Epoch [ 66/70]: loss 0.7209, auc 0.4890, ap 0.5223
2024-01-10 22:06:29,903 - GAugM EPNet train, Epoch [ 67/70]: loss 0.7209, auc 0.5251, ap 0.5436
2024-01-10 22:06:29,999 - GAugM EPNet train, Epoch [ 68/70]: loss 0.7210, auc 0.4996, ap 0.5363
2024-01-10 22:06:30,089 - GAugM EPNet train, Epoch [ 69/70]: loss 0.7210, auc 0.5767, ap 0.5744
2024-01-10 22:06:30,178 - GAugM EPNet train, Epoch [ 70/70]: loss 0.7210, auc 0.4731, ap 0.4663
2024-01-10 22:06:30,187 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d08245050>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:06:30,915 - GAugM EPNet train, Epoch [  1/70]: loss 0.7210, auc 0.4685, ap 0.4709
2024-01-10 22:06:31,007 - GAugM EPNet train, Epoch [  2/70]: loss 0.7210, auc 0.5080, ap 0.5200
2024-01-10 22:06:31,101 - GAugM EPNet train, Epoch [  3/70]: loss 0.7209, auc 0.4938, ap 0.5188
2024-01-10 22:06:31,189 - GAugM EPNet train, Epoch [  4/70]: loss 0.7209, auc 0.4674, ap 0.4938
2024-01-10 22:06:31,287 - GAugM EPNet train, Epoch [  5/70]: loss 0.7209, auc 0.5589, ap 0.5691
2024-01-10 22:06:31,366 - GAugM EPNet train, Epoch [  6/70]: loss 0.7209, auc 0.4877, ap 0.4941
2024-01-10 22:06:31,448 - GAugM EPNet train, Epoch [  7/70]: loss 0.7209, auc 0.4913, ap 0.4773
2024-01-10 22:06:31,525 - GAugM EPNet train, Epoch [  8/70]: loss 0.7210, auc 0.5080, ap 0.5037
2024-01-10 22:06:31,602 - GAugM EPNet train, Epoch [  9/70]: loss 0.7209, auc 0.5048, ap 0.5141
2024-01-10 22:06:31,692 - GAugM EPNet train, Epoch [ 10/70]: loss 0.7208, auc 0.5034, ap 0.5286
2024-01-10 22:06:31,774 - GAugM EPNet train, Epoch [ 11/70]: loss 0.7209, auc 0.5187, ap 0.5584
2024-01-10 22:06:31,877 - GAugM EPNet train, Epoch [ 12/70]: loss 0.7210, auc 0.4724, ap 0.4895
2024-01-10 22:06:31,957 - GAugM EPNet train, Epoch [ 13/70]: loss 0.7209, auc 0.5767, ap 0.5871
2024-01-10 22:06:32,042 - GAugM EPNet train, Epoch [ 14/70]: loss 0.7209, auc 0.5294, ap 0.5251
2024-01-10 22:06:32,122 - GAugM EPNet train, Epoch [ 15/70]: loss 0.7210, auc 0.4393, ap 0.4959
2024-01-10 22:06:32,202 - GAugM EPNet train, Epoch [ 16/70]: loss 0.7209, auc 0.5700, ap 0.5984
2024-01-10 22:06:32,282 - GAugM EPNet train, Epoch [ 17/70]: loss 0.7210, auc 0.5023, ap 0.5118
2024-01-10 22:06:32,358 - GAugM EPNet train, Epoch [ 18/70]: loss 0.7210, auc 0.5664, ap 0.5668
2024-01-10 22:06:32,433 - GAugM EPNet train, Epoch [ 19/70]: loss 0.7209, auc 0.5226, ap 0.5025
2024-01-10 22:06:32,507 - GAugM EPNet train, Epoch [ 20/70]: loss 0.7210, auc 0.5016, ap 0.5303
2024-01-10 22:06:32,584 - GAugM EPNet train, Epoch [ 21/70]: loss 0.7209, auc 0.4948, ap 0.5147
2024-01-10 22:06:32,660 - GAugM EPNet train, Epoch [ 22/70]: loss 0.7210, auc 0.3991, ap 0.4533
2024-01-10 22:06:32,740 - GAugM EPNet train, Epoch [ 23/70]: loss 0.7208, auc 0.5130, ap 0.5218
2024-01-10 22:06:32,820 - GAugM EPNet train, Epoch [ 24/70]: loss 0.7209, auc 0.5500, ap 0.5480
2024-01-10 22:06:32,904 - GAugM EPNet train, Epoch [ 25/70]: loss 0.7209, auc 0.4208, ap 0.4589
2024-01-10 22:06:32,982 - GAugM EPNet train, Epoch [ 26/70]: loss 0.7210, auc 0.5546, ap 0.5557
2024-01-10 22:06:33,059 - GAugM EPNet train, Epoch [ 27/70]: loss 0.7209, auc 0.4318, ap 0.4795
2024-01-10 22:06:33,136 - GAugM EPNet train, Epoch [ 28/70]: loss 0.7209, auc 0.5927, ap 0.6135
2024-01-10 22:06:33,220 - GAugM EPNet train, Epoch [ 29/70]: loss 0.7210, auc 0.4781, ap 0.5071
2024-01-10 22:06:33,292 - GAugM EPNet train, Epoch [ 30/70]: loss 0.7209, auc 0.5874, ap 0.6068
2024-01-10 22:06:33,367 - GAugM EPNet train, Epoch [ 31/70]: loss 0.7208, auc 0.5222, ap 0.5228
2024-01-10 22:06:33,440 - GAugM EPNet train, Epoch [ 32/70]: loss 0.7210, auc 0.5874, ap 0.5696
2024-01-10 22:06:33,515 - GAugM EPNet train, Epoch [ 33/70]: loss 0.7209, auc 0.5319, ap 0.5445
2024-01-10 22:06:33,592 - GAugM EPNet train, Epoch [ 34/70]: loss 0.7209, auc 0.4635, ap 0.4984
2024-01-10 22:06:33,664 - GAugM EPNet train, Epoch [ 35/70]: loss 0.7209, auc 0.5180, ap 0.5205
2024-01-10 22:06:33,736 - GAugM EPNet train, Epoch [ 36/70]: loss 0.7209, auc 0.5867, ap 0.5623
2024-01-10 22:06:33,815 - GAugM EPNet train, Epoch [ 37/70]: loss 0.7209, auc 0.4389, ap 0.4786
2024-01-10 22:06:33,891 - GAugM EPNet train, Epoch [ 38/70]: loss 0.7209, auc 0.4493, ap 0.4599
2024-01-10 22:06:33,968 - GAugM EPNet train, Epoch [ 39/70]: loss 0.7208, auc 0.4770, ap 0.5311
2024-01-10 22:06:34,044 - GAugM EPNet train, Epoch [ 40/70]: loss 0.7210, auc 0.5347, ap 0.5292
2024-01-10 22:06:34,132 - GAugM EPNet train, Epoch [ 41/70]: loss 0.7210, auc 0.4767, ap 0.5270
2024-01-10 22:06:34,211 - GAugM EPNet train, Epoch [ 42/70]: loss 0.7209, auc 0.5479, ap 0.5615
2024-01-10 22:06:34,284 - GAugM EPNet train, Epoch [ 43/70]: loss 0.7208, auc 0.5155, ap 0.5396
2024-01-10 22:06:34,361 - GAugM EPNet train, Epoch [ 44/70]: loss 0.7208, auc 0.4005, ap 0.4531
2024-01-10 22:06:34,434 - GAugM EPNet train, Epoch [ 45/70]: loss 0.7209, auc 0.5443, ap 0.5818
2024-01-10 22:06:34,506 - GAugM EPNet train, Epoch [ 46/70]: loss 0.7209, auc 0.4422, ap 0.4721
2024-01-10 22:06:34,581 - GAugM EPNet train, Epoch [ 47/70]: loss 0.7210, auc 0.4571, ap 0.4488
2024-01-10 22:06:34,659 - GAugM EPNet train, Epoch [ 48/70]: loss 0.7210, auc 0.6746, ap 0.6729
2024-01-10 22:06:34,736 - GAugM EPNet train, Epoch [ 49/70]: loss 0.7209, auc 0.5005, ap 0.5158
2024-01-10 22:06:34,810 - GAugM EPNet train, Epoch [ 50/70]: loss 0.7210, auc 0.5404, ap 0.5189
2024-01-10 22:06:34,889 - GAugM EPNet train, Epoch [ 51/70]: loss 0.7210, auc 0.4201, ap 0.4582
2024-01-10 22:06:34,965 - GAugM EPNet train, Epoch [ 52/70]: loss 0.7209, auc 0.5294, ap 0.5388
2024-01-10 22:06:35,041 - GAugM EPNet train, Epoch [ 53/70]: loss 0.7209, auc 0.5023, ap 0.5301
2024-01-10 22:06:35,120 - GAugM EPNet train, Epoch [ 54/70]: loss 0.7211, auc 0.5831, ap 0.6050
2024-01-10 22:06:35,196 - GAugM EPNet train, Epoch [ 55/70]: loss 0.7209, auc 0.5956, ap 0.6044
2024-01-10 22:06:35,277 - GAugM EPNet train, Epoch [ 56/70]: loss 0.7208, auc 0.4902, ap 0.4947
2024-01-10 22:06:35,372 - GAugM EPNet train, Epoch [ 57/70]: loss 0.7209, auc 0.4404, ap 0.4406
2024-01-10 22:06:35,464 - GAugM EPNet train, Epoch [ 58/70]: loss 0.7210, auc 0.4546, ap 0.5253
2024-01-10 22:06:35,558 - GAugM EPNet train, Epoch [ 59/70]: loss 0.7211, auc 0.4834, ap 0.4863
2024-01-10 22:06:35,652 - GAugM EPNet train, Epoch [ 60/70]: loss 0.7210, auc 0.5611, ap 0.5512
2024-01-10 22:06:35,742 - GAugM EPNet train, Epoch [ 61/70]: loss 0.7209, auc 0.5105, ap 0.5126
2024-01-10 22:06:35,829 - GAugM EPNet train, Epoch [ 62/70]: loss 0.7210, auc 0.5400, ap 0.5480
2024-01-10 22:06:35,917 - GAugM EPNet train, Epoch [ 63/70]: loss 0.7208, auc 0.4414, ap 0.4874
2024-01-10 22:06:36,006 - GAugM EPNet train, Epoch [ 64/70]: loss 0.7208, auc 0.4927, ap 0.5340
2024-01-10 22:06:36,097 - GAugM EPNet train, Epoch [ 65/70]: loss 0.7208, auc 0.5290, ap 0.5471
2024-01-10 22:06:36,182 - GAugM EPNet train, Epoch [ 66/70]: loss 0.7209, auc 0.4806, ap 0.5027
2024-01-10 22:06:36,268 - GAugM EPNet train, Epoch [ 67/70]: loss 0.7209, auc 0.6198, ap 0.5682
2024-01-10 22:06:36,358 - GAugM EPNet train, Epoch [ 68/70]: loss 0.7210, auc 0.4945, ap 0.5007
2024-01-10 22:06:36,461 - GAugM EPNet train, Epoch [ 69/70]: loss 0.7210, auc 0.4557, ap 0.4836
2024-01-10 22:06:36,552 - GAugM EPNet train, Epoch [ 70/70]: loss 0.7210, auc 0.4842, ap 0.4703
2024-01-10 22:06:36,559 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa0d4b50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:06:37,314 - GAugM EPNet train, Epoch [  1/70]: loss 0.7210, auc 0.4708, ap 0.4909
2024-01-10 22:06:37,405 - GAugM EPNet train, Epoch [  2/70]: loss 0.7210, auc 0.4770, ap 0.4867
2024-01-10 22:06:37,492 - GAugM EPNet train, Epoch [  3/70]: loss 0.7209, auc 0.5351, ap 0.5441
2024-01-10 22:06:37,587 - GAugM EPNet train, Epoch [  4/70]: loss 0.7209, auc 0.4788, ap 0.5114
2024-01-10 22:06:37,675 - GAugM EPNet train, Epoch [  5/70]: loss 0.7209, auc 0.5002, ap 0.5130
2024-01-10 22:06:37,762 - GAugM EPNet train, Epoch [  6/70]: loss 0.7209, auc 0.4961, ap 0.5159
2024-01-10 22:06:37,859 - GAugM EPNet train, Epoch [  7/70]: loss 0.7209, auc 0.4475, ap 0.4493
2024-01-10 22:06:37,943 - GAugM EPNet train, Epoch [  8/70]: loss 0.7210, auc 0.5383, ap 0.5171
2024-01-10 22:06:38,037 - GAugM EPNet train, Epoch [  9/70]: loss 0.7209, auc 0.5183, ap 0.5500
2024-01-10 22:06:38,124 - GAugM EPNet train, Epoch [ 10/70]: loss 0.7208, auc 0.5018, ap 0.5171
2024-01-10 22:06:38,215 - GAugM EPNet train, Epoch [ 11/70]: loss 0.7209, auc 0.5351, ap 0.5081
2024-01-10 22:06:38,300 - GAugM EPNet train, Epoch [ 12/70]: loss 0.7210, auc 0.4646, ap 0.5078
2024-01-10 22:06:38,385 - GAugM EPNet train, Epoch [ 13/70]: loss 0.7209, auc 0.5657, ap 0.5910
2024-01-10 22:06:38,474 - GAugM EPNet train, Epoch [ 14/70]: loss 0.7209, auc 0.5550, ap 0.5511
2024-01-10 22:06:38,559 - GAugM EPNet train, Epoch [ 15/70]: loss 0.7210, auc 0.4397, ap 0.5015
2024-01-10 22:06:38,661 - GAugM EPNet train, Epoch [ 16/70]: loss 0.7209, auc 0.4713, ap 0.4716
2024-01-10 22:06:38,752 - GAugM EPNet train, Epoch [ 17/70]: loss 0.7210, auc 0.5422, ap 0.5318
2024-01-10 22:06:38,845 - GAugM EPNet train, Epoch [ 18/70]: loss 0.7210, auc 0.5744, ap 0.5617
2024-01-10 22:06:38,941 - GAugM EPNet train, Epoch [ 19/70]: loss 0.7209, auc 0.4559, ap 0.4678
2024-01-10 22:06:39,031 - GAugM EPNet train, Epoch [ 20/70]: loss 0.7210, auc 0.4943, ap 0.5444
2024-01-10 22:06:39,118 - GAugM EPNet train, Epoch [ 21/70]: loss 0.7209, auc 0.5290, ap 0.5315
2024-01-10 22:06:39,206 - GAugM EPNet train, Epoch [ 22/70]: loss 0.7210, auc 0.4016, ap 0.4333
2024-01-10 22:06:39,298 - GAugM EPNet train, Epoch [ 23/70]: loss 0.7208, auc 0.4756, ap 0.4793
2024-01-10 22:06:39,388 - GAugM EPNet train, Epoch [ 24/70]: loss 0.7209, auc 0.5924, ap 0.5735
2024-01-10 22:06:39,470 - GAugM EPNet train, Epoch [ 25/70]: loss 0.7209, auc 0.4375, ap 0.4733
2024-01-10 22:06:39,548 - GAugM EPNet train, Epoch [ 26/70]: loss 0.7210, auc 0.6023, ap 0.6161
2024-01-10 22:06:39,624 - GAugM EPNet train, Epoch [ 27/70]: loss 0.7209, auc 0.4553, ap 0.5103
2024-01-10 22:06:39,697 - GAugM EPNet train, Epoch [ 28/70]: loss 0.7209, auc 0.5315, ap 0.5620
2024-01-10 22:06:39,772 - GAugM EPNet train, Epoch [ 29/70]: loss 0.7210, auc 0.5180, ap 0.5153
2024-01-10 22:06:39,848 - GAugM EPNet train, Epoch [ 30/70]: loss 0.7209, auc 0.5055, ap 0.5169
2024-01-10 22:06:39,929 - GAugM EPNet train, Epoch [ 31/70]: loss 0.7208, auc 0.4906, ap 0.5047
2024-01-10 22:06:40,004 - GAugM EPNet train, Epoch [ 32/70]: loss 0.7210, auc 0.4931, ap 0.5104
2024-01-10 22:06:40,083 - GAugM EPNet train, Epoch [ 33/70]: loss 0.7209, auc 0.5931, ap 0.5991
2024-01-10 22:06:40,159 - GAugM EPNet train, Epoch [ 34/70]: loss 0.7209, auc 0.4293, ap 0.4688
2024-01-10 22:06:40,237 - GAugM EPNet train, Epoch [ 35/70]: loss 0.7209, auc 0.5514, ap 0.5514
2024-01-10 22:06:40,323 - GAugM EPNet train, Epoch [ 36/70]: loss 0.7209, auc 0.6155, ap 0.6186
2024-01-10 22:06:40,411 - GAugM EPNet train, Epoch [ 37/70]: loss 0.7209, auc 0.5208, ap 0.5206
2024-01-10 22:06:40,505 - GAugM EPNet train, Epoch [ 38/70]: loss 0.7209, auc 0.4311, ap 0.4503
2024-01-10 22:06:40,591 - GAugM EPNet train, Epoch [ 39/70]: loss 0.7208, auc 0.3955, ap 0.4486
2024-01-10 22:06:40,692 - GAugM EPNet train, Epoch [ 40/70]: loss 0.7210, auc 0.6205, ap 0.5885
2024-01-10 22:06:40,780 - GAugM EPNet train, Epoch [ 41/70]: loss 0.7210, auc 0.4653, ap 0.5030
2024-01-10 22:06:40,860 - GAugM EPNet train, Epoch [ 42/70]: loss 0.7209, auc 0.4653, ap 0.5024
2024-01-10 22:06:40,951 - GAugM EPNet train, Epoch [ 43/70]: loss 0.7208, auc 0.4026, ap 0.4317
2024-01-10 22:06:41,035 - GAugM EPNet train, Epoch [ 44/70]: loss 0.7208, auc 0.4197, ap 0.4585
2024-01-10 22:06:41,119 - GAugM EPNet train, Epoch [ 45/70]: loss 0.7209, auc 0.5860, ap 0.5712
2024-01-10 22:06:41,204 - GAugM EPNet train, Epoch [ 46/70]: loss 0.7209, auc 0.3985, ap 0.4527
2024-01-10 22:06:41,292 - GAugM EPNet train, Epoch [ 47/70]: loss 0.7210, auc 0.4931, ap 0.5315
2024-01-10 22:06:41,385 - GAugM EPNet train, Epoch [ 48/70]: loss 0.7210, auc 0.5951, ap 0.6032
2024-01-10 22:06:41,475 - GAugM EPNet train, Epoch [ 49/70]: loss 0.7209, auc 0.5726, ap 0.5857
2024-01-10 22:06:41,565 - GAugM EPNet train, Epoch [ 50/70]: loss 0.7210, auc 0.5495, ap 0.5394
2024-01-10 22:06:41,655 - GAugM EPNet train, Epoch [ 51/70]: loss 0.7210, auc 0.4778, ap 0.5133
2024-01-10 22:06:41,734 - GAugM EPNet train, Epoch [ 52/70]: loss 0.7209, auc 0.4895, ap 0.5405
2024-01-10 22:06:41,823 - GAugM EPNet train, Epoch [ 53/70]: loss 0.7209, auc 0.5027, ap 0.5508
2024-01-10 22:06:41,910 - GAugM EPNet train, Epoch [ 54/70]: loss 0.7211, auc 0.5589, ap 0.5413
2024-01-10 22:06:41,998 - GAugM EPNet train, Epoch [ 55/70]: loss 0.7209, auc 0.5372, ap 0.5640
2024-01-10 22:06:42,086 - GAugM EPNet train, Epoch [ 56/70]: loss 0.7208, auc 0.5262, ap 0.5188
2024-01-10 22:06:42,175 - GAugM EPNet train, Epoch [ 57/70]: loss 0.7209, auc 0.4411, ap 0.4611
2024-01-10 22:06:42,271 - GAugM EPNet train, Epoch [ 58/70]: loss 0.7210, auc 0.4941, ap 0.5563
2024-01-10 22:06:42,354 - GAugM EPNet train, Epoch [ 59/70]: loss 0.7211, auc 0.4567, ap 0.4554
2024-01-10 22:06:42,434 - GAugM EPNet train, Epoch [ 60/70]: loss 0.7210, auc 0.5201, ap 0.5075
2024-01-10 22:06:42,525 - GAugM EPNet train, Epoch [ 61/70]: loss 0.7209, auc 0.5664, ap 0.5540
2024-01-10 22:06:42,616 - GAugM EPNet train, Epoch [ 62/70]: loss 0.7210, auc 0.4738, ap 0.5021
2024-01-10 22:06:42,704 - GAugM EPNet train, Epoch [ 63/70]: loss 0.7208, auc 0.4130, ap 0.4684
2024-01-10 22:06:42,797 - GAugM EPNet train, Epoch [ 64/70]: loss 0.7208, auc 0.5069, ap 0.5267
2024-01-10 22:06:42,886 - GAugM EPNet train, Epoch [ 65/70]: loss 0.7208, auc 0.5276, ap 0.5333
2024-01-10 22:06:42,973 - GAugM EPNet train, Epoch [ 66/70]: loss 0.7209, auc 0.4422, ap 0.4713
2024-01-10 22:06:43,062 - GAugM EPNet train, Epoch [ 67/70]: loss 0.7209, auc 0.4899, ap 0.5046
2024-01-10 22:06:43,156 - GAugM EPNet train, Epoch [ 68/70]: loss 0.7210, auc 0.5433, ap 0.5496
2024-01-10 22:06:43,243 - GAugM EPNet train, Epoch [ 69/70]: loss 0.7210, auc 0.4813, ap 0.5355
2024-01-10 22:06:43,334 - GAugM EPNet train, Epoch [ 70/70]: loss 0.7210, auc 0.4112, ap 0.4614
2024-01-10 22:06:43,335 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d0377ab90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:06:44,092 - GAugM EPNet train, Epoch [  1/70]: loss 0.7210, auc 0.4210, ap 0.4729
2024-01-10 22:06:44,178 - GAugM EPNet train, Epoch [  2/70]: loss 0.7210, auc 0.5641, ap 0.5629
2024-01-10 22:06:44,263 - GAugM EPNet train, Epoch [  3/70]: loss 0.7209, auc 0.4423, ap 0.4577
2024-01-10 22:06:44,356 - GAugM EPNet train, Epoch [  4/70]: loss 0.7209, auc 0.5135, ap 0.5500
2024-01-10 22:06:44,439 - GAugM EPNet train, Epoch [  5/70]: loss 0.7209, auc 0.5762, ap 0.6267
2024-01-10 22:06:44,517 - GAugM EPNet train, Epoch [  6/70]: loss 0.7209, auc 0.5278, ap 0.5118
2024-01-10 22:06:44,609 - GAugM EPNet train, Epoch [  7/70]: loss 0.7209, auc 0.4648, ap 0.4800
2024-01-10 22:06:44,688 - GAugM EPNet train, Epoch [  8/70]: loss 0.7210, auc 0.4826, ap 0.5510
2024-01-10 22:06:44,772 - GAugM EPNet train, Epoch [  9/70]: loss 0.7209, auc 0.4779, ap 0.4876
2024-01-10 22:06:44,848 - GAugM EPNet train, Epoch [ 10/70]: loss 0.7208, auc 0.5381, ap 0.5263
2024-01-10 22:06:44,927 - GAugM EPNet train, Epoch [ 11/70]: loss 0.7209, auc 0.4957, ap 0.5315
2024-01-10 22:06:45,016 - GAugM EPNet train, Epoch [ 12/70]: loss 0.7210, auc 0.4060, ap 0.4826
2024-01-10 22:06:45,094 - GAugM EPNet train, Epoch [ 13/70]: loss 0.7209, auc 0.5463, ap 0.5541
2024-01-10 22:06:45,185 - GAugM EPNet train, Epoch [ 14/70]: loss 0.7209, auc 0.5605, ap 0.5684
2024-01-10 22:06:45,277 - GAugM EPNet train, Epoch [ 15/70]: loss 0.7210, auc 0.3854, ap 0.4847
2024-01-10 22:06:45,369 - GAugM EPNet train, Epoch [ 16/70]: loss 0.7209, auc 0.5424, ap 0.5433
2024-01-10 22:06:45,467 - GAugM EPNet train, Epoch [ 17/70]: loss 0.7210, auc 0.5349, ap 0.5310
2024-01-10 22:06:45,567 - GAugM EPNet train, Epoch [ 18/70]: loss 0.7210, auc 0.5822, ap 0.5734
2024-01-10 22:06:45,659 - GAugM EPNet train, Epoch [ 19/70]: loss 0.7209, auc 0.4242, ap 0.4511
2024-01-10 22:06:45,740 - GAugM EPNet train, Epoch [ 20/70]: loss 0.7210, auc 0.4705, ap 0.5344
2024-01-10 22:06:45,822 - GAugM EPNet train, Epoch [ 21/70]: loss 0.7209, auc 0.4537, ap 0.4880
2024-01-10 22:06:45,915 - GAugM EPNet train, Epoch [ 22/70]: loss 0.7210, auc 0.4512, ap 0.4815
2024-01-10 22:06:45,998 - GAugM EPNet train, Epoch [ 23/70]: loss 0.7208, auc 0.4854, ap 0.4987
2024-01-10 22:06:46,074 - GAugM EPNet train, Epoch [ 24/70]: loss 0.7209, auc 0.5246, ap 0.5086
2024-01-10 22:06:46,152 - GAugM EPNet train, Epoch [ 25/70]: loss 0.7209, auc 0.4000, ap 0.4410
2024-01-10 22:06:46,231 - GAugM EPNet train, Epoch [ 26/70]: loss 0.7210, auc 0.5812, ap 0.5814
2024-01-10 22:06:46,309 - GAugM EPNet train, Epoch [ 27/70]: loss 0.7209, auc 0.5089, ap 0.5700
2024-01-10 22:06:46,396 - GAugM EPNet train, Epoch [ 28/70]: loss 0.7209, auc 0.6310, ap 0.6227
2024-01-10 22:06:46,478 - GAugM EPNet train, Epoch [ 29/70]: loss 0.7210, auc 0.4534, ap 0.4790
2024-01-10 22:06:46,556 - GAugM EPNet train, Epoch [ 30/70]: loss 0.7209, auc 0.5844, ap 0.6066
2024-01-10 22:06:46,636 - GAugM EPNet train, Epoch [ 31/70]: loss 0.7208, auc 0.4861, ap 0.5117
2024-01-10 22:06:46,718 - GAugM EPNet train, Epoch [ 32/70]: loss 0.7210, auc 0.5053, ap 0.5151
2024-01-10 22:06:46,797 - GAugM EPNet train, Epoch [ 33/70]: loss 0.7209, auc 0.5117, ap 0.5270
2024-01-10 22:06:46,881 - GAugM EPNet train, Epoch [ 34/70]: loss 0.7209, auc 0.4733, ap 0.5167
2024-01-10 22:06:46,962 - GAugM EPNet train, Epoch [ 35/70]: loss 0.7209, auc 0.5890, ap 0.5769
2024-01-10 22:06:47,061 - GAugM EPNet train, Epoch [ 36/70]: loss 0.7209, auc 0.5577, ap 0.5490
2024-01-10 22:06:47,150 - GAugM EPNet train, Epoch [ 37/70]: loss 0.7209, auc 0.4366, ap 0.4946
2024-01-10 22:06:47,240 - GAugM EPNet train, Epoch [ 38/70]: loss 0.7209, auc 0.4972, ap 0.4965
2024-01-10 22:06:47,334 - GAugM EPNet train, Epoch [ 39/70]: loss 0.7208, auc 0.4491, ap 0.4860
2024-01-10 22:06:47,423 - GAugM EPNet train, Epoch [ 40/70]: loss 0.7210, auc 0.5659, ap 0.5483
2024-01-10 22:06:47,521 - GAugM EPNet train, Epoch [ 41/70]: loss 0.7210, auc 0.5114, ap 0.5338
2024-01-10 22:06:47,616 - GAugM EPNet train, Epoch [ 42/70]: loss 0.7209, auc 0.5028, ap 0.5724
2024-01-10 22:06:47,708 - GAugM EPNet train, Epoch [ 43/70]: loss 0.7208, auc 0.4594, ap 0.5479
2024-01-10 22:06:47,799 - GAugM EPNet train, Epoch [ 44/70]: loss 0.7208, auc 0.4142, ap 0.4536
2024-01-10 22:06:47,903 - GAugM EPNet train, Epoch [ 45/70]: loss 0.7209, auc 0.4939, ap 0.5425
2024-01-10 22:06:47,989 - GAugM EPNet train, Epoch [ 46/70]: loss 0.7209, auc 0.4900, ap 0.4816
2024-01-10 22:06:48,073 - GAugM EPNet train, Epoch [ 47/70]: loss 0.7210, auc 0.5139, ap 0.5201
2024-01-10 22:06:48,161 - GAugM EPNet train, Epoch [ 48/70]: loss 0.7210, auc 0.5829, ap 0.5855
2024-01-10 22:06:48,255 - GAugM EPNet train, Epoch [ 49/70]: loss 0.7209, auc 0.4295, ap 0.4671
2024-01-10 22:06:48,347 - GAugM EPNet train, Epoch [ 50/70]: loss 0.7210, auc 0.5121, ap 0.5201
2024-01-10 22:06:48,440 - GAugM EPNet train, Epoch [ 51/70]: loss 0.7210, auc 0.4224, ap 0.4424
2024-01-10 22:06:48,538 - GAugM EPNet train, Epoch [ 52/70]: loss 0.7209, auc 0.4737, ap 0.5287
2024-01-10 22:06:48,630 - GAugM EPNet train, Epoch [ 53/70]: loss 0.7209, auc 0.5819, ap 0.5973
2024-01-10 22:06:48,720 - GAugM EPNet train, Epoch [ 54/70]: loss 0.7211, auc 0.5829, ap 0.5761
2024-01-10 22:06:48,814 - GAugM EPNet train, Epoch [ 55/70]: loss 0.7209, auc 0.5765, ap 0.5830
2024-01-10 22:06:48,904 - GAugM EPNet train, Epoch [ 56/70]: loss 0.7208, auc 0.4687, ap 0.4726
2024-01-10 22:06:48,992 - GAugM EPNet train, Epoch [ 57/70]: loss 0.7209, auc 0.4630, ap 0.4690
2024-01-10 22:06:49,083 - GAugM EPNet train, Epoch [ 58/70]: loss 0.7210, auc 0.5566, ap 0.6062
2024-01-10 22:06:49,173 - GAugM EPNet train, Epoch [ 59/70]: loss 0.7211, auc 0.5135, ap 0.5388
2024-01-10 22:06:49,262 - GAugM EPNet train, Epoch [ 60/70]: loss 0.7210, auc 0.5616, ap 0.5531
2024-01-10 22:06:49,350 - GAugM EPNet train, Epoch [ 61/70]: loss 0.7209, auc 0.4850, ap 0.4971
2024-01-10 22:06:49,442 - GAugM EPNet train, Epoch [ 62/70]: loss 0.7210, auc 0.5142, ap 0.5611
2024-01-10 22:06:49,533 - GAugM EPNet train, Epoch [ 63/70]: loss 0.7208, auc 0.4708, ap 0.5137
2024-01-10 22:06:49,627 - GAugM EPNet train, Epoch [ 64/70]: loss 0.7208, auc 0.5267, ap 0.5666
2024-01-10 22:06:49,718 - GAugM EPNet train, Epoch [ 65/70]: loss 0.7208, auc 0.5185, ap 0.5536
2024-01-10 22:06:49,805 - GAugM EPNet train, Epoch [ 66/70]: loss 0.7209, auc 0.4071, ap 0.4352
2024-01-10 22:06:49,894 - GAugM EPNet train, Epoch [ 67/70]: loss 0.7209, auc 0.5292, ap 0.5321
2024-01-10 22:06:49,989 - GAugM EPNet train, Epoch [ 68/70]: loss 0.7210, auc 0.5449, ap 0.5950
2024-01-10 22:06:50,080 - GAugM EPNet train, Epoch [ 69/70]: loss 0.7210, auc 0.5185, ap 0.5270
2024-01-10 22:06:50,171 - GAugM EPNet train, Epoch [ 70/70]: loss 0.7210, auc 0.5278, ap 0.5105
2024-01-10 22:06:50,183 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0dd5a56c90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:06:50,886 - GAugM EPNet train, Epoch [  1/70]: loss 0.7210, auc 0.4651, ap 0.4758
2024-01-10 22:06:50,979 - GAugM EPNet train, Epoch [  2/70]: loss 0.7210, auc 0.5789, ap 0.5626
2024-01-10 22:06:51,076 - GAugM EPNet train, Epoch [  3/70]: loss 0.7209, auc 0.5071, ap 0.5268
2024-01-10 22:06:51,161 - GAugM EPNet train, Epoch [  4/70]: loss 0.7209, auc 0.5700, ap 0.5520
2024-01-10 22:06:51,243 - GAugM EPNet train, Epoch [  5/70]: loss 0.7209, auc 0.5730, ap 0.6004
2024-01-10 22:06:51,324 - GAugM EPNet train, Epoch [  6/70]: loss 0.7209, auc 0.4865, ap 0.4796
2024-01-10 22:06:51,400 - GAugM EPNet train, Epoch [  7/70]: loss 0.7209, auc 0.4813, ap 0.5062
2024-01-10 22:06:51,474 - GAugM EPNet train, Epoch [  8/70]: loss 0.7210, auc 0.5089, ap 0.5307
2024-01-10 22:06:51,548 - GAugM EPNet train, Epoch [  9/70]: loss 0.7209, auc 0.4290, ap 0.4524
2024-01-10 22:06:51,631 - GAugM EPNet train, Epoch [ 10/70]: loss 0.7208, auc 0.5101, ap 0.5170
2024-01-10 22:06:51,722 - GAugM EPNet train, Epoch [ 11/70]: loss 0.7209, auc 0.5575, ap 0.5710
2024-01-10 22:06:51,801 - GAugM EPNet train, Epoch [ 12/70]: loss 0.7210, auc 0.4292, ap 0.4624
2024-01-10 22:06:51,880 - GAugM EPNet train, Epoch [ 13/70]: loss 0.7209, auc 0.5255, ap 0.5439
2024-01-10 22:06:51,956 - GAugM EPNet train, Epoch [ 14/70]: loss 0.7209, auc 0.4890, ap 0.5132
2024-01-10 22:06:52,041 - GAugM EPNet train, Epoch [ 15/70]: loss 0.7210, auc 0.4062, ap 0.4727
2024-01-10 22:06:52,123 - GAugM EPNet train, Epoch [ 16/70]: loss 0.7209, auc 0.5005, ap 0.5021
2024-01-10 22:06:52,199 - GAugM EPNet train, Epoch [ 17/70]: loss 0.7210, auc 0.5956, ap 0.5871
2024-01-10 22:06:52,278 - GAugM EPNet train, Epoch [ 18/70]: loss 0.7210, auc 0.6314, ap 0.6106
2024-01-10 22:06:52,359 - GAugM EPNet train, Epoch [ 19/70]: loss 0.7209, auc 0.4822, ap 0.4942
2024-01-10 22:06:52,436 - GAugM EPNet train, Epoch [ 20/70]: loss 0.7210, auc 0.5011, ap 0.5750
2024-01-10 22:06:52,515 - GAugM EPNet train, Epoch [ 21/70]: loss 0.7209, auc 0.5324, ap 0.5059
2024-01-10 22:06:52,599 - GAugM EPNet train, Epoch [ 22/70]: loss 0.7210, auc 0.3346, ap 0.4063
2024-01-10 22:06:52,681 - GAugM EPNet train, Epoch [ 23/70]: loss 0.7208, auc 0.5523, ap 0.5386
2024-01-10 22:06:52,765 - GAugM EPNet train, Epoch [ 24/70]: loss 0.7209, auc 0.5774, ap 0.5460
2024-01-10 22:06:52,852 - GAugM EPNet train, Epoch [ 25/70]: loss 0.7209, auc 0.4236, ap 0.4658
2024-01-10 22:06:52,930 - GAugM EPNet train, Epoch [ 26/70]: loss 0.7210, auc 0.5682, ap 0.5676
2024-01-10 22:06:53,012 - GAugM EPNet train, Epoch [ 27/70]: loss 0.7209, auc 0.4176, ap 0.5027
2024-01-10 22:06:53,092 - GAugM EPNet train, Epoch [ 28/70]: loss 0.7209, auc 0.5991, ap 0.6017
2024-01-10 22:06:53,192 - GAugM EPNet train, Epoch [ 29/70]: loss 0.7210, auc 0.5109, ap 0.4988
2024-01-10 22:06:53,281 - GAugM EPNet train, Epoch [ 30/70]: loss 0.7209, auc 0.5048, ap 0.5472
2024-01-10 22:06:53,381 - GAugM EPNet train, Epoch [ 31/70]: loss 0.7208, auc 0.5554, ap 0.5671
2024-01-10 22:06:53,479 - GAugM EPNet train, Epoch [ 32/70]: loss 0.7210, auc 0.5675, ap 0.5443
2024-01-10 22:06:53,577 - GAugM EPNet train, Epoch [ 33/70]: loss 0.7209, auc 0.4948, ap 0.5308
2024-01-10 22:06:53,668 - GAugM EPNet train, Epoch [ 34/70]: loss 0.7209, auc 0.4849, ap 0.5176
2024-01-10 22:06:53,760 - GAugM EPNet train, Epoch [ 35/70]: loss 0.7209, auc 0.4996, ap 0.4928
2024-01-10 22:06:53,858 - GAugM EPNet train, Epoch [ 36/70]: loss 0.7209, auc 0.5756, ap 0.5855
2024-01-10 22:06:53,947 - GAugM EPNet train, Epoch [ 37/70]: loss 0.7209, auc 0.4948, ap 0.5194
2024-01-10 22:06:54,039 - GAugM EPNet train, Epoch [ 38/70]: loss 0.7209, auc 0.4781, ap 0.4774
2024-01-10 22:06:54,132 - GAugM EPNet train, Epoch [ 39/70]: loss 0.7208, auc 0.4952, ap 0.5129
2024-01-10 22:06:54,229 - GAugM EPNet train, Epoch [ 40/70]: loss 0.7210, auc 0.5036, ap 0.4972
2024-01-10 22:06:54,321 - GAugM EPNet train, Epoch [ 41/70]: loss 0.7210, auc 0.5100, ap 0.5315
2024-01-10 22:06:54,410 - GAugM EPNet train, Epoch [ 42/70]: loss 0.7209, auc 0.5653, ap 0.6199
2024-01-10 22:06:54,499 - GAugM EPNet train, Epoch [ 43/70]: loss 0.7208, auc 0.5128, ap 0.5466
2024-01-10 22:06:54,587 - GAugM EPNet train, Epoch [ 44/70]: loss 0.7208, auc 0.3982, ap 0.4455
2024-01-10 22:06:54,665 - GAugM EPNet train, Epoch [ 45/70]: loss 0.7209, auc 0.5014, ap 0.5431
2024-01-10 22:06:54,743 - GAugM EPNet train, Epoch [ 46/70]: loss 0.7209, auc 0.4434, ap 0.4829
2024-01-10 22:06:54,822 - GAugM EPNet train, Epoch [ 47/70]: loss 0.7210, auc 0.4842, ap 0.5063
2024-01-10 22:06:54,902 - GAugM EPNet train, Epoch [ 48/70]: loss 0.7210, auc 0.6059, ap 0.6342
2024-01-10 22:06:54,994 - GAugM EPNet train, Epoch [ 49/70]: loss 0.7209, auc 0.6007, ap 0.5936
2024-01-10 22:06:55,082 - GAugM EPNet train, Epoch [ 50/70]: loss 0.7210, auc 0.5091, ap 0.5108
2024-01-10 22:06:55,173 - GAugM EPNet train, Epoch [ 51/70]: loss 0.7210, auc 0.4710, ap 0.4791
2024-01-10 22:06:55,260 - GAugM EPNet train, Epoch [ 52/70]: loss 0.7209, auc 0.3784, ap 0.4367
2024-01-10 22:06:55,347 - GAugM EPNet train, Epoch [ 53/70]: loss 0.7209, auc 0.4687, ap 0.5098
2024-01-10 22:06:55,434 - GAugM EPNet train, Epoch [ 54/70]: loss 0.7211, auc 0.5566, ap 0.5340
2024-01-10 22:06:55,523 - GAugM EPNet train, Epoch [ 55/70]: loss 0.7209, auc 0.6266, ap 0.6211
2024-01-10 22:06:55,611 - GAugM EPNet train, Epoch [ 56/70]: loss 0.7208, auc 0.5078, ap 0.5222
2024-01-10 22:06:55,695 - GAugM EPNet train, Epoch [ 57/70]: loss 0.7209, auc 0.5158, ap 0.5053
2024-01-10 22:06:55,784 - GAugM EPNet train, Epoch [ 58/70]: loss 0.7210, auc 0.5452, ap 0.5565
2024-01-10 22:06:55,878 - GAugM EPNet train, Epoch [ 59/70]: loss 0.7211, auc 0.5475, ap 0.5799
2024-01-10 22:06:55,964 - GAugM EPNet train, Epoch [ 60/70]: loss 0.7210, auc 0.5682, ap 0.5853
2024-01-10 22:06:56,053 - GAugM EPNet train, Epoch [ 61/70]: loss 0.7209, auc 0.5166, ap 0.5025
2024-01-10 22:06:56,133 - GAugM EPNet train, Epoch [ 62/70]: loss 0.7210, auc 0.4810, ap 0.5283
2024-01-10 22:06:56,211 - GAugM EPNet train, Epoch [ 63/70]: loss 0.7208, auc 0.4155, ap 0.4462
2024-01-10 22:06:56,310 - GAugM EPNet train, Epoch [ 64/70]: loss 0.7208, auc 0.4393, ap 0.4826
2024-01-10 22:06:56,405 - GAugM EPNet train, Epoch [ 65/70]: loss 0.7208, auc 0.5892, ap 0.5839
2024-01-10 22:06:56,490 - GAugM EPNet train, Epoch [ 66/70]: loss 0.7209, auc 0.4254, ap 0.4750
2024-01-10 22:06:56,568 - GAugM EPNet train, Epoch [ 67/70]: loss 0.7209, auc 0.5648, ap 0.5594
2024-01-10 22:06:56,652 - GAugM EPNet train, Epoch [ 68/70]: loss 0.7210, auc 0.5954, ap 0.6104
2024-01-10 22:06:56,731 - GAugM EPNet train, Epoch [ 69/70]: loss 0.7210, auc 0.5308, ap 0.5742
2024-01-10 22:06:56,813 - GAugM EPNet train, Epoch [ 70/70]: loss 0.7210, auc 0.4672, ap 0.4762
2024-01-10 22:06:56,822 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03503d50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:06:57,505 - GAugM EPNet train, Epoch [  1/55]: loss 0.7210, auc 0.4341, ap 0.4986
2024-01-10 22:06:57,588 - GAugM EPNet train, Epoch [  2/55]: loss 0.7210, auc 0.4900, ap 0.4785
2024-01-10 22:06:57,667 - GAugM EPNet train, Epoch [  3/55]: loss 0.7209, auc 0.5295, ap 0.5532
2024-01-10 22:06:57,753 - GAugM EPNet train, Epoch [  4/55]: loss 0.7209, auc 0.4836, ap 0.5243
2024-01-10 22:06:57,840 - GAugM EPNet train, Epoch [  5/55]: loss 0.7209, auc 0.5926, ap 0.5912
2024-01-10 22:06:57,935 - GAugM EPNet train, Epoch [  6/55]: loss 0.7209, auc 0.4972, ap 0.4934
2024-01-10 22:06:58,031 - GAugM EPNet train, Epoch [  7/55]: loss 0.7209, auc 0.4530, ap 0.4574
2024-01-10 22:06:58,121 - GAugM EPNet train, Epoch [  8/55]: loss 0.7210, auc 0.4519, ap 0.4601
2024-01-10 22:06:58,208 - GAugM EPNet train, Epoch [  9/55]: loss 0.7209, auc 0.4042, ap 0.4427
2024-01-10 22:06:58,298 - GAugM EPNet train, Epoch [ 10/55]: loss 0.7208, auc 0.4121, ap 0.4408
2024-01-10 22:06:58,391 - GAugM EPNet train, Epoch [ 11/55]: loss 0.7209, auc 0.5541, ap 0.5784
2024-01-10 22:06:58,475 - GAugM EPNet train, Epoch [ 12/55]: loss 0.7210, auc 0.5384, ap 0.5115
2024-01-10 22:06:58,563 - GAugM EPNet train, Epoch [ 13/55]: loss 0.7209, auc 0.5570, ap 0.5406
2024-01-10 22:06:58,659 - GAugM EPNet train, Epoch [ 14/55]: loss 0.7209, auc 0.5317, ap 0.5281
2024-01-10 22:06:58,749 - GAugM EPNet train, Epoch [ 15/55]: loss 0.7210, auc 0.3619, ap 0.4376
2024-01-10 22:06:58,843 - GAugM EPNet train, Epoch [ 16/55]: loss 0.7209, auc 0.5990, ap 0.5873
2024-01-10 22:06:58,928 - GAugM EPNet train, Epoch [ 17/55]: loss 0.7210, auc 0.5214, ap 0.5232
2024-01-10 22:06:59,014 - GAugM EPNet train, Epoch [ 18/55]: loss 0.7210, auc 0.5587, ap 0.5641
2024-01-10 22:06:59,099 - GAugM EPNet train, Epoch [ 19/55]: loss 0.7209, auc 0.4616, ap 0.4644
2024-01-10 22:06:59,190 - GAugM EPNet train, Epoch [ 20/55]: loss 0.7210, auc 0.4954, ap 0.5117
2024-01-10 22:06:59,282 - GAugM EPNet train, Epoch [ 21/55]: loss 0.7209, auc 0.4982, ap 0.5349
2024-01-10 22:06:59,372 - GAugM EPNet train, Epoch [ 22/55]: loss 0.7210, auc 0.4299, ap 0.4557
2024-01-10 22:06:59,458 - GAugM EPNet train, Epoch [ 23/55]: loss 0.7208, auc 0.5039, ap 0.4963
2024-01-10 22:06:59,541 - GAugM EPNet train, Epoch [ 24/55]: loss 0.7209, auc 0.5320, ap 0.5078
2024-01-10 22:06:59,627 - GAugM EPNet train, Epoch [ 25/55]: loss 0.7209, auc 0.4416, ap 0.4613
2024-01-10 22:06:59,713 - GAugM EPNet train, Epoch [ 26/55]: loss 0.7210, auc 0.4539, ap 0.4631
2024-01-10 22:06:59,800 - GAugM EPNet train, Epoch [ 27/55]: loss 0.7209, auc 0.4470, ap 0.5159
2024-01-10 22:06:59,892 - GAugM EPNet train, Epoch [ 28/55]: loss 0.7209, auc 0.5904, ap 0.5736
2024-01-10 22:06:59,977 - GAugM EPNet train, Epoch [ 29/55]: loss 0.7210, auc 0.5203, ap 0.5241
2024-01-10 22:07:00,063 - GAugM EPNet train, Epoch [ 30/55]: loss 0.7209, auc 0.4886, ap 0.5076
2024-01-10 22:07:00,145 - GAugM EPNet train, Epoch [ 31/55]: loss 0.7208, auc 0.4996, ap 0.5279
2024-01-10 22:07:00,229 - GAugM EPNet train, Epoch [ 32/55]: loss 0.7210, auc 0.6125, ap 0.5843
2024-01-10 22:07:00,319 - GAugM EPNet train, Epoch [ 33/55]: loss 0.7209, auc 0.4972, ap 0.5029
2024-01-10 22:07:00,405 - GAugM EPNet train, Epoch [ 34/55]: loss 0.7209, auc 0.4341, ap 0.4878
2024-01-10 22:07:00,491 - GAugM EPNet train, Epoch [ 35/55]: loss 0.7209, auc 0.5036, ap 0.4868
2024-01-10 22:07:00,574 - GAugM EPNet train, Epoch [ 36/55]: loss 0.7209, auc 0.5409, ap 0.5523
2024-01-10 22:07:00,663 - GAugM EPNet train, Epoch [ 37/55]: loss 0.7209, auc 0.4982, ap 0.5163
2024-01-10 22:07:00,747 - GAugM EPNet train, Epoch [ 38/55]: loss 0.7209, auc 0.5199, ap 0.4973
2024-01-10 22:07:00,824 - GAugM EPNet train, Epoch [ 39/55]: loss 0.7208, auc 0.4220, ap 0.4599
2024-01-10 22:07:00,902 - GAugM EPNet train, Epoch [ 40/55]: loss 0.7210, auc 0.5708, ap 0.5578
2024-01-10 22:07:00,977 - GAugM EPNet train, Epoch [ 41/55]: loss 0.7210, auc 0.5288, ap 0.5517
2024-01-10 22:07:01,063 - GAugM EPNet train, Epoch [ 42/55]: loss 0.7209, auc 0.5046, ap 0.5272
2024-01-10 22:07:01,154 - GAugM EPNet train, Epoch [ 43/55]: loss 0.7208, auc 0.4270, ap 0.4763
2024-01-10 22:07:01,238 - GAugM EPNet train, Epoch [ 44/55]: loss 0.7208, auc 0.4153, ap 0.4688
2024-01-10 22:07:01,311 - GAugM EPNet train, Epoch [ 45/55]: loss 0.7209, auc 0.5687, ap 0.5744
2024-01-10 22:07:01,387 - GAugM EPNet train, Epoch [ 46/55]: loss 0.7209, auc 0.4452, ap 0.4754
2024-01-10 22:07:01,465 - GAugM EPNet train, Epoch [ 47/55]: loss 0.7210, auc 0.4181, ap 0.4469
2024-01-10 22:07:01,565 - GAugM EPNet train, Epoch [ 48/55]: loss 0.7210, auc 0.5342, ap 0.5341
2024-01-10 22:07:01,653 - GAugM EPNet train, Epoch [ 49/55]: loss 0.7209, auc 0.5381, ap 0.5603
2024-01-10 22:07:01,738 - GAugM EPNet train, Epoch [ 50/55]: loss 0.7210, auc 0.5523, ap 0.5598
2024-01-10 22:07:01,818 - GAugM EPNet train, Epoch [ 51/55]: loss 0.7210, auc 0.3968, ap 0.4752
2024-01-10 22:07:01,901 - GAugM EPNet train, Epoch [ 52/55]: loss 0.7209, auc 0.5117, ap 0.5140
2024-01-10 22:07:01,989 - GAugM EPNet train, Epoch [ 53/55]: loss 0.7209, auc 0.5068, ap 0.5537
2024-01-10 22:07:02,078 - GAugM EPNet train, Epoch [ 54/55]: loss 0.7211, auc 0.5837, ap 0.5771
2024-01-10 22:07:02,163 - GAugM EPNet train, Epoch [ 55/55]: loss 0.7209, auc 0.5203, ap 0.5437
2024-01-10 22:07:02,173 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d039e6c50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:07:02,927 - GAugM EPNet train, Epoch [  1/55]: loss 0.7210, auc 0.4680, ap 0.4742
2024-01-10 22:07:03,023 - GAugM EPNet train, Epoch [  2/55]: loss 0.7210, auc 0.4737, ap 0.4829
2024-01-10 22:07:03,109 - GAugM EPNet train, Epoch [  3/55]: loss 0.7209, auc 0.5303, ap 0.5153
2024-01-10 22:07:03,190 - GAugM EPNet train, Epoch [  4/55]: loss 0.7209, auc 0.4669, ap 0.4802
2024-01-10 22:07:03,267 - GAugM EPNet train, Epoch [  5/55]: loss 0.7209, auc 0.5584, ap 0.5504
2024-01-10 22:07:03,341 - GAugM EPNet train, Epoch [  6/55]: loss 0.7209, auc 0.5363, ap 0.5229
2024-01-10 22:07:03,436 - GAugM EPNet train, Epoch [  7/55]: loss 0.7209, auc 0.4370, ap 0.4490
2024-01-10 22:07:03,523 - GAugM EPNet train, Epoch [  8/55]: loss 0.7210, auc 0.5064, ap 0.4978
2024-01-10 22:07:03,609 - GAugM EPNet train, Epoch [  9/55]: loss 0.7209, auc 0.5142, ap 0.4869
2024-01-10 22:07:03,697 - GAugM EPNet train, Epoch [ 10/55]: loss 0.7208, auc 0.5506, ap 0.5362
2024-01-10 22:07:03,784 - GAugM EPNet train, Epoch [ 11/55]: loss 0.7209, auc 0.5139, ap 0.5456
2024-01-10 22:07:03,869 - GAugM EPNet train, Epoch [ 12/55]: loss 0.7210, auc 0.4765, ap 0.4639
2024-01-10 22:07:03,958 - GAugM EPNet train, Epoch [ 13/55]: loss 0.7209, auc 0.6040, ap 0.5952
2024-01-10 22:07:04,046 - GAugM EPNet train, Epoch [ 14/55]: loss 0.7209, auc 0.5498, ap 0.5111
2024-01-10 22:07:04,137 - GAugM EPNet train, Epoch [ 15/55]: loss 0.7210, auc 0.4466, ap 0.4815
2024-01-10 22:07:04,222 - GAugM EPNet train, Epoch [ 16/55]: loss 0.7209, auc 0.5862, ap 0.5834
2024-01-10 22:07:04,308 - GAugM EPNet train, Epoch [ 17/55]: loss 0.7210, auc 0.4843, ap 0.4765
2024-01-10 22:07:04,392 - GAugM EPNet train, Epoch [ 18/55]: loss 0.7210, auc 0.6609, ap 0.6262
2024-01-10 22:07:04,477 - GAugM EPNet train, Epoch [ 19/55]: loss 0.7209, auc 0.5377, ap 0.5070
2024-01-10 22:07:04,562 - GAugM EPNet train, Epoch [ 20/55]: loss 0.7210, auc 0.5018, ap 0.5065
2024-01-10 22:07:04,650 - GAugM EPNet train, Epoch [ 21/55]: loss 0.7209, auc 0.5157, ap 0.4908
2024-01-10 22:07:04,738 - GAugM EPNet train, Epoch [ 22/55]: loss 0.7210, auc 0.3982, ap 0.4464
2024-01-10 22:07:04,823 - GAugM EPNet train, Epoch [ 23/55]: loss 0.7208, auc 0.4683, ap 0.4809
2024-01-10 22:07:04,908 - GAugM EPNet train, Epoch [ 24/55]: loss 0.7209, auc 0.5605, ap 0.5276
2024-01-10 22:07:04,996 - GAugM EPNet train, Epoch [ 25/55]: loss 0.7209, auc 0.4516, ap 0.4602
2024-01-10 22:07:05,080 - GAugM EPNet train, Epoch [ 26/55]: loss 0.7210, auc 0.5676, ap 0.5643
2024-01-10 22:07:05,173 - GAugM EPNet train, Epoch [ 27/55]: loss 0.7209, auc 0.4199, ap 0.4456
2024-01-10 22:07:05,259 - GAugM EPNet train, Epoch [ 28/55]: loss 0.7209, auc 0.5975, ap 0.5646
2024-01-10 22:07:05,345 - GAugM EPNet train, Epoch [ 29/55]: loss 0.7210, auc 0.5217, ap 0.5460
2024-01-10 22:07:05,429 - GAugM EPNet train, Epoch [ 30/55]: loss 0.7209, auc 0.5349, ap 0.5291
2024-01-10 22:07:05,515 - GAugM EPNet train, Epoch [ 31/55]: loss 0.7208, auc 0.4797, ap 0.4738
2024-01-10 22:07:05,601 - GAugM EPNet train, Epoch [ 32/55]: loss 0.7210, auc 0.6082, ap 0.5757
2024-01-10 22:07:05,690 - GAugM EPNet train, Epoch [ 33/55]: loss 0.7209, auc 0.5965, ap 0.5719
2024-01-10 22:07:05,775 - GAugM EPNet train, Epoch [ 34/55]: loss 0.7209, auc 0.4559, ap 0.4634
2024-01-10 22:07:05,862 - GAugM EPNet train, Epoch [ 35/55]: loss 0.7209, auc 0.4683, ap 0.4663
2024-01-10 22:07:05,946 - GAugM EPNet train, Epoch [ 36/55]: loss 0.7209, auc 0.5577, ap 0.5550
2024-01-10 22:07:06,033 - GAugM EPNet train, Epoch [ 37/55]: loss 0.7209, auc 0.4779, ap 0.4801
2024-01-10 22:07:06,120 - GAugM EPNet train, Epoch [ 38/55]: loss 0.7209, auc 0.5007, ap 0.4942
2024-01-10 22:07:06,212 - GAugM EPNet train, Epoch [ 39/55]: loss 0.7208, auc 0.4530, ap 0.4935
2024-01-10 22:07:06,302 - GAugM EPNet train, Epoch [ 40/55]: loss 0.7210, auc 0.5320, ap 0.5251
2024-01-10 22:07:06,390 - GAugM EPNet train, Epoch [ 41/55]: loss 0.7210, auc 0.4715, ap 0.5091
2024-01-10 22:07:06,477 - GAugM EPNet train, Epoch [ 42/55]: loss 0.7209, auc 0.5367, ap 0.5434
2024-01-10 22:07:06,565 - GAugM EPNet train, Epoch [ 43/55]: loss 0.7208, auc 0.4299, ap 0.4526
2024-01-10 22:07:06,655 - GAugM EPNet train, Epoch [ 44/55]: loss 0.7208, auc 0.4462, ap 0.4562
2024-01-10 22:07:06,748 - GAugM EPNet train, Epoch [ 45/55]: loss 0.7209, auc 0.5338, ap 0.5198
2024-01-10 22:07:06,835 - GAugM EPNet train, Epoch [ 46/55]: loss 0.7209, auc 0.4352, ap 0.4616
2024-01-10 22:07:06,918 - GAugM EPNet train, Epoch [ 47/55]: loss 0.7210, auc 0.4537, ap 0.4542
2024-01-10 22:07:07,004 - GAugM EPNet train, Epoch [ 48/55]: loss 0.7210, auc 0.6595, ap 0.6271
2024-01-10 22:07:07,093 - GAugM EPNet train, Epoch [ 49/55]: loss 0.7209, auc 0.5196, ap 0.5156
2024-01-10 22:07:07,177 - GAugM EPNet train, Epoch [ 50/55]: loss 0.7210, auc 0.5491, ap 0.5337
2024-01-10 22:07:07,266 - GAugM EPNet train, Epoch [ 51/55]: loss 0.7210, auc 0.4925, ap 0.4914
2024-01-10 22:07:07,351 - GAugM EPNet train, Epoch [ 52/55]: loss 0.7209, auc 0.4883, ap 0.4780
2024-01-10 22:07:07,439 - GAugM EPNet train, Epoch [ 53/55]: loss 0.7209, auc 0.5050, ap 0.4853
2024-01-10 22:07:07,531 - GAugM EPNet train, Epoch [ 54/55]: loss 0.7211, auc 0.5150, ap 0.4962
2024-01-10 22:07:07,618 - GAugM EPNet train, Epoch [ 55/55]: loss 0.7209, auc 0.6096, ap 0.6206
2024-01-10 22:07:07,626 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa0158d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:07:08,340 - GAugM EPNet train, Epoch [  1/55]: loss 0.7210, auc 0.4633, ap 0.4603
2024-01-10 22:07:08,427 - GAugM EPNet train, Epoch [  2/55]: loss 0.7210, auc 0.4731, ap 0.4857
2024-01-10 22:07:08,520 - GAugM EPNet train, Epoch [  3/55]: loss 0.7209, auc 0.5133, ap 0.5116
2024-01-10 22:07:08,607 - GAugM EPNet train, Epoch [  4/55]: loss 0.7209, auc 0.4769, ap 0.4902
2024-01-10 22:07:08,695 - GAugM EPNet train, Epoch [  5/55]: loss 0.7209, auc 0.5342, ap 0.5260
2024-01-10 22:07:08,791 - GAugM EPNet train, Epoch [  6/55]: loss 0.7209, auc 0.4909, ap 0.4802
2024-01-10 22:07:08,879 - GAugM EPNet train, Epoch [  7/55]: loss 0.7209, auc 0.4438, ap 0.4481
2024-01-10 22:07:08,966 - GAugM EPNet train, Epoch [  8/55]: loss 0.7210, auc 0.5639, ap 0.5502
2024-01-10 22:07:09,046 - GAugM EPNet train, Epoch [  9/55]: loss 0.7209, auc 0.5132, ap 0.4985
2024-01-10 22:07:09,124 - GAugM EPNet train, Epoch [ 10/55]: loss 0.7208, auc 0.5215, ap 0.5145
2024-01-10 22:07:09,203 - GAugM EPNet train, Epoch [ 11/55]: loss 0.7209, auc 0.4265, ap 0.4441
2024-01-10 22:07:09,287 - GAugM EPNet train, Epoch [ 12/55]: loss 0.7210, auc 0.4845, ap 0.4921
2024-01-10 22:07:09,367 - GAugM EPNet train, Epoch [ 13/55]: loss 0.7209, auc 0.5326, ap 0.5364
2024-01-10 22:07:09,442 - GAugM EPNet train, Epoch [ 14/55]: loss 0.7209, auc 0.5190, ap 0.4909
2024-01-10 22:07:09,519 - GAugM EPNet train, Epoch [ 15/55]: loss 0.7210, auc 0.4033, ap 0.4768
2024-01-10 22:07:09,593 - GAugM EPNet train, Epoch [ 16/55]: loss 0.7209, auc 0.5069, ap 0.5449
2024-01-10 22:07:09,676 - GAugM EPNet train, Epoch [ 17/55]: loss 0.7210, auc 0.5247, ap 0.5123
2024-01-10 22:07:09,758 - GAugM EPNet train, Epoch [ 18/55]: loss 0.7210, auc 0.5999, ap 0.5753
2024-01-10 22:07:09,836 - GAugM EPNet train, Epoch [ 19/55]: loss 0.7209, auc 0.5881, ap 0.5490
2024-01-10 22:07:09,912 - GAugM EPNet train, Epoch [ 20/55]: loss 0.7210, auc 0.4979, ap 0.5236
2024-01-10 22:07:09,989 - GAugM EPNet train, Epoch [ 21/55]: loss 0.7209, auc 0.5166, ap 0.5071
2024-01-10 22:07:10,062 - GAugM EPNet train, Epoch [ 22/55]: loss 0.7210, auc 0.4160, ap 0.4400
2024-01-10 22:07:10,141 - GAugM EPNet train, Epoch [ 23/55]: loss 0.7208, auc 0.4591, ap 0.4731
2024-01-10 22:07:10,220 - GAugM EPNet train, Epoch [ 24/55]: loss 0.7209, auc 0.5468, ap 0.5206
2024-01-10 22:07:10,294 - GAugM EPNet train, Epoch [ 25/55]: loss 0.7209, auc 0.4283, ap 0.4548
2024-01-10 22:07:10,369 - GAugM EPNet train, Epoch [ 26/55]: loss 0.7210, auc 0.4530, ap 0.5032
2024-01-10 22:07:10,445 - GAugM EPNet train, Epoch [ 27/55]: loss 0.7209, auc 0.4425, ap 0.4874
2024-01-10 22:07:10,518 - GAugM EPNet train, Epoch [ 28/55]: loss 0.7209, auc 0.5862, ap 0.5878
2024-01-10 22:07:10,607 - GAugM EPNet train, Epoch [ 29/55]: loss 0.7210, auc 0.4728, ap 0.4896
2024-01-10 22:07:10,684 - GAugM EPNet train, Epoch [ 30/55]: loss 0.7209, auc 0.5320, ap 0.5334
2024-01-10 22:07:10,757 - GAugM EPNet train, Epoch [ 31/55]: loss 0.7208, auc 0.4393, ap 0.4686
2024-01-10 22:07:10,832 - GAugM EPNet train, Epoch [ 32/55]: loss 0.7210, auc 0.5240, ap 0.5099
2024-01-10 22:07:10,913 - GAugM EPNet train, Epoch [ 33/55]: loss 0.7209, auc 0.5497, ap 0.5439
2024-01-10 22:07:10,988 - GAugM EPNet train, Epoch [ 34/55]: loss 0.7209, auc 0.4333, ap 0.4566
2024-01-10 22:07:11,068 - GAugM EPNet train, Epoch [ 35/55]: loss 0.7209, auc 0.5568, ap 0.5233
2024-01-10 22:07:11,145 - GAugM EPNet train, Epoch [ 36/55]: loss 0.7209, auc 0.5116, ap 0.5292
2024-01-10 22:07:11,221 - GAugM EPNet train, Epoch [ 37/55]: loss 0.7209, auc 0.4306, ap 0.4383
2024-01-10 22:07:11,296 - GAugM EPNet train, Epoch [ 38/55]: loss 0.7209, auc 0.5082, ap 0.4806
2024-01-10 22:07:11,375 - GAugM EPNet train, Epoch [ 39/55]: loss 0.7208, auc 0.5441, ap 0.5268
2024-01-10 22:07:11,452 - GAugM EPNet train, Epoch [ 40/55]: loss 0.7210, auc 0.5470, ap 0.5023
2024-01-10 22:07:11,529 - GAugM EPNet train, Epoch [ 41/55]: loss 0.7210, auc 0.4639, ap 0.4800
2024-01-10 22:07:11,602 - GAugM EPNet train, Epoch [ 42/55]: loss 0.7209, auc 0.5696, ap 0.5902
2024-01-10 22:07:11,679 - GAugM EPNet train, Epoch [ 43/55]: loss 0.7208, auc 0.4729, ap 0.4988
2024-01-10 22:07:11,760 - GAugM EPNet train, Epoch [ 44/55]: loss 0.7208, auc 0.3745, ap 0.4255
2024-01-10 22:07:11,834 - GAugM EPNet train, Epoch [ 45/55]: loss 0.7209, auc 0.4822, ap 0.5138
2024-01-10 22:07:11,908 - GAugM EPNet train, Epoch [ 46/55]: loss 0.7209, auc 0.4064, ap 0.4325
2024-01-10 22:07:11,981 - GAugM EPNet train, Epoch [ 47/55]: loss 0.7210, auc 0.5345, ap 0.5430
2024-01-10 22:07:12,061 - GAugM EPNet train, Epoch [ 48/55]: loss 0.7210, auc 0.5673, ap 0.5551
2024-01-10 22:07:12,138 - GAugM EPNet train, Epoch [ 49/55]: loss 0.7209, auc 0.5764, ap 0.5512
2024-01-10 22:07:12,212 - GAugM EPNet train, Epoch [ 50/55]: loss 0.7210, auc 0.5497, ap 0.5381
2024-01-10 22:07:12,285 - GAugM EPNet train, Epoch [ 51/55]: loss 0.7210, auc 0.5041, ap 0.5473
2024-01-10 22:07:12,360 - GAugM EPNet train, Epoch [ 52/55]: loss 0.7209, auc 0.4601, ap 0.4765
2024-01-10 22:07:12,437 - GAugM EPNet train, Epoch [ 53/55]: loss 0.7209, auc 0.5057, ap 0.4859
2024-01-10 22:07:12,511 - GAugM EPNet train, Epoch [ 54/55]: loss 0.7211, auc 0.5260, ap 0.5150
2024-01-10 22:07:12,592 - GAugM EPNet train, Epoch [ 55/55]: loss 0.7209, auc 0.5682, ap 0.5663
2024-01-10 22:07:12,592 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9e44dd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:07:13,269 - GAugM EPNet train, Epoch [  1/55]: loss 0.7210, auc 0.4436, ap 0.4556
2024-01-10 22:07:13,367 - GAugM EPNet train, Epoch [  2/55]: loss 0.7210, auc 0.5301, ap 0.5113
2024-01-10 22:07:13,470 - GAugM EPNet train, Epoch [  3/55]: loss 0.7209, auc 0.5983, ap 0.5723
2024-01-10 22:07:13,573 - GAugM EPNet train, Epoch [  4/55]: loss 0.7209, auc 0.4560, ap 0.5022
2024-01-10 22:07:13,666 - GAugM EPNet train, Epoch [  5/55]: loss 0.7209, auc 0.5530, ap 0.5736
2024-01-10 22:07:13,750 - GAugM EPNet train, Epoch [  6/55]: loss 0.7209, auc 0.5344, ap 0.5178
2024-01-10 22:07:13,842 - GAugM EPNet train, Epoch [  7/55]: loss 0.7209, auc 0.4525, ap 0.4592
2024-01-10 22:07:13,927 - GAugM EPNet train, Epoch [  8/55]: loss 0.7210, auc 0.5043, ap 0.4881
2024-01-10 22:07:14,011 - GAugM EPNet train, Epoch [  9/55]: loss 0.7209, auc 0.4284, ap 0.4471
2024-01-10 22:07:14,098 - GAugM EPNet train, Epoch [ 10/55]: loss 0.7208, auc 0.5214, ap 0.5063
2024-01-10 22:07:14,194 - GAugM EPNet train, Epoch [ 11/55]: loss 0.7209, auc 0.5384, ap 0.5213
2024-01-10 22:07:14,279 - GAugM EPNet train, Epoch [ 12/55]: loss 0.7210, auc 0.4438, ap 0.4827
2024-01-10 22:07:14,368 - GAugM EPNet train, Epoch [ 13/55]: loss 0.7209, auc 0.6000, ap 0.5823
2024-01-10 22:07:14,454 - GAugM EPNet train, Epoch [ 14/55]: loss 0.7209, auc 0.5148, ap 0.5082
2024-01-10 22:07:14,544 - GAugM EPNet train, Epoch [ 15/55]: loss 0.7210, auc 0.3743, ap 0.4462
2024-01-10 22:07:14,633 - GAugM EPNet train, Epoch [ 16/55]: loss 0.7209, auc 0.4395, ap 0.4600
2024-01-10 22:07:14,719 - GAugM EPNet train, Epoch [ 17/55]: loss 0.7210, auc 0.5539, ap 0.5242
2024-01-10 22:07:14,808 - GAugM EPNet train, Epoch [ 18/55]: loss 0.7210, auc 0.5696, ap 0.5470
2024-01-10 22:07:14,891 - GAugM EPNet train, Epoch [ 19/55]: loss 0.7209, auc 0.5020, ap 0.4925
2024-01-10 22:07:14,980 - GAugM EPNet train, Epoch [ 20/55]: loss 0.7210, auc 0.4033, ap 0.4562
2024-01-10 22:07:15,063 - GAugM EPNet train, Epoch [ 21/55]: loss 0.7209, auc 0.4915, ap 0.4982
2024-01-10 22:07:15,148 - GAugM EPNet train, Epoch [ 22/55]: loss 0.7210, auc 0.4005, ap 0.4467
2024-01-10 22:07:15,230 - GAugM EPNet train, Epoch [ 23/55]: loss 0.7208, auc 0.5190, ap 0.5163
2024-01-10 22:07:15,315 - GAugM EPNet train, Epoch [ 24/55]: loss 0.7209, auc 0.4982, ap 0.4990
2024-01-10 22:07:15,400 - GAugM EPNet train, Epoch [ 25/55]: loss 0.7209, auc 0.4712, ap 0.4645
2024-01-10 22:07:15,481 - GAugM EPNet train, Epoch [ 26/55]: loss 0.7210, auc 0.5381, ap 0.5659
2024-01-10 22:07:15,571 - GAugM EPNet train, Epoch [ 27/55]: loss 0.7209, auc 0.4252, ap 0.4979
2024-01-10 22:07:15,655 - GAugM EPNet train, Epoch [ 28/55]: loss 0.7209, auc 0.5392, ap 0.5554
2024-01-10 22:07:15,738 - GAugM EPNet train, Epoch [ 29/55]: loss 0.7210, auc 0.4681, ap 0.4844
2024-01-10 22:07:15,831 - GAugM EPNet train, Epoch [ 30/55]: loss 0.7209, auc 0.4859, ap 0.4742
2024-01-10 22:07:15,915 - GAugM EPNet train, Epoch [ 31/55]: loss 0.7208, auc 0.5112, ap 0.5115
2024-01-10 22:07:15,996 - GAugM EPNet train, Epoch [ 32/55]: loss 0.7210, auc 0.5901, ap 0.5701
2024-01-10 22:07:16,079 - GAugM EPNet train, Epoch [ 33/55]: loss 0.7209, auc 0.4961, ap 0.5348
2024-01-10 22:07:16,167 - GAugM EPNet train, Epoch [ 34/55]: loss 0.7209, auc 0.4318, ap 0.4581
2024-01-10 22:07:16,249 - GAugM EPNet train, Epoch [ 35/55]: loss 0.7209, auc 0.5436, ap 0.5121
2024-01-10 22:07:16,338 - GAugM EPNet train, Epoch [ 36/55]: loss 0.7209, auc 0.5913, ap 0.5990
2024-01-10 22:07:16,419 - GAugM EPNet train, Epoch [ 37/55]: loss 0.7209, auc 0.4455, ap 0.4611
2024-01-10 22:07:16,504 - GAugM EPNet train, Epoch [ 38/55]: loss 0.7209, auc 0.5255, ap 0.4975
2024-01-10 22:07:16,590 - GAugM EPNet train, Epoch [ 39/55]: loss 0.7208, auc 0.4612, ap 0.4896
2024-01-10 22:07:16,672 - GAugM EPNet train, Epoch [ 40/55]: loss 0.7210, auc 0.5256, ap 0.5027
2024-01-10 22:07:16,755 - GAugM EPNet train, Epoch [ 41/55]: loss 0.7210, auc 0.4950, ap 0.5151
2024-01-10 22:07:16,851 - GAugM EPNet train, Epoch [ 42/55]: loss 0.7209, auc 0.6004, ap 0.5958
2024-01-10 22:07:16,940 - GAugM EPNet train, Epoch [ 43/55]: loss 0.7208, auc 0.4251, ap 0.4830
2024-01-10 22:07:17,029 - GAugM EPNet train, Epoch [ 44/55]: loss 0.7208, auc 0.3786, ap 0.4400
2024-01-10 22:07:17,115 - GAugM EPNet train, Epoch [ 45/55]: loss 0.7209, auc 0.5603, ap 0.5724
2024-01-10 22:07:17,200 - GAugM EPNet train, Epoch [ 46/55]: loss 0.7209, auc 0.4112, ap 0.4670
2024-01-10 22:07:17,291 - GAugM EPNet train, Epoch [ 47/55]: loss 0.7210, auc 0.5545, ap 0.5488
2024-01-10 22:07:17,375 - GAugM EPNet train, Epoch [ 48/55]: loss 0.7210, auc 0.5365, ap 0.5662
2024-01-10 22:07:17,459 - GAugM EPNet train, Epoch [ 49/55]: loss 0.7209, auc 0.4550, ap 0.4718
2024-01-10 22:07:17,551 - GAugM EPNet train, Epoch [ 50/55]: loss 0.7210, auc 0.5632, ap 0.5632
2024-01-10 22:07:17,631 - GAugM EPNet train, Epoch [ 51/55]: loss 0.7210, auc 0.5417, ap 0.5391
2024-01-10 22:07:17,710 - GAugM EPNet train, Epoch [ 52/55]: loss 0.7209, auc 0.4041, ap 0.4493
2024-01-10 22:07:17,784 - GAugM EPNet train, Epoch [ 53/55]: loss 0.7209, auc 0.5198, ap 0.4956
2024-01-10 22:07:17,857 - GAugM EPNet train, Epoch [ 54/55]: loss 0.7211, auc 0.5865, ap 0.5546
2024-01-10 22:07:17,931 - GAugM EPNet train, Epoch [ 55/55]: loss 0.7209, auc 0.6153, ap 0.6425
2024-01-10 22:07:17,932 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d0354cc90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:07:18,626 - GAugM EPNet train, Epoch [  1/55]: loss 0.7210, auc 0.4633, ap 0.4661
2024-01-10 22:07:18,715 - GAugM EPNet train, Epoch [  2/55]: loss 0.7210, auc 0.4877, ap 0.4980
2024-01-10 22:07:18,809 - GAugM EPNet train, Epoch [  3/55]: loss 0.7209, auc 0.5550, ap 0.5622
2024-01-10 22:07:18,897 - GAugM EPNet train, Epoch [  4/55]: loss 0.7209, auc 0.4260, ap 0.4873
2024-01-10 22:07:18,995 - GAugM EPNet train, Epoch [  5/55]: loss 0.7209, auc 0.5603, ap 0.5659
2024-01-10 22:07:19,087 - GAugM EPNet train, Epoch [  6/55]: loss 0.7209, auc 0.5066, ap 0.4992
2024-01-10 22:07:19,172 - GAugM EPNet train, Epoch [  7/55]: loss 0.7209, auc 0.4455, ap 0.4651
2024-01-10 22:07:19,257 - GAugM EPNet train, Epoch [  8/55]: loss 0.7210, auc 0.5347, ap 0.5583
2024-01-10 22:07:19,339 - GAugM EPNet train, Epoch [  9/55]: loss 0.7209, auc 0.4931, ap 0.5247
2024-01-10 22:07:19,423 - GAugM EPNet train, Epoch [ 10/55]: loss 0.7208, auc 0.4761, ap 0.4987
2024-01-10 22:07:19,506 - GAugM EPNet train, Epoch [ 11/55]: loss 0.7209, auc 0.4511, ap 0.4579
2024-01-10 22:07:19,588 - GAugM EPNet train, Epoch [ 12/55]: loss 0.7210, auc 0.4446, ap 0.4530
2024-01-10 22:07:19,673 - GAugM EPNet train, Epoch [ 13/55]: loss 0.7209, auc 0.5057, ap 0.5385
2024-01-10 22:07:19,757 - GAugM EPNet train, Epoch [ 14/55]: loss 0.7209, auc 0.5402, ap 0.5565
2024-01-10 22:07:19,844 - GAugM EPNet train, Epoch [ 15/55]: loss 0.7210, auc 0.4359, ap 0.4951
2024-01-10 22:07:19,926 - GAugM EPNet train, Epoch [ 16/55]: loss 0.7209, auc 0.4907, ap 0.5124
2024-01-10 22:07:20,011 - GAugM EPNet train, Epoch [ 17/55]: loss 0.7210, auc 0.5849, ap 0.5831
2024-01-10 22:07:20,093 - GAugM EPNet train, Epoch [ 18/55]: loss 0.7210, auc 0.6255, ap 0.6022
2024-01-10 22:07:20,179 - GAugM EPNet train, Epoch [ 19/55]: loss 0.7209, auc 0.4507, ap 0.4789
2024-01-10 22:07:20,262 - GAugM EPNet train, Epoch [ 20/55]: loss 0.7210, auc 0.5520, ap 0.5629
2024-01-10 22:07:20,349 - GAugM EPNet train, Epoch [ 21/55]: loss 0.7209, auc 0.4893, ap 0.5219
2024-01-10 22:07:20,432 - GAugM EPNet train, Epoch [ 22/55]: loss 0.7210, auc 0.4067, ap 0.4935
2024-01-10 22:07:20,514 - GAugM EPNet train, Epoch [ 23/55]: loss 0.7208, auc 0.4799, ap 0.4939
2024-01-10 22:07:20,598 - GAugM EPNet train, Epoch [ 24/55]: loss 0.7209, auc 0.4500, ap 0.4800
2024-01-10 22:07:20,680 - GAugM EPNet train, Epoch [ 25/55]: loss 0.7209, auc 0.5011, ap 0.5058
2024-01-10 22:07:20,770 - GAugM EPNet train, Epoch [ 26/55]: loss 0.7210, auc 0.4998, ap 0.5058
2024-01-10 22:07:20,852 - GAugM EPNet train, Epoch [ 27/55]: loss 0.7209, auc 0.4660, ap 0.4621
2024-01-10 22:07:20,934 - GAugM EPNet train, Epoch [ 28/55]: loss 0.7209, auc 0.5239, ap 0.5388
2024-01-10 22:07:21,017 - GAugM EPNet train, Epoch [ 29/55]: loss 0.7210, auc 0.5128, ap 0.5467
2024-01-10 22:07:21,103 - GAugM EPNet train, Epoch [ 30/55]: loss 0.7209, auc 0.5251, ap 0.5299
2024-01-10 22:07:21,187 - GAugM EPNet train, Epoch [ 31/55]: loss 0.7208, auc 0.4875, ap 0.5165
2024-01-10 22:07:21,271 - GAugM EPNet train, Epoch [ 32/55]: loss 0.7210, auc 0.5167, ap 0.5108
2024-01-10 22:07:21,354 - GAugM EPNet train, Epoch [ 33/55]: loss 0.7209, auc 0.4925, ap 0.5099
2024-01-10 22:07:21,443 - GAugM EPNet train, Epoch [ 34/55]: loss 0.7209, auc 0.4352, ap 0.4555
2024-01-10 22:07:21,524 - GAugM EPNet train, Epoch [ 35/55]: loss 0.7209, auc 0.5723, ap 0.5533
2024-01-10 22:07:21,608 - GAugM EPNet train, Epoch [ 36/55]: loss 0.7209, auc 0.6696, ap 0.6304
2024-01-10 22:07:21,695 - GAugM EPNet train, Epoch [ 37/55]: loss 0.7209, auc 0.4980, ap 0.4755
2024-01-10 22:07:21,778 - GAugM EPNet train, Epoch [ 38/55]: loss 0.7209, auc 0.5073, ap 0.4849
2024-01-10 22:07:21,860 - GAugM EPNet train, Epoch [ 39/55]: loss 0.7208, auc 0.4281, ap 0.4552
2024-01-10 22:07:21,952 - GAugM EPNet train, Epoch [ 40/55]: loss 0.7210, auc 0.6006, ap 0.5628
2024-01-10 22:07:22,036 - GAugM EPNet train, Epoch [ 41/55]: loss 0.7210, auc 0.4760, ap 0.4872
2024-01-10 22:07:22,118 - GAugM EPNet train, Epoch [ 42/55]: loss 0.7209, auc 0.5381, ap 0.5706
2024-01-10 22:07:22,200 - GAugM EPNet train, Epoch [ 43/55]: loss 0.7208, auc 0.4471, ap 0.4667
2024-01-10 22:07:22,281 - GAugM EPNet train, Epoch [ 44/55]: loss 0.7208, auc 0.3948, ap 0.4636
2024-01-10 22:07:22,367 - GAugM EPNet train, Epoch [ 45/55]: loss 0.7209, auc 0.5271, ap 0.5270
2024-01-10 22:07:22,448 - GAugM EPNet train, Epoch [ 46/55]: loss 0.7209, auc 0.4705, ap 0.4971
2024-01-10 22:07:22,530 - GAugM EPNet train, Epoch [ 47/55]: loss 0.7210, auc 0.4256, ap 0.4450
2024-01-10 22:07:22,609 - GAugM EPNet train, Epoch [ 48/55]: loss 0.7210, auc 0.6072, ap 0.6053
2024-01-10 22:07:22,697 - GAugM EPNet train, Epoch [ 49/55]: loss 0.7209, auc 0.5000, ap 0.5128
2024-01-10 22:07:22,779 - GAugM EPNet train, Epoch [ 50/55]: loss 0.7210, auc 0.5182, ap 0.5174
2024-01-10 22:07:22,862 - GAugM EPNet train, Epoch [ 51/55]: loss 0.7210, auc 0.4411, ap 0.4898
2024-01-10 22:07:22,947 - GAugM EPNet train, Epoch [ 52/55]: loss 0.7209, auc 0.4865, ap 0.4777
2024-01-10 22:07:23,029 - GAugM EPNet train, Epoch [ 53/55]: loss 0.7209, auc 0.4571, ap 0.4851
2024-01-10 22:07:23,114 - GAugM EPNet train, Epoch [ 54/55]: loss 0.7211, auc 0.5242, ap 0.5179
2024-01-10 22:07:23,195 - GAugM EPNet train, Epoch [ 55/55]: loss 0.7209, auc 0.5954, ap 0.6043
2024-01-10 22:07:23,202 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d039d9dd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:07:23,902 - GAugM EPNet train, Epoch [  1/55]: loss 0.7210, auc 0.4559, ap 0.4709
2024-01-10 22:07:23,988 - GAugM EPNet train, Epoch [  2/55]: loss 0.7210, auc 0.5625, ap 0.5226
2024-01-10 22:07:24,071 - GAugM EPNet train, Epoch [  3/55]: loss 0.7209, auc 0.5707, ap 0.5362
2024-01-10 22:07:24,155 - GAugM EPNet train, Epoch [  4/55]: loss 0.7209, auc 0.4551, ap 0.4809
2024-01-10 22:07:24,247 - GAugM EPNet train, Epoch [  5/55]: loss 0.7209, auc 0.5548, ap 0.5661
2024-01-10 22:07:24,332 - GAugM EPNet train, Epoch [  6/55]: loss 0.7209, auc 0.4587, ap 0.4609
2024-01-10 22:07:24,413 - GAugM EPNet train, Epoch [  7/55]: loss 0.7209, auc 0.4327, ap 0.4415
2024-01-10 22:07:24,503 - GAugM EPNet train, Epoch [  8/55]: loss 0.7210, auc 0.4521, ap 0.4656
2024-01-10 22:07:24,587 - GAugM EPNet train, Epoch [  9/55]: loss 0.7209, auc 0.4349, ap 0.4847
2024-01-10 22:07:24,669 - GAugM EPNet train, Epoch [ 10/55]: loss 0.7208, auc 0.5349, ap 0.5429
2024-01-10 22:07:24,753 - GAugM EPNet train, Epoch [ 11/55]: loss 0.7209, auc 0.4826, ap 0.4890
2024-01-10 22:07:24,840 - GAugM EPNet train, Epoch [ 12/55]: loss 0.7210, auc 0.4697, ap 0.4755
2024-01-10 22:07:24,927 - GAugM EPNet train, Epoch [ 13/55]: loss 0.7209, auc 0.5320, ap 0.5437
2024-01-10 22:07:25,013 - GAugM EPNet train, Epoch [ 14/55]: loss 0.7209, auc 0.5723, ap 0.5620
2024-01-10 22:07:25,095 - GAugM EPNet train, Epoch [ 15/55]: loss 0.7210, auc 0.3859, ap 0.4391
2024-01-10 22:07:25,178 - GAugM EPNet train, Epoch [ 16/55]: loss 0.7209, auc 0.5094, ap 0.4991
2024-01-10 22:07:25,266 - GAugM EPNet train, Epoch [ 17/55]: loss 0.7210, auc 0.5246, ap 0.5318
2024-01-10 22:07:25,353 - GAugM EPNet train, Epoch [ 18/55]: loss 0.7210, auc 0.6169, ap 0.6116
2024-01-10 22:07:25,437 - GAugM EPNet train, Epoch [ 19/55]: loss 0.7209, auc 0.5167, ap 0.5062
2024-01-10 22:07:25,519 - GAugM EPNet train, Epoch [ 20/55]: loss 0.7210, auc 0.5025, ap 0.5358
2024-01-10 22:07:25,605 - GAugM EPNet train, Epoch [ 21/55]: loss 0.7209, auc 0.4963, ap 0.5205
2024-01-10 22:07:25,697 - GAugM EPNet train, Epoch [ 22/55]: loss 0.7210, auc 0.3622, ap 0.4246
2024-01-10 22:07:25,780 - GAugM EPNet train, Epoch [ 23/55]: loss 0.7208, auc 0.4550, ap 0.4645
2024-01-10 22:07:25,863 - GAugM EPNet train, Epoch [ 24/55]: loss 0.7209, auc 0.5269, ap 0.5202
2024-01-10 22:07:25,948 - GAugM EPNet train, Epoch [ 25/55]: loss 0.7209, auc 0.4518, ap 0.4585
2024-01-10 22:07:26,035 - GAugM EPNet train, Epoch [ 26/55]: loss 0.7210, auc 0.6073, ap 0.5693
2024-01-10 22:07:26,118 - GAugM EPNet train, Epoch [ 27/55]: loss 0.7209, auc 0.3984, ap 0.4730
2024-01-10 22:07:26,205 - GAugM EPNet train, Epoch [ 28/55]: loss 0.7209, auc 0.6061, ap 0.5904
2024-01-10 22:07:26,288 - GAugM EPNet train, Epoch [ 29/55]: loss 0.7210, auc 0.5566, ap 0.5485
2024-01-10 22:07:26,370 - GAugM EPNet train, Epoch [ 30/55]: loss 0.7209, auc 0.5137, ap 0.5176
2024-01-10 22:07:26,452 - GAugM EPNet train, Epoch [ 31/55]: loss 0.7208, auc 0.3996, ap 0.4338
2024-01-10 22:07:26,534 - GAugM EPNet train, Epoch [ 32/55]: loss 0.7210, auc 0.4836, ap 0.4802
2024-01-10 22:07:26,616 - GAugM EPNet train, Epoch [ 33/55]: loss 0.7209, auc 0.5488, ap 0.5384
2024-01-10 22:07:26,700 - GAugM EPNet train, Epoch [ 34/55]: loss 0.7209, auc 0.4101, ap 0.4517
2024-01-10 22:07:26,782 - GAugM EPNet train, Epoch [ 35/55]: loss 0.7209, auc 0.5128, ap 0.5046
2024-01-10 22:07:26,867 - GAugM EPNet train, Epoch [ 36/55]: loss 0.7209, auc 0.5324, ap 0.5500
2024-01-10 22:07:26,953 - GAugM EPNet train, Epoch [ 37/55]: loss 0.7209, auc 0.4829, ap 0.5019
2024-01-10 22:07:27,036 - GAugM EPNet train, Epoch [ 38/55]: loss 0.7209, auc 0.4555, ap 0.4593
2024-01-10 22:07:27,118 - GAugM EPNet train, Epoch [ 39/55]: loss 0.7208, auc 0.4240, ap 0.4772
2024-01-10 22:07:27,204 - GAugM EPNet train, Epoch [ 40/55]: loss 0.7210, auc 0.5611, ap 0.5293
2024-01-10 22:07:27,286 - GAugM EPNet train, Epoch [ 41/55]: loss 0.7210, auc 0.4254, ap 0.4845
2024-01-10 22:07:27,374 - GAugM EPNet train, Epoch [ 42/55]: loss 0.7209, auc 0.5203, ap 0.5387
2024-01-10 22:07:27,457 - GAugM EPNet train, Epoch [ 43/55]: loss 0.7208, auc 0.4071, ap 0.4750
2024-01-10 22:07:27,546 - GAugM EPNet train, Epoch [ 44/55]: loss 0.7208, auc 0.3761, ap 0.4356
2024-01-10 22:07:27,628 - GAugM EPNet train, Epoch [ 45/55]: loss 0.7209, auc 0.4918, ap 0.5113
2024-01-10 22:07:27,713 - GAugM EPNet train, Epoch [ 46/55]: loss 0.7209, auc 0.4601, ap 0.5084
2024-01-10 22:07:27,796 - GAugM EPNet train, Epoch [ 47/55]: loss 0.7210, auc 0.4738, ap 0.5367
2024-01-10 22:07:27,888 - GAugM EPNet train, Epoch [ 48/55]: loss 0.7210, auc 0.5447, ap 0.5677
2024-01-10 22:07:27,969 - GAugM EPNet train, Epoch [ 49/55]: loss 0.7209, auc 0.5064, ap 0.5060
2024-01-10 22:07:28,051 - GAugM EPNet train, Epoch [ 50/55]: loss 0.7210, auc 0.5189, ap 0.5209
2024-01-10 22:07:28,133 - GAugM EPNet train, Epoch [ 51/55]: loss 0.7210, auc 0.5320, ap 0.5516
2024-01-10 22:07:28,221 - GAugM EPNet train, Epoch [ 52/55]: loss 0.7209, auc 0.4783, ap 0.5023
2024-01-10 22:07:28,302 - GAugM EPNet train, Epoch [ 53/55]: loss 0.7209, auc 0.5080, ap 0.5034
2024-01-10 22:07:28,385 - GAugM EPNet train, Epoch [ 54/55]: loss 0.7211, auc 0.5700, ap 0.5558
2024-01-10 22:07:28,466 - GAugM EPNet train, Epoch [ 55/55]: loss 0.7209, auc 0.5870, ap 0.6028
2024-01-10 22:07:28,471 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03559590>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:07:29,190 - GAugM EPNet train, Epoch [  1/55]: loss 0.7210, auc 0.5415, ap 0.5460
2024-01-10 22:07:29,272 - GAugM EPNet train, Epoch [  2/55]: loss 0.7210, auc 0.4913, ap 0.4958
2024-01-10 22:07:29,355 - GAugM EPNet train, Epoch [  3/55]: loss 0.7209, auc 0.5224, ap 0.5364
2024-01-10 22:07:29,436 - GAugM EPNet train, Epoch [  4/55]: loss 0.7209, auc 0.4418, ap 0.4761
2024-01-10 22:07:29,519 - GAugM EPNet train, Epoch [  5/55]: loss 0.7209, auc 0.5530, ap 0.5987
2024-01-10 22:07:29,610 - GAugM EPNet train, Epoch [  6/55]: loss 0.7209, auc 0.5096, ap 0.5300
2024-01-10 22:07:29,695 - GAugM EPNet train, Epoch [  7/55]: loss 0.7209, auc 0.4630, ap 0.4884
2024-01-10 22:07:29,782 - GAugM EPNet train, Epoch [  8/55]: loss 0.7210, auc 0.4288, ap 0.4444
2024-01-10 22:07:29,869 - GAugM EPNet train, Epoch [  9/55]: loss 0.7209, auc 0.3943, ap 0.4369
2024-01-10 22:07:29,952 - GAugM EPNet train, Epoch [ 10/55]: loss 0.7208, auc 0.4818, ap 0.5212
2024-01-10 22:07:30,040 - GAugM EPNet train, Epoch [ 11/55]: loss 0.7209, auc 0.4754, ap 0.5046
2024-01-10 22:07:30,125 - GAugM EPNet train, Epoch [ 12/55]: loss 0.7210, auc 0.4500, ap 0.4746
2024-01-10 22:07:30,207 - GAugM EPNet train, Epoch [ 13/55]: loss 0.7209, auc 0.5783, ap 0.5703
2024-01-10 22:07:30,297 - GAugM EPNet train, Epoch [ 14/55]: loss 0.7209, auc 0.5449, ap 0.5510
2024-01-10 22:07:30,379 - GAugM EPNet train, Epoch [ 15/55]: loss 0.7210, auc 0.4155, ap 0.4720
2024-01-10 22:07:30,460 - GAugM EPNet train, Epoch [ 16/55]: loss 0.7209, auc 0.5251, ap 0.5621
2024-01-10 22:07:30,541 - GAugM EPNet train, Epoch [ 17/55]: loss 0.7210, auc 0.5507, ap 0.5463
2024-01-10 22:07:30,629 - GAugM EPNet train, Epoch [ 18/55]: loss 0.7210, auc 0.5667, ap 0.5693
2024-01-10 22:07:30,712 - GAugM EPNet train, Epoch [ 19/55]: loss 0.7209, auc 0.4776, ap 0.4848
2024-01-10 22:07:30,795 - GAugM EPNet train, Epoch [ 20/55]: loss 0.7210, auc 0.5135, ap 0.5545
2024-01-10 22:07:30,887 - GAugM EPNet train, Epoch [ 21/55]: loss 0.7209, auc 0.4856, ap 0.5069
2024-01-10 22:07:30,972 - GAugM EPNet train, Epoch [ 22/55]: loss 0.7210, auc 0.3549, ap 0.4122
2024-01-10 22:07:31,056 - GAugM EPNet train, Epoch [ 23/55]: loss 0.7208, auc 0.6369, ap 0.5892
2024-01-10 22:07:31,139 - GAugM EPNet train, Epoch [ 24/55]: loss 0.7209, auc 0.5643, ap 0.5631
2024-01-10 22:07:31,221 - GAugM EPNet train, Epoch [ 25/55]: loss 0.7209, auc 0.5473, ap 0.5472
2024-01-10 22:07:31,304 - GAugM EPNet train, Epoch [ 26/55]: loss 0.7210, auc 0.5037, ap 0.5218
2024-01-10 22:07:31,390 - GAugM EPNet train, Epoch [ 27/55]: loss 0.7209, auc 0.4562, ap 0.4946
2024-01-10 22:07:31,480 - GAugM EPNet train, Epoch [ 28/55]: loss 0.7209, auc 0.5167, ap 0.5373
2024-01-10 22:07:31,562 - GAugM EPNet train, Epoch [ 29/55]: loss 0.7210, auc 0.5007, ap 0.5296
2024-01-10 22:07:31,650 - GAugM EPNet train, Epoch [ 30/55]: loss 0.7209, auc 0.5043, ap 0.5143
2024-01-10 22:07:31,735 - GAugM EPNet train, Epoch [ 31/55]: loss 0.7208, auc 0.5525, ap 0.5463
2024-01-10 22:07:31,823 - GAugM EPNet train, Epoch [ 32/55]: loss 0.7210, auc 0.5707, ap 0.5566
2024-01-10 22:07:31,906 - GAugM EPNet train, Epoch [ 33/55]: loss 0.7209, auc 0.5776, ap 0.5859
2024-01-10 22:07:31,989 - GAugM EPNet train, Epoch [ 34/55]: loss 0.7209, auc 0.4635, ap 0.4927
2024-01-10 22:07:32,076 - GAugM EPNet train, Epoch [ 35/55]: loss 0.7209, auc 0.4655, ap 0.4702
2024-01-10 22:07:32,159 - GAugM EPNet train, Epoch [ 36/55]: loss 0.7209, auc 0.6251, ap 0.6189
2024-01-10 22:07:32,245 - GAugM EPNet train, Epoch [ 37/55]: loss 0.7209, auc 0.4852, ap 0.4920
2024-01-10 22:07:32,336 - GAugM EPNet train, Epoch [ 38/55]: loss 0.7209, auc 0.4532, ap 0.4820
2024-01-10 22:07:32,426 - GAugM EPNet train, Epoch [ 39/55]: loss 0.7208, auc 0.4690, ap 0.5219
2024-01-10 22:07:32,509 - GAugM EPNet train, Epoch [ 40/55]: loss 0.7210, auc 0.5778, ap 0.5479
2024-01-10 22:07:32,595 - GAugM EPNet train, Epoch [ 41/55]: loss 0.7210, auc 0.5552, ap 0.5716
2024-01-10 22:07:32,679 - GAugM EPNet train, Epoch [ 42/55]: loss 0.7209, auc 0.4737, ap 0.5146
2024-01-10 22:07:32,766 - GAugM EPNet train, Epoch [ 43/55]: loss 0.7208, auc 0.4706, ap 0.5241
2024-01-10 22:07:32,851 - GAugM EPNet train, Epoch [ 44/55]: loss 0.7208, auc 0.3759, ap 0.4497
2024-01-10 22:07:32,936 - GAugM EPNet train, Epoch [ 45/55]: loss 0.7209, auc 0.5721, ap 0.6201
2024-01-10 22:07:33,019 - GAugM EPNet train, Epoch [ 46/55]: loss 0.7209, auc 0.4705, ap 0.5051
2024-01-10 22:07:33,105 - GAugM EPNet train, Epoch [ 47/55]: loss 0.7210, auc 0.4527, ap 0.4691
2024-01-10 22:07:33,186 - GAugM EPNet train, Epoch [ 48/55]: loss 0.7210, auc 0.5876, ap 0.5871
2024-01-10 22:07:33,268 - GAugM EPNet train, Epoch [ 49/55]: loss 0.7209, auc 0.4384, ap 0.4958
2024-01-10 22:07:33,350 - GAugM EPNet train, Epoch [ 50/55]: loss 0.7210, auc 0.5255, ap 0.5402
2024-01-10 22:07:33,439 - GAugM EPNet train, Epoch [ 51/55]: loss 0.7210, auc 0.4715, ap 0.5218
2024-01-10 22:07:33,523 - GAugM EPNet train, Epoch [ 52/55]: loss 0.7209, auc 0.4879, ap 0.5041
2024-01-10 22:07:33,614 - GAugM EPNet train, Epoch [ 53/55]: loss 0.7209, auc 0.6029, ap 0.6116
2024-01-10 22:07:33,700 - GAugM EPNet train, Epoch [ 54/55]: loss 0.7211, auc 0.5178, ap 0.5107
2024-01-10 22:07:33,790 - GAugM EPNet train, Epoch [ 55/55]: loss 0.7209, auc 0.6129, ap 0.6126
2024-01-10 22:07:33,795 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d039d9dd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:07:34,534 - GAugM EPNet train, Epoch [  1/55]: loss 0.7210, auc 0.4986, ap 0.4850
2024-01-10 22:07:34,619 - GAugM EPNet train, Epoch [  2/55]: loss 0.7210, auc 0.4850, ap 0.4972
2024-01-10 22:07:34,701 - GAugM EPNet train, Epoch [  3/55]: loss 0.7209, auc 0.5532, ap 0.5720
2024-01-10 22:07:34,784 - GAugM EPNet train, Epoch [  4/55]: loss 0.7209, auc 0.4452, ap 0.4796
2024-01-10 22:07:34,865 - GAugM EPNet train, Epoch [  5/55]: loss 0.7209, auc 0.5052, ap 0.5011
2024-01-10 22:07:34,951 - GAugM EPNet train, Epoch [  6/55]: loss 0.7209, auc 0.5256, ap 0.4992
2024-01-10 22:07:35,040 - GAugM EPNet train, Epoch [  7/55]: loss 0.7209, auc 0.4712, ap 0.4682
2024-01-10 22:07:35,123 - GAugM EPNet train, Epoch [  8/55]: loss 0.7210, auc 0.4813, ap 0.4978
2024-01-10 22:07:35,207 - GAugM EPNet train, Epoch [  9/55]: loss 0.7209, auc 0.4827, ap 0.4954
2024-01-10 22:07:35,290 - GAugM EPNet train, Epoch [ 10/55]: loss 0.7208, auc 0.4539, ap 0.4661
2024-01-10 22:07:35,371 - GAugM EPNet train, Epoch [ 11/55]: loss 0.7209, auc 0.5294, ap 0.5228
2024-01-10 22:07:35,458 - GAugM EPNet train, Epoch [ 12/55]: loss 0.7210, auc 0.4546, ap 0.4622
2024-01-10 22:07:35,539 - GAugM EPNet train, Epoch [ 13/55]: loss 0.7209, auc 0.5105, ap 0.5178
2024-01-10 22:07:35,624 - GAugM EPNet train, Epoch [ 14/55]: loss 0.7209, auc 0.5762, ap 0.5852
2024-01-10 22:07:35,706 - GAugM EPNet train, Epoch [ 15/55]: loss 0.7210, auc 0.4194, ap 0.5047
2024-01-10 22:07:35,788 - GAugM EPNet train, Epoch [ 16/55]: loss 0.7209, auc 0.4956, ap 0.5240
2024-01-10 22:07:35,871 - GAugM EPNet train, Epoch [ 17/55]: loss 0.7210, auc 0.5303, ap 0.5467
2024-01-10 22:07:35,954 - GAugM EPNet train, Epoch [ 18/55]: loss 0.7210, auc 0.5924, ap 0.5803
2024-01-10 22:07:36,031 - GAugM EPNet train, Epoch [ 19/55]: loss 0.7209, auc 0.5345, ap 0.5241
2024-01-10 22:07:36,103 - GAugM EPNet train, Epoch [ 20/55]: loss 0.7210, auc 0.5021, ap 0.5310
2024-01-10 22:07:36,183 - GAugM EPNet train, Epoch [ 21/55]: loss 0.7209, auc 0.4884, ap 0.4976
2024-01-10 22:07:36,264 - GAugM EPNet train, Epoch [ 22/55]: loss 0.7210, auc 0.3847, ap 0.4480
2024-01-10 22:07:36,337 - GAugM EPNet train, Epoch [ 23/55]: loss 0.7208, auc 0.4776, ap 0.4930
2024-01-10 22:07:36,411 - GAugM EPNet train, Epoch [ 24/55]: loss 0.7209, auc 0.5087, ap 0.4999
2024-01-10 22:07:36,492 - GAugM EPNet train, Epoch [ 25/55]: loss 0.7209, auc 0.4845, ap 0.4925
2024-01-10 22:07:36,572 - GAugM EPNet train, Epoch [ 26/55]: loss 0.7210, auc 0.5785, ap 0.5743
2024-01-10 22:07:36,648 - GAugM EPNet train, Epoch [ 27/55]: loss 0.7209, auc 0.4945, ap 0.5203
2024-01-10 22:07:36,729 - GAugM EPNet train, Epoch [ 28/55]: loss 0.7209, auc 0.5148, ap 0.5523
2024-01-10 22:07:36,804 - GAugM EPNet train, Epoch [ 29/55]: loss 0.7210, auc 0.5331, ap 0.5366
2024-01-10 22:07:36,887 - GAugM EPNet train, Epoch [ 30/55]: loss 0.7209, auc 0.5854, ap 0.5685
2024-01-10 22:07:36,962 - GAugM EPNet train, Epoch [ 31/55]: loss 0.7208, auc 0.4491, ap 0.4990
2024-01-10 22:07:37,038 - GAugM EPNet train, Epoch [ 32/55]: loss 0.7210, auc 0.5518, ap 0.5343
2024-01-10 22:07:37,114 - GAugM EPNet train, Epoch [ 33/55]: loss 0.7209, auc 0.5020, ap 0.5075
2024-01-10 22:07:37,188 - GAugM EPNet train, Epoch [ 34/55]: loss 0.7209, auc 0.5310, ap 0.5303
2024-01-10 22:07:37,269 - GAugM EPNet train, Epoch [ 35/55]: loss 0.7209, auc 0.5370, ap 0.5275
2024-01-10 22:07:37,344 - GAugM EPNet train, Epoch [ 36/55]: loss 0.7209, auc 0.5968, ap 0.5738
2024-01-10 22:07:37,420 - GAugM EPNet train, Epoch [ 37/55]: loss 0.7209, auc 0.4582, ap 0.4955
2024-01-10 22:07:37,495 - GAugM EPNet train, Epoch [ 38/55]: loss 0.7209, auc 0.4366, ap 0.4466
2024-01-10 22:07:37,569 - GAugM EPNet train, Epoch [ 39/55]: loss 0.7208, auc 0.4632, ap 0.4772
2024-01-10 22:07:37,652 - GAugM EPNet train, Epoch [ 40/55]: loss 0.7210, auc 0.4699, ap 0.4765
2024-01-10 22:07:37,729 - GAugM EPNet train, Epoch [ 41/55]: loss 0.7210, auc 0.5283, ap 0.5420
2024-01-10 22:07:37,803 - GAugM EPNet train, Epoch [ 42/55]: loss 0.7209, auc 0.5457, ap 0.5565
2024-01-10 22:07:37,880 - GAugM EPNet train, Epoch [ 43/55]: loss 0.7208, auc 0.5367, ap 0.5210
2024-01-10 22:07:37,965 - GAugM EPNet train, Epoch [ 44/55]: loss 0.7208, auc 0.3396, ap 0.4179
2024-01-10 22:07:38,038 - GAugM EPNet train, Epoch [ 45/55]: loss 0.7209, auc 0.5716, ap 0.5607
2024-01-10 22:07:38,112 - GAugM EPNet train, Epoch [ 46/55]: loss 0.7209, auc 0.4267, ap 0.4529
2024-01-10 22:07:38,186 - GAugM EPNet train, Epoch [ 47/55]: loss 0.7210, auc 0.4158, ap 0.4624
2024-01-10 22:07:38,260 - GAugM EPNet train, Epoch [ 48/55]: loss 0.7210, auc 0.5876, ap 0.6259
2024-01-10 22:07:38,335 - GAugM EPNet train, Epoch [ 49/55]: loss 0.7209, auc 0.5157, ap 0.5219
2024-01-10 22:07:38,412 - GAugM EPNet train, Epoch [ 50/55]: loss 0.7210, auc 0.4850, ap 0.4979
2024-01-10 22:07:38,488 - GAugM EPNet train, Epoch [ 51/55]: loss 0.7210, auc 0.4340, ap 0.5021
2024-01-10 22:07:38,562 - GAugM EPNet train, Epoch [ 52/55]: loss 0.7209, auc 0.5050, ap 0.5261
2024-01-10 22:07:38,636 - GAugM EPNet train, Epoch [ 53/55]: loss 0.7209, auc 0.5078, ap 0.5146
2024-01-10 22:07:38,714 - GAugM EPNet train, Epoch [ 54/55]: loss 0.7211, auc 0.5611, ap 0.5794
2024-01-10 22:07:38,789 - GAugM EPNet train, Epoch [ 55/55]: loss 0.7209, auc 0.5714, ap 0.5791
2024-01-10 22:07:38,789 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03559590>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:07:39,489 - GAugM EPNet train, Epoch [  1/55]: loss 0.7210, auc 0.4507, ap 0.4599
2024-01-10 22:07:39,575 - GAugM EPNet train, Epoch [  2/55]: loss 0.7210, auc 0.5888, ap 0.5681
2024-01-10 22:07:39,660 - GAugM EPNet train, Epoch [  3/55]: loss 0.7209, auc 0.5954, ap 0.5752
2024-01-10 22:07:39,739 - GAugM EPNet train, Epoch [  4/55]: loss 0.7209, auc 0.4818, ap 0.5170
2024-01-10 22:07:39,813 - GAugM EPNet train, Epoch [  5/55]: loss 0.7209, auc 0.5269, ap 0.5358
2024-01-10 22:07:39,886 - GAugM EPNet train, Epoch [  6/55]: loss 0.7209, auc 0.5194, ap 0.5201
2024-01-10 22:07:39,962 - GAugM EPNet train, Epoch [  7/55]: loss 0.7209, auc 0.4450, ap 0.4628
2024-01-10 22:07:40,043 - GAugM EPNet train, Epoch [  8/55]: loss 0.7210, auc 0.5253, ap 0.5244
2024-01-10 22:07:40,119 - GAugM EPNet train, Epoch [  9/55]: loss 0.7209, auc 0.4580, ap 0.4553
2024-01-10 22:07:40,192 - GAugM EPNet train, Epoch [ 10/55]: loss 0.7208, auc 0.4884, ap 0.5243
2024-01-10 22:07:40,267 - GAugM EPNet train, Epoch [ 11/55]: loss 0.7209, auc 0.4505, ap 0.4795
2024-01-10 22:07:40,340 - GAugM EPNet train, Epoch [ 12/55]: loss 0.7210, auc 0.4254, ap 0.4549
2024-01-10 22:07:40,414 - GAugM EPNet train, Epoch [ 13/55]: loss 0.7209, auc 0.6066, ap 0.5953
2024-01-10 22:07:40,487 - GAugM EPNet train, Epoch [ 14/55]: loss 0.7209, auc 0.4553, ap 0.4834
2024-01-10 22:07:40,564 - GAugM EPNet train, Epoch [ 15/55]: loss 0.7210, auc 0.4778, ap 0.5282
2024-01-10 22:07:40,640 - GAugM EPNet train, Epoch [ 16/55]: loss 0.7209, auc 0.4995, ap 0.4873
2024-01-10 22:07:40,720 - GAugM EPNet train, Epoch [ 17/55]: loss 0.7210, auc 0.4984, ap 0.5039
2024-01-10 22:07:40,796 - GAugM EPNet train, Epoch [ 18/55]: loss 0.7210, auc 0.5890, ap 0.5710
2024-01-10 22:07:40,872 - GAugM EPNet train, Epoch [ 19/55]: loss 0.7209, auc 0.4858, ap 0.4967
2024-01-10 22:07:40,952 - GAugM EPNet train, Epoch [ 20/55]: loss 0.7210, auc 0.4923, ap 0.5104
2024-01-10 22:07:41,030 - GAugM EPNet train, Epoch [ 21/55]: loss 0.7209, auc 0.5084, ap 0.5219
2024-01-10 22:07:41,110 - GAugM EPNet train, Epoch [ 22/55]: loss 0.7210, auc 0.4201, ap 0.4527
2024-01-10 22:07:41,185 - GAugM EPNet train, Epoch [ 23/55]: loss 0.7208, auc 0.4838, ap 0.4898
2024-01-10 22:07:41,259 - GAugM EPNet train, Epoch [ 24/55]: loss 0.7209, auc 0.5520, ap 0.5297
2024-01-10 22:07:41,332 - GAugM EPNet train, Epoch [ 25/55]: loss 0.7209, auc 0.4489, ap 0.4700
2024-01-10 22:07:41,405 - GAugM EPNet train, Epoch [ 26/55]: loss 0.7210, auc 0.5673, ap 0.5994
2024-01-10 22:07:41,481 - GAugM EPNet train, Epoch [ 27/55]: loss 0.7209, auc 0.4758, ap 0.5465
2024-01-10 22:07:41,554 - GAugM EPNet train, Epoch [ 28/55]: loss 0.7209, auc 0.5418, ap 0.5695
2024-01-10 22:07:41,629 - GAugM EPNet train, Epoch [ 29/55]: loss 0.7210, auc 0.5166, ap 0.5302
2024-01-10 22:07:41,703 - GAugM EPNet train, Epoch [ 30/55]: loss 0.7209, auc 0.4776, ap 0.4770
2024-01-10 22:07:41,779 - GAugM EPNet train, Epoch [ 31/55]: loss 0.7208, auc 0.5005, ap 0.5429
2024-01-10 22:07:41,853 - GAugM EPNet train, Epoch [ 32/55]: loss 0.7210, auc 0.5012, ap 0.5016
2024-01-10 22:07:41,933 - GAugM EPNet train, Epoch [ 33/55]: loss 0.7209, auc 0.6004, ap 0.6251
2024-01-10 22:07:42,012 - GAugM EPNet train, Epoch [ 34/55]: loss 0.7209, auc 0.4297, ap 0.4479
2024-01-10 22:07:42,092 - GAugM EPNet train, Epoch [ 35/55]: loss 0.7209, auc 0.5372, ap 0.5456
2024-01-10 22:07:42,169 - GAugM EPNet train, Epoch [ 36/55]: loss 0.7209, auc 0.6121, ap 0.6136
2024-01-10 22:07:42,241 - GAugM EPNet train, Epoch [ 37/55]: loss 0.7209, auc 0.3991, ap 0.4339
2024-01-10 22:07:42,321 - GAugM EPNet train, Epoch [ 38/55]: loss 0.7209, auc 0.5011, ap 0.4861
2024-01-10 22:07:42,395 - GAugM EPNet train, Epoch [ 39/55]: loss 0.7208, auc 0.3421, ap 0.4387
2024-01-10 22:07:42,478 - GAugM EPNet train, Epoch [ 40/55]: loss 0.7210, auc 0.5440, ap 0.5280
2024-01-10 22:07:42,555 - GAugM EPNet train, Epoch [ 41/55]: loss 0.7210, auc 0.5069, ap 0.5580
2024-01-10 22:07:42,627 - GAugM EPNet train, Epoch [ 42/55]: loss 0.7209, auc 0.4929, ap 0.4983
2024-01-10 22:07:42,702 - GAugM EPNet train, Epoch [ 43/55]: loss 0.7208, auc 0.4763, ap 0.4908
2024-01-10 22:07:42,779 - GAugM EPNet train, Epoch [ 44/55]: loss 0.7208, auc 0.4500, ap 0.4976
2024-01-10 22:07:42,865 - GAugM EPNet train, Epoch [ 45/55]: loss 0.7209, auc 0.5486, ap 0.5696
2024-01-10 22:07:42,946 - GAugM EPNet train, Epoch [ 46/55]: loss 0.7209, auc 0.4482, ap 0.4890
2024-01-10 22:07:43,022 - GAugM EPNet train, Epoch [ 47/55]: loss 0.7210, auc 0.5635, ap 0.5758
2024-01-10 22:07:43,096 - GAugM EPNet train, Epoch [ 48/55]: loss 0.7210, auc 0.5643, ap 0.5785
2024-01-10 22:07:43,178 - GAugM EPNet train, Epoch [ 49/55]: loss 0.7209, auc 0.5032, ap 0.5420
2024-01-10 22:07:43,257 - GAugM EPNet train, Epoch [ 50/55]: loss 0.7210, auc 0.5171, ap 0.5185
2024-01-10 22:07:43,342 - GAugM EPNet train, Epoch [ 51/55]: loss 0.7210, auc 0.4742, ap 0.5165
2024-01-10 22:07:43,417 - GAugM EPNet train, Epoch [ 52/55]: loss 0.7209, auc 0.4717, ap 0.5202
2024-01-10 22:07:43,493 - GAugM EPNet train, Epoch [ 53/55]: loss 0.7209, auc 0.5212, ap 0.5291
2024-01-10 22:07:43,566 - GAugM EPNet train, Epoch [ 54/55]: loss 0.7211, auc 0.5037, ap 0.4901
2024-01-10 22:07:43,641 - GAugM EPNet train, Epoch [ 55/55]: loss 0.7209, auc 0.5628, ap 0.5484
2024-01-10 22:07:43,657 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d036f0a90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:07:44,343 - GAugM EPNet train, Epoch [  1/55]: loss 0.7210, auc 0.4911, ap 0.4941
2024-01-10 22:07:44,422 - GAugM EPNet train, Epoch [  2/55]: loss 0.7210, auc 0.5260, ap 0.5352
2024-01-10 22:07:44,508 - GAugM EPNet train, Epoch [  3/55]: loss 0.7209, auc 0.5605, ap 0.5507
2024-01-10 22:07:44,585 - GAugM EPNet train, Epoch [  4/55]: loss 0.7209, auc 0.4662, ap 0.4976
2024-01-10 22:07:44,661 - GAugM EPNet train, Epoch [  5/55]: loss 0.7209, auc 0.5822, ap 0.6032
2024-01-10 22:07:44,737 - GAugM EPNet train, Epoch [  6/55]: loss 0.7209, auc 0.4672, ap 0.4594
2024-01-10 22:07:44,812 - GAugM EPNet train, Epoch [  7/55]: loss 0.7209, auc 0.4569, ap 0.4801
2024-01-10 22:07:44,886 - GAugM EPNet train, Epoch [  8/55]: loss 0.7210, auc 0.4932, ap 0.4892
2024-01-10 22:07:44,959 - GAugM EPNet train, Epoch [  9/55]: loss 0.7209, auc 0.5032, ap 0.4952
2024-01-10 22:07:45,033 - GAugM EPNet train, Epoch [ 10/55]: loss 0.7208, auc 0.5438, ap 0.5454
2024-01-10 22:07:45,108 - GAugM EPNet train, Epoch [ 11/55]: loss 0.7209, auc 0.5043, ap 0.4893
2024-01-10 22:07:45,182 - GAugM EPNet train, Epoch [ 12/55]: loss 0.7210, auc 0.4523, ap 0.4503
2024-01-10 22:07:45,258 - GAugM EPNet train, Epoch [ 13/55]: loss 0.7209, auc 0.5680, ap 0.5683
2024-01-10 22:07:45,334 - GAugM EPNet train, Epoch [ 14/55]: loss 0.7209, auc 0.5794, ap 0.5723
2024-01-10 22:07:45,410 - GAugM EPNet train, Epoch [ 15/55]: loss 0.7210, auc 0.4099, ap 0.4697
2024-01-10 22:07:45,484 - GAugM EPNet train, Epoch [ 16/55]: loss 0.7209, auc 0.5096, ap 0.5017
2024-01-10 22:07:45,559 - GAugM EPNet train, Epoch [ 17/55]: loss 0.7210, auc 0.5249, ap 0.5295
2024-01-10 22:07:45,632 - GAugM EPNet train, Epoch [ 18/55]: loss 0.7210, auc 0.5862, ap 0.5657
2024-01-10 22:07:45,710 - GAugM EPNet train, Epoch [ 19/55]: loss 0.7209, auc 0.5043, ap 0.5020
2024-01-10 22:07:45,783 - GAugM EPNet train, Epoch [ 20/55]: loss 0.7210, auc 0.4359, ap 0.4482
2024-01-10 22:07:45,859 - GAugM EPNet train, Epoch [ 21/55]: loss 0.7209, auc 0.5214, ap 0.4995
2024-01-10 22:07:45,935 - GAugM EPNet train, Epoch [ 22/55]: loss 0.7210, auc 0.3857, ap 0.4292
2024-01-10 22:07:46,010 - GAugM EPNet train, Epoch [ 23/55]: loss 0.7208, auc 0.4381, ap 0.4517
2024-01-10 22:07:46,086 - GAugM EPNet train, Epoch [ 24/55]: loss 0.7209, auc 0.4790, ap 0.4866
2024-01-10 22:07:46,161 - GAugM EPNet train, Epoch [ 25/55]: loss 0.7209, auc 0.4544, ap 0.4944
2024-01-10 22:07:46,240 - GAugM EPNet train, Epoch [ 26/55]: loss 0.7210, auc 0.5397, ap 0.5255
2024-01-10 22:07:46,321 - GAugM EPNet train, Epoch [ 27/55]: loss 0.7209, auc 0.4790, ap 0.5284
2024-01-10 22:07:46,396 - GAugM EPNet train, Epoch [ 28/55]: loss 0.7209, auc 0.6360, ap 0.6300
2024-01-10 22:07:46,475 - GAugM EPNet train, Epoch [ 29/55]: loss 0.7210, auc 0.5256, ap 0.5297
2024-01-10 22:07:46,553 - GAugM EPNet train, Epoch [ 30/55]: loss 0.7209, auc 0.4989, ap 0.5230
2024-01-10 22:07:46,625 - GAugM EPNet train, Epoch [ 31/55]: loss 0.7208, auc 0.5007, ap 0.5423
2024-01-10 22:07:46,699 - GAugM EPNet train, Epoch [ 32/55]: loss 0.7210, auc 0.5281, ap 0.5213
2024-01-10 22:07:46,774 - GAugM EPNet train, Epoch [ 33/55]: loss 0.7209, auc 0.5509, ap 0.5685
2024-01-10 22:07:46,846 - GAugM EPNet train, Epoch [ 34/55]: loss 0.7209, auc 0.4377, ap 0.4637
2024-01-10 22:07:46,920 - GAugM EPNet train, Epoch [ 35/55]: loss 0.7209, auc 0.5719, ap 0.5475
2024-01-10 22:07:47,000 - GAugM EPNet train, Epoch [ 36/55]: loss 0.7209, auc 0.5847, ap 0.6079
2024-01-10 22:07:47,077 - GAugM EPNet train, Epoch [ 37/55]: loss 0.7209, auc 0.4505, ap 0.4528
2024-01-10 22:07:47,164 - GAugM EPNet train, Epoch [ 38/55]: loss 0.7209, auc 0.5103, ap 0.4906
2024-01-10 22:07:47,241 - GAugM EPNet train, Epoch [ 39/55]: loss 0.7208, auc 0.5484, ap 0.5447
2024-01-10 22:07:47,321 - GAugM EPNet train, Epoch [ 40/55]: loss 0.7210, auc 0.5466, ap 0.5278
2024-01-10 22:07:47,399 - GAugM EPNet train, Epoch [ 41/55]: loss 0.7210, auc 0.4758, ap 0.5221
2024-01-10 22:07:47,473 - GAugM EPNet train, Epoch [ 42/55]: loss 0.7209, auc 0.5174, ap 0.5127
2024-01-10 22:07:47,555 - GAugM EPNet train, Epoch [ 43/55]: loss 0.7208, auc 0.4733, ap 0.5038
2024-01-10 22:07:47,630 - GAugM EPNet train, Epoch [ 44/55]: loss 0.7208, auc 0.4160, ap 0.4542
2024-01-10 22:07:47,706 - GAugM EPNet train, Epoch [ 45/55]: loss 0.7209, auc 0.5470, ap 0.5348
2024-01-10 22:07:47,785 - GAugM EPNet train, Epoch [ 46/55]: loss 0.7209, auc 0.5096, ap 0.5135
2024-01-10 22:07:47,868 - GAugM EPNet train, Epoch [ 47/55]: loss 0.7210, auc 0.5100, ap 0.5292
2024-01-10 22:07:47,944 - GAugM EPNet train, Epoch [ 48/55]: loss 0.7210, auc 0.6399, ap 0.6379
2024-01-10 22:07:48,018 - GAugM EPNet train, Epoch [ 49/55]: loss 0.7209, auc 0.5484, ap 0.5556
2024-01-10 22:07:48,092 - GAugM EPNet train, Epoch [ 50/55]: loss 0.7210, auc 0.4608, ap 0.4851
2024-01-10 22:07:48,171 - GAugM EPNet train, Epoch [ 51/55]: loss 0.7210, auc 0.5025, ap 0.5459
2024-01-10 22:07:48,248 - GAugM EPNet train, Epoch [ 52/55]: loss 0.7209, auc 0.4598, ap 0.5207
2024-01-10 22:07:48,328 - GAugM EPNet train, Epoch [ 53/55]: loss 0.7209, auc 0.5053, ap 0.5435
2024-01-10 22:07:48,407 - GAugM EPNet train, Epoch [ 54/55]: loss 0.7211, auc 0.5627, ap 0.5601
2024-01-10 22:07:48,481 - GAugM EPNet train, Epoch [ 55/55]: loss 0.7209, auc 0.6506, ap 0.6756
2024-01-10 22:07:48,484 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035ed690>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:07:49,236 - GAugM EPNet train, Epoch [  1/190]: loss 0.7210, auc 0.4573, ap 0.4733
2024-01-10 22:07:49,321 - GAugM EPNet train, Epoch [  2/190]: loss 0.7210, auc 0.5032, ap 0.5133
2024-01-10 22:07:49,403 - GAugM EPNet train, Epoch [  3/190]: loss 0.7209, auc 0.5158, ap 0.5588
2024-01-10 22:07:49,482 - GAugM EPNet train, Epoch [  4/190]: loss 0.7209, auc 0.5119, ap 0.5397
2024-01-10 22:07:49,575 - GAugM EPNet train, Epoch [  5/190]: loss 0.7209, auc 0.5676, ap 0.6011
2024-01-10 22:07:49,653 - GAugM EPNet train, Epoch [  6/190]: loss 0.7209, auc 0.5463, ap 0.5259
2024-01-10 22:07:49,730 - GAugM EPNet train, Epoch [  7/190]: loss 0.7209, auc 0.4571, ap 0.4540
2024-01-10 22:07:49,806 - GAugM EPNet train, Epoch [  8/190]: loss 0.7210, auc 0.4794, ap 0.4738
2024-01-10 22:07:49,885 - GAugM EPNet train, Epoch [  9/190]: loss 0.7209, auc 0.4382, ap 0.4959
2024-01-10 22:07:49,959 - GAugM EPNet train, Epoch [ 10/190]: loss 0.7208, auc 0.4772, ap 0.5023
2024-01-10 22:07:50,030 - GAugM EPNet train, Epoch [ 11/190]: loss 0.7209, auc 0.4589, ap 0.5266
2024-01-10 22:07:50,106 - GAugM EPNet train, Epoch [ 12/190]: loss 0.7210, auc 0.4541, ap 0.4757
2024-01-10 22:07:50,182 - GAugM EPNet train, Epoch [ 13/190]: loss 0.7209, auc 0.5829, ap 0.5657
2024-01-10 22:07:50,258 - GAugM EPNet train, Epoch [ 14/190]: loss 0.7209, auc 0.5128, ap 0.5469
2024-01-10 22:07:50,336 - GAugM EPNet train, Epoch [ 15/190]: loss 0.7210, auc 0.3966, ap 0.4575
2024-01-10 22:07:50,424 - GAugM EPNet train, Epoch [ 16/190]: loss 0.7209, auc 0.5276, ap 0.5528
2024-01-10 22:07:50,502 - GAugM EPNet train, Epoch [ 17/190]: loss 0.7210, auc 0.5249, ap 0.5160
2024-01-10 22:07:50,582 - GAugM EPNet train, Epoch [ 18/190]: loss 0.7210, auc 0.5424, ap 0.5452
2024-01-10 22:07:50,658 - GAugM EPNet train, Epoch [ 19/190]: loss 0.7209, auc 0.4884, ap 0.4815
2024-01-10 22:07:50,732 - GAugM EPNet train, Epoch [ 20/190]: loss 0.7210, auc 0.4231, ap 0.4740
2024-01-10 22:07:50,808 - GAugM EPNet train, Epoch [ 21/190]: loss 0.7209, auc 0.5336, ap 0.5396
2024-01-10 22:07:50,894 - GAugM EPNet train, Epoch [ 22/190]: loss 0.7210, auc 0.3747, ap 0.4644
2024-01-10 22:07:50,971 - GAugM EPNet train, Epoch [ 23/190]: loss 0.7208, auc 0.4769, ap 0.4976
2024-01-10 22:07:51,046 - GAugM EPNet train, Epoch [ 24/190]: loss 0.7209, auc 0.5295, ap 0.5058
2024-01-10 22:07:51,125 - GAugM EPNet train, Epoch [ 25/190]: loss 0.7209, auc 0.3971, ap 0.4476
2024-01-10 22:07:51,212 - GAugM EPNet train, Epoch [ 26/190]: loss 0.7210, auc 0.6203, ap 0.6174
2024-01-10 22:07:51,287 - GAugM EPNet train, Epoch [ 27/190]: loss 0.7209, auc 0.4906, ap 0.5558
2024-01-10 22:07:51,361 - GAugM EPNet train, Epoch [ 28/190]: loss 0.7209, auc 0.5374, ap 0.5633
2024-01-10 22:07:51,437 - GAugM EPNet train, Epoch [ 29/190]: loss 0.7210, auc 0.4765, ap 0.4724
2024-01-10 22:07:51,510 - GAugM EPNet train, Epoch [ 30/190]: loss 0.7209, auc 0.4838, ap 0.5236
2024-01-10 22:07:51,592 - GAugM EPNet train, Epoch [ 31/190]: loss 0.7208, auc 0.5525, ap 0.5584
2024-01-10 22:07:51,678 - GAugM EPNet train, Epoch [ 32/190]: loss 0.7210, auc 0.5924, ap 0.5600
2024-01-10 22:07:51,755 - GAugM EPNet train, Epoch [ 33/190]: loss 0.7209, auc 0.4847, ap 0.5104
2024-01-10 22:07:51,841 - GAugM EPNet train, Epoch [ 34/190]: loss 0.7209, auc 0.5244, ap 0.5409
2024-01-10 22:07:51,915 - GAugM EPNet train, Epoch [ 35/190]: loss 0.7209, auc 0.4980, ap 0.5106
2024-01-10 22:07:51,991 - GAugM EPNet train, Epoch [ 36/190]: loss 0.7209, auc 0.5945, ap 0.6189
2024-01-10 22:07:52,066 - GAugM EPNet train, Epoch [ 37/190]: loss 0.7209, auc 0.4883, ap 0.5298
2024-01-10 22:07:52,139 - GAugM EPNet train, Epoch [ 38/190]: loss 0.7209, auc 0.5057, ap 0.4890
2024-01-10 22:07:52,219 - GAugM EPNet train, Epoch [ 39/190]: loss 0.7208, auc 0.4571, ap 0.5043
2024-01-10 22:07:52,294 - GAugM EPNet train, Epoch [ 40/190]: loss 0.7210, auc 0.5870, ap 0.5386
2024-01-10 22:07:52,366 - GAugM EPNet train, Epoch [ 41/190]: loss 0.7210, auc 0.5150, ap 0.5384
2024-01-10 22:07:52,441 - GAugM EPNet train, Epoch [ 42/190]: loss 0.7209, auc 0.5028, ap 0.5365
2024-01-10 22:07:52,519 - GAugM EPNet train, Epoch [ 43/190]: loss 0.7208, auc 0.4537, ap 0.5029
2024-01-10 22:07:52,597 - GAugM EPNet train, Epoch [ 44/190]: loss 0.7208, auc 0.4007, ap 0.4493
2024-01-10 22:07:52,673 - GAugM EPNet train, Epoch [ 45/190]: loss 0.7209, auc 0.4769, ap 0.5057
2024-01-10 22:07:52,750 - GAugM EPNet train, Epoch [ 46/190]: loss 0.7209, auc 0.3900, ap 0.4374
2024-01-10 22:07:52,833 - GAugM EPNet train, Epoch [ 47/190]: loss 0.7210, auc 0.4333, ap 0.4892
2024-01-10 22:07:52,908 - GAugM EPNet train, Epoch [ 48/190]: loss 0.7210, auc 0.5160, ap 0.5452
2024-01-10 22:07:52,989 - GAugM EPNet train, Epoch [ 49/190]: loss 0.7209, auc 0.5438, ap 0.5346
2024-01-10 22:07:53,062 - GAugM EPNet train, Epoch [ 50/190]: loss 0.7210, auc 0.4806, ap 0.4949
2024-01-10 22:07:53,136 - GAugM EPNet train, Epoch [ 51/190]: loss 0.7210, auc 0.4500, ap 0.5080
2024-01-10 22:07:53,210 - GAugM EPNet train, Epoch [ 52/190]: loss 0.7209, auc 0.4689, ap 0.5158
2024-01-10 22:07:53,281 - GAugM EPNet train, Epoch [ 53/190]: loss 0.7209, auc 0.5902, ap 0.5568
2024-01-10 22:07:53,367 - GAugM EPNet train, Epoch [ 54/190]: loss 0.7211, auc 0.5363, ap 0.5303
2024-01-10 22:07:53,444 - GAugM EPNet train, Epoch [ 55/190]: loss 0.7209, auc 0.5215, ap 0.5219
2024-01-10 22:07:53,521 - GAugM EPNet train, Epoch [ 56/190]: loss 0.7208, auc 0.4706, ap 0.5172
2024-01-10 22:07:53,600 - GAugM EPNet train, Epoch [ 57/190]: loss 0.7209, auc 0.4710, ap 0.4985
2024-01-10 22:07:53,682 - GAugM EPNet train, Epoch [ 58/190]: loss 0.7210, auc 0.5879, ap 0.6309
2024-01-10 22:07:53,764 - GAugM EPNet train, Epoch [ 59/190]: loss 0.7211, auc 0.4964, ap 0.5217
2024-01-10 22:07:53,838 - GAugM EPNet train, Epoch [ 60/190]: loss 0.7210, auc 0.5627, ap 0.5362
2024-01-10 22:07:53,915 - GAugM EPNet train, Epoch [ 61/190]: loss 0.7209, auc 0.5368, ap 0.5282
2024-01-10 22:07:53,995 - GAugM EPNet train, Epoch [ 62/190]: loss 0.7210, auc 0.5157, ap 0.5612
2024-01-10 22:07:54,071 - GAugM EPNet train, Epoch [ 63/190]: loss 0.7208, auc 0.4414, ap 0.4565
2024-01-10 22:07:54,147 - GAugM EPNet train, Epoch [ 64/190]: loss 0.7208, auc 0.4518, ap 0.4888
2024-01-10 22:07:54,227 - GAugM EPNet train, Epoch [ 65/190]: loss 0.7208, auc 0.5110, ap 0.5424
2024-01-10 22:07:54,315 - GAugM EPNet train, Epoch [ 66/190]: loss 0.7209, auc 0.4804, ap 0.4787
2024-01-10 22:07:54,392 - GAugM EPNet train, Epoch [ 67/190]: loss 0.7209, auc 0.4902, ap 0.5035
2024-01-10 22:07:54,472 - GAugM EPNet train, Epoch [ 68/190]: loss 0.7210, auc 0.5214, ap 0.5386
2024-01-10 22:07:54,550 - GAugM EPNet train, Epoch [ 69/190]: loss 0.7210, auc 0.4984, ap 0.5392
2024-01-10 22:07:54,622 - GAugM EPNet train, Epoch [ 70/190]: loss 0.7210, auc 0.5055, ap 0.4984
2024-01-10 22:07:54,700 - GAugM EPNet train, Epoch [ 71/190]: loss 0.7210, auc 0.5258, ap 0.5165
2024-01-10 22:07:54,773 - GAugM EPNet train, Epoch [ 72/190]: loss 0.7210, auc 0.4966, ap 0.5396
2024-01-10 22:07:54,848 - GAugM EPNet train, Epoch [ 73/190]: loss 0.7209, auc 0.5217, ap 0.5043
2024-01-10 22:07:54,936 - GAugM EPNet train, Epoch [ 74/190]: loss 0.7209, auc 0.5110, ap 0.5324
2024-01-10 22:07:55,014 - GAugM EPNet train, Epoch [ 75/190]: loss 0.7210, auc 0.4614, ap 0.5035
2024-01-10 22:07:55,092 - GAugM EPNet train, Epoch [ 76/190]: loss 0.7209, auc 0.4434, ap 0.4617
2024-01-10 22:07:55,170 - GAugM EPNet train, Epoch [ 77/190]: loss 0.7208, auc 0.5552, ap 0.5707
2024-01-10 22:07:55,245 - GAugM EPNet train, Epoch [ 78/190]: loss 0.7209, auc 0.4991, ap 0.5002
2024-01-10 22:07:55,318 - GAugM EPNet train, Epoch [ 79/190]: loss 0.7208, auc 0.5094, ap 0.5281
2024-01-10 22:07:55,393 - GAugM EPNet train, Epoch [ 80/190]: loss 0.7209, auc 0.5023, ap 0.4924
2024-01-10 22:07:55,476 - GAugM EPNet train, Epoch [ 81/190]: loss 0.7209, auc 0.4879, ap 0.4873
2024-01-10 22:07:55,550 - GAugM EPNet train, Epoch [ 82/190]: loss 0.7210, auc 0.5068, ap 0.5318
2024-01-10 22:07:55,623 - GAugM EPNet train, Epoch [ 83/190]: loss 0.7209, auc 0.4799, ap 0.5092
2024-01-10 22:07:55,698 - GAugM EPNet train, Epoch [ 84/190]: loss 0.7209, auc 0.4722, ap 0.5198
2024-01-10 22:07:55,783 - GAugM EPNet train, Epoch [ 85/190]: loss 0.7210, auc 0.4025, ap 0.4655
2024-01-10 22:07:55,857 - GAugM EPNet train, Epoch [ 86/190]: loss 0.7208, auc 0.4640, ap 0.4865
2024-01-10 22:07:55,931 - GAugM EPNet train, Epoch [ 87/190]: loss 0.7209, auc 0.4687, ap 0.4974
2024-01-10 22:07:56,015 - GAugM EPNet train, Epoch [ 88/190]: loss 0.7210, auc 0.4541, ap 0.4911
2024-01-10 22:07:56,093 - GAugM EPNet train, Epoch [ 89/190]: loss 0.7210, auc 0.5020, ap 0.5276
2024-01-10 22:07:56,173 - GAugM EPNet train, Epoch [ 90/190]: loss 0.7209, auc 0.4429, ap 0.4779
2024-01-10 22:07:56,250 - GAugM EPNet train, Epoch [ 91/190]: loss 0.7208, auc 0.5504, ap 0.5209
2024-01-10 22:07:56,325 - GAugM EPNet train, Epoch [ 92/190]: loss 0.7209, auc 0.6036, ap 0.6056
2024-01-10 22:07:56,409 - GAugM EPNet train, Epoch [ 93/190]: loss 0.7209, auc 0.4103, ap 0.4971
2024-01-10 22:07:56,489 - GAugM EPNet train, Epoch [ 94/190]: loss 0.7210, auc 0.4870, ap 0.5400
2024-01-10 22:07:56,571 - GAugM EPNet train, Epoch [ 95/190]: loss 0.7210, auc 0.6326, ap 0.6206
2024-01-10 22:07:56,646 - GAugM EPNet train, Epoch [ 96/190]: loss 0.7209, auc 0.4968, ap 0.5312
2024-01-10 22:07:56,725 - GAugM EPNet train, Epoch [ 97/190]: loss 0.7209, auc 0.5158, ap 0.5599
2024-01-10 22:07:56,798 - GAugM EPNet train, Epoch [ 98/190]: loss 0.7209, auc 0.5244, ap 0.5040
2024-01-10 22:07:56,877 - GAugM EPNet train, Epoch [ 99/190]: loss 0.7209, auc 0.5142, ap 0.5536
2024-01-10 22:07:56,949 - GAugM EPNet train, Epoch [100/190]: loss 0.7210, auc 0.4544, ap 0.5032
2024-01-10 22:07:57,025 - GAugM EPNet train, Epoch [101/190]: loss 0.7210, auc 0.4767, ap 0.5078
2024-01-10 22:07:57,109 - GAugM EPNet train, Epoch [102/190]: loss 0.7209, auc 0.4502, ap 0.4772
2024-01-10 22:07:57,181 - GAugM EPNet train, Epoch [103/190]: loss 0.7209, auc 0.5080, ap 0.5480
2024-01-10 22:07:57,254 - GAugM EPNet train, Epoch [104/190]: loss 0.7209, auc 0.4548, ap 0.4735
2024-01-10 22:07:57,331 - GAugM EPNet train, Epoch [105/190]: loss 0.7209, auc 0.4548, ap 0.4825
2024-01-10 22:07:57,409 - GAugM EPNet train, Epoch [106/190]: loss 0.7210, auc 0.4724, ap 0.4734
2024-01-10 22:07:57,486 - GAugM EPNet train, Epoch [107/190]: loss 0.7210, auc 0.4662, ap 0.5422
2024-01-10 22:07:57,564 - GAugM EPNet train, Epoch [108/190]: loss 0.7208, auc 0.5187, ap 0.5362
2024-01-10 22:07:57,638 - GAugM EPNet train, Epoch [109/190]: loss 0.7210, auc 0.4922, ap 0.4998
2024-01-10 22:07:57,710 - GAugM EPNet train, Epoch [110/190]: loss 0.7209, auc 0.4525, ap 0.4970
2024-01-10 22:07:57,791 - GAugM EPNet train, Epoch [111/190]: loss 0.7210, auc 0.5199, ap 0.5314
2024-01-10 22:07:57,867 - GAugM EPNet train, Epoch [112/190]: loss 0.7209, auc 0.5164, ap 0.5437
2024-01-10 22:07:57,946 - GAugM EPNet train, Epoch [113/190]: loss 0.7210, auc 0.4498, ap 0.5004
2024-01-10 22:07:58,021 - GAugM EPNet train, Epoch [114/190]: loss 0.7209, auc 0.4340, ap 0.4745
2024-01-10 22:07:58,097 - GAugM EPNet train, Epoch [115/190]: loss 0.7210, auc 0.4420, ap 0.4886
2024-01-10 22:07:58,182 - GAugM EPNet train, Epoch [116/190]: loss 0.7209, auc 0.5267, ap 0.5762
2024-01-10 22:07:58,260 - GAugM EPNet train, Epoch [117/190]: loss 0.7208, auc 0.5235, ap 0.5431
2024-01-10 22:07:58,335 - GAugM EPNet train, Epoch [118/190]: loss 0.7209, auc 0.5139, ap 0.5362
2024-01-10 22:07:58,411 - GAugM EPNet train, Epoch [119/190]: loss 0.7209, auc 0.4950, ap 0.5392
2024-01-10 22:07:58,485 - GAugM EPNet train, Epoch [120/190]: loss 0.7210, auc 0.4740, ap 0.4692
2024-01-10 22:07:58,564 - GAugM EPNet train, Epoch [121/190]: loss 0.7210, auc 0.5004, ap 0.5060
2024-01-10 22:07:58,642 - GAugM EPNet train, Epoch [122/190]: loss 0.7209, auc 0.4283, ap 0.4786
2024-01-10 22:07:58,720 - GAugM EPNet train, Epoch [123/190]: loss 0.7209, auc 0.5621, ap 0.6003
2024-01-10 22:07:58,792 - GAugM EPNet train, Epoch [124/190]: loss 0.7210, auc 0.4804, ap 0.5031
2024-01-10 22:07:58,869 - GAugM EPNet train, Epoch [125/190]: loss 0.7209, auc 0.4672, ap 0.4843
2024-01-10 22:07:58,949 - GAugM EPNet train, Epoch [126/190]: loss 0.7210, auc 0.4471, ap 0.4875
2024-01-10 22:07:59,022 - GAugM EPNet train, Epoch [127/190]: loss 0.7209, auc 0.4963, ap 0.4992
2024-01-10 22:07:59,097 - GAugM EPNet train, Epoch [128/190]: loss 0.7210, auc 0.5680, ap 0.5620
2024-01-10 22:07:59,176 - GAugM EPNet train, Epoch [129/190]: loss 0.7208, auc 0.3677, ap 0.4319
2024-01-10 22:07:59,253 - GAugM EPNet train, Epoch [130/190]: loss 0.7210, auc 0.4829, ap 0.5262
2024-01-10 22:07:59,326 - GAugM EPNet train, Epoch [131/190]: loss 0.7210, auc 0.5317, ap 0.5804
2024-01-10 22:07:59,405 - GAugM EPNet train, Epoch [132/190]: loss 0.7209, auc 0.5100, ap 0.5016
2024-01-10 22:07:59,482 - GAugM EPNet train, Epoch [133/190]: loss 0.7209, auc 0.4178, ap 0.4797
2024-01-10 22:07:59,565 - GAugM EPNet train, Epoch [134/190]: loss 0.7210, auc 0.5288, ap 0.5557
2024-01-10 22:07:59,639 - GAugM EPNet train, Epoch [135/190]: loss 0.7209, auc 0.3749, ap 0.4238
2024-01-10 22:07:59,723 - GAugM EPNet train, Epoch [136/190]: loss 0.7209, auc 0.4920, ap 0.4918
2024-01-10 22:07:59,798 - GAugM EPNet train, Epoch [137/190]: loss 0.7210, auc 0.4523, ap 0.4769
2024-01-10 22:07:59,876 - GAugM EPNet train, Epoch [138/190]: loss 0.7210, auc 0.5311, ap 0.5327
2024-01-10 22:07:59,955 - GAugM EPNet train, Epoch [139/190]: loss 0.7210, auc 0.5078, ap 0.5168
2024-01-10 22:08:00,033 - GAugM EPNet train, Epoch [140/190]: loss 0.7209, auc 0.4662, ap 0.5343
2024-01-10 22:08:00,118 - GAugM EPNet train, Epoch [141/190]: loss 0.7209, auc 0.4907, ap 0.5022
2024-01-10 22:08:00,195 - GAugM EPNet train, Epoch [142/190]: loss 0.7209, auc 0.4993, ap 0.5377
2024-01-10 22:08:00,269 - GAugM EPNet train, Epoch [143/190]: loss 0.7209, auc 0.4567, ap 0.5001
2024-01-10 22:08:00,347 - GAugM EPNet train, Epoch [144/190]: loss 0.7209, auc 0.4943, ap 0.4991
2024-01-10 22:08:00,434 - GAugM EPNet train, Epoch [145/190]: loss 0.7209, auc 0.3788, ap 0.4576
2024-01-10 22:08:00,508 - GAugM EPNet train, Epoch [146/190]: loss 0.7209, auc 0.5265, ap 0.5408
2024-01-10 22:08:00,594 - GAugM EPNet train, Epoch [147/190]: loss 0.7209, auc 0.5904, ap 0.6057
2024-01-10 22:08:00,671 - GAugM EPNet train, Epoch [148/190]: loss 0.7209, auc 0.4758, ap 0.5075
2024-01-10 22:08:00,745 - GAugM EPNet train, Epoch [149/190]: loss 0.7208, auc 0.4464, ap 0.4604
2024-01-10 22:08:00,820 - GAugM EPNet train, Epoch [150/190]: loss 0.7209, auc 0.5203, ap 0.5135
2024-01-10 22:08:00,896 - GAugM EPNet train, Epoch [151/190]: loss 0.7209, auc 0.5616, ap 0.5743
2024-01-10 22:08:00,977 - GAugM EPNet train, Epoch [152/190]: loss 0.7209, auc 0.5180, ap 0.5200
2024-01-10 22:08:01,050 - GAugM EPNet train, Epoch [153/190]: loss 0.7209, auc 0.4637, ap 0.5135
2024-01-10 22:08:01,123 - GAugM EPNet train, Epoch [154/190]: loss 0.7209, auc 0.5408, ap 0.5885
2024-01-10 22:08:01,203 - GAugM EPNet train, Epoch [155/190]: loss 0.7209, auc 0.5951, ap 0.6174
2024-01-10 22:08:01,283 - GAugM EPNet train, Epoch [156/190]: loss 0.7209, auc 0.4982, ap 0.5065
2024-01-10 22:08:01,356 - GAugM EPNet train, Epoch [157/190]: loss 0.7209, auc 0.5707, ap 0.5669
2024-01-10 22:08:01,433 - GAugM EPNet train, Epoch [158/190]: loss 0.7208, auc 0.4405, ap 0.4666
2024-01-10 22:08:01,506 - GAugM EPNet train, Epoch [159/190]: loss 0.7208, auc 0.5283, ap 0.5162
2024-01-10 22:08:01,588 - GAugM EPNet train, Epoch [160/190]: loss 0.7209, auc 0.4849, ap 0.5167
2024-01-10 22:08:01,660 - GAugM EPNet train, Epoch [161/190]: loss 0.7209, auc 0.5498, ap 0.5683
2024-01-10 22:08:01,738 - GAugM EPNet train, Epoch [162/190]: loss 0.7209, auc 0.3925, ap 0.4355
2024-01-10 22:08:01,814 - GAugM EPNet train, Epoch [163/190]: loss 0.7209, auc 0.4735, ap 0.4812
2024-01-10 22:08:01,894 - GAugM EPNet train, Epoch [164/190]: loss 0.7211, auc 0.5255, ap 0.5225
2024-01-10 22:08:01,969 - GAugM EPNet train, Epoch [165/190]: loss 0.7210, auc 0.4292, ap 0.4825
2024-01-10 22:08:02,043 - GAugM EPNet train, Epoch [166/190]: loss 0.7208, auc 0.5208, ap 0.5050
2024-01-10 22:08:02,119 - GAugM EPNet train, Epoch [167/190]: loss 0.7209, auc 0.5158, ap 0.5408
2024-01-10 22:08:02,193 - GAugM EPNet train, Epoch [168/190]: loss 0.7209, auc 0.5167, ap 0.5684
2024-01-10 22:08:02,274 - GAugM EPNet train, Epoch [169/190]: loss 0.7209, auc 0.5157, ap 0.5655
2024-01-10 22:08:02,351 - GAugM EPNet train, Epoch [170/190]: loss 0.7210, auc 0.5032, ap 0.4946
2024-01-10 22:08:02,431 - GAugM EPNet train, Epoch [171/190]: loss 0.7209, auc 0.4557, ap 0.4902
2024-01-10 22:08:02,506 - GAugM EPNet train, Epoch [172/190]: loss 0.7208, auc 0.5408, ap 0.5327
2024-01-10 22:08:02,583 - GAugM EPNet train, Epoch [173/190]: loss 0.7209, auc 0.4511, ap 0.4867
2024-01-10 22:08:02,658 - GAugM EPNet train, Epoch [174/190]: loss 0.7209, auc 0.4119, ap 0.4397
2024-01-10 22:08:02,748 - GAugM EPNet train, Epoch [175/190]: loss 0.7209, auc 0.5776, ap 0.5894
2024-01-10 22:08:02,826 - GAugM EPNet train, Epoch [176/190]: loss 0.7209, auc 0.4697, ap 0.4788
2024-01-10 22:08:02,905 - GAugM EPNet train, Epoch [177/190]: loss 0.7210, auc 0.5221, ap 0.5202
2024-01-10 22:08:02,980 - GAugM EPNet train, Epoch [178/190]: loss 0.7210, auc 0.5109, ap 0.5387
2024-01-10 22:08:03,055 - GAugM EPNet train, Epoch [179/190]: loss 0.7210, auc 0.4786, ap 0.5358
2024-01-10 22:08:03,134 - GAugM EPNet train, Epoch [180/190]: loss 0.7210, auc 0.4906, ap 0.5305
2024-01-10 22:08:03,213 - GAugM EPNet train, Epoch [181/190]: loss 0.7209, auc 0.4459, ap 0.4645
2024-01-10 22:08:03,294 - GAugM EPNet train, Epoch [182/190]: loss 0.7209, auc 0.4124, ap 0.4711
2024-01-10 22:08:03,369 - GAugM EPNet train, Epoch [183/190]: loss 0.7210, auc 0.5190, ap 0.5292
2024-01-10 22:08:03,450 - GAugM EPNet train, Epoch [184/190]: loss 0.7209, auc 0.5721, ap 0.5645
2024-01-10 22:08:03,525 - GAugM EPNet train, Epoch [185/190]: loss 0.7209, auc 0.3993, ap 0.4499
2024-01-10 22:08:03,601 - GAugM EPNet train, Epoch [186/190]: loss 0.7208, auc 0.5069, ap 0.5618
2024-01-10 22:08:03,677 - GAugM EPNet train, Epoch [187/190]: loss 0.7209, auc 0.4756, ap 0.4934
2024-01-10 22:08:03,750 - GAugM EPNet train, Epoch [188/190]: loss 0.7209, auc 0.4591, ap 0.4725
2024-01-10 22:08:03,829 - GAugM EPNet train, Epoch [189/190]: loss 0.7209, auc 0.5936, ap 0.6401
2024-01-10 22:08:03,903 - GAugM EPNet train, Epoch [190/190]: loss 0.7209, auc 0.4555, ap 0.4747
2024-01-10 22:08:03,917 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03558410>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:08:04,604 - GAugM EPNet train, Epoch [  1/190]: loss 0.7210, auc 0.4411, ap 0.4559
2024-01-10 22:08:04,691 - GAugM EPNet train, Epoch [  2/190]: loss 0.7210, auc 0.5098, ap 0.4986
2024-01-10 22:08:04,779 - GAugM EPNet train, Epoch [  3/190]: loss 0.7209, auc 0.5208, ap 0.5090
2024-01-10 22:08:04,865 - GAugM EPNet train, Epoch [  4/190]: loss 0.7209, auc 0.4356, ap 0.4853
2024-01-10 22:08:04,956 - GAugM EPNet train, Epoch [  5/190]: loss 0.7209, auc 0.5911, ap 0.6091
2024-01-10 22:08:05,044 - GAugM EPNet train, Epoch [  6/190]: loss 0.7209, auc 0.4772, ap 0.4730
2024-01-10 22:08:05,143 - GAugM EPNet train, Epoch [  7/190]: loss 0.7209, auc 0.4672, ap 0.4760
2024-01-10 22:08:05,231 - GAugM EPNet train, Epoch [  8/190]: loss 0.7210, auc 0.5107, ap 0.5157
2024-01-10 22:08:05,321 - GAugM EPNet train, Epoch [  9/190]: loss 0.7209, auc 0.4411, ap 0.4698
2024-01-10 22:08:05,407 - GAugM EPNet train, Epoch [ 10/190]: loss 0.7208, auc 0.5634, ap 0.5703
2024-01-10 22:08:05,503 - GAugM EPNet train, Epoch [ 11/190]: loss 0.7209, auc 0.5226, ap 0.5708
2024-01-10 22:08:05,588 - GAugM EPNet train, Epoch [ 12/190]: loss 0.7210, auc 0.4429, ap 0.4642
2024-01-10 22:08:05,675 - GAugM EPNet train, Epoch [ 13/190]: loss 0.7209, auc 0.5417, ap 0.5400
2024-01-10 22:08:05,767 - GAugM EPNet train, Epoch [ 14/190]: loss 0.7209, auc 0.5096, ap 0.5142
2024-01-10 22:08:05,853 - GAugM EPNet train, Epoch [ 15/190]: loss 0.7210, auc 0.4694, ap 0.5251
2024-01-10 22:08:05,942 - GAugM EPNet train, Epoch [ 16/190]: loss 0.7209, auc 0.4989, ap 0.5106
2024-01-10 22:08:06,026 - GAugM EPNet train, Epoch [ 17/190]: loss 0.7210, auc 0.5173, ap 0.5230
2024-01-10 22:08:06,116 - GAugM EPNet train, Epoch [ 18/190]: loss 0.7210, auc 0.5956, ap 0.6054
2024-01-10 22:08:06,202 - GAugM EPNet train, Epoch [ 19/190]: loss 0.7209, auc 0.5112, ap 0.5145
2024-01-10 22:08:06,291 - GAugM EPNet train, Epoch [ 20/190]: loss 0.7210, auc 0.4082, ap 0.4799
2024-01-10 22:08:06,371 - GAugM EPNet train, Epoch [ 21/190]: loss 0.7209, auc 0.5089, ap 0.5047
2024-01-10 22:08:06,451 - GAugM EPNet train, Epoch [ 22/190]: loss 0.7210, auc 0.3987, ap 0.4724
2024-01-10 22:08:06,525 - GAugM EPNet train, Epoch [ 23/190]: loss 0.7208, auc 0.4952, ap 0.4857
2024-01-10 22:08:06,598 - GAugM EPNet train, Epoch [ 24/190]: loss 0.7209, auc 0.5023, ap 0.5231
2024-01-10 22:08:06,672 - GAugM EPNet train, Epoch [ 25/190]: loss 0.7209, auc 0.4455, ap 0.4700
2024-01-10 22:08:06,747 - GAugM EPNet train, Epoch [ 26/190]: loss 0.7210, auc 0.5212, ap 0.5362
2024-01-10 22:08:06,824 - GAugM EPNet train, Epoch [ 27/190]: loss 0.7209, auc 0.4660, ap 0.5116
2024-01-10 22:08:06,904 - GAugM EPNet train, Epoch [ 28/190]: loss 0.7209, auc 0.5110, ap 0.5337
2024-01-10 22:08:06,977 - GAugM EPNet train, Epoch [ 29/190]: loss 0.7210, auc 0.5780, ap 0.5426
2024-01-10 22:08:07,056 - GAugM EPNet train, Epoch [ 30/190]: loss 0.7209, auc 0.5500, ap 0.6005
2024-01-10 22:08:07,130 - GAugM EPNet train, Epoch [ 31/190]: loss 0.7208, auc 0.4701, ap 0.5005
2024-01-10 22:08:07,205 - GAugM EPNet train, Epoch [ 32/190]: loss 0.7210, auc 0.5837, ap 0.5613
2024-01-10 22:08:07,289 - GAugM EPNet train, Epoch [ 33/190]: loss 0.7209, auc 0.5634, ap 0.5802
2024-01-10 22:08:07,366 - GAugM EPNet train, Epoch [ 34/190]: loss 0.7209, auc 0.5417, ap 0.5522
2024-01-10 22:08:07,449 - GAugM EPNet train, Epoch [ 35/190]: loss 0.7209, auc 0.5308, ap 0.5296
2024-01-10 22:08:07,530 - GAugM EPNet train, Epoch [ 36/190]: loss 0.7209, auc 0.5986, ap 0.5841
2024-01-10 22:08:07,605 - GAugM EPNet train, Epoch [ 37/190]: loss 0.7209, auc 0.4436, ap 0.4676
2024-01-10 22:08:07,679 - GAugM EPNet train, Epoch [ 38/190]: loss 0.7209, auc 0.5333, ap 0.5251
2024-01-10 22:08:07,752 - GAugM EPNet train, Epoch [ 39/190]: loss 0.7208, auc 0.3952, ap 0.4600
2024-01-10 22:08:07,826 - GAugM EPNet train, Epoch [ 40/190]: loss 0.7210, auc 0.5331, ap 0.5177
2024-01-10 22:08:07,905 - GAugM EPNet train, Epoch [ 41/190]: loss 0.7210, auc 0.4541, ap 0.4923
2024-01-10 22:08:07,981 - GAugM EPNet train, Epoch [ 42/190]: loss 0.7209, auc 0.5228, ap 0.5595
2024-01-10 22:08:08,060 - GAugM EPNet train, Epoch [ 43/190]: loss 0.7208, auc 0.5084, ap 0.5573
2024-01-10 22:08:08,141 - GAugM EPNet train, Epoch [ 44/190]: loss 0.7208, auc 0.5112, ap 0.5283
2024-01-10 22:08:08,218 - GAugM EPNet train, Epoch [ 45/190]: loss 0.7209, auc 0.4842, ap 0.5328
2024-01-10 22:08:08,303 - GAugM EPNet train, Epoch [ 46/190]: loss 0.7209, auc 0.4644, ap 0.5021
2024-01-10 22:08:08,375 - GAugM EPNet train, Epoch [ 47/190]: loss 0.7210, auc 0.4553, ap 0.4676
2024-01-10 22:08:08,457 - GAugM EPNet train, Epoch [ 48/190]: loss 0.7210, auc 0.5840, ap 0.6114
2024-01-10 22:08:08,551 - GAugM EPNet train, Epoch [ 49/190]: loss 0.7209, auc 0.5046, ap 0.5107
2024-01-10 22:08:08,627 - GAugM EPNet train, Epoch [ 50/190]: loss 0.7210, auc 0.5691, ap 0.5502
2024-01-10 22:08:08,701 - GAugM EPNet train, Epoch [ 51/190]: loss 0.7210, auc 0.4600, ap 0.4867
2024-01-10 22:08:08,775 - GAugM EPNet train, Epoch [ 52/190]: loss 0.7209, auc 0.4610, ap 0.4996
2024-01-10 22:08:08,855 - GAugM EPNet train, Epoch [ 53/190]: loss 0.7209, auc 0.5486, ap 0.5459
2024-01-10 22:08:08,931 - GAugM EPNet train, Epoch [ 54/190]: loss 0.7211, auc 0.5360, ap 0.5561
2024-01-10 22:08:09,005 - GAugM EPNet train, Epoch [ 55/190]: loss 0.7209, auc 0.5130, ap 0.5618
2024-01-10 22:08:09,078 - GAugM EPNet train, Epoch [ 56/190]: loss 0.7208, auc 0.5027, ap 0.5374
2024-01-10 22:08:09,153 - GAugM EPNet train, Epoch [ 57/190]: loss 0.7209, auc 0.4457, ap 0.4708
2024-01-10 22:08:09,226 - GAugM EPNet train, Epoch [ 58/190]: loss 0.7210, auc 0.5039, ap 0.5289
2024-01-10 22:08:09,297 - GAugM EPNet train, Epoch [ 59/190]: loss 0.7211, auc 0.5493, ap 0.5546
2024-01-10 22:08:09,372 - GAugM EPNet train, Epoch [ 60/190]: loss 0.7210, auc 0.5454, ap 0.5249
2024-01-10 22:08:09,451 - GAugM EPNet train, Epoch [ 61/190]: loss 0.7209, auc 0.4559, ap 0.4707
2024-01-10 22:08:09,525 - GAugM EPNet train, Epoch [ 62/190]: loss 0.7210, auc 0.4363, ap 0.4748
2024-01-10 22:08:09,600 - GAugM EPNet train, Epoch [ 63/190]: loss 0.7208, auc 0.4544, ap 0.4759
2024-01-10 22:08:09,674 - GAugM EPNet train, Epoch [ 64/190]: loss 0.7208, auc 0.5310, ap 0.5445
2024-01-10 22:08:09,749 - GAugM EPNet train, Epoch [ 65/190]: loss 0.7208, auc 0.5669, ap 0.5695
2024-01-10 22:08:09,823 - GAugM EPNet train, Epoch [ 66/190]: loss 0.7209, auc 0.5331, ap 0.5340
2024-01-10 22:08:09,900 - GAugM EPNet train, Epoch [ 67/190]: loss 0.7209, auc 0.5847, ap 0.5707
2024-01-10 22:08:09,974 - GAugM EPNet train, Epoch [ 68/190]: loss 0.7210, auc 0.5570, ap 0.5876
2024-01-10 22:08:10,053 - GAugM EPNet train, Epoch [ 69/190]: loss 0.7210, auc 0.5018, ap 0.5233
2024-01-10 22:08:10,126 - GAugM EPNet train, Epoch [ 70/190]: loss 0.7210, auc 0.5217, ap 0.5066
2024-01-10 22:08:10,200 - GAugM EPNet train, Epoch [ 71/190]: loss 0.7210, auc 0.4959, ap 0.5044
2024-01-10 22:08:10,278 - GAugM EPNet train, Epoch [ 72/190]: loss 0.7210, auc 0.5253, ap 0.5500
2024-01-10 22:08:10,356 - GAugM EPNet train, Epoch [ 73/190]: loss 0.7209, auc 0.4616, ap 0.4645
2024-01-10 22:08:10,431 - GAugM EPNet train, Epoch [ 74/190]: loss 0.7209, auc 0.4772, ap 0.5185
2024-01-10 22:08:10,505 - GAugM EPNet train, Epoch [ 75/190]: loss 0.7210, auc 0.4731, ap 0.5082
2024-01-10 22:08:10,577 - GAugM EPNet train, Epoch [ 76/190]: loss 0.7209, auc 0.4516, ap 0.4943
2024-01-10 22:08:10,651 - GAugM EPNet train, Epoch [ 77/190]: loss 0.7208, auc 0.5256, ap 0.5600
2024-01-10 22:08:10,729 - GAugM EPNet train, Epoch [ 78/190]: loss 0.7209, auc 0.5041, ap 0.5035
2024-01-10 22:08:10,808 - GAugM EPNet train, Epoch [ 79/190]: loss 0.7208, auc 0.3991, ap 0.4399
2024-01-10 22:08:10,896 - GAugM EPNet train, Epoch [ 80/190]: loss 0.7209, auc 0.6237, ap 0.5871
2024-01-10 22:08:10,971 - GAugM EPNet train, Epoch [ 81/190]: loss 0.7209, auc 0.5263, ap 0.5126
2024-01-10 22:08:11,045 - GAugM EPNet train, Epoch [ 82/190]: loss 0.7210, auc 0.5233, ap 0.5412
2024-01-10 22:08:11,119 - GAugM EPNet train, Epoch [ 83/190]: loss 0.7209, auc 0.4470, ap 0.4878
2024-01-10 22:08:11,194 - GAugM EPNet train, Epoch [ 84/190]: loss 0.7209, auc 0.4553, ap 0.4804
2024-01-10 22:08:11,286 - GAugM EPNet train, Epoch [ 85/190]: loss 0.7210, auc 0.4281, ap 0.4901
2024-01-10 22:08:11,368 - GAugM EPNet train, Epoch [ 86/190]: loss 0.7208, auc 0.5383, ap 0.5682
2024-01-10 22:08:11,444 - GAugM EPNet train, Epoch [ 87/190]: loss 0.7209, auc 0.5538, ap 0.5534
2024-01-10 22:08:11,517 - GAugM EPNet train, Epoch [ 88/190]: loss 0.7210, auc 0.4607, ap 0.5345
2024-01-10 22:08:11,596 - GAugM EPNet train, Epoch [ 89/190]: loss 0.7210, auc 0.5621, ap 0.5895
2024-01-10 22:08:11,676 - GAugM EPNet train, Epoch [ 90/190]: loss 0.7209, auc 0.5087, ap 0.5209
2024-01-10 22:08:11,757 - GAugM EPNet train, Epoch [ 91/190]: loss 0.7208, auc 0.5918, ap 0.5722
2024-01-10 22:08:11,832 - GAugM EPNet train, Epoch [ 92/190]: loss 0.7209, auc 0.6301, ap 0.6166
2024-01-10 22:08:11,907 - GAugM EPNet train, Epoch [ 93/190]: loss 0.7209, auc 0.3637, ap 0.4369
2024-01-10 22:08:11,989 - GAugM EPNet train, Epoch [ 94/190]: loss 0.7210, auc 0.4840, ap 0.5355
2024-01-10 22:08:12,066 - GAugM EPNet train, Epoch [ 95/190]: loss 0.7210, auc 0.5053, ap 0.4891
2024-01-10 22:08:12,141 - GAugM EPNet train, Epoch [ 96/190]: loss 0.7209, auc 0.5336, ap 0.5694
2024-01-10 22:08:12,223 - GAugM EPNet train, Epoch [ 97/190]: loss 0.7209, auc 0.4884, ap 0.5552
2024-01-10 22:08:12,297 - GAugM EPNet train, Epoch [ 98/190]: loss 0.7209, auc 0.5215, ap 0.5330
2024-01-10 22:08:12,373 - GAugM EPNet train, Epoch [ 99/190]: loss 0.7209, auc 0.5011, ap 0.5417
2024-01-10 22:08:12,448 - GAugM EPNet train, Epoch [100/190]: loss 0.7210, auc 0.5913, ap 0.5726
2024-01-10 22:08:12,524 - GAugM EPNet train, Epoch [101/190]: loss 0.7210, auc 0.5203, ap 0.5257
2024-01-10 22:08:12,598 - GAugM EPNet train, Epoch [102/190]: loss 0.7209, auc 0.5383, ap 0.5868
2024-01-10 22:08:12,670 - GAugM EPNet train, Epoch [103/190]: loss 0.7209, auc 0.4703, ap 0.5011
2024-01-10 22:08:12,744 - GAugM EPNet train, Epoch [104/190]: loss 0.7209, auc 0.4959, ap 0.5111
2024-01-10 22:08:12,825 - GAugM EPNet train, Epoch [105/190]: loss 0.7209, auc 0.5459, ap 0.5401
2024-01-10 22:08:12,898 - GAugM EPNet train, Epoch [106/190]: loss 0.7210, auc 0.4550, ap 0.4781
2024-01-10 22:08:12,976 - GAugM EPNet train, Epoch [107/190]: loss 0.7210, auc 0.4626, ap 0.4948
2024-01-10 22:08:13,060 - GAugM EPNet train, Epoch [108/190]: loss 0.7208, auc 0.5034, ap 0.5120
2024-01-10 22:08:13,138 - GAugM EPNet train, Epoch [109/190]: loss 0.7210, auc 0.4690, ap 0.4805
2024-01-10 22:08:13,218 - GAugM EPNet train, Epoch [110/190]: loss 0.7209, auc 0.4858, ap 0.5541
2024-01-10 22:08:13,295 - GAugM EPNet train, Epoch [111/190]: loss 0.7210, auc 0.5221, ap 0.5633
2024-01-10 22:08:13,368 - GAugM EPNet train, Epoch [112/190]: loss 0.7209, auc 0.4560, ap 0.5045
2024-01-10 22:08:13,443 - GAugM EPNet train, Epoch [113/190]: loss 0.7210, auc 0.4948, ap 0.5301
2024-01-10 22:08:13,534 - GAugM EPNet train, Epoch [114/190]: loss 0.7209, auc 0.4425, ap 0.4493
2024-01-10 22:08:13,611 - GAugM EPNet train, Epoch [115/190]: loss 0.7210, auc 0.4438, ap 0.4662
2024-01-10 22:08:13,685 - GAugM EPNet train, Epoch [116/190]: loss 0.7209, auc 0.5892, ap 0.6193
2024-01-10 22:08:13,758 - GAugM EPNet train, Epoch [117/190]: loss 0.7208, auc 0.4772, ap 0.4920
2024-01-10 22:08:13,831 - GAugM EPNet train, Epoch [118/190]: loss 0.7209, auc 0.4701, ap 0.4963
2024-01-10 22:08:13,904 - GAugM EPNet train, Epoch [119/190]: loss 0.7209, auc 0.4984, ap 0.5109
2024-01-10 22:08:13,991 - GAugM EPNet train, Epoch [120/190]: loss 0.7210, auc 0.4722, ap 0.4897
2024-01-10 22:08:14,069 - GAugM EPNet train, Epoch [121/190]: loss 0.7210, auc 0.4007, ap 0.4528
2024-01-10 22:08:14,142 - GAugM EPNet train, Epoch [122/190]: loss 0.7209, auc 0.4785, ap 0.5076
2024-01-10 22:08:14,216 - GAugM EPNet train, Epoch [123/190]: loss 0.7209, auc 0.4874, ap 0.5467
2024-01-10 22:08:14,291 - GAugM EPNet train, Epoch [124/190]: loss 0.7210, auc 0.4402, ap 0.4604
2024-01-10 22:08:14,371 - GAugM EPNet train, Epoch [125/190]: loss 0.7209, auc 0.5255, ap 0.5074
2024-01-10 22:08:14,446 - GAugM EPNet train, Epoch [126/190]: loss 0.7210, auc 0.4635, ap 0.4772
2024-01-10 22:08:14,520 - GAugM EPNet train, Epoch [127/190]: loss 0.7209, auc 0.4982, ap 0.4972
2024-01-10 22:08:14,600 - GAugM EPNet train, Epoch [128/190]: loss 0.7210, auc 0.5484, ap 0.5367
2024-01-10 22:08:14,675 - GAugM EPNet train, Epoch [129/190]: loss 0.7208, auc 0.4671, ap 0.4831
2024-01-10 22:08:14,755 - GAugM EPNet train, Epoch [130/190]: loss 0.7210, auc 0.4438, ap 0.4734
2024-01-10 22:08:14,837 - GAugM EPNet train, Epoch [131/190]: loss 0.7210, auc 0.5171, ap 0.5338
2024-01-10 22:08:14,914 - GAugM EPNet train, Epoch [132/190]: loss 0.7209, auc 0.4931, ap 0.4902
2024-01-10 22:08:14,987 - GAugM EPNet train, Epoch [133/190]: loss 0.7209, auc 0.4788, ap 0.5291
2024-01-10 22:08:15,062 - GAugM EPNet train, Epoch [134/190]: loss 0.7210, auc 0.4530, ap 0.4964
2024-01-10 22:08:15,136 - GAugM EPNet train, Epoch [135/190]: loss 0.7209, auc 0.4060, ap 0.4689
2024-01-10 22:08:15,218 - GAugM EPNet train, Epoch [136/190]: loss 0.7209, auc 0.5030, ap 0.5189
2024-01-10 22:08:15,300 - GAugM EPNet train, Epoch [137/190]: loss 0.7210, auc 0.4350, ap 0.4529
2024-01-10 22:08:15,376 - GAugM EPNet train, Epoch [138/190]: loss 0.7210, auc 0.5311, ap 0.5217
2024-01-10 22:08:15,451 - GAugM EPNet train, Epoch [139/190]: loss 0.7210, auc 0.4890, ap 0.5028
2024-01-10 22:08:15,529 - GAugM EPNet train, Epoch [140/190]: loss 0.7209, auc 0.5591, ap 0.5801
2024-01-10 22:08:15,605 - GAugM EPNet train, Epoch [141/190]: loss 0.7209, auc 0.5256, ap 0.5196
2024-01-10 22:08:15,685 - GAugM EPNet train, Epoch [142/190]: loss 0.7209, auc 0.5354, ap 0.5518
2024-01-10 22:08:15,762 - GAugM EPNet train, Epoch [143/190]: loss 0.7209, auc 0.4487, ap 0.4772
2024-01-10 22:08:15,844 - GAugM EPNet train, Epoch [144/190]: loss 0.7209, auc 0.4405, ap 0.4758
2024-01-10 22:08:15,929 - GAugM EPNet train, Epoch [145/190]: loss 0.7209, auc 0.4925, ap 0.5454
2024-01-10 22:08:16,005 - GAugM EPNet train, Epoch [146/190]: loss 0.7209, auc 0.4907, ap 0.5235
2024-01-10 22:08:16,081 - GAugM EPNet train, Epoch [147/190]: loss 0.7209, auc 0.5758, ap 0.6065
2024-01-10 22:08:16,170 - GAugM EPNet train, Epoch [148/190]: loss 0.7209, auc 0.4850, ap 0.5034
2024-01-10 22:08:16,245 - GAugM EPNet train, Epoch [149/190]: loss 0.7208, auc 0.4810, ap 0.5117
2024-01-10 22:08:16,326 - GAugM EPNet train, Epoch [150/190]: loss 0.7209, auc 0.5368, ap 0.5263
2024-01-10 22:08:16,401 - GAugM EPNet train, Epoch [151/190]: loss 0.7209, auc 0.5331, ap 0.5524
2024-01-10 22:08:16,480 - GAugM EPNet train, Epoch [152/190]: loss 0.7209, auc 0.5004, ap 0.5165
2024-01-10 22:08:16,556 - GAugM EPNet train, Epoch [153/190]: loss 0.7209, auc 0.5000, ap 0.5048
2024-01-10 22:08:16,631 - GAugM EPNet train, Epoch [154/190]: loss 0.7209, auc 0.6041, ap 0.6461
2024-01-10 22:08:16,711 - GAugM EPNet train, Epoch [155/190]: loss 0.7209, auc 0.5105, ap 0.5264
2024-01-10 22:08:16,785 - GAugM EPNet train, Epoch [156/190]: loss 0.7209, auc 0.4580, ap 0.4556
2024-01-10 22:08:16,862 - GAugM EPNet train, Epoch [157/190]: loss 0.7209, auc 0.5287, ap 0.5107
2024-01-10 22:08:16,935 - GAugM EPNet train, Epoch [158/190]: loss 0.7208, auc 0.5288, ap 0.5299
2024-01-10 22:08:17,014 - GAugM EPNet train, Epoch [159/190]: loss 0.7208, auc 0.4464, ap 0.4854
2024-01-10 22:08:17,098 - GAugM EPNet train, Epoch [160/190]: loss 0.7209, auc 0.5112, ap 0.5577
2024-01-10 22:08:17,173 - GAugM EPNet train, Epoch [161/190]: loss 0.7209, auc 0.6002, ap 0.6012
2024-01-10 22:08:17,248 - GAugM EPNet train, Epoch [162/190]: loss 0.7209, auc 0.4651, ap 0.4961
2024-01-10 22:08:17,328 - GAugM EPNet train, Epoch [163/190]: loss 0.7209, auc 0.5623, ap 0.5510
2024-01-10 22:08:17,402 - GAugM EPNet train, Epoch [164/190]: loss 0.7211, auc 0.4632, ap 0.4758
2024-01-10 22:08:17,481 - GAugM EPNet train, Epoch [165/190]: loss 0.7210, auc 0.5199, ap 0.5647
2024-01-10 22:08:17,557 - GAugM EPNet train, Epoch [166/190]: loss 0.7208, auc 0.5578, ap 0.5537
2024-01-10 22:08:17,630 - GAugM EPNet train, Epoch [167/190]: loss 0.7209, auc 0.5258, ap 0.5490
2024-01-10 22:08:17,705 - GAugM EPNet train, Epoch [168/190]: loss 0.7209, auc 0.5137, ap 0.5677
2024-01-10 22:08:17,779 - GAugM EPNet train, Epoch [169/190]: loss 0.7209, auc 0.5114, ap 0.5281
2024-01-10 22:08:17,851 - GAugM EPNet train, Epoch [170/190]: loss 0.7210, auc 0.5360, ap 0.5214
2024-01-10 22:08:17,932 - GAugM EPNet train, Epoch [171/190]: loss 0.7209, auc 0.4427, ap 0.4866
2024-01-10 22:08:18,005 - GAugM EPNet train, Epoch [172/190]: loss 0.7208, auc 0.4251, ap 0.4576
2024-01-10 22:08:18,080 - GAugM EPNet train, Epoch [173/190]: loss 0.7209, auc 0.5162, ap 0.5511
2024-01-10 22:08:18,153 - GAugM EPNet train, Epoch [174/190]: loss 0.7209, auc 0.4560, ap 0.4761
2024-01-10 22:08:18,228 - GAugM EPNet train, Epoch [175/190]: loss 0.7209, auc 0.5110, ap 0.5290
2024-01-10 22:08:18,309 - GAugM EPNet train, Epoch [176/190]: loss 0.7209, auc 0.5219, ap 0.5202
2024-01-10 22:08:18,384 - GAugM EPNet train, Epoch [177/190]: loss 0.7210, auc 0.5328, ap 0.5338
2024-01-10 22:08:18,455 - GAugM EPNet train, Epoch [178/190]: loss 0.7210, auc 0.4478, ap 0.4787
2024-01-10 22:08:18,528 - GAugM EPNet train, Epoch [179/190]: loss 0.7210, auc 0.4749, ap 0.4621
2024-01-10 22:08:18,608 - GAugM EPNet train, Epoch [180/190]: loss 0.7210, auc 0.5694, ap 0.6049
2024-01-10 22:08:18,683 - GAugM EPNet train, Epoch [181/190]: loss 0.7209, auc 0.4598, ap 0.4690
2024-01-10 22:08:18,757 - GAugM EPNet train, Epoch [182/190]: loss 0.7209, auc 0.5023, ap 0.5149
2024-01-10 22:08:18,832 - GAugM EPNet train, Epoch [183/190]: loss 0.7210, auc 0.5109, ap 0.4977
2024-01-10 22:08:18,905 - GAugM EPNet train, Epoch [184/190]: loss 0.7209, auc 0.4121, ap 0.4846
2024-01-10 22:08:18,983 - GAugM EPNet train, Epoch [185/190]: loss 0.7209, auc 0.4514, ap 0.4996
2024-01-10 22:08:19,055 - GAugM EPNet train, Epoch [186/190]: loss 0.7208, auc 0.5438, ap 0.5665
2024-01-10 22:08:19,128 - GAugM EPNet train, Epoch [187/190]: loss 0.7209, auc 0.4642, ap 0.4748
2024-01-10 22:08:19,201 - GAugM EPNet train, Epoch [188/190]: loss 0.7209, auc 0.4105, ap 0.4423
2024-01-10 22:08:19,284 - GAugM EPNet train, Epoch [189/190]: loss 0.7209, auc 0.5883, ap 0.5814
2024-01-10 22:08:19,360 - GAugM EPNet train, Epoch [190/190]: loss 0.7209, auc 0.4605, ap 0.4754
2024-01-10 22:08:19,370 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d036f0a90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:08:20,045 - GAugM EPNet train, Epoch [  1/190]: loss 0.7210, auc 0.4984, ap 0.4926
2024-01-10 22:08:20,123 - GAugM EPNet train, Epoch [  2/190]: loss 0.7210, auc 0.4852, ap 0.4872
2024-01-10 22:08:20,202 - GAugM EPNet train, Epoch [  3/190]: loss 0.7209, auc 0.5728, ap 0.5612
2024-01-10 22:08:20,281 - GAugM EPNet train, Epoch [  4/190]: loss 0.7209, auc 0.4703, ap 0.5202
2024-01-10 22:08:20,367 - GAugM EPNet train, Epoch [  5/190]: loss 0.7209, auc 0.5618, ap 0.5685
2024-01-10 22:08:20,446 - GAugM EPNet train, Epoch [  6/190]: loss 0.7209, auc 0.5091, ap 0.4948
2024-01-10 22:08:20,530 - GAugM EPNet train, Epoch [  7/190]: loss 0.7209, auc 0.5126, ap 0.5029
2024-01-10 22:08:20,607 - GAugM EPNet train, Epoch [  8/190]: loss 0.7210, auc 0.4956, ap 0.5197
2024-01-10 22:08:20,683 - GAugM EPNet train, Epoch [  9/190]: loss 0.7209, auc 0.4347, ap 0.4724
2024-01-10 22:08:20,758 - GAugM EPNet train, Epoch [ 10/190]: loss 0.7208, auc 0.5297, ap 0.5126
2024-01-10 22:08:20,842 - GAugM EPNet train, Epoch [ 11/190]: loss 0.7209, auc 0.4856, ap 0.4986
2024-01-10 22:08:20,920 - GAugM EPNet train, Epoch [ 12/190]: loss 0.7210, auc 0.4888, ap 0.4924
2024-01-10 22:08:20,994 - GAugM EPNet train, Epoch [ 13/190]: loss 0.7209, auc 0.5301, ap 0.5458
2024-01-10 22:08:21,074 - GAugM EPNet train, Epoch [ 14/190]: loss 0.7209, auc 0.5180, ap 0.5118
2024-01-10 22:08:21,149 - GAugM EPNet train, Epoch [ 15/190]: loss 0.7210, auc 0.3866, ap 0.4473
2024-01-10 22:08:21,230 - GAugM EPNet train, Epoch [ 16/190]: loss 0.7209, auc 0.4386, ap 0.4706
2024-01-10 22:08:21,317 - GAugM EPNet train, Epoch [ 17/190]: loss 0.7210, auc 0.5489, ap 0.5442
2024-01-10 22:08:21,393 - GAugM EPNet train, Epoch [ 18/190]: loss 0.7210, auc 0.5942, ap 0.5951
2024-01-10 22:08:21,473 - GAugM EPNet train, Epoch [ 19/190]: loss 0.7209, auc 0.5429, ap 0.5310
2024-01-10 22:08:21,555 - GAugM EPNet train, Epoch [ 20/190]: loss 0.7210, auc 0.4354, ap 0.4692
2024-01-10 22:08:21,634 - GAugM EPNet train, Epoch [ 21/190]: loss 0.7209, auc 0.5098, ap 0.5125
2024-01-10 22:08:21,707 - GAugM EPNet train, Epoch [ 22/190]: loss 0.7210, auc 0.3510, ap 0.4154
2024-01-10 22:08:21,789 - GAugM EPNet train, Epoch [ 23/190]: loss 0.7208, auc 0.5158, ap 0.5081
2024-01-10 22:08:21,869 - GAugM EPNet train, Epoch [ 24/190]: loss 0.7209, auc 0.5294, ap 0.5073
2024-01-10 22:08:21,944 - GAugM EPNet train, Epoch [ 25/190]: loss 0.7209, auc 0.4781, ap 0.4917
2024-01-10 22:08:22,016 - GAugM EPNet train, Epoch [ 26/190]: loss 0.7210, auc 0.5239, ap 0.5223
2024-01-10 22:08:22,103 - GAugM EPNet train, Epoch [ 27/190]: loss 0.7209, auc 0.4311, ap 0.5137
2024-01-10 22:08:22,179 - GAugM EPNet train, Epoch [ 28/190]: loss 0.7209, auc 0.6323, ap 0.6163
2024-01-10 22:08:22,255 - GAugM EPNet train, Epoch [ 29/190]: loss 0.7210, auc 0.4909, ap 0.5406
2024-01-10 22:08:22,332 - GAugM EPNet train, Epoch [ 30/190]: loss 0.7209, auc 0.4920, ap 0.5386
2024-01-10 22:08:22,409 - GAugM EPNet train, Epoch [ 31/190]: loss 0.7208, auc 0.5212, ap 0.5157
2024-01-10 22:08:22,485 - GAugM EPNet train, Epoch [ 32/190]: loss 0.7210, auc 0.5999, ap 0.5644
2024-01-10 22:08:22,570 - GAugM EPNet train, Epoch [ 33/190]: loss 0.7209, auc 0.5173, ap 0.5207
2024-01-10 22:08:22,648 - GAugM EPNet train, Epoch [ 34/190]: loss 0.7209, auc 0.4386, ap 0.4649
2024-01-10 22:08:22,721 - GAugM EPNet train, Epoch [ 35/190]: loss 0.7209, auc 0.4799, ap 0.4776
2024-01-10 22:08:22,796 - GAugM EPNet train, Epoch [ 36/190]: loss 0.7209, auc 0.4870, ap 0.5089
2024-01-10 22:08:22,872 - GAugM EPNet train, Epoch [ 37/190]: loss 0.7209, auc 0.4411, ap 0.4949
2024-01-10 22:08:22,946 - GAugM EPNet train, Epoch [ 38/190]: loss 0.7209, auc 0.5201, ap 0.5089
2024-01-10 22:08:23,023 - GAugM EPNet train, Epoch [ 39/190]: loss 0.7208, auc 0.3677, ap 0.4418
2024-01-10 22:08:23,101 - GAugM EPNet train, Epoch [ 40/190]: loss 0.7210, auc 0.5048, ap 0.5036
2024-01-10 22:08:23,178 - GAugM EPNet train, Epoch [ 41/190]: loss 0.7210, auc 0.5703, ap 0.5649
2024-01-10 22:08:23,254 - GAugM EPNet train, Epoch [ 42/190]: loss 0.7209, auc 0.5094, ap 0.5459
2024-01-10 22:08:23,335 - GAugM EPNet train, Epoch [ 43/190]: loss 0.7208, auc 0.4824, ap 0.5051
2024-01-10 22:08:23,409 - GAugM EPNet train, Epoch [ 44/190]: loss 0.7208, auc 0.4155, ap 0.4474
2024-01-10 22:08:23,485 - GAugM EPNet train, Epoch [ 45/190]: loss 0.7209, auc 0.4778, ap 0.4876
2024-01-10 22:08:23,559 - GAugM EPNet train, Epoch [ 46/190]: loss 0.7209, auc 0.5052, ap 0.5153
2024-01-10 22:08:23,636 - GAugM EPNet train, Epoch [ 47/190]: loss 0.7210, auc 0.5080, ap 0.5175
2024-01-10 22:08:23,711 - GAugM EPNet train, Epoch [ 48/190]: loss 0.7210, auc 0.5664, ap 0.5785
2024-01-10 22:08:23,784 - GAugM EPNet train, Epoch [ 49/190]: loss 0.7209, auc 0.4589, ap 0.4807
2024-01-10 22:08:23,859 - GAugM EPNet train, Epoch [ 50/190]: loss 0.7210, auc 0.5354, ap 0.5226
2024-01-10 22:08:23,937 - GAugM EPNet train, Epoch [ 51/190]: loss 0.7210, auc 0.5546, ap 0.5497
2024-01-10 22:08:24,013 - GAugM EPNet train, Epoch [ 52/190]: loss 0.7209, auc 0.4258, ap 0.4577
2024-01-10 22:08:24,090 - GAugM EPNet train, Epoch [ 53/190]: loss 0.7209, auc 0.5411, ap 0.5462
2024-01-10 22:08:24,165 - GAugM EPNet train, Epoch [ 54/190]: loss 0.7211, auc 0.5611, ap 0.5576
2024-01-10 22:08:24,246 - GAugM EPNet train, Epoch [ 55/190]: loss 0.7209, auc 0.5959, ap 0.5800
2024-01-10 22:08:24,321 - GAugM EPNet train, Epoch [ 56/190]: loss 0.7208, auc 0.4845, ap 0.4964
2024-01-10 22:08:24,394 - GAugM EPNet train, Epoch [ 57/190]: loss 0.7209, auc 0.4507, ap 0.4554
2024-01-10 22:08:24,468 - GAugM EPNet train, Epoch [ 58/190]: loss 0.7210, auc 0.5482, ap 0.6067
2024-01-10 22:08:24,548 - GAugM EPNet train, Epoch [ 59/190]: loss 0.7211, auc 0.5262, ap 0.5397
2024-01-10 22:08:24,622 - GAugM EPNet train, Epoch [ 60/190]: loss 0.7210, auc 0.5212, ap 0.5444
2024-01-10 22:08:24,701 - GAugM EPNet train, Epoch [ 61/190]: loss 0.7209, auc 0.5333, ap 0.5098
2024-01-10 22:08:24,776 - GAugM EPNet train, Epoch [ 62/190]: loss 0.7210, auc 0.4916, ap 0.5329
2024-01-10 22:08:24,856 - GAugM EPNet train, Epoch [ 63/190]: loss 0.7208, auc 0.4952, ap 0.5143
2024-01-10 22:08:24,933 - GAugM EPNet train, Epoch [ 64/190]: loss 0.7208, auc 0.4226, ap 0.4670
2024-01-10 22:08:25,016 - GAugM EPNet train, Epoch [ 65/190]: loss 0.7208, auc 0.5799, ap 0.5695
2024-01-10 22:08:25,089 - GAugM EPNet train, Epoch [ 66/190]: loss 0.7209, auc 0.4300, ap 0.4752
2024-01-10 22:08:25,164 - GAugM EPNet train, Epoch [ 67/190]: loss 0.7209, auc 0.5422, ap 0.5456
2024-01-10 22:08:25,242 - GAugM EPNet train, Epoch [ 68/190]: loss 0.7210, auc 0.4810, ap 0.5073
2024-01-10 22:08:25,317 - GAugM EPNet train, Epoch [ 69/190]: loss 0.7210, auc 0.4770, ap 0.5070
2024-01-10 22:08:25,391 - GAugM EPNet train, Epoch [ 70/190]: loss 0.7210, auc 0.5187, ap 0.5093
2024-01-10 22:08:25,472 - GAugM EPNet train, Epoch [ 71/190]: loss 0.7210, auc 0.5821, ap 0.5820
2024-01-10 22:08:25,549 - GAugM EPNet train, Epoch [ 72/190]: loss 0.7210, auc 0.4877, ap 0.5079
2024-01-10 22:08:25,626 - GAugM EPNet train, Epoch [ 73/190]: loss 0.7209, auc 0.5539, ap 0.5303
2024-01-10 22:08:25,700 - GAugM EPNet train, Epoch [ 74/190]: loss 0.7209, auc 0.4543, ap 0.4807
2024-01-10 22:08:25,776 - GAugM EPNet train, Epoch [ 75/190]: loss 0.7210, auc 0.4628, ap 0.5010
2024-01-10 22:08:25,869 - GAugM EPNet train, Epoch [ 76/190]: loss 0.7209, auc 0.4087, ap 0.4500
2024-01-10 22:08:25,945 - GAugM EPNet train, Epoch [ 77/190]: loss 0.7208, auc 0.6145, ap 0.6158
2024-01-10 22:08:26,021 - GAugM EPNet train, Epoch [ 78/190]: loss 0.7209, auc 0.4037, ap 0.4407
2024-01-10 22:08:26,097 - GAugM EPNet train, Epoch [ 79/190]: loss 0.7208, auc 0.4742, ap 0.4793
2024-01-10 22:08:26,170 - GAugM EPNet train, Epoch [ 80/190]: loss 0.7209, auc 0.5568, ap 0.5359
2024-01-10 22:08:26,249 - GAugM EPNet train, Epoch [ 81/190]: loss 0.7209, auc 0.4578, ap 0.4887
2024-01-10 22:08:26,324 - GAugM EPNet train, Epoch [ 82/190]: loss 0.7210, auc 0.5956, ap 0.5804
2024-01-10 22:08:26,398 - GAugM EPNet train, Epoch [ 83/190]: loss 0.7209, auc 0.4639, ap 0.5050
2024-01-10 22:08:26,472 - GAugM EPNet train, Epoch [ 84/190]: loss 0.7209, auc 0.4397, ap 0.4443
2024-01-10 22:08:26,544 - GAugM EPNet train, Epoch [ 85/190]: loss 0.7210, auc 0.4340, ap 0.4588
2024-01-10 22:08:26,624 - GAugM EPNet train, Epoch [ 86/190]: loss 0.7208, auc 0.4642, ap 0.4844
2024-01-10 22:08:26,704 - GAugM EPNet train, Epoch [ 87/190]: loss 0.7209, auc 0.5247, ap 0.5332
2024-01-10 22:08:26,791 - GAugM EPNet train, Epoch [ 88/190]: loss 0.7210, auc 0.4432, ap 0.4685
2024-01-10 22:08:26,865 - GAugM EPNet train, Epoch [ 89/190]: loss 0.7210, auc 0.4603, ap 0.4890
2024-01-10 22:08:26,939 - GAugM EPNet train, Epoch [ 90/190]: loss 0.7209, auc 0.3831, ap 0.4424
2024-01-10 22:08:27,013 - GAugM EPNet train, Epoch [ 91/190]: loss 0.7208, auc 0.5386, ap 0.5083
2024-01-10 22:08:27,089 - GAugM EPNet train, Epoch [ 92/190]: loss 0.7209, auc 0.5789, ap 0.5644
2024-01-10 22:08:27,166 - GAugM EPNet train, Epoch [ 93/190]: loss 0.7209, auc 0.4439, ap 0.4824
2024-01-10 22:08:27,239 - GAugM EPNet train, Epoch [ 94/190]: loss 0.7210, auc 0.4767, ap 0.4987
2024-01-10 22:08:27,316 - GAugM EPNet train, Epoch [ 95/190]: loss 0.7210, auc 0.4927, ap 0.4805
2024-01-10 22:08:27,399 - GAugM EPNet train, Epoch [ 96/190]: loss 0.7209, auc 0.6095, ap 0.5914
2024-01-10 22:08:27,475 - GAugM EPNet train, Epoch [ 97/190]: loss 0.7209, auc 0.3948, ap 0.4450
2024-01-10 22:08:27,551 - GAugM EPNet train, Epoch [ 98/190]: loss 0.7209, auc 0.4414, ap 0.4554
2024-01-10 22:08:27,629 - GAugM EPNet train, Epoch [ 99/190]: loss 0.7209, auc 0.4201, ap 0.4675
2024-01-10 22:08:27,710 - GAugM EPNet train, Epoch [100/190]: loss 0.7210, auc 0.4610, ap 0.4938
2024-01-10 22:08:27,786 - GAugM EPNet train, Epoch [101/190]: loss 0.7210, auc 0.4575, ap 0.5153
2024-01-10 22:08:27,862 - GAugM EPNet train, Epoch [102/190]: loss 0.7209, auc 0.4785, ap 0.4964
2024-01-10 22:08:27,942 - GAugM EPNet train, Epoch [103/190]: loss 0.7209, auc 0.4838, ap 0.5190
2024-01-10 22:08:28,016 - GAugM EPNet train, Epoch [104/190]: loss 0.7209, auc 0.4048, ap 0.4367
2024-01-10 22:08:28,091 - GAugM EPNet train, Epoch [105/190]: loss 0.7209, auc 0.4471, ap 0.4874
2024-01-10 22:08:28,164 - GAugM EPNet train, Epoch [106/190]: loss 0.7210, auc 0.4906, ap 0.4851
2024-01-10 22:08:28,238 - GAugM EPNet train, Epoch [107/190]: loss 0.7210, auc 0.5258, ap 0.5410
2024-01-10 22:08:28,314 - GAugM EPNet train, Epoch [108/190]: loss 0.7208, auc 0.5112, ap 0.5275
2024-01-10 22:08:28,391 - GAugM EPNet train, Epoch [109/190]: loss 0.7210, auc 0.4414, ap 0.4449
2024-01-10 22:08:28,465 - GAugM EPNet train, Epoch [110/190]: loss 0.7209, auc 0.4315, ap 0.4885
2024-01-10 22:08:28,541 - GAugM EPNet train, Epoch [111/190]: loss 0.7210, auc 0.5942, ap 0.5620
2024-01-10 22:08:28,614 - GAugM EPNet train, Epoch [112/190]: loss 0.7209, auc 0.4649, ap 0.4846
2024-01-10 22:08:28,691 - GAugM EPNet train, Epoch [113/190]: loss 0.7210, auc 0.4069, ap 0.4658
2024-01-10 22:08:28,765 - GAugM EPNet train, Epoch [114/190]: loss 0.7209, auc 0.4564, ap 0.4587
2024-01-10 22:08:28,842 - GAugM EPNet train, Epoch [115/190]: loss 0.7210, auc 0.5646, ap 0.5520
2024-01-10 22:08:28,914 - GAugM EPNet train, Epoch [116/190]: loss 0.7209, auc 0.5489, ap 0.5679
2024-01-10 22:08:28,985 - GAugM EPNet train, Epoch [117/190]: loss 0.7208, auc 0.4617, ap 0.4876
2024-01-10 22:08:29,065 - GAugM EPNet train, Epoch [118/190]: loss 0.7209, auc 0.5411, ap 0.5827
2024-01-10 22:08:29,138 - GAugM EPNet train, Epoch [119/190]: loss 0.7209, auc 0.4952, ap 0.5514
2024-01-10 22:08:29,220 - GAugM EPNet train, Epoch [120/190]: loss 0.7210, auc 0.4514, ap 0.4569
2024-01-10 22:08:29,294 - GAugM EPNet train, Epoch [121/190]: loss 0.7210, auc 0.3592, ap 0.4094
2024-01-10 22:08:29,374 - GAugM EPNet train, Epoch [122/190]: loss 0.7209, auc 0.5365, ap 0.5388
2024-01-10 22:08:29,449 - GAugM EPNet train, Epoch [123/190]: loss 0.7209, auc 0.4792, ap 0.5311
2024-01-10 22:08:29,526 - GAugM EPNet train, Epoch [124/190]: loss 0.7210, auc 0.4329, ap 0.4596
2024-01-10 22:08:29,603 - GAugM EPNet train, Epoch [125/190]: loss 0.7209, auc 0.5080, ap 0.5392
2024-01-10 22:08:29,677 - GAugM EPNet train, Epoch [126/190]: loss 0.7210, auc 0.4820, ap 0.5107
2024-01-10 22:08:29,750 - GAugM EPNet train, Epoch [127/190]: loss 0.7209, auc 0.5404, ap 0.5380
2024-01-10 22:08:29,836 - GAugM EPNet train, Epoch [128/190]: loss 0.7210, auc 0.4973, ap 0.4960
2024-01-10 22:08:29,914 - GAugM EPNet train, Epoch [129/190]: loss 0.7208, auc 0.4009, ap 0.4553
2024-01-10 22:08:29,989 - GAugM EPNet train, Epoch [130/190]: loss 0.7210, auc 0.4863, ap 0.5034
2024-01-10 22:08:30,067 - GAugM EPNet train, Epoch [131/190]: loss 0.7210, auc 0.5212, ap 0.5769
2024-01-10 22:08:30,144 - GAugM EPNet train, Epoch [132/190]: loss 0.7209, auc 0.4770, ap 0.5002
2024-01-10 22:08:30,217 - GAugM EPNet train, Epoch [133/190]: loss 0.7209, auc 0.4632, ap 0.5259
2024-01-10 22:08:30,300 - GAugM EPNet train, Epoch [134/190]: loss 0.7210, auc 0.5333, ap 0.5180
2024-01-10 22:08:30,376 - GAugM EPNet train, Epoch [135/190]: loss 0.7209, auc 0.4258, ap 0.4672
2024-01-10 22:08:30,451 - GAugM EPNet train, Epoch [136/190]: loss 0.7209, auc 0.4617, ap 0.4764
2024-01-10 22:08:30,530 - GAugM EPNet train, Epoch [137/190]: loss 0.7210, auc 0.3635, ap 0.4107
2024-01-10 22:08:30,603 - GAugM EPNet train, Epoch [138/190]: loss 0.7210, auc 0.5796, ap 0.5925
2024-01-10 22:08:30,676 - GAugM EPNet train, Epoch [139/190]: loss 0.7210, auc 0.4717, ap 0.4858
2024-01-10 22:08:30,751 - GAugM EPNet train, Epoch [140/190]: loss 0.7209, auc 0.4496, ap 0.4808
2024-01-10 22:08:30,829 - GAugM EPNet train, Epoch [141/190]: loss 0.7209, auc 0.5109, ap 0.5290
2024-01-10 22:08:30,910 - GAugM EPNet train, Epoch [142/190]: loss 0.7209, auc 0.4849, ap 0.5084
2024-01-10 22:08:30,986 - GAugM EPNet train, Epoch [143/190]: loss 0.7209, auc 0.4400, ap 0.4608
2024-01-10 22:08:31,066 - GAugM EPNet train, Epoch [144/190]: loss 0.7209, auc 0.4290, ap 0.4584
2024-01-10 22:08:31,140 - GAugM EPNet train, Epoch [145/190]: loss 0.7209, auc 0.4247, ap 0.5012
2024-01-10 22:08:31,213 - GAugM EPNet train, Epoch [146/190]: loss 0.7209, auc 0.5190, ap 0.5356
2024-01-10 22:08:31,296 - GAugM EPNet train, Epoch [147/190]: loss 0.7209, auc 0.5942, ap 0.6192
2024-01-10 22:08:31,373 - GAugM EPNet train, Epoch [148/190]: loss 0.7209, auc 0.3959, ap 0.4290
2024-01-10 22:08:31,446 - GAugM EPNet train, Epoch [149/190]: loss 0.7208, auc 0.5813, ap 0.5958
2024-01-10 22:08:31,519 - GAugM EPNet train, Epoch [150/190]: loss 0.7209, auc 0.5037, ap 0.5162
2024-01-10 22:08:31,598 - GAugM EPNet train, Epoch [151/190]: loss 0.7209, auc 0.5297, ap 0.5169
2024-01-10 22:08:31,670 - GAugM EPNet train, Epoch [152/190]: loss 0.7209, auc 0.5578, ap 0.5728
2024-01-10 22:08:31,753 - GAugM EPNet train, Epoch [153/190]: loss 0.7209, auc 0.4646, ap 0.4951
2024-01-10 22:08:31,828 - GAugM EPNet train, Epoch [154/190]: loss 0.7209, auc 0.5967, ap 0.6140
2024-01-10 22:08:31,913 - GAugM EPNet train, Epoch [155/190]: loss 0.7209, auc 0.4920, ap 0.5117
2024-01-10 22:08:31,988 - GAugM EPNet train, Epoch [156/190]: loss 0.7209, auc 0.4208, ap 0.4461
2024-01-10 22:08:32,069 - GAugM EPNet train, Epoch [157/190]: loss 0.7209, auc 0.4315, ap 0.4548
2024-01-10 22:08:32,145 - GAugM EPNet train, Epoch [158/190]: loss 0.7208, auc 0.3813, ap 0.4330
2024-01-10 22:08:32,224 - GAugM EPNet train, Epoch [159/190]: loss 0.7208, auc 0.4692, ap 0.4736
2024-01-10 22:08:32,301 - GAugM EPNet train, Epoch [160/190]: loss 0.7209, auc 0.5557, ap 0.5717
2024-01-10 22:08:32,373 - GAugM EPNet train, Epoch [161/190]: loss 0.7209, auc 0.4788, ap 0.4946
2024-01-10 22:08:32,455 - GAugM EPNet train, Epoch [162/190]: loss 0.7209, auc 0.4322, ap 0.4477
2024-01-10 22:08:32,528 - GAugM EPNet train, Epoch [163/190]: loss 0.7209, auc 0.4845, ap 0.4872
2024-01-10 22:08:32,607 - GAugM EPNet train, Epoch [164/190]: loss 0.7211, auc 0.5977, ap 0.5629
2024-01-10 22:08:32,681 - GAugM EPNet train, Epoch [165/190]: loss 0.7210, auc 0.5425, ap 0.5353
2024-01-10 22:08:32,755 - GAugM EPNet train, Epoch [166/190]: loss 0.7208, auc 0.5027, ap 0.5222
2024-01-10 22:08:32,830 - GAugM EPNet train, Epoch [167/190]: loss 0.7209, auc 0.4749, ap 0.4852
2024-01-10 22:08:32,907 - GAugM EPNet train, Epoch [168/190]: loss 0.7209, auc 0.5073, ap 0.5501
2024-01-10 22:08:32,984 - GAugM EPNet train, Epoch [169/190]: loss 0.7209, auc 0.5126, ap 0.5563
2024-01-10 22:08:33,063 - GAugM EPNet train, Epoch [170/190]: loss 0.7210, auc 0.4963, ap 0.4774
2024-01-10 22:08:33,142 - GAugM EPNet train, Epoch [171/190]: loss 0.7209, auc 0.4653, ap 0.4920
2024-01-10 22:08:33,217 - GAugM EPNet train, Epoch [172/190]: loss 0.7208, auc 0.4315, ap 0.4432
2024-01-10 22:08:33,291 - GAugM EPNet train, Epoch [173/190]: loss 0.7209, auc 0.5764, ap 0.5823
2024-01-10 22:08:33,366 - GAugM EPNet train, Epoch [174/190]: loss 0.7209, auc 0.4158, ap 0.4329
2024-01-10 22:08:33,441 - GAugM EPNet train, Epoch [175/190]: loss 0.7209, auc 0.6241, ap 0.6258
2024-01-10 22:08:33,523 - GAugM EPNet train, Epoch [176/190]: loss 0.7209, auc 0.5130, ap 0.5316
2024-01-10 22:08:33,595 - GAugM EPNet train, Epoch [177/190]: loss 0.7210, auc 0.4817, ap 0.4883
2024-01-10 22:08:33,671 - GAugM EPNet train, Epoch [178/190]: loss 0.7210, auc 0.5351, ap 0.5520
2024-01-10 22:08:33,744 - GAugM EPNet train, Epoch [179/190]: loss 0.7210, auc 0.3838, ap 0.4480
2024-01-10 22:08:33,827 - GAugM EPNet train, Epoch [180/190]: loss 0.7210, auc 0.5497, ap 0.5798
2024-01-10 22:08:33,902 - GAugM EPNet train, Epoch [181/190]: loss 0.7209, auc 0.4044, ap 0.4648
2024-01-10 22:08:33,978 - GAugM EPNet train, Epoch [182/190]: loss 0.7209, auc 0.4204, ap 0.5252
2024-01-10 22:08:34,052 - GAugM EPNet train, Epoch [183/190]: loss 0.7210, auc 0.6041, ap 0.5895
2024-01-10 22:08:34,129 - GAugM EPNet train, Epoch [184/190]: loss 0.7209, auc 0.5333, ap 0.5575
2024-01-10 22:08:34,203 - GAugM EPNet train, Epoch [185/190]: loss 0.7209, auc 0.4112, ap 0.4786
2024-01-10 22:08:34,279 - GAugM EPNet train, Epoch [186/190]: loss 0.7208, auc 0.4795, ap 0.5196
2024-01-10 22:08:34,353 - GAugM EPNet train, Epoch [187/190]: loss 0.7209, auc 0.5329, ap 0.5467
2024-01-10 22:08:34,439 - GAugM EPNet train, Epoch [188/190]: loss 0.7209, auc 0.5052, ap 0.4985
2024-01-10 22:08:34,520 - GAugM EPNet train, Epoch [189/190]: loss 0.7209, auc 0.5290, ap 0.5657
2024-01-10 22:08:34,594 - GAugM EPNet train, Epoch [190/190]: loss 0.7209, auc 0.4678, ap 0.4811
2024-01-10 22:08:34,605 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035cb850>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:08:35,265 - GAugM EPNet train, Epoch [  1/190]: loss 0.7210, auc 0.4413, ap 0.4453
2024-01-10 22:08:35,343 - GAugM EPNet train, Epoch [  2/190]: loss 0.7210, auc 0.5315, ap 0.5186
2024-01-10 22:08:35,424 - GAugM EPNet train, Epoch [  3/190]: loss 0.7209, auc 0.5650, ap 0.5592
2024-01-10 22:08:35,502 - GAugM EPNet train, Epoch [  4/190]: loss 0.7209, auc 0.5228, ap 0.5314
2024-01-10 22:08:35,581 - GAugM EPNet train, Epoch [  5/190]: loss 0.7209, auc 0.5365, ap 0.5359
2024-01-10 22:08:35,666 - GAugM EPNet train, Epoch [  6/190]: loss 0.7209, auc 0.5012, ap 0.5000
2024-01-10 22:08:35,743 - GAugM EPNet train, Epoch [  7/190]: loss 0.7209, auc 0.4587, ap 0.4633
2024-01-10 22:08:35,821 - GAugM EPNet train, Epoch [  8/190]: loss 0.7210, auc 0.4548, ap 0.4847
2024-01-10 22:08:35,914 - GAugM EPNet train, Epoch [  9/190]: loss 0.7209, auc 0.4834, ap 0.4821
2024-01-10 22:08:35,994 - GAugM EPNet train, Epoch [ 10/190]: loss 0.7208, auc 0.4448, ap 0.4574
2024-01-10 22:08:36,073 - GAugM EPNet train, Epoch [ 11/190]: loss 0.7209, auc 0.5091, ap 0.5155
2024-01-10 22:08:36,148 - GAugM EPNet train, Epoch [ 12/190]: loss 0.7210, auc 0.4662, ap 0.4681
2024-01-10 22:08:36,228 - GAugM EPNet train, Epoch [ 13/190]: loss 0.7209, auc 0.6248, ap 0.6057
2024-01-10 22:08:36,310 - GAugM EPNet train, Epoch [ 14/190]: loss 0.7209, auc 0.4972, ap 0.4975
2024-01-10 22:08:36,386 - GAugM EPNet train, Epoch [ 15/190]: loss 0.7210, auc 0.3661, ap 0.4237
2024-01-10 22:08:36,462 - GAugM EPNet train, Epoch [ 16/190]: loss 0.7209, auc 0.5059, ap 0.4999
2024-01-10 22:08:36,545 - GAugM EPNet train, Epoch [ 17/190]: loss 0.7210, auc 0.5242, ap 0.5118
2024-01-10 22:08:36,631 - GAugM EPNet train, Epoch [ 18/190]: loss 0.7210, auc 0.5258, ap 0.5302
2024-01-10 22:08:36,715 - GAugM EPNet train, Epoch [ 19/190]: loss 0.7209, auc 0.5272, ap 0.5010
2024-01-10 22:08:36,796 - GAugM EPNet train, Epoch [ 20/190]: loss 0.7210, auc 0.4340, ap 0.4546
2024-01-10 22:08:36,877 - GAugM EPNet train, Epoch [ 21/190]: loss 0.7209, auc 0.5025, ap 0.5116
2024-01-10 22:08:36,953 - GAugM EPNet train, Epoch [ 22/190]: loss 0.7210, auc 0.3398, ap 0.4037
2024-01-10 22:08:37,034 - GAugM EPNet train, Epoch [ 23/190]: loss 0.7208, auc 0.4724, ap 0.4781
2024-01-10 22:08:37,112 - GAugM EPNet train, Epoch [ 24/190]: loss 0.7209, auc 0.5559, ap 0.5536
2024-01-10 22:08:37,189 - GAugM EPNet train, Epoch [ 25/190]: loss 0.7209, auc 0.4915, ap 0.4957
2024-01-10 22:08:37,263 - GAugM EPNet train, Epoch [ 26/190]: loss 0.7210, auc 0.5591, ap 0.5822
2024-01-10 22:08:37,337 - GAugM EPNet train, Epoch [ 27/190]: loss 0.7209, auc 0.4268, ap 0.4881
2024-01-10 22:08:37,410 - GAugM EPNet train, Epoch [ 28/190]: loss 0.7209, auc 0.5865, ap 0.5810
2024-01-10 22:08:37,492 - GAugM EPNet train, Epoch [ 29/190]: loss 0.7210, auc 0.5203, ap 0.5105
2024-01-10 22:08:37,578 - GAugM EPNet train, Epoch [ 30/190]: loss 0.7209, auc 0.5506, ap 0.5128
2024-01-10 22:08:37,653 - GAugM EPNet train, Epoch [ 31/190]: loss 0.7208, auc 0.4409, ap 0.4728
2024-01-10 22:08:37,728 - GAugM EPNet train, Epoch [ 32/190]: loss 0.7210, auc 0.6088, ap 0.5730
2024-01-10 22:08:37,804 - GAugM EPNet train, Epoch [ 33/190]: loss 0.7209, auc 0.4877, ap 0.5091
2024-01-10 22:08:37,878 - GAugM EPNet train, Epoch [ 34/190]: loss 0.7209, auc 0.4569, ap 0.4890
2024-01-10 22:08:37,958 - GAugM EPNet train, Epoch [ 35/190]: loss 0.7209, auc 0.4925, ap 0.4816
2024-01-10 22:08:38,032 - GAugM EPNet train, Epoch [ 36/190]: loss 0.7209, auc 0.5760, ap 0.5544
2024-01-10 22:08:38,117 - GAugM EPNet train, Epoch [ 37/190]: loss 0.7209, auc 0.4986, ap 0.5330
2024-01-10 22:08:38,192 - GAugM EPNet train, Epoch [ 38/190]: loss 0.7209, auc 0.4915, ap 0.4767
2024-01-10 22:08:38,270 - GAugM EPNet train, Epoch [ 39/190]: loss 0.7208, auc 0.4674, ap 0.5032
2024-01-10 22:08:38,362 - GAugM EPNet train, Epoch [ 40/190]: loss 0.7210, auc 0.5242, ap 0.5047
2024-01-10 22:08:38,438 - GAugM EPNet train, Epoch [ 41/190]: loss 0.7210, auc 0.4993, ap 0.5014
2024-01-10 22:08:38,510 - GAugM EPNet train, Epoch [ 42/190]: loss 0.7209, auc 0.4685, ap 0.5000
2024-01-10 22:08:38,589 - GAugM EPNet train, Epoch [ 43/190]: loss 0.7208, auc 0.4655, ap 0.4959
2024-01-10 22:08:38,664 - GAugM EPNet train, Epoch [ 44/190]: loss 0.7208, auc 0.3907, ap 0.4376
2024-01-10 22:08:38,738 - GAugM EPNet train, Epoch [ 45/190]: loss 0.7209, auc 0.5433, ap 0.5477
2024-01-10 22:08:38,818 - GAugM EPNet train, Epoch [ 46/190]: loss 0.7209, auc 0.5028, ap 0.5015
2024-01-10 22:08:38,891 - GAugM EPNet train, Epoch [ 47/190]: loss 0.7210, auc 0.5237, ap 0.4988
2024-01-10 22:08:38,965 - GAugM EPNet train, Epoch [ 48/190]: loss 0.7210, auc 0.6011, ap 0.5994
2024-01-10 22:08:39,040 - GAugM EPNet train, Epoch [ 49/190]: loss 0.7209, auc 0.4658, ap 0.4709
2024-01-10 22:08:39,115 - GAugM EPNet train, Epoch [ 50/190]: loss 0.7210, auc 0.5767, ap 0.5620
2024-01-10 22:08:39,189 - GAugM EPNet train, Epoch [ 51/190]: loss 0.7210, auc 0.5441, ap 0.5510
2024-01-10 22:08:39,278 - GAugM EPNet train, Epoch [ 52/190]: loss 0.7209, auc 0.4187, ap 0.4361
2024-01-10 22:08:39,354 - GAugM EPNet train, Epoch [ 53/190]: loss 0.7209, auc 0.5219, ap 0.5195
2024-01-10 22:08:39,428 - GAugM EPNet train, Epoch [ 54/190]: loss 0.7211, auc 0.5196, ap 0.5210
2024-01-10 22:08:39,502 - GAugM EPNet train, Epoch [ 55/190]: loss 0.7209, auc 0.6460, ap 0.6343
2024-01-10 22:08:39,581 - GAugM EPNet train, Epoch [ 56/190]: loss 0.7208, auc 0.4884, ap 0.4832
2024-01-10 22:08:39,656 - GAugM EPNet train, Epoch [ 57/190]: loss 0.7209, auc 0.5066, ap 0.4998
2024-01-10 22:08:39,730 - GAugM EPNet train, Epoch [ 58/190]: loss 0.7210, auc 0.4781, ap 0.5196
2024-01-10 22:08:39,809 - GAugM EPNet train, Epoch [ 59/190]: loss 0.7211, auc 0.4872, ap 0.4863
2024-01-10 22:08:39,885 - GAugM EPNet train, Epoch [ 60/190]: loss 0.7210, auc 0.5023, ap 0.5147
2024-01-10 22:08:39,965 - GAugM EPNet train, Epoch [ 61/190]: loss 0.7209, auc 0.5457, ap 0.5415
2024-01-10 22:08:40,044 - GAugM EPNet train, Epoch [ 62/190]: loss 0.7210, auc 0.5678, ap 0.5684
2024-01-10 22:08:40,119 - GAugM EPNet train, Epoch [ 63/190]: loss 0.7208, auc 0.4877, ap 0.4943
2024-01-10 22:08:40,199 - GAugM EPNet train, Epoch [ 64/190]: loss 0.7208, auc 0.4258, ap 0.4538
2024-01-10 22:08:40,275 - GAugM EPNet train, Epoch [ 65/190]: loss 0.7208, auc 0.6394, ap 0.6326
2024-01-10 22:08:40,363 - GAugM EPNet train, Epoch [ 66/190]: loss 0.7209, auc 0.4811, ap 0.5289
2024-01-10 22:08:40,439 - GAugM EPNet train, Epoch [ 67/190]: loss 0.7209, auc 0.5306, ap 0.5285
2024-01-10 22:08:40,513 - GAugM EPNet train, Epoch [ 68/190]: loss 0.7210, auc 0.4653, ap 0.4902
2024-01-10 22:08:40,585 - GAugM EPNet train, Epoch [ 69/190]: loss 0.7210, auc 0.5684, ap 0.5695
2024-01-10 22:08:40,673 - GAugM EPNet train, Epoch [ 70/190]: loss 0.7210, auc 0.5128, ap 0.4933
2024-01-10 22:08:40,747 - GAugM EPNet train, Epoch [ 71/190]: loss 0.7210, auc 0.5523, ap 0.5206
2024-01-10 22:08:40,823 - GAugM EPNet train, Epoch [ 72/190]: loss 0.7210, auc 0.4735, ap 0.5040
2024-01-10 22:08:40,909 - GAugM EPNet train, Epoch [ 73/190]: loss 0.7209, auc 0.5377, ap 0.5097
2024-01-10 22:08:40,984 - GAugM EPNet train, Epoch [ 74/190]: loss 0.7209, auc 0.4525, ap 0.4788
2024-01-10 22:08:41,059 - GAugM EPNet train, Epoch [ 75/190]: loss 0.7210, auc 0.4147, ap 0.4557
2024-01-10 22:08:41,134 - GAugM EPNet train, Epoch [ 76/190]: loss 0.7209, auc 0.4210, ap 0.4419
2024-01-10 22:08:41,209 - GAugM EPNet train, Epoch [ 77/190]: loss 0.7208, auc 0.5497, ap 0.5543
2024-01-10 22:08:41,289 - GAugM EPNet train, Epoch [ 78/190]: loss 0.7209, auc 0.4840, ap 0.4829
2024-01-10 22:08:41,369 - GAugM EPNet train, Epoch [ 79/190]: loss 0.7208, auc 0.4119, ap 0.4327
2024-01-10 22:08:41,449 - GAugM EPNet train, Epoch [ 80/190]: loss 0.7209, auc 0.5571, ap 0.5592
2024-01-10 22:08:41,527 - GAugM EPNet train, Epoch [ 81/190]: loss 0.7209, auc 0.4765, ap 0.4815
2024-01-10 22:08:41,609 - GAugM EPNet train, Epoch [ 82/190]: loss 0.7210, auc 0.5392, ap 0.5225
2024-01-10 22:08:41,687 - GAugM EPNet train, Epoch [ 83/190]: loss 0.7209, auc 0.4377, ap 0.4682
2024-01-10 22:08:41,767 - GAugM EPNet train, Epoch [ 84/190]: loss 0.7209, auc 0.3661, ap 0.4427
2024-01-10 22:08:41,841 - GAugM EPNet train, Epoch [ 85/190]: loss 0.7210, auc 0.4735, ap 0.4791
2024-01-10 22:08:41,916 - GAugM EPNet train, Epoch [ 86/190]: loss 0.7208, auc 0.5048, ap 0.4929
2024-01-10 22:08:41,994 - GAugM EPNet train, Epoch [ 87/190]: loss 0.7209, auc 0.5285, ap 0.5261
2024-01-10 22:08:42,071 - GAugM EPNet train, Epoch [ 88/190]: loss 0.7210, auc 0.4703, ap 0.5317
2024-01-10 22:08:42,162 - GAugM EPNet train, Epoch [ 89/190]: loss 0.7210, auc 0.4349, ap 0.4744
2024-01-10 22:08:42,240 - GAugM EPNet train, Epoch [ 90/190]: loss 0.7209, auc 0.4231, ap 0.4523
2024-01-10 22:08:42,316 - GAugM EPNet train, Epoch [ 91/190]: loss 0.7208, auc 0.5014, ap 0.4765
2024-01-10 22:08:42,389 - GAugM EPNet train, Epoch [ 92/190]: loss 0.7209, auc 0.5856, ap 0.5792
2024-01-10 22:08:42,470 - GAugM EPNet train, Epoch [ 93/190]: loss 0.7209, auc 0.4416, ap 0.5029
2024-01-10 22:08:42,545 - GAugM EPNet train, Epoch [ 94/190]: loss 0.7210, auc 0.4493, ap 0.4900
2024-01-10 22:08:42,626 - GAugM EPNet train, Epoch [ 95/190]: loss 0.7210, auc 0.5292, ap 0.5251
2024-01-10 22:08:42,701 - GAugM EPNet train, Epoch [ 96/190]: loss 0.7209, auc 0.5267, ap 0.5128
2024-01-10 22:08:42,777 - GAugM EPNet train, Epoch [ 97/190]: loss 0.7209, auc 0.4473, ap 0.4973
2024-01-10 22:08:42,867 - GAugM EPNet train, Epoch [ 98/190]: loss 0.7209, auc 0.4754, ap 0.4960
2024-01-10 22:08:42,944 - GAugM EPNet train, Epoch [ 99/190]: loss 0.7209, auc 0.5748, ap 0.5773
2024-01-10 22:08:43,018 - GAugM EPNet train, Epoch [100/190]: loss 0.7210, auc 0.5009, ap 0.4965
2024-01-10 22:08:43,093 - GAugM EPNet train, Epoch [101/190]: loss 0.7210, auc 0.5142, ap 0.5745
2024-01-10 22:08:43,167 - GAugM EPNet train, Epoch [102/190]: loss 0.7209, auc 0.4398, ap 0.4505
2024-01-10 22:08:43,248 - GAugM EPNet train, Epoch [103/190]: loss 0.7209, auc 0.5146, ap 0.5326
2024-01-10 22:08:43,321 - GAugM EPNet train, Epoch [104/190]: loss 0.7209, auc 0.5360, ap 0.5508
2024-01-10 22:08:43,395 - GAugM EPNet train, Epoch [105/190]: loss 0.7209, auc 0.4931, ap 0.4852
2024-01-10 22:08:43,471 - GAugM EPNet train, Epoch [106/190]: loss 0.7210, auc 0.5123, ap 0.4953
2024-01-10 22:08:43,544 - GAugM EPNet train, Epoch [107/190]: loss 0.7210, auc 0.4491, ap 0.4913
2024-01-10 22:08:43,627 - GAugM EPNet train, Epoch [108/190]: loss 0.7208, auc 0.5376, ap 0.5265
2024-01-10 22:08:43,706 - GAugM EPNet train, Epoch [109/190]: loss 0.7210, auc 0.4443, ap 0.4658
2024-01-10 22:08:43,783 - GAugM EPNet train, Epoch [110/190]: loss 0.7209, auc 0.4534, ap 0.4812
2024-01-10 22:08:43,864 - GAugM EPNet train, Epoch [111/190]: loss 0.7210, auc 0.5409, ap 0.5665
2024-01-10 22:08:43,945 - GAugM EPNet train, Epoch [112/190]: loss 0.7209, auc 0.5025, ap 0.5241
2024-01-10 22:08:44,022 - GAugM EPNet train, Epoch [113/190]: loss 0.7210, auc 0.4785, ap 0.4999
2024-01-10 22:08:44,096 - GAugM EPNet train, Epoch [114/190]: loss 0.7209, auc 0.4870, ap 0.4966
2024-01-10 22:08:44,176 - GAugM EPNet train, Epoch [115/190]: loss 0.7210, auc 0.4592, ap 0.4753
2024-01-10 22:08:44,249 - GAugM EPNet train, Epoch [116/190]: loss 0.7209, auc 0.5555, ap 0.5505
2024-01-10 22:08:44,323 - GAugM EPNet train, Epoch [117/190]: loss 0.7208, auc 0.4676, ap 0.4808
2024-01-10 22:08:44,396 - GAugM EPNet train, Epoch [118/190]: loss 0.7209, auc 0.5020, ap 0.5280
2024-01-10 22:08:44,469 - GAugM EPNet train, Epoch [119/190]: loss 0.7209, auc 0.5247, ap 0.5549
2024-01-10 22:08:44,543 - GAugM EPNet train, Epoch [120/190]: loss 0.7210, auc 0.4690, ap 0.4718
2024-01-10 22:08:44,618 - GAugM EPNet train, Epoch [121/190]: loss 0.7210, auc 0.4222, ap 0.4504
2024-01-10 22:08:44,693 - GAugM EPNet train, Epoch [122/190]: loss 0.7209, auc 0.5087, ap 0.5301
2024-01-10 22:08:44,782 - GAugM EPNet train, Epoch [123/190]: loss 0.7209, auc 0.5961, ap 0.5692
2024-01-10 22:08:44,856 - GAugM EPNet train, Epoch [124/190]: loss 0.7210, auc 0.5059, ap 0.5229
2024-01-10 22:08:44,932 - GAugM EPNet train, Epoch [125/190]: loss 0.7209, auc 0.4534, ap 0.4798
2024-01-10 22:08:45,006 - GAugM EPNet train, Epoch [126/190]: loss 0.7210, auc 0.4690, ap 0.4701
2024-01-10 22:08:45,081 - GAugM EPNet train, Epoch [127/190]: loss 0.7209, auc 0.4470, ap 0.4705
2024-01-10 22:08:45,160 - GAugM EPNet train, Epoch [128/190]: loss 0.7210, auc 0.5445, ap 0.5332
2024-01-10 22:08:45,244 - GAugM EPNet train, Epoch [129/190]: loss 0.7208, auc 0.3921, ap 0.4481
2024-01-10 22:08:45,318 - GAugM EPNet train, Epoch [130/190]: loss 0.7210, auc 0.4496, ap 0.4660
2024-01-10 22:08:45,392 - GAugM EPNet train, Epoch [131/190]: loss 0.7210, auc 0.5061, ap 0.5120
2024-01-10 22:08:45,465 - GAugM EPNet train, Epoch [132/190]: loss 0.7209, auc 0.4676, ap 0.4855
2024-01-10 22:08:45,539 - GAugM EPNet train, Epoch [133/190]: loss 0.7209, auc 0.4272, ap 0.4610
2024-01-10 22:08:45,624 - GAugM EPNet train, Epoch [134/190]: loss 0.7210, auc 0.5064, ap 0.5245
2024-01-10 22:08:45,704 - GAugM EPNet train, Epoch [135/190]: loss 0.7209, auc 0.4434, ap 0.4832
2024-01-10 22:08:45,778 - GAugM EPNet train, Epoch [136/190]: loss 0.7209, auc 0.4616, ap 0.4687
2024-01-10 22:08:45,855 - GAugM EPNet train, Epoch [137/190]: loss 0.7210, auc 0.4872, ap 0.4890
2024-01-10 22:08:45,930 - GAugM EPNet train, Epoch [138/190]: loss 0.7210, auc 0.5651, ap 0.5498
2024-01-10 22:08:46,005 - GAugM EPNet train, Epoch [139/190]: loss 0.7210, auc 0.4284, ap 0.4594
2024-01-10 22:08:46,084 - GAugM EPNet train, Epoch [140/190]: loss 0.7209, auc 0.5230, ap 0.5301
2024-01-10 22:08:46,159 - GAugM EPNet train, Epoch [141/190]: loss 0.7209, auc 0.4988, ap 0.5136
2024-01-10 22:08:46,239 - GAugM EPNet train, Epoch [142/190]: loss 0.7209, auc 0.5854, ap 0.6057
2024-01-10 22:08:46,324 - GAugM EPNet train, Epoch [143/190]: loss 0.7209, auc 0.4391, ap 0.4726
2024-01-10 22:08:46,400 - GAugM EPNet train, Epoch [144/190]: loss 0.7209, auc 0.4058, ap 0.4290
2024-01-10 22:08:46,475 - GAugM EPNet train, Epoch [145/190]: loss 0.7209, auc 0.4811, ap 0.5242
2024-01-10 22:08:46,551 - GAugM EPNet train, Epoch [146/190]: loss 0.7209, auc 0.4409, ap 0.4667
2024-01-10 22:08:46,627 - GAugM EPNet train, Epoch [147/190]: loss 0.7209, auc 0.5470, ap 0.5763
2024-01-10 22:08:46,706 - GAugM EPNet train, Epoch [148/190]: loss 0.7209, auc 0.4980, ap 0.5123
2024-01-10 22:08:46,785 - GAugM EPNet train, Epoch [149/190]: loss 0.7208, auc 0.4952, ap 0.4995
2024-01-10 22:08:46,860 - GAugM EPNet train, Epoch [150/190]: loss 0.7209, auc 0.5078, ap 0.5013
2024-01-10 22:08:46,935 - GAugM EPNet train, Epoch [151/190]: loss 0.7209, auc 0.5607, ap 0.5348
2024-01-10 22:08:47,012 - GAugM EPNet train, Epoch [152/190]: loss 0.7209, auc 0.5673, ap 0.5703
2024-01-10 22:08:47,093 - GAugM EPNet train, Epoch [153/190]: loss 0.7209, auc 0.3766, ap 0.4189
2024-01-10 22:08:47,171 - GAugM EPNet train, Epoch [154/190]: loss 0.7209, auc 0.5465, ap 0.5603
2024-01-10 22:08:47,244 - GAugM EPNet train, Epoch [155/190]: loss 0.7209, auc 0.5217, ap 0.5397
2024-01-10 22:08:47,322 - GAugM EPNet train, Epoch [156/190]: loss 0.7209, auc 0.4094, ap 0.4635
2024-01-10 22:08:47,397 - GAugM EPNet train, Epoch [157/190]: loss 0.7209, auc 0.4715, ap 0.5040
2024-01-10 22:08:47,471 - GAugM EPNet train, Epoch [158/190]: loss 0.7208, auc 0.4300, ap 0.4612
2024-01-10 22:08:47,546 - GAugM EPNet train, Epoch [159/190]: loss 0.7208, auc 0.4915, ap 0.4839
2024-01-10 22:08:47,621 - GAugM EPNet train, Epoch [160/190]: loss 0.7209, auc 0.4968, ap 0.5087
2024-01-10 22:08:47,696 - GAugM EPNet train, Epoch [161/190]: loss 0.7209, auc 0.5457, ap 0.5244
2024-01-10 22:08:47,784 - GAugM EPNet train, Epoch [162/190]: loss 0.7209, auc 0.4633, ap 0.4740
2024-01-10 22:08:47,862 - GAugM EPNet train, Epoch [163/190]: loss 0.7209, auc 0.5347, ap 0.5109
2024-01-10 22:08:47,937 - GAugM EPNet train, Epoch [164/190]: loss 0.7211, auc 0.5562, ap 0.5356
2024-01-10 22:08:48,014 - GAugM EPNet train, Epoch [165/190]: loss 0.7210, auc 0.4393, ap 0.4731
2024-01-10 22:08:48,089 - GAugM EPNet train, Epoch [166/190]: loss 0.7208, auc 0.4810, ap 0.4727
2024-01-10 22:08:48,173 - GAugM EPNet train, Epoch [167/190]: loss 0.7209, auc 0.4751, ap 0.4852
2024-01-10 22:08:48,248 - GAugM EPNet train, Epoch [168/190]: loss 0.7209, auc 0.4802, ap 0.5215
2024-01-10 22:08:48,324 - GAugM EPNet train, Epoch [169/190]: loss 0.7209, auc 0.5135, ap 0.5003
2024-01-10 22:08:48,398 - GAugM EPNet train, Epoch [170/190]: loss 0.7210, auc 0.4672, ap 0.4682
2024-01-10 22:08:48,473 - GAugM EPNet train, Epoch [171/190]: loss 0.7209, auc 0.4528, ap 0.4980
2024-01-10 22:08:48,554 - GAugM EPNet train, Epoch [172/190]: loss 0.7208, auc 0.4708, ap 0.4770
2024-01-10 22:08:48,627 - GAugM EPNet train, Epoch [173/190]: loss 0.7209, auc 0.5021, ap 0.5414
2024-01-10 22:08:48,702 - GAugM EPNet train, Epoch [174/190]: loss 0.7209, auc 0.4534, ap 0.4830
2024-01-10 22:08:48,779 - GAugM EPNet train, Epoch [175/190]: loss 0.7209, auc 0.5096, ap 0.5129
2024-01-10 22:08:48,854 - GAugM EPNet train, Epoch [176/190]: loss 0.7209, auc 0.4827, ap 0.4865
2024-01-10 22:08:48,928 - GAugM EPNet train, Epoch [177/190]: loss 0.7210, auc 0.5187, ap 0.4984
2024-01-10 22:08:49,010 - GAugM EPNet train, Epoch [178/190]: loss 0.7210, auc 0.5514, ap 0.5757
2024-01-10 22:08:49,089 - GAugM EPNet train, Epoch [179/190]: loss 0.7210, auc 0.4580, ap 0.5094
2024-01-10 22:08:49,164 - GAugM EPNet train, Epoch [180/190]: loss 0.7210, auc 0.5708, ap 0.5839
2024-01-10 22:08:49,238 - GAugM EPNet train, Epoch [181/190]: loss 0.7209, auc 0.4416, ap 0.4543
2024-01-10 22:08:49,320 - GAugM EPNet train, Epoch [182/190]: loss 0.7209, auc 0.4665, ap 0.5175
2024-01-10 22:08:49,394 - GAugM EPNet train, Epoch [183/190]: loss 0.7210, auc 0.5376, ap 0.5179
2024-01-10 22:08:49,467 - GAugM EPNet train, Epoch [184/190]: loss 0.7209, auc 0.4591, ap 0.4764
2024-01-10 22:08:49,548 - GAugM EPNet train, Epoch [185/190]: loss 0.7209, auc 0.4737, ap 0.5124
2024-01-10 22:08:49,622 - GAugM EPNet train, Epoch [186/190]: loss 0.7208, auc 0.4446, ap 0.4940
2024-01-10 22:08:49,696 - GAugM EPNet train, Epoch [187/190]: loss 0.7209, auc 0.4742, ap 0.4730
2024-01-10 22:08:49,771 - GAugM EPNet train, Epoch [188/190]: loss 0.7209, auc 0.4297, ap 0.4480
2024-01-10 22:08:49,845 - GAugM EPNet train, Epoch [189/190]: loss 0.7209, auc 0.5602, ap 0.5860
2024-01-10 22:08:49,919 - GAugM EPNet train, Epoch [190/190]: loss 0.7209, auc 0.4130, ap 0.4467
2024-01-10 22:08:49,920 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa0d4b90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:08:50,620 - GAugM EPNet train, Epoch [  1/190]: loss 0.7210, auc 0.4562, ap 0.4603
2024-01-10 22:08:50,696 - GAugM EPNet train, Epoch [  2/190]: loss 0.7210, auc 0.5381, ap 0.5321
2024-01-10 22:08:50,782 - GAugM EPNet train, Epoch [  3/190]: loss 0.7209, auc 0.5107, ap 0.5074
2024-01-10 22:08:50,859 - GAugM EPNet train, Epoch [  4/190]: loss 0.7209, auc 0.4804, ap 0.5005
2024-01-10 22:08:50,937 - GAugM EPNet train, Epoch [  5/190]: loss 0.7209, auc 0.5616, ap 0.5540
2024-01-10 22:08:51,017 - GAugM EPNet train, Epoch [  6/190]: loss 0.7209, auc 0.4883, ap 0.4749
2024-01-10 22:08:51,098 - GAugM EPNet train, Epoch [  7/190]: loss 0.7209, auc 0.5224, ap 0.5008
2024-01-10 22:08:51,177 - GAugM EPNet train, Epoch [  8/190]: loss 0.7210, auc 0.4274, ap 0.4659
2024-01-10 22:08:51,256 - GAugM EPNet train, Epoch [  9/190]: loss 0.7209, auc 0.5260, ap 0.5297
2024-01-10 22:08:51,336 - GAugM EPNet train, Epoch [ 10/190]: loss 0.7208, auc 0.5199, ap 0.5331
2024-01-10 22:08:51,416 - GAugM EPNet train, Epoch [ 11/190]: loss 0.7209, auc 0.4683, ap 0.4929
2024-01-10 22:08:51,493 - GAugM EPNet train, Epoch [ 12/190]: loss 0.7210, auc 0.4494, ap 0.4551
2024-01-10 22:08:51,568 - GAugM EPNet train, Epoch [ 13/190]: loss 0.7209, auc 0.5530, ap 0.5525
2024-01-10 22:08:51,650 - GAugM EPNet train, Epoch [ 14/190]: loss 0.7209, auc 0.4701, ap 0.4782
2024-01-10 22:08:51,737 - GAugM EPNet train, Epoch [ 15/190]: loss 0.7210, auc 0.3850, ap 0.4560
2024-01-10 22:08:51,814 - GAugM EPNet train, Epoch [ 16/190]: loss 0.7209, auc 0.5096, ap 0.5198
2024-01-10 22:08:51,894 - GAugM EPNet train, Epoch [ 17/190]: loss 0.7210, auc 0.5182, ap 0.5252
2024-01-10 22:08:51,970 - GAugM EPNet train, Epoch [ 18/190]: loss 0.7210, auc 0.6104, ap 0.5953
2024-01-10 22:08:52,049 - GAugM EPNet train, Epoch [ 19/190]: loss 0.7209, auc 0.5513, ap 0.5378
2024-01-10 22:08:52,129 - GAugM EPNet train, Epoch [ 20/190]: loss 0.7210, auc 0.4690, ap 0.4980
2024-01-10 22:08:52,204 - GAugM EPNet train, Epoch [ 21/190]: loss 0.7209, auc 0.4687, ap 0.4973
2024-01-10 22:08:52,280 - GAugM EPNet train, Epoch [ 22/190]: loss 0.7210, auc 0.3629, ap 0.4177
2024-01-10 22:08:52,352 - GAugM EPNet train, Epoch [ 23/190]: loss 0.7208, auc 0.5174, ap 0.5039
2024-01-10 22:08:52,424 - GAugM EPNet train, Epoch [ 24/190]: loss 0.7209, auc 0.5360, ap 0.5126
2024-01-10 22:08:52,503 - GAugM EPNet train, Epoch [ 25/190]: loss 0.7209, auc 0.5142, ap 0.5235
2024-01-10 22:08:52,589 - GAugM EPNet train, Epoch [ 26/190]: loss 0.7210, auc 0.5634, ap 0.5706
2024-01-10 22:08:52,675 - GAugM EPNet train, Epoch [ 27/190]: loss 0.7209, auc 0.4324, ap 0.4897
2024-01-10 22:08:52,750 - GAugM EPNet train, Epoch [ 28/190]: loss 0.7209, auc 0.5495, ap 0.5357
2024-01-10 22:08:52,830 - GAugM EPNet train, Epoch [ 29/190]: loss 0.7210, auc 0.4740, ap 0.4603
2024-01-10 22:08:52,905 - GAugM EPNet train, Epoch [ 30/190]: loss 0.7209, auc 0.5018, ap 0.5452
2024-01-10 22:08:52,983 - GAugM EPNet train, Epoch [ 31/190]: loss 0.7208, auc 0.4612, ap 0.4973
2024-01-10 22:08:53,058 - GAugM EPNet train, Epoch [ 32/190]: loss 0.7210, auc 0.6011, ap 0.5789
2024-01-10 22:08:53,135 - GAugM EPNet train, Epoch [ 33/190]: loss 0.7209, auc 0.5025, ap 0.4914
2024-01-10 22:08:53,210 - GAugM EPNet train, Epoch [ 34/190]: loss 0.7209, auc 0.4883, ap 0.4916
2024-01-10 22:08:53,283 - GAugM EPNet train, Epoch [ 35/190]: loss 0.7209, auc 0.4897, ap 0.4945
2024-01-10 22:08:53,356 - GAugM EPNet train, Epoch [ 36/190]: loss 0.7209, auc 0.5908, ap 0.5624
2024-01-10 22:08:53,429 - GAugM EPNet train, Epoch [ 37/190]: loss 0.7209, auc 0.4868, ap 0.4883
2024-01-10 22:08:53,505 - GAugM EPNet train, Epoch [ 38/190]: loss 0.7209, auc 0.5466, ap 0.5313
2024-01-10 22:08:53,580 - GAugM EPNet train, Epoch [ 39/190]: loss 0.7208, auc 0.4498, ap 0.4870
2024-01-10 22:08:53,657 - GAugM EPNet train, Epoch [ 40/190]: loss 0.7210, auc 0.5370, ap 0.5218
2024-01-10 22:08:53,732 - GAugM EPNet train, Epoch [ 41/190]: loss 0.7210, auc 0.4416, ap 0.4970
2024-01-10 22:08:53,805 - GAugM EPNet train, Epoch [ 42/190]: loss 0.7209, auc 0.6171, ap 0.6477
2024-01-10 22:08:53,880 - GAugM EPNet train, Epoch [ 43/190]: loss 0.7208, auc 0.4915, ap 0.4979
2024-01-10 22:08:53,959 - GAugM EPNet train, Epoch [ 44/190]: loss 0.7208, auc 0.3864, ap 0.4400
2024-01-10 22:08:54,033 - GAugM EPNet train, Epoch [ 45/190]: loss 0.7209, auc 0.5438, ap 0.5620
2024-01-10 22:08:54,105 - GAugM EPNet train, Epoch [ 46/190]: loss 0.7209, auc 0.4616, ap 0.4844
2024-01-10 22:08:54,179 - GAugM EPNet train, Epoch [ 47/190]: loss 0.7210, auc 0.4950, ap 0.4979
2024-01-10 22:08:54,254 - GAugM EPNet train, Epoch [ 48/190]: loss 0.7210, auc 0.6296, ap 0.6434
2024-01-10 22:08:54,328 - GAugM EPNet train, Epoch [ 49/190]: loss 0.7209, auc 0.5708, ap 0.5942
2024-01-10 22:08:54,411 - GAugM EPNet train, Epoch [ 50/190]: loss 0.7210, auc 0.4373, ap 0.4750
2024-01-10 22:08:54,485 - GAugM EPNet train, Epoch [ 51/190]: loss 0.7210, auc 0.4637, ap 0.5066
2024-01-10 22:08:54,559 - GAugM EPNet train, Epoch [ 52/190]: loss 0.7209, auc 0.4847, ap 0.5276
2024-01-10 22:08:54,637 - GAugM EPNet train, Epoch [ 53/190]: loss 0.7209, auc 0.5708, ap 0.5739
2024-01-10 22:08:54,720 - GAugM EPNet train, Epoch [ 54/190]: loss 0.7211, auc 0.5491, ap 0.5270
2024-01-10 22:08:54,798 - GAugM EPNet train, Epoch [ 55/190]: loss 0.7209, auc 0.5538, ap 0.5349
2024-01-10 22:08:54,871 - GAugM EPNet train, Epoch [ 56/190]: loss 0.7208, auc 0.4648, ap 0.4719
2024-01-10 22:08:54,950 - GAugM EPNet train, Epoch [ 57/190]: loss 0.7209, auc 0.5249, ap 0.4971
2024-01-10 22:08:55,033 - GAugM EPNet train, Epoch [ 58/190]: loss 0.7210, auc 0.4430, ap 0.4869
2024-01-10 22:08:55,109 - GAugM EPNet train, Epoch [ 59/190]: loss 0.7211, auc 0.4772, ap 0.4676
2024-01-10 22:08:55,183 - GAugM EPNet train, Epoch [ 60/190]: loss 0.7210, auc 0.4861, ap 0.4935
2024-01-10 22:08:55,258 - GAugM EPNet train, Epoch [ 61/190]: loss 0.7209, auc 0.4808, ap 0.4943
2024-01-10 22:08:55,349 - GAugM EPNet train, Epoch [ 62/190]: loss 0.7210, auc 0.4786, ap 0.5178
2024-01-10 22:08:55,428 - GAugM EPNet train, Epoch [ 63/190]: loss 0.7208, auc 0.4484, ap 0.4586
2024-01-10 22:08:55,509 - GAugM EPNet train, Epoch [ 64/190]: loss 0.7208, auc 0.4865, ap 0.4901
2024-01-10 22:08:55,584 - GAugM EPNet train, Epoch [ 65/190]: loss 0.7208, auc 0.5808, ap 0.5866
2024-01-10 22:08:55,665 - GAugM EPNet train, Epoch [ 66/190]: loss 0.7209, auc 0.4854, ap 0.5104
2024-01-10 22:08:55,745 - GAugM EPNet train, Epoch [ 67/190]: loss 0.7209, auc 0.5534, ap 0.5339
2024-01-10 22:08:55,823 - GAugM EPNet train, Epoch [ 68/190]: loss 0.7210, auc 0.4954, ap 0.5299
2024-01-10 22:08:55,897 - GAugM EPNet train, Epoch [ 69/190]: loss 0.7210, auc 0.4829, ap 0.5401
2024-01-10 22:08:55,978 - GAugM EPNet train, Epoch [ 70/190]: loss 0.7210, auc 0.4263, ap 0.4467
2024-01-10 22:08:56,053 - GAugM EPNet train, Epoch [ 71/190]: loss 0.7210, auc 0.5185, ap 0.5243
2024-01-10 22:08:56,133 - GAugM EPNet train, Epoch [ 72/190]: loss 0.7210, auc 0.4021, ap 0.4479
2024-01-10 22:08:56,209 - GAugM EPNet train, Epoch [ 73/190]: loss 0.7209, auc 0.4612, ap 0.4679
2024-01-10 22:08:56,290 - GAugM EPNet train, Epoch [ 74/190]: loss 0.7209, auc 0.5214, ap 0.5142
2024-01-10 22:08:56,367 - GAugM EPNet train, Epoch [ 75/190]: loss 0.7210, auc 0.4847, ap 0.5298
2024-01-10 22:08:56,446 - GAugM EPNet train, Epoch [ 76/190]: loss 0.7209, auc 0.4509, ap 0.4706
2024-01-10 22:08:56,520 - GAugM EPNet train, Epoch [ 77/190]: loss 0.7208, auc 0.6200, ap 0.6182
2024-01-10 22:08:56,596 - GAugM EPNet train, Epoch [ 78/190]: loss 0.7209, auc 0.4605, ap 0.4714
2024-01-10 22:08:56,677 - GAugM EPNet train, Epoch [ 79/190]: loss 0.7208, auc 0.4954, ap 0.5332
2024-01-10 22:08:56,751 - GAugM EPNet train, Epoch [ 80/190]: loss 0.7209, auc 0.6079, ap 0.5658
2024-01-10 22:08:56,833 - GAugM EPNet train, Epoch [ 81/190]: loss 0.7209, auc 0.5217, ap 0.5003
2024-01-10 22:08:56,908 - GAugM EPNet train, Epoch [ 82/190]: loss 0.7210, auc 0.5370, ap 0.5304
2024-01-10 22:08:56,982 - GAugM EPNet train, Epoch [ 83/190]: loss 0.7209, auc 0.4420, ap 0.5075
2024-01-10 22:08:57,057 - GAugM EPNet train, Epoch [ 84/190]: loss 0.7209, auc 0.4776, ap 0.4863
2024-01-10 22:08:57,131 - GAugM EPNet train, Epoch [ 85/190]: loss 0.7210, auc 0.4502, ap 0.5067
2024-01-10 22:08:57,211 - GAugM EPNet train, Epoch [ 86/190]: loss 0.7208, auc 0.4900, ap 0.4873
2024-01-10 22:08:57,285 - GAugM EPNet train, Epoch [ 87/190]: loss 0.7209, auc 0.5530, ap 0.5243
2024-01-10 22:08:57,358 - GAugM EPNet train, Epoch [ 88/190]: loss 0.7210, auc 0.4868, ap 0.5217
2024-01-10 22:08:57,434 - GAugM EPNet train, Epoch [ 89/190]: loss 0.7210, auc 0.4982, ap 0.5499
2024-01-10 22:08:57,510 - GAugM EPNet train, Epoch [ 90/190]: loss 0.7209, auc 0.4302, ap 0.4609
2024-01-10 22:08:57,586 - GAugM EPNet train, Epoch [ 91/190]: loss 0.7208, auc 0.5719, ap 0.5329
2024-01-10 22:08:57,662 - GAugM EPNet train, Epoch [ 92/190]: loss 0.7209, auc 0.6292, ap 0.6112
2024-01-10 22:08:57,745 - GAugM EPNet train, Epoch [ 93/190]: loss 0.7209, auc 0.4509, ap 0.4715
2024-01-10 22:08:57,824 - GAugM EPNet train, Epoch [ 94/190]: loss 0.7210, auc 0.4484, ap 0.4864
2024-01-10 22:08:57,898 - GAugM EPNet train, Epoch [ 95/190]: loss 0.7210, auc 0.4954, ap 0.5153
2024-01-10 22:08:57,971 - GAugM EPNet train, Epoch [ 96/190]: loss 0.7209, auc 0.5263, ap 0.5347
2024-01-10 22:08:58,045 - GAugM EPNet train, Epoch [ 97/190]: loss 0.7209, auc 0.4776, ap 0.4977
2024-01-10 22:08:58,129 - GAugM EPNet train, Epoch [ 98/190]: loss 0.7209, auc 0.4534, ap 0.4705
2024-01-10 22:08:58,204 - GAugM EPNet train, Epoch [ 99/190]: loss 0.7209, auc 0.4594, ap 0.5000
2024-01-10 22:08:58,282 - GAugM EPNet train, Epoch [100/190]: loss 0.7210, auc 0.5381, ap 0.5263
2024-01-10 22:08:58,363 - GAugM EPNet train, Epoch [101/190]: loss 0.7210, auc 0.4505, ap 0.5147
2024-01-10 22:08:58,439 - GAugM EPNet train, Epoch [102/190]: loss 0.7209, auc 0.4737, ap 0.4752
2024-01-10 22:08:58,522 - GAugM EPNet train, Epoch [103/190]: loss 0.7209, auc 0.5171, ap 0.5293
2024-01-10 22:08:58,595 - GAugM EPNet train, Epoch [104/190]: loss 0.7209, auc 0.4121, ap 0.4502
2024-01-10 22:08:58,679 - GAugM EPNet train, Epoch [105/190]: loss 0.7209, auc 0.4811, ap 0.4877
2024-01-10 22:08:58,764 - GAugM EPNet train, Epoch [106/190]: loss 0.7210, auc 0.4220, ap 0.4339
2024-01-10 22:08:58,839 - GAugM EPNet train, Epoch [107/190]: loss 0.7210, auc 0.5648, ap 0.5654
2024-01-10 22:08:58,913 - GAugM EPNet train, Epoch [108/190]: loss 0.7208, auc 0.6018, ap 0.5628
2024-01-10 22:08:58,987 - GAugM EPNet train, Epoch [109/190]: loss 0.7210, auc 0.5114, ap 0.5305
2024-01-10 22:08:59,061 - GAugM EPNet train, Epoch [110/190]: loss 0.7209, auc 0.4249, ap 0.4701
2024-01-10 22:08:59,135 - GAugM EPNet train, Epoch [111/190]: loss 0.7210, auc 0.5328, ap 0.5223
2024-01-10 22:08:59,222 - GAugM EPNet train, Epoch [112/190]: loss 0.7209, auc 0.5356, ap 0.5534
2024-01-10 22:08:59,299 - GAugM EPNet train, Epoch [113/190]: loss 0.7210, auc 0.5466, ap 0.5501
2024-01-10 22:08:59,372 - GAugM EPNet train, Epoch [114/190]: loss 0.7209, auc 0.4580, ap 0.4636
2024-01-10 22:08:59,451 - GAugM EPNet train, Epoch [115/190]: loss 0.7210, auc 0.5281, ap 0.5584
2024-01-10 22:08:59,528 - GAugM EPNet train, Epoch [116/190]: loss 0.7209, auc 0.5826, ap 0.5904
2024-01-10 22:08:59,625 - GAugM EPNet train, Epoch [117/190]: loss 0.7208, auc 0.4470, ap 0.4704
2024-01-10 22:08:59,716 - GAugM EPNet train, Epoch [118/190]: loss 0.7209, auc 0.4633, ap 0.4898
2024-01-10 22:08:59,805 - GAugM EPNet train, Epoch [119/190]: loss 0.7209, auc 0.4057, ap 0.4525
2024-01-10 22:08:59,891 - GAugM EPNet train, Epoch [120/190]: loss 0.7210, auc 0.5210, ap 0.5238
2024-01-10 22:08:59,976 - GAugM EPNet train, Epoch [121/190]: loss 0.7210, auc 0.4224, ap 0.4434
2024-01-10 22:09:00,057 - GAugM EPNet train, Epoch [122/190]: loss 0.7209, auc 0.4961, ap 0.5024
2024-01-10 22:09:00,137 - GAugM EPNet train, Epoch [123/190]: loss 0.7209, auc 0.5459, ap 0.5590
2024-01-10 22:09:00,210 - GAugM EPNet train, Epoch [124/190]: loss 0.7210, auc 0.4608, ap 0.4789
2024-01-10 22:09:00,293 - GAugM EPNet train, Epoch [125/190]: loss 0.7209, auc 0.5495, ap 0.5429
2024-01-10 22:09:00,381 - GAugM EPNet train, Epoch [126/190]: loss 0.7210, auc 0.5292, ap 0.5241
2024-01-10 22:09:00,469 - GAugM EPNet train, Epoch [127/190]: loss 0.7209, auc 0.4754, ap 0.4862
2024-01-10 22:09:00,555 - GAugM EPNet train, Epoch [128/190]: loss 0.7210, auc 0.4776, ap 0.4896
2024-01-10 22:09:00,641 - GAugM EPNet train, Epoch [129/190]: loss 0.7208, auc 0.3163, ap 0.3918
2024-01-10 22:09:00,732 - GAugM EPNet train, Epoch [130/190]: loss 0.7210, auc 0.4936, ap 0.5137
2024-01-10 22:09:00,819 - GAugM EPNet train, Epoch [131/190]: loss 0.7210, auc 0.5100, ap 0.5552
2024-01-10 22:09:00,907 - GAugM EPNet train, Epoch [132/190]: loss 0.7209, auc 0.5267, ap 0.5126
2024-01-10 22:09:00,997 - GAugM EPNet train, Epoch [133/190]: loss 0.7209, auc 0.4377, ap 0.4740
2024-01-10 22:09:01,084 - GAugM EPNet train, Epoch [134/190]: loss 0.7210, auc 0.4712, ap 0.5131
2024-01-10 22:09:01,174 - GAugM EPNet train, Epoch [135/190]: loss 0.7209, auc 0.3807, ap 0.4291
2024-01-10 22:09:01,265 - GAugM EPNet train, Epoch [136/190]: loss 0.7209, auc 0.5399, ap 0.5119
2024-01-10 22:09:01,351 - GAugM EPNet train, Epoch [137/190]: loss 0.7210, auc 0.4733, ap 0.4882
2024-01-10 22:09:01,439 - GAugM EPNet train, Epoch [138/190]: loss 0.7210, auc 0.5242, ap 0.4985
2024-01-10 22:09:01,524 - GAugM EPNet train, Epoch [139/190]: loss 0.7210, auc 0.4697, ap 0.4884
2024-01-10 22:09:01,608 - GAugM EPNet train, Epoch [140/190]: loss 0.7209, auc 0.4580, ap 0.5041
2024-01-10 22:09:01,705 - GAugM EPNet train, Epoch [141/190]: loss 0.7209, auc 0.5406, ap 0.4913
2024-01-10 22:09:01,794 - GAugM EPNet train, Epoch [142/190]: loss 0.7209, auc 0.5153, ap 0.5278
2024-01-10 22:09:01,898 - GAugM EPNet train, Epoch [143/190]: loss 0.7209, auc 0.4776, ap 0.4920
2024-01-10 22:09:01,986 - GAugM EPNet train, Epoch [144/190]: loss 0.7209, auc 0.4405, ap 0.4547
2024-01-10 22:09:02,076 - GAugM EPNet train, Epoch [145/190]: loss 0.7209, auc 0.4270, ap 0.4699
2024-01-10 22:09:02,167 - GAugM EPNet train, Epoch [146/190]: loss 0.7209, auc 0.5502, ap 0.5688
2024-01-10 22:09:02,255 - GAugM EPNet train, Epoch [147/190]: loss 0.7209, auc 0.6100, ap 0.6200
2024-01-10 22:09:02,345 - GAugM EPNet train, Epoch [148/190]: loss 0.7209, auc 0.5121, ap 0.5484
2024-01-10 22:09:02,433 - GAugM EPNet train, Epoch [149/190]: loss 0.7208, auc 0.4790, ap 0.4934
2024-01-10 22:09:02,518 - GAugM EPNet train, Epoch [150/190]: loss 0.7209, auc 0.5121, ap 0.5130
2024-01-10 22:09:02,609 - GAugM EPNet train, Epoch [151/190]: loss 0.7209, auc 0.4943, ap 0.5020
2024-01-10 22:09:02,696 - GAugM EPNet train, Epoch [152/190]: loss 0.7209, auc 0.5698, ap 0.5763
2024-01-10 22:09:02,790 - GAugM EPNet train, Epoch [153/190]: loss 0.7209, auc 0.4559, ap 0.5130
2024-01-10 22:09:02,876 - GAugM EPNet train, Epoch [154/190]: loss 0.7209, auc 0.5125, ap 0.5435
2024-01-10 22:09:02,972 - GAugM EPNet train, Epoch [155/190]: loss 0.7209, auc 0.4822, ap 0.4853
2024-01-10 22:09:03,056 - GAugM EPNet train, Epoch [156/190]: loss 0.7209, auc 0.5256, ap 0.5518
2024-01-10 22:09:03,143 - GAugM EPNet train, Epoch [157/190]: loss 0.7209, auc 0.5271, ap 0.5093
2024-01-10 22:09:03,231 - GAugM EPNet train, Epoch [158/190]: loss 0.7208, auc 0.4580, ap 0.4664
2024-01-10 22:09:03,317 - GAugM EPNet train, Epoch [159/190]: loss 0.7208, auc 0.4900, ap 0.5009
2024-01-10 22:09:03,401 - GAugM EPNet train, Epoch [160/190]: loss 0.7209, auc 0.6111, ap 0.6134
2024-01-10 22:09:03,486 - GAugM EPNet train, Epoch [161/190]: loss 0.7209, auc 0.5121, ap 0.5226
2024-01-10 22:09:03,571 - GAugM EPNet train, Epoch [162/190]: loss 0.7209, auc 0.4480, ap 0.4652
2024-01-10 22:09:03,656 - GAugM EPNet train, Epoch [163/190]: loss 0.7209, auc 0.4719, ap 0.4628
2024-01-10 22:09:03,746 - GAugM EPNet train, Epoch [164/190]: loss 0.7211, auc 0.5399, ap 0.5147
2024-01-10 22:09:03,831 - GAugM EPNet train, Epoch [165/190]: loss 0.7210, auc 0.3871, ap 0.4558
2024-01-10 22:09:03,918 - GAugM EPNet train, Epoch [166/190]: loss 0.7208, auc 0.5452, ap 0.5484
2024-01-10 22:09:04,005 - GAugM EPNet train, Epoch [167/190]: loss 0.7209, auc 0.4662, ap 0.4742
2024-01-10 22:09:04,091 - GAugM EPNet train, Epoch [168/190]: loss 0.7209, auc 0.4121, ap 0.4342
2024-01-10 22:09:04,180 - GAugM EPNet train, Epoch [169/190]: loss 0.7209, auc 0.5705, ap 0.5980
2024-01-10 22:09:04,267 - GAugM EPNet train, Epoch [170/190]: loss 0.7210, auc 0.5192, ap 0.4877
2024-01-10 22:09:04,379 - GAugM EPNet train, Epoch [171/190]: loss 0.7209, auc 0.4338, ap 0.4587
2024-01-10 22:09:04,472 - GAugM EPNet train, Epoch [172/190]: loss 0.7208, auc 0.4519, ap 0.4624
2024-01-10 22:09:04,561 - GAugM EPNet train, Epoch [173/190]: loss 0.7209, auc 0.4957, ap 0.5295
2024-01-10 22:09:04,660 - GAugM EPNet train, Epoch [174/190]: loss 0.7209, auc 0.4911, ap 0.5066
2024-01-10 22:09:04,748 - GAugM EPNet train, Epoch [175/190]: loss 0.7209, auc 0.5883, ap 0.5748
2024-01-10 22:09:04,841 - GAugM EPNet train, Epoch [176/190]: loss 0.7209, auc 0.4409, ap 0.4658
2024-01-10 22:09:04,931 - GAugM EPNet train, Epoch [177/190]: loss 0.7210, auc 0.5541, ap 0.5425
2024-01-10 22:09:05,011 - GAugM EPNet train, Epoch [178/190]: loss 0.7210, auc 0.5911, ap 0.5799
2024-01-10 22:09:05,090 - GAugM EPNet train, Epoch [179/190]: loss 0.7210, auc 0.4281, ap 0.4900
2024-01-10 22:09:05,168 - GAugM EPNet train, Epoch [180/190]: loss 0.7210, auc 0.4968, ap 0.5413
2024-01-10 22:09:05,246 - GAugM EPNet train, Epoch [181/190]: loss 0.7209, auc 0.4879, ap 0.5099
2024-01-10 22:09:05,328 - GAugM EPNet train, Epoch [182/190]: loss 0.7209, auc 0.4712, ap 0.4910
2024-01-10 22:09:05,419 - GAugM EPNet train, Epoch [183/190]: loss 0.7210, auc 0.5719, ap 0.5366
2024-01-10 22:09:05,508 - GAugM EPNet train, Epoch [184/190]: loss 0.7209, auc 0.4801, ap 0.5010
2024-01-10 22:09:05,585 - GAugM EPNet train, Epoch [185/190]: loss 0.7209, auc 0.4327, ap 0.4638
2024-01-10 22:09:05,676 - GAugM EPNet train, Epoch [186/190]: loss 0.7208, auc 0.4498, ap 0.5188
2024-01-10 22:09:05,775 - GAugM EPNet train, Epoch [187/190]: loss 0.7209, auc 0.5107, ap 0.5167
2024-01-10 22:09:05,852 - GAugM EPNet train, Epoch [188/190]: loss 0.7209, auc 0.4801, ap 0.4660
2024-01-10 22:09:05,939 - GAugM EPNet train, Epoch [189/190]: loss 0.7209, auc 0.5342, ap 0.5613
2024-01-10 22:09:06,031 - GAugM EPNet train, Epoch [190/190]: loss 0.7209, auc 0.4103, ap 0.4471
2024-01-10 22:09:06,032 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035ec1d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:09:06,748 - GAugM EPNet train, Epoch [  1/190]: loss 0.7210, auc 0.4548, ap 0.4577
2024-01-10 22:09:06,841 - GAugM EPNet train, Epoch [  2/190]: loss 0.7210, auc 0.5246, ap 0.5067
2024-01-10 22:09:06,929 - GAugM EPNet train, Epoch [  3/190]: loss 0.7209, auc 0.5411, ap 0.5259
2024-01-10 22:09:07,025 - GAugM EPNet train, Epoch [  4/190]: loss 0.7209, auc 0.4708, ap 0.5286
2024-01-10 22:09:07,102 - GAugM EPNet train, Epoch [  5/190]: loss 0.7209, auc 0.5347, ap 0.5697
2024-01-10 22:09:07,178 - GAugM EPNet train, Epoch [  6/190]: loss 0.7209, auc 0.4708, ap 0.5113
2024-01-10 22:09:07,254 - GAugM EPNet train, Epoch [  7/190]: loss 0.7209, auc 0.4767, ap 0.4774
2024-01-10 22:09:07,338 - GAugM EPNet train, Epoch [  8/190]: loss 0.7210, auc 0.5169, ap 0.5195
2024-01-10 22:09:07,415 - GAugM EPNet train, Epoch [  9/190]: loss 0.7209, auc 0.4648, ap 0.4753
2024-01-10 22:09:07,496 - GAugM EPNet train, Epoch [ 10/190]: loss 0.7208, auc 0.4452, ap 0.4648
2024-01-10 22:09:07,573 - GAugM EPNet train, Epoch [ 11/190]: loss 0.7209, auc 0.5529, ap 0.5551
2024-01-10 22:09:07,655 - GAugM EPNet train, Epoch [ 12/190]: loss 0.7210, auc 0.5189, ap 0.5225
2024-01-10 22:09:07,734 - GAugM EPNet train, Epoch [ 13/190]: loss 0.7209, auc 0.5153, ap 0.5465
2024-01-10 22:09:07,811 - GAugM EPNet train, Epoch [ 14/190]: loss 0.7209, auc 0.5434, ap 0.5448
2024-01-10 22:09:07,885 - GAugM EPNet train, Epoch [ 15/190]: loss 0.7210, auc 0.4475, ap 0.4849
2024-01-10 22:09:07,959 - GAugM EPNet train, Epoch [ 16/190]: loss 0.7209, auc 0.6095, ap 0.5908
2024-01-10 22:09:08,032 - GAugM EPNet train, Epoch [ 17/190]: loss 0.7210, auc 0.5180, ap 0.5157
2024-01-10 22:09:08,110 - GAugM EPNet train, Epoch [ 18/190]: loss 0.7210, auc 0.5534, ap 0.5503
2024-01-10 22:09:08,187 - GAugM EPNet train, Epoch [ 19/190]: loss 0.7209, auc 0.4822, ap 0.4808
2024-01-10 22:09:08,277 - GAugM EPNet train, Epoch [ 20/190]: loss 0.7210, auc 0.5433, ap 0.5721
2024-01-10 22:09:08,368 - GAugM EPNet train, Epoch [ 21/190]: loss 0.7209, auc 0.5644, ap 0.5291
2024-01-10 22:09:08,471 - GAugM EPNet train, Epoch [ 22/190]: loss 0.7210, auc 0.3647, ap 0.4153
2024-01-10 22:09:08,565 - GAugM EPNet train, Epoch [ 23/190]: loss 0.7208, auc 0.4626, ap 0.4885
2024-01-10 22:09:08,657 - GAugM EPNet train, Epoch [ 24/190]: loss 0.7209, auc 0.5263, ap 0.4922
2024-01-10 22:09:08,759 - GAugM EPNet train, Epoch [ 25/190]: loss 0.7209, auc 0.4829, ap 0.4907
2024-01-10 22:09:08,850 - GAugM EPNet train, Epoch [ 26/190]: loss 0.7210, auc 0.5477, ap 0.5696
2024-01-10 22:09:08,945 - GAugM EPNet train, Epoch [ 27/190]: loss 0.7209, auc 0.4701, ap 0.5085
2024-01-10 22:09:09,037 - GAugM EPNet train, Epoch [ 28/190]: loss 0.7209, auc 0.5408, ap 0.5668
2024-01-10 22:09:09,119 - GAugM EPNet train, Epoch [ 29/190]: loss 0.7210, auc 0.4423, ap 0.4554
2024-01-10 22:09:09,196 - GAugM EPNet train, Epoch [ 30/190]: loss 0.7209, auc 0.5242, ap 0.5219
2024-01-10 22:09:09,286 - GAugM EPNet train, Epoch [ 31/190]: loss 0.7208, auc 0.4567, ap 0.5197
2024-01-10 22:09:09,377 - GAugM EPNet train, Epoch [ 32/190]: loss 0.7210, auc 0.5929, ap 0.5635
2024-01-10 22:09:09,466 - GAugM EPNet train, Epoch [ 33/190]: loss 0.7209, auc 0.5815, ap 0.6069
2024-01-10 22:09:09,543 - GAugM EPNet train, Epoch [ 34/190]: loss 0.7209, auc 0.4621, ap 0.4878
2024-01-10 22:09:09,627 - GAugM EPNet train, Epoch [ 35/190]: loss 0.7209, auc 0.5342, ap 0.5296
2024-01-10 22:09:09,705 - GAugM EPNet train, Epoch [ 36/190]: loss 0.7209, auc 0.6428, ap 0.6188
2024-01-10 22:09:09,785 - GAugM EPNet train, Epoch [ 37/190]: loss 0.7209, auc 0.5043, ap 0.5201
2024-01-10 22:09:09,875 - GAugM EPNet train, Epoch [ 38/190]: loss 0.7209, auc 0.4925, ap 0.4923
2024-01-10 22:09:09,953 - GAugM EPNet train, Epoch [ 39/190]: loss 0.7208, auc 0.4665, ap 0.4797
2024-01-10 22:09:10,038 - GAugM EPNet train, Epoch [ 40/190]: loss 0.7210, auc 0.4763, ap 0.4831
2024-01-10 22:09:10,115 - GAugM EPNet train, Epoch [ 41/190]: loss 0.7210, auc 0.4833, ap 0.5051
2024-01-10 22:09:10,192 - GAugM EPNet train, Epoch [ 42/190]: loss 0.7209, auc 0.5098, ap 0.5253
2024-01-10 22:09:10,273 - GAugM EPNet train, Epoch [ 43/190]: loss 0.7208, auc 0.4185, ap 0.4556
2024-01-10 22:09:10,356 - GAugM EPNet train, Epoch [ 44/190]: loss 0.7208, auc 0.3727, ap 0.4265
2024-01-10 22:09:10,435 - GAugM EPNet train, Epoch [ 45/190]: loss 0.7209, auc 0.5577, ap 0.5750
2024-01-10 22:09:10,524 - GAugM EPNet train, Epoch [ 46/190]: loss 0.7209, auc 0.4760, ap 0.5159
2024-01-10 22:09:10,599 - GAugM EPNet train, Epoch [ 47/190]: loss 0.7210, auc 0.4535, ap 0.4679
2024-01-10 22:09:10,680 - GAugM EPNet train, Epoch [ 48/190]: loss 0.7210, auc 0.5833, ap 0.6091
2024-01-10 22:09:10,763 - GAugM EPNet train, Epoch [ 49/190]: loss 0.7209, auc 0.5425, ap 0.5674
2024-01-10 22:09:10,842 - GAugM EPNet train, Epoch [ 50/190]: loss 0.7210, auc 0.5345, ap 0.5390
2024-01-10 22:09:10,922 - GAugM EPNet train, Epoch [ 51/190]: loss 0.7210, auc 0.4973, ap 0.5135
2024-01-10 22:09:10,998 - GAugM EPNet train, Epoch [ 52/190]: loss 0.7209, auc 0.4617, ap 0.4737
2024-01-10 22:09:11,074 - GAugM EPNet train, Epoch [ 53/190]: loss 0.7209, auc 0.5222, ap 0.5398
2024-01-10 22:09:11,148 - GAugM EPNet train, Epoch [ 54/190]: loss 0.7211, auc 0.5915, ap 0.5776
2024-01-10 22:09:11,239 - GAugM EPNet train, Epoch [ 55/190]: loss 0.7209, auc 0.5634, ap 0.5884
2024-01-10 22:09:11,331 - GAugM EPNet train, Epoch [ 56/190]: loss 0.7208, auc 0.4891, ap 0.4999
2024-01-10 22:09:11,411 - GAugM EPNet train, Epoch [ 57/190]: loss 0.7209, auc 0.4423, ap 0.4523
2024-01-10 22:09:11,508 - GAugM EPNet train, Epoch [ 58/190]: loss 0.7210, auc 0.4484, ap 0.5013
2024-01-10 22:09:11,594 - GAugM EPNet train, Epoch [ 59/190]: loss 0.7211, auc 0.5278, ap 0.5272
2024-01-10 22:09:11,679 - GAugM EPNet train, Epoch [ 60/190]: loss 0.7210, auc 0.4373, ap 0.4494
2024-01-10 22:09:11,753 - GAugM EPNet train, Epoch [ 61/190]: loss 0.7209, auc 0.5114, ap 0.5619
2024-01-10 22:09:11,825 - GAugM EPNet train, Epoch [ 62/190]: loss 0.7210, auc 0.5466, ap 0.5665
2024-01-10 22:09:11,920 - GAugM EPNet train, Epoch [ 63/190]: loss 0.7208, auc 0.5408, ap 0.5104
2024-01-10 22:09:12,009 - GAugM EPNet train, Epoch [ 64/190]: loss 0.7208, auc 0.5068, ap 0.5381
2024-01-10 22:09:12,114 - GAugM EPNet train, Epoch [ 65/190]: loss 0.7208, auc 0.5740, ap 0.5857
2024-01-10 22:09:12,203 - GAugM EPNet train, Epoch [ 66/190]: loss 0.7209, auc 0.4811, ap 0.5278
2024-01-10 22:09:12,295 - GAugM EPNet train, Epoch [ 67/190]: loss 0.7209, auc 0.5224, ap 0.5332
2024-01-10 22:09:12,385 - GAugM EPNet train, Epoch [ 68/190]: loss 0.7210, auc 0.5297, ap 0.5461
2024-01-10 22:09:12,473 - GAugM EPNet train, Epoch [ 69/190]: loss 0.7210, auc 0.5555, ap 0.5862
2024-01-10 22:09:12,564 - GAugM EPNet train, Epoch [ 70/190]: loss 0.7210, auc 0.4098, ap 0.4445
2024-01-10 22:09:12,648 - GAugM EPNet train, Epoch [ 71/190]: loss 0.7210, auc 0.4888, ap 0.4986
2024-01-10 22:09:12,725 - GAugM EPNet train, Epoch [ 72/190]: loss 0.7210, auc 0.4099, ap 0.4361
2024-01-10 22:09:12,817 - GAugM EPNet train, Epoch [ 73/190]: loss 0.7209, auc 0.4856, ap 0.4781
2024-01-10 22:09:12,898 - GAugM EPNet train, Epoch [ 74/190]: loss 0.7209, auc 0.5397, ap 0.5383
2024-01-10 22:09:12,982 - GAugM EPNet train, Epoch [ 75/190]: loss 0.7210, auc 0.4964, ap 0.5280
2024-01-10 22:09:13,063 - GAugM EPNet train, Epoch [ 76/190]: loss 0.7209, auc 0.4626, ap 0.4747
2024-01-10 22:09:13,145 - GAugM EPNet train, Epoch [ 77/190]: loss 0.7208, auc 0.5418, ap 0.5696
2024-01-10 22:09:13,221 - GAugM EPNet train, Epoch [ 78/190]: loss 0.7209, auc 0.5336, ap 0.5139
2024-01-10 22:09:13,306 - GAugM EPNet train, Epoch [ 79/190]: loss 0.7208, auc 0.4726, ap 0.4848
2024-01-10 22:09:13,403 - GAugM EPNet train, Epoch [ 80/190]: loss 0.7209, auc 0.5183, ap 0.5120
2024-01-10 22:09:13,497 - GAugM EPNet train, Epoch [ 81/190]: loss 0.7209, auc 0.4858, ap 0.4823
2024-01-10 22:09:13,590 - GAugM EPNet train, Epoch [ 82/190]: loss 0.7210, auc 0.5845, ap 0.5667
2024-01-10 22:09:13,675 - GAugM EPNet train, Epoch [ 83/190]: loss 0.7209, auc 0.3597, ap 0.4307
2024-01-10 22:09:13,765 - GAugM EPNet train, Epoch [ 84/190]: loss 0.7209, auc 0.4614, ap 0.4752
2024-01-10 22:09:13,853 - GAugM EPNet train, Epoch [ 85/190]: loss 0.7210, auc 0.4505, ap 0.4916
2024-01-10 22:09:13,944 - GAugM EPNet train, Epoch [ 86/190]: loss 0.7208, auc 0.4687, ap 0.5211
2024-01-10 22:09:14,034 - GAugM EPNet train, Epoch [ 87/190]: loss 0.7209, auc 0.5619, ap 0.5360
2024-01-10 22:09:14,124 - GAugM EPNet train, Epoch [ 88/190]: loss 0.7210, auc 0.4801, ap 0.4991
2024-01-10 22:09:14,212 - GAugM EPNet train, Epoch [ 89/190]: loss 0.7210, auc 0.4585, ap 0.4922
2024-01-10 22:09:14,303 - GAugM EPNet train, Epoch [ 90/190]: loss 0.7209, auc 0.4527, ap 0.4779
2024-01-10 22:09:14,390 - GAugM EPNet train, Epoch [ 91/190]: loss 0.7208, auc 0.5719, ap 0.5368
2024-01-10 22:09:14,489 - GAugM EPNet train, Epoch [ 92/190]: loss 0.7209, auc 0.5781, ap 0.6028
2024-01-10 22:09:14,579 - GAugM EPNet train, Epoch [ 93/190]: loss 0.7209, auc 0.3966, ap 0.4368
2024-01-10 22:09:14,667 - GAugM EPNet train, Epoch [ 94/190]: loss 0.7210, auc 0.4311, ap 0.4607
2024-01-10 22:09:14,759 - GAugM EPNet train, Epoch [ 95/190]: loss 0.7210, auc 0.5199, ap 0.5177
2024-01-10 22:09:14,846 - GAugM EPNet train, Epoch [ 96/190]: loss 0.7209, auc 0.4774, ap 0.4952
2024-01-10 22:09:14,933 - GAugM EPNet train, Epoch [ 97/190]: loss 0.7209, auc 0.4500, ap 0.5181
2024-01-10 22:09:15,024 - GAugM EPNet train, Epoch [ 98/190]: loss 0.7209, auc 0.4368, ap 0.4562
2024-01-10 22:09:15,117 - GAugM EPNet train, Epoch [ 99/190]: loss 0.7209, auc 0.4455, ap 0.4775
2024-01-10 22:09:15,209 - GAugM EPNet train, Epoch [100/190]: loss 0.7210, auc 0.4738, ap 0.4629
2024-01-10 22:09:15,298 - GAugM EPNet train, Epoch [101/190]: loss 0.7210, auc 0.3891, ap 0.4403
2024-01-10 22:09:15,396 - GAugM EPNet train, Epoch [102/190]: loss 0.7209, auc 0.5386, ap 0.5377
2024-01-10 22:09:15,487 - GAugM EPNet train, Epoch [103/190]: loss 0.7209, auc 0.4902, ap 0.5375
2024-01-10 22:09:15,578 - GAugM EPNet train, Epoch [104/190]: loss 0.7209, auc 0.4402, ap 0.4725
2024-01-10 22:09:15,672 - GAugM EPNet train, Epoch [105/190]: loss 0.7209, auc 0.4162, ap 0.4455
2024-01-10 22:09:15,764 - GAugM EPNet train, Epoch [106/190]: loss 0.7210, auc 0.4934, ap 0.5298
2024-01-10 22:09:15,849 - GAugM EPNet train, Epoch [107/190]: loss 0.7210, auc 0.4820, ap 0.5147
2024-01-10 22:09:15,936 - GAugM EPNet train, Epoch [108/190]: loss 0.7208, auc 0.5101, ap 0.5314
2024-01-10 22:09:16,027 - GAugM EPNet train, Epoch [109/190]: loss 0.7210, auc 0.5399, ap 0.5318
2024-01-10 22:09:16,118 - GAugM EPNet train, Epoch [110/190]: loss 0.7209, auc 0.4681, ap 0.4893
2024-01-10 22:09:16,197 - GAugM EPNet train, Epoch [111/190]: loss 0.7210, auc 0.4359, ap 0.4914
2024-01-10 22:09:16,291 - GAugM EPNet train, Epoch [112/190]: loss 0.7209, auc 0.4984, ap 0.5321
2024-01-10 22:09:16,383 - GAugM EPNet train, Epoch [113/190]: loss 0.7210, auc 0.4975, ap 0.5137
2024-01-10 22:09:16,474 - GAugM EPNet train, Epoch [114/190]: loss 0.7209, auc 0.4302, ap 0.4545
2024-01-10 22:09:16,569 - GAugM EPNet train, Epoch [115/190]: loss 0.7210, auc 0.5130, ap 0.5296
2024-01-10 22:09:16,652 - GAugM EPNet train, Epoch [116/190]: loss 0.7209, auc 0.4722, ap 0.4759
2024-01-10 22:09:16,731 - GAugM EPNet train, Epoch [117/190]: loss 0.7208, auc 0.4722, ap 0.5157
2024-01-10 22:09:16,835 - GAugM EPNet train, Epoch [118/190]: loss 0.7209, auc 0.5055, ap 0.5410
2024-01-10 22:09:16,930 - GAugM EPNet train, Epoch [119/190]: loss 0.7209, auc 0.4653, ap 0.5116
2024-01-10 22:09:17,032 - GAugM EPNet train, Epoch [120/190]: loss 0.7210, auc 0.4562, ap 0.4578
2024-01-10 22:09:17,132 - GAugM EPNet train, Epoch [121/190]: loss 0.7210, auc 0.4649, ap 0.4815
2024-01-10 22:09:17,223 - GAugM EPNet train, Epoch [122/190]: loss 0.7209, auc 0.4875, ap 0.5209
2024-01-10 22:09:17,308 - GAugM EPNet train, Epoch [123/190]: loss 0.7209, auc 0.4865, ap 0.5155
2024-01-10 22:09:17,399 - GAugM EPNet train, Epoch [124/190]: loss 0.7210, auc 0.5411, ap 0.5086
2024-01-10 22:09:17,492 - GAugM EPNet train, Epoch [125/190]: loss 0.7209, auc 0.5117, ap 0.5116
2024-01-10 22:09:17,588 - GAugM EPNet train, Epoch [126/190]: loss 0.7210, auc 0.5158, ap 0.5127
2024-01-10 22:09:17,681 - GAugM EPNet train, Epoch [127/190]: loss 0.7209, auc 0.5050, ap 0.5119
2024-01-10 22:09:17,776 - GAugM EPNet train, Epoch [128/190]: loss 0.7210, auc 0.4655, ap 0.4755
2024-01-10 22:09:17,868 - GAugM EPNet train, Epoch [129/190]: loss 0.7208, auc 0.3706, ap 0.4286
2024-01-10 22:09:17,959 - GAugM EPNet train, Epoch [130/190]: loss 0.7210, auc 0.5463, ap 0.5549
2024-01-10 22:09:18,057 - GAugM EPNet train, Epoch [131/190]: loss 0.7210, auc 0.4021, ap 0.4639
2024-01-10 22:09:18,145 - GAugM EPNet train, Epoch [132/190]: loss 0.7209, auc 0.4947, ap 0.5057
2024-01-10 22:09:18,238 - GAugM EPNet train, Epoch [133/190]: loss 0.7209, auc 0.4258, ap 0.4693
2024-01-10 22:09:18,329 - GAugM EPNet train, Epoch [134/190]: loss 0.7210, auc 0.5105, ap 0.4840
2024-01-10 22:09:18,416 - GAugM EPNet train, Epoch [135/190]: loss 0.7209, auc 0.3868, ap 0.4352
2024-01-10 22:09:18,493 - GAugM EPNet train, Epoch [136/190]: loss 0.7209, auc 0.5214, ap 0.5106
2024-01-10 22:09:18,577 - GAugM EPNet train, Epoch [137/190]: loss 0.7210, auc 0.4689, ap 0.4893
2024-01-10 22:09:18,665 - GAugM EPNet train, Epoch [138/190]: loss 0.7210, auc 0.6022, ap 0.5635
2024-01-10 22:09:18,759 - GAugM EPNet train, Epoch [139/190]: loss 0.7210, auc 0.4441, ap 0.4838
2024-01-10 22:09:18,843 - GAugM EPNet train, Epoch [140/190]: loss 0.7209, auc 0.4721, ap 0.5238
2024-01-10 22:09:18,929 - GAugM EPNet train, Epoch [141/190]: loss 0.7209, auc 0.5128, ap 0.4925
2024-01-10 22:09:19,001 - GAugM EPNet train, Epoch [142/190]: loss 0.7209, auc 0.5438, ap 0.5669
2024-01-10 22:09:19,081 - GAugM EPNet train, Epoch [143/190]: loss 0.7209, auc 0.4639, ap 0.4923
2024-01-10 22:09:19,168 - GAugM EPNet train, Epoch [144/190]: loss 0.7209, auc 0.4578, ap 0.4912
2024-01-10 22:09:19,255 - GAugM EPNet train, Epoch [145/190]: loss 0.7209, auc 0.4651, ap 0.5049
2024-01-10 22:09:19,351 - GAugM EPNet train, Epoch [146/190]: loss 0.7209, auc 0.5141, ap 0.5647
2024-01-10 22:09:19,438 - GAugM EPNet train, Epoch [147/190]: loss 0.7209, auc 0.6331, ap 0.6480
2024-01-10 22:09:19,524 - GAugM EPNet train, Epoch [148/190]: loss 0.7209, auc 0.4386, ap 0.4754
2024-01-10 22:09:19,610 - GAugM EPNet train, Epoch [149/190]: loss 0.7208, auc 0.4858, ap 0.5141
2024-01-10 22:09:19,697 - GAugM EPNet train, Epoch [150/190]: loss 0.7209, auc 0.4932, ap 0.5211
2024-01-10 22:09:19,786 - GAugM EPNet train, Epoch [151/190]: loss 0.7209, auc 0.5438, ap 0.5516
2024-01-10 22:09:19,874 - GAugM EPNet train, Epoch [152/190]: loss 0.7209, auc 0.5918, ap 0.5792
2024-01-10 22:09:19,964 - GAugM EPNet train, Epoch [153/190]: loss 0.7209, auc 0.4188, ap 0.4771
2024-01-10 22:09:20,052 - GAugM EPNet train, Epoch [154/190]: loss 0.7209, auc 0.5352, ap 0.5765
2024-01-10 22:09:20,140 - GAugM EPNet train, Epoch [155/190]: loss 0.7209, auc 0.5290, ap 0.5478
2024-01-10 22:09:20,227 - GAugM EPNet train, Epoch [156/190]: loss 0.7209, auc 0.5075, ap 0.5416
2024-01-10 22:09:20,314 - GAugM EPNet train, Epoch [157/190]: loss 0.7209, auc 0.4838, ap 0.4793
2024-01-10 22:09:20,403 - GAugM EPNet train, Epoch [158/190]: loss 0.7208, auc 0.4361, ap 0.4763
2024-01-10 22:09:20,494 - GAugM EPNet train, Epoch [159/190]: loss 0.7208, auc 0.4525, ap 0.4697
2024-01-10 22:09:20,585 - GAugM EPNet train, Epoch [160/190]: loss 0.7209, auc 0.6040, ap 0.6114
2024-01-10 22:09:20,670 - GAugM EPNet train, Epoch [161/190]: loss 0.7209, auc 0.5803, ap 0.5834
2024-01-10 22:09:20,756 - GAugM EPNet train, Epoch [162/190]: loss 0.7209, auc 0.4316, ap 0.4580
2024-01-10 22:09:20,841 - GAugM EPNet train, Epoch [163/190]: loss 0.7209, auc 0.5105, ap 0.5016
2024-01-10 22:09:20,926 - GAugM EPNet train, Epoch [164/190]: loss 0.7211, auc 0.5384, ap 0.5075
2024-01-10 22:09:21,010 - GAugM EPNet train, Epoch [165/190]: loss 0.7210, auc 0.5055, ap 0.5150
2024-01-10 22:09:21,110 - GAugM EPNet train, Epoch [166/190]: loss 0.7208, auc 0.5529, ap 0.5417
2024-01-10 22:09:21,193 - GAugM EPNet train, Epoch [167/190]: loss 0.7209, auc 0.4220, ap 0.4594
2024-01-10 22:09:21,287 - GAugM EPNet train, Epoch [168/190]: loss 0.7209, auc 0.4957, ap 0.5800
2024-01-10 22:09:21,372 - GAugM EPNet train, Epoch [169/190]: loss 0.7209, auc 0.6171, ap 0.6067
2024-01-10 22:09:21,458 - GAugM EPNet train, Epoch [170/190]: loss 0.7210, auc 0.5096, ap 0.5069
2024-01-10 22:09:21,544 - GAugM EPNet train, Epoch [171/190]: loss 0.7209, auc 0.5034, ap 0.5108
2024-01-10 22:09:21,630 - GAugM EPNet train, Epoch [172/190]: loss 0.7208, auc 0.4904, ap 0.5050
2024-01-10 22:09:21,720 - GAugM EPNet train, Epoch [173/190]: loss 0.7209, auc 0.5580, ap 0.5640
2024-01-10 22:09:21,810 - GAugM EPNet train, Epoch [174/190]: loss 0.7209, auc 0.4681, ap 0.4770
2024-01-10 22:09:21,896 - GAugM EPNet train, Epoch [175/190]: loss 0.7209, auc 0.5632, ap 0.5630
2024-01-10 22:09:21,986 - GAugM EPNet train, Epoch [176/190]: loss 0.7209, auc 0.5125, ap 0.5077
2024-01-10 22:09:22,071 - GAugM EPNet train, Epoch [177/190]: loss 0.7210, auc 0.4468, ap 0.4566
2024-01-10 22:09:22,160 - GAugM EPNet train, Epoch [178/190]: loss 0.7210, auc 0.4943, ap 0.4955
2024-01-10 22:09:22,246 - GAugM EPNet train, Epoch [179/190]: loss 0.7210, auc 0.3434, ap 0.4259
2024-01-10 22:09:22,332 - GAugM EPNet train, Epoch [180/190]: loss 0.7210, auc 0.5069, ap 0.5355
2024-01-10 22:09:22,420 - GAugM EPNet train, Epoch [181/190]: loss 0.7209, auc 0.4361, ap 0.4503
2024-01-10 22:09:22,506 - GAugM EPNet train, Epoch [182/190]: loss 0.7209, auc 0.4838, ap 0.5313
2024-01-10 22:09:22,595 - GAugM EPNet train, Epoch [183/190]: loss 0.7210, auc 0.4817, ap 0.4817
2024-01-10 22:09:22,688 - GAugM EPNet train, Epoch [184/190]: loss 0.7209, auc 0.5023, ap 0.5175
2024-01-10 22:09:22,786 - GAugM EPNet train, Epoch [185/190]: loss 0.7209, auc 0.4996, ap 0.5120
2024-01-10 22:09:22,875 - GAugM EPNet train, Epoch [186/190]: loss 0.7208, auc 0.4790, ap 0.5179
2024-01-10 22:09:22,963 - GAugM EPNet train, Epoch [187/190]: loss 0.7209, auc 0.4343, ap 0.4546
2024-01-10 22:09:23,051 - GAugM EPNet train, Epoch [188/190]: loss 0.7209, auc 0.4423, ap 0.4621
2024-01-10 22:09:23,144 - GAugM EPNet train, Epoch [189/190]: loss 0.7209, auc 0.5324, ap 0.5703
2024-01-10 22:09:23,232 - GAugM EPNet train, Epoch [190/190]: loss 0.7209, auc 0.4511, ap 0.4785
2024-01-10 22:09:23,233 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d073b5290>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:09:23,995 - GAugM EPNet train, Epoch [  1/190]: loss 0.7210, auc 0.5052, ap 0.5164
2024-01-10 22:09:24,072 - GAugM EPNet train, Epoch [  2/190]: loss 0.7210, auc 0.5301, ap 0.5215
2024-01-10 22:09:24,151 - GAugM EPNet train, Epoch [  3/190]: loss 0.7209, auc 0.5739, ap 0.5604
2024-01-10 22:09:24,227 - GAugM EPNet train, Epoch [  4/190]: loss 0.7209, auc 0.5023, ap 0.5442
2024-01-10 22:09:24,310 - GAugM EPNet train, Epoch [  5/190]: loss 0.7209, auc 0.6091, ap 0.6520
2024-01-10 22:09:24,387 - GAugM EPNet train, Epoch [  6/190]: loss 0.7209, auc 0.4717, ap 0.4889
2024-01-10 22:09:24,462 - GAugM EPNet train, Epoch [  7/190]: loss 0.7209, auc 0.4377, ap 0.4731
2024-01-10 22:09:24,538 - GAugM EPNet train, Epoch [  8/190]: loss 0.7210, auc 0.4404, ap 0.4722
2024-01-10 22:09:24,625 - GAugM EPNet train, Epoch [  9/190]: loss 0.7209, auc 0.4144, ap 0.4567
2024-01-10 22:09:24,713 - GAugM EPNet train, Epoch [ 10/190]: loss 0.7208, auc 0.5400, ap 0.5629
2024-01-10 22:09:24,802 - GAugM EPNet train, Epoch [ 11/190]: loss 0.7209, auc 0.4511, ap 0.4916
2024-01-10 22:09:24,887 - GAugM EPNet train, Epoch [ 12/190]: loss 0.7210, auc 0.4646, ap 0.4752
2024-01-10 22:09:24,971 - GAugM EPNet train, Epoch [ 13/190]: loss 0.7209, auc 0.6330, ap 0.6224
2024-01-10 22:09:25,052 - GAugM EPNet train, Epoch [ 14/190]: loss 0.7209, auc 0.5671, ap 0.5475
2024-01-10 22:09:25,138 - GAugM EPNet train, Epoch [ 15/190]: loss 0.7210, auc 0.3916, ap 0.4734
2024-01-10 22:09:25,226 - GAugM EPNet train, Epoch [ 16/190]: loss 0.7209, auc 0.5643, ap 0.5310
2024-01-10 22:09:25,303 - GAugM EPNet train, Epoch [ 17/190]: loss 0.7210, auc 0.5187, ap 0.5001
2024-01-10 22:09:25,381 - GAugM EPNet train, Epoch [ 18/190]: loss 0.7210, auc 0.5828, ap 0.5809
2024-01-10 22:09:25,455 - GAugM EPNet train, Epoch [ 19/190]: loss 0.7209, auc 0.5155, ap 0.5029
2024-01-10 22:09:25,541 - GAugM EPNet train, Epoch [ 20/190]: loss 0.7210, auc 0.4852, ap 0.5070
2024-01-10 22:09:25,616 - GAugM EPNet train, Epoch [ 21/190]: loss 0.7209, auc 0.5297, ap 0.5312
2024-01-10 22:09:25,696 - GAugM EPNet train, Epoch [ 22/190]: loss 0.7210, auc 0.4454, ap 0.4782
2024-01-10 22:09:25,773 - GAugM EPNet train, Epoch [ 23/190]: loss 0.7208, auc 0.5529, ap 0.5625
2024-01-10 22:09:25,853 - GAugM EPNet train, Epoch [ 24/190]: loss 0.7209, auc 0.5781, ap 0.5821
2024-01-10 22:09:25,933 - GAugM EPNet train, Epoch [ 25/190]: loss 0.7209, auc 0.4713, ap 0.5179
2024-01-10 22:09:26,017 - GAugM EPNet train, Epoch [ 26/190]: loss 0.7210, auc 0.5874, ap 0.6117
2024-01-10 22:09:26,098 - GAugM EPNet train, Epoch [ 27/190]: loss 0.7209, auc 0.4083, ap 0.4739
2024-01-10 22:09:26,187 - GAugM EPNet train, Epoch [ 28/190]: loss 0.7209, auc 0.5212, ap 0.5240
2024-01-10 22:09:26,280 - GAugM EPNet train, Epoch [ 29/190]: loss 0.7210, auc 0.5037, ap 0.5078
2024-01-10 22:09:26,367 - GAugM EPNet train, Epoch [ 30/190]: loss 0.7209, auc 0.5319, ap 0.5821
2024-01-10 22:09:26,452 - GAugM EPNet train, Epoch [ 31/190]: loss 0.7208, auc 0.5732, ap 0.5953
2024-01-10 22:09:26,548 - GAugM EPNet train, Epoch [ 32/190]: loss 0.7210, auc 0.6041, ap 0.5782
2024-01-10 22:09:26,639 - GAugM EPNet train, Epoch [ 33/190]: loss 0.7209, auc 0.5262, ap 0.5576
2024-01-10 22:09:26,731 - GAugM EPNet train, Epoch [ 34/190]: loss 0.7209, auc 0.4122, ap 0.4302
2024-01-10 22:09:26,823 - GAugM EPNet train, Epoch [ 35/190]: loss 0.7209, auc 0.4639, ap 0.4984
2024-01-10 22:09:26,917 - GAugM EPNet train, Epoch [ 36/190]: loss 0.7209, auc 0.5660, ap 0.5586
2024-01-10 22:09:27,020 - GAugM EPNet train, Epoch [ 37/190]: loss 0.7209, auc 0.5094, ap 0.4928
2024-01-10 22:09:27,097 - GAugM EPNet train, Epoch [ 38/190]: loss 0.7209, auc 0.5016, ap 0.5002
2024-01-10 22:09:27,173 - GAugM EPNet train, Epoch [ 39/190]: loss 0.7208, auc 0.4115, ap 0.4816
2024-01-10 22:09:27,248 - GAugM EPNet train, Epoch [ 40/190]: loss 0.7210, auc 0.5618, ap 0.5326
2024-01-10 22:09:27,339 - GAugM EPNet train, Epoch [ 41/190]: loss 0.7210, auc 0.5183, ap 0.5774
2024-01-10 22:09:27,418 - GAugM EPNet train, Epoch [ 42/190]: loss 0.7209, auc 0.5336, ap 0.5922
2024-01-10 22:09:27,492 - GAugM EPNet train, Epoch [ 43/190]: loss 0.7208, auc 0.4140, ap 0.4555
2024-01-10 22:09:27,577 - GAugM EPNet train, Epoch [ 44/190]: loss 0.7208, auc 0.4222, ap 0.4732
2024-01-10 22:09:27,653 - GAugM EPNet train, Epoch [ 45/190]: loss 0.7209, auc 0.5931, ap 0.6236
2024-01-10 22:09:27,736 - GAugM EPNet train, Epoch [ 46/190]: loss 0.7209, auc 0.4667, ap 0.4778
2024-01-10 22:09:27,811 - GAugM EPNet train, Epoch [ 47/190]: loss 0.7210, auc 0.4877, ap 0.5420
2024-01-10 22:09:27,886 - GAugM EPNet train, Epoch [ 48/190]: loss 0.7210, auc 0.6426, ap 0.6595
2024-01-10 22:09:27,959 - GAugM EPNet train, Epoch [ 49/190]: loss 0.7209, auc 0.5479, ap 0.5561
2024-01-10 22:09:28,032 - GAugM EPNet train, Epoch [ 50/190]: loss 0.7210, auc 0.4909, ap 0.5157
2024-01-10 22:09:28,107 - GAugM EPNet train, Epoch [ 51/190]: loss 0.7210, auc 0.5361, ap 0.5902
2024-01-10 22:09:28,184 - GAugM EPNet train, Epoch [ 52/190]: loss 0.7209, auc 0.5109, ap 0.5391
2024-01-10 22:09:28,260 - GAugM EPNet train, Epoch [ 53/190]: loss 0.7209, auc 0.5190, ap 0.5563
2024-01-10 22:09:28,338 - GAugM EPNet train, Epoch [ 54/190]: loss 0.7211, auc 0.6109, ap 0.6202
2024-01-10 22:09:28,418 - GAugM EPNet train, Epoch [ 55/190]: loss 0.7209, auc 0.5344, ap 0.5696
2024-01-10 22:09:28,502 - GAugM EPNet train, Epoch [ 56/190]: loss 0.7208, auc 0.5461, ap 0.5718
2024-01-10 22:09:28,576 - GAugM EPNet train, Epoch [ 57/190]: loss 0.7209, auc 0.4770, ap 0.4648
2024-01-10 22:09:28,652 - GAugM EPNet train, Epoch [ 58/190]: loss 0.7210, auc 0.5155, ap 0.5595
2024-01-10 22:09:28,727 - GAugM EPNet train, Epoch [ 59/190]: loss 0.7211, auc 0.5101, ap 0.5423
2024-01-10 22:09:28,805 - GAugM EPNet train, Epoch [ 60/190]: loss 0.7210, auc 0.5326, ap 0.5473
2024-01-10 22:09:28,882 - GAugM EPNet train, Epoch [ 61/190]: loss 0.7209, auc 0.4956, ap 0.5461
2024-01-10 22:09:28,967 - GAugM EPNet train, Epoch [ 62/190]: loss 0.7210, auc 0.5265, ap 0.5435
2024-01-10 22:09:29,050 - GAugM EPNet train, Epoch [ 63/190]: loss 0.7208, auc 0.5158, ap 0.5018
2024-01-10 22:09:29,136 - GAugM EPNet train, Epoch [ 64/190]: loss 0.7208, auc 0.4411, ap 0.4587
2024-01-10 22:09:29,220 - GAugM EPNet train, Epoch [ 65/190]: loss 0.7208, auc 0.5845, ap 0.5802
2024-01-10 22:09:29,308 - GAugM EPNet train, Epoch [ 66/190]: loss 0.7209, auc 0.4468, ap 0.4740
2024-01-10 22:09:29,393 - GAugM EPNet train, Epoch [ 67/190]: loss 0.7209, auc 0.5525, ap 0.5428
2024-01-10 22:09:29,475 - GAugM EPNet train, Epoch [ 68/190]: loss 0.7210, auc 0.5109, ap 0.5603
2024-01-10 22:09:29,560 - GAugM EPNet train, Epoch [ 69/190]: loss 0.7210, auc 0.4909, ap 0.5636
2024-01-10 22:09:29,646 - GAugM EPNet train, Epoch [ 70/190]: loss 0.7210, auc 0.4884, ap 0.4957
2024-01-10 22:09:29,731 - GAugM EPNet train, Epoch [ 71/190]: loss 0.7210, auc 0.5568, ap 0.5379
2024-01-10 22:09:29,819 - GAugM EPNet train, Epoch [ 72/190]: loss 0.7210, auc 0.4756, ap 0.5045
2024-01-10 22:09:29,904 - GAugM EPNet train, Epoch [ 73/190]: loss 0.7209, auc 0.5130, ap 0.4984
2024-01-10 22:09:29,989 - GAugM EPNet train, Epoch [ 74/190]: loss 0.7209, auc 0.4799, ap 0.5195
2024-01-10 22:09:30,074 - GAugM EPNet train, Epoch [ 75/190]: loss 0.7210, auc 0.4906, ap 0.5354
2024-01-10 22:09:30,159 - GAugM EPNet train, Epoch [ 76/190]: loss 0.7209, auc 0.4304, ap 0.4807
2024-01-10 22:09:30,242 - GAugM EPNet train, Epoch [ 77/190]: loss 0.7208, auc 0.4810, ap 0.5262
2024-01-10 22:09:30,324 - GAugM EPNet train, Epoch [ 78/190]: loss 0.7209, auc 0.4881, ap 0.5134
2024-01-10 22:09:30,405 - GAugM EPNet train, Epoch [ 79/190]: loss 0.7208, auc 0.5422, ap 0.5741
2024-01-10 22:09:30,491 - GAugM EPNet train, Epoch [ 80/190]: loss 0.7209, auc 0.5621, ap 0.5520
2024-01-10 22:09:30,577 - GAugM EPNet train, Epoch [ 81/190]: loss 0.7209, auc 0.5607, ap 0.5367
2024-01-10 22:09:30,661 - GAugM EPNet train, Epoch [ 82/190]: loss 0.7210, auc 0.5536, ap 0.5524
2024-01-10 22:09:30,748 - GAugM EPNet train, Epoch [ 83/190]: loss 0.7209, auc 0.4389, ap 0.5038
2024-01-10 22:09:30,832 - GAugM EPNet train, Epoch [ 84/190]: loss 0.7209, auc 0.4717, ap 0.5204
2024-01-10 22:09:30,919 - GAugM EPNet train, Epoch [ 85/190]: loss 0.7210, auc 0.5009, ap 0.5354
2024-01-10 22:09:31,007 - GAugM EPNet train, Epoch [ 86/190]: loss 0.7208, auc 0.4956, ap 0.4987
2024-01-10 22:09:31,087 - GAugM EPNet train, Epoch [ 87/190]: loss 0.7209, auc 0.5813, ap 0.5787
2024-01-10 22:09:31,179 - GAugM EPNet train, Epoch [ 88/190]: loss 0.7210, auc 0.5429, ap 0.5527
2024-01-10 22:09:31,268 - GAugM EPNet train, Epoch [ 89/190]: loss 0.7210, auc 0.4952, ap 0.5382
2024-01-10 22:09:31,355 - GAugM EPNet train, Epoch [ 90/190]: loss 0.7209, auc 0.4457, ap 0.4812
2024-01-10 22:09:31,435 - GAugM EPNet train, Epoch [ 91/190]: loss 0.7208, auc 0.5824, ap 0.5474
2024-01-10 22:09:31,516 - GAugM EPNet train, Epoch [ 92/190]: loss 0.7209, auc 0.5785, ap 0.5974
2024-01-10 22:09:31,604 - GAugM EPNet train, Epoch [ 93/190]: loss 0.7209, auc 0.3895, ap 0.4594
2024-01-10 22:09:31,688 - GAugM EPNet train, Epoch [ 94/190]: loss 0.7210, auc 0.4382, ap 0.4817
2024-01-10 22:09:31,772 - GAugM EPNet train, Epoch [ 95/190]: loss 0.7210, auc 0.4909, ap 0.5246
2024-01-10 22:09:31,858 - GAugM EPNet train, Epoch [ 96/190]: loss 0.7209, auc 0.5660, ap 0.5929
2024-01-10 22:09:31,953 - GAugM EPNet train, Epoch [ 97/190]: loss 0.7209, auc 0.4446, ap 0.4966
2024-01-10 22:09:32,040 - GAugM EPNet train, Epoch [ 98/190]: loss 0.7209, auc 0.3656, ap 0.4343
2024-01-10 22:09:32,122 - GAugM EPNet train, Epoch [ 99/190]: loss 0.7209, auc 0.4489, ap 0.4763
2024-01-10 22:09:32,223 - GAugM EPNet train, Epoch [100/190]: loss 0.7210, auc 0.4931, ap 0.5473
2024-01-10 22:09:32,307 - GAugM EPNet train, Epoch [101/190]: loss 0.7210, auc 0.4222, ap 0.5136
2024-01-10 22:09:32,398 - GAugM EPNet train, Epoch [102/190]: loss 0.7209, auc 0.4478, ap 0.4930
2024-01-10 22:09:32,484 - GAugM EPNet train, Epoch [103/190]: loss 0.7209, auc 0.4945, ap 0.5538
2024-01-10 22:09:32,569 - GAugM EPNet train, Epoch [104/190]: loss 0.7209, auc 0.4283, ap 0.4856
2024-01-10 22:09:32,645 - GAugM EPNet train, Epoch [105/190]: loss 0.7209, auc 0.4667, ap 0.4918
2024-01-10 22:09:32,731 - GAugM EPNet train, Epoch [106/190]: loss 0.7210, auc 0.4382, ap 0.4727
2024-01-10 22:09:32,836 - GAugM EPNet train, Epoch [107/190]: loss 0.7210, auc 0.4899, ap 0.5132
2024-01-10 22:09:32,927 - GAugM EPNet train, Epoch [108/190]: loss 0.7208, auc 0.4838, ap 0.5013
2024-01-10 22:09:33,016 - GAugM EPNet train, Epoch [109/190]: loss 0.7210, auc 0.5240, ap 0.5570
2024-01-10 22:09:33,105 - GAugM EPNet train, Epoch [110/190]: loss 0.7209, auc 0.5287, ap 0.5590
2024-01-10 22:09:33,196 - GAugM EPNet train, Epoch [111/190]: loss 0.7210, auc 0.4834, ap 0.5364
2024-01-10 22:09:33,289 - GAugM EPNet train, Epoch [112/190]: loss 0.7209, auc 0.4778, ap 0.4977
2024-01-10 22:09:33,382 - GAugM EPNet train, Epoch [113/190]: loss 0.7210, auc 0.4867, ap 0.5018
2024-01-10 22:09:33,468 - GAugM EPNet train, Epoch [114/190]: loss 0.7209, auc 0.4610, ap 0.4748
2024-01-10 22:09:33,552 - GAugM EPNet train, Epoch [115/190]: loss 0.7210, auc 0.4543, ap 0.4929
2024-01-10 22:09:33,636 - GAugM EPNet train, Epoch [116/190]: loss 0.7209, auc 0.4870, ap 0.5278
2024-01-10 22:09:33,722 - GAugM EPNet train, Epoch [117/190]: loss 0.7208, auc 0.3969, ap 0.4549
2024-01-10 22:09:33,810 - GAugM EPNet train, Epoch [118/190]: loss 0.7209, auc 0.4710, ap 0.4912
2024-01-10 22:09:33,908 - GAugM EPNet train, Epoch [119/190]: loss 0.7209, auc 0.5621, ap 0.5828
2024-01-10 22:09:33,993 - GAugM EPNet train, Epoch [120/190]: loss 0.7210, auc 0.4386, ap 0.4528
2024-01-10 22:09:34,077 - GAugM EPNet train, Epoch [121/190]: loss 0.7210, auc 0.4824, ap 0.5133
2024-01-10 22:09:34,166 - GAugM EPNet train, Epoch [122/190]: loss 0.7209, auc 0.4945, ap 0.5185
2024-01-10 22:09:34,255 - GAugM EPNet train, Epoch [123/190]: loss 0.7209, auc 0.4918, ap 0.5068
2024-01-10 22:09:34,340 - GAugM EPNet train, Epoch [124/190]: loss 0.7210, auc 0.4778, ap 0.5137
2024-01-10 22:09:34,426 - GAugM EPNet train, Epoch [125/190]: loss 0.7209, auc 0.4767, ap 0.4800
2024-01-10 22:09:34,509 - GAugM EPNet train, Epoch [126/190]: loss 0.7210, auc 0.5368, ap 0.5220
2024-01-10 22:09:34,591 - GAugM EPNet train, Epoch [127/190]: loss 0.7209, auc 0.5400, ap 0.5278
2024-01-10 22:09:34,678 - GAugM EPNet train, Epoch [128/190]: loss 0.7210, auc 0.4496, ap 0.4730
2024-01-10 22:09:34,763 - GAugM EPNet train, Epoch [129/190]: loss 0.7208, auc 0.4051, ap 0.4427
2024-01-10 22:09:34,846 - GAugM EPNet train, Epoch [130/190]: loss 0.7210, auc 0.5393, ap 0.5395
2024-01-10 22:09:34,930 - GAugM EPNet train, Epoch [131/190]: loss 0.7210, auc 0.5322, ap 0.5698
2024-01-10 22:09:35,017 - GAugM EPNet train, Epoch [132/190]: loss 0.7209, auc 0.5497, ap 0.5547
2024-01-10 22:09:35,100 - GAugM EPNet train, Epoch [133/190]: loss 0.7209, auc 0.5123, ap 0.5620
2024-01-10 22:09:35,177 - GAugM EPNet train, Epoch [134/190]: loss 0.7210, auc 0.4315, ap 0.5101
2024-01-10 22:09:35,253 - GAugM EPNet train, Epoch [135/190]: loss 0.7209, auc 0.4222, ap 0.4585
2024-01-10 22:09:35,333 - GAugM EPNet train, Epoch [136/190]: loss 0.7209, auc 0.5005, ap 0.4935
2024-01-10 22:09:35,409 - GAugM EPNet train, Epoch [137/190]: loss 0.7210, auc 0.4162, ap 0.4780
2024-01-10 22:09:35,501 - GAugM EPNet train, Epoch [138/190]: loss 0.7210, auc 0.5892, ap 0.5503
2024-01-10 22:09:35,586 - GAugM EPNet train, Epoch [139/190]: loss 0.7210, auc 0.4817, ap 0.5183
2024-01-10 22:09:35,669 - GAugM EPNet train, Epoch [140/190]: loss 0.7209, auc 0.5162, ap 0.5588
2024-01-10 22:09:35,747 - GAugM EPNet train, Epoch [141/190]: loss 0.7209, auc 0.5792, ap 0.5615
2024-01-10 22:09:35,825 - GAugM EPNet train, Epoch [142/190]: loss 0.7209, auc 0.4920, ap 0.5160
2024-01-10 22:09:35,903 - GAugM EPNet train, Epoch [143/190]: loss 0.7209, auc 0.3934, ap 0.4414
2024-01-10 22:09:35,986 - GAugM EPNet train, Epoch [144/190]: loss 0.7209, auc 0.5447, ap 0.5409
2024-01-10 22:09:36,066 - GAugM EPNet train, Epoch [145/190]: loss 0.7209, auc 0.4689, ap 0.5386
2024-01-10 22:09:36,152 - GAugM EPNet train, Epoch [146/190]: loss 0.7209, auc 0.4204, ap 0.4664
2024-01-10 22:09:36,232 - GAugM EPNet train, Epoch [147/190]: loss 0.7209, auc 0.5721, ap 0.6143
2024-01-10 22:09:36,325 - GAugM EPNet train, Epoch [148/190]: loss 0.7209, auc 0.5810, ap 0.6051
2024-01-10 22:09:36,413 - GAugM EPNet train, Epoch [149/190]: loss 0.7208, auc 0.4372, ap 0.4979
2024-01-10 22:09:36,505 - GAugM EPNet train, Epoch [150/190]: loss 0.7209, auc 0.4685, ap 0.4881
2024-01-10 22:09:36,593 - GAugM EPNet train, Epoch [151/190]: loss 0.7209, auc 0.5771, ap 0.5777
2024-01-10 22:09:36,673 - GAugM EPNet train, Epoch [152/190]: loss 0.7209, auc 0.5354, ap 0.5392
2024-01-10 22:09:36,760 - GAugM EPNet train, Epoch [153/190]: loss 0.7209, auc 0.4785, ap 0.4942
2024-01-10 22:09:36,848 - GAugM EPNet train, Epoch [154/190]: loss 0.7209, auc 0.5789, ap 0.6419
2024-01-10 22:09:36,936 - GAugM EPNet train, Epoch [155/190]: loss 0.7209, auc 0.4738, ap 0.5013
2024-01-10 22:09:37,031 - GAugM EPNet train, Epoch [156/190]: loss 0.7209, auc 0.4877, ap 0.5005
2024-01-10 22:09:37,111 - GAugM EPNet train, Epoch [157/190]: loss 0.7209, auc 0.5429, ap 0.5480
2024-01-10 22:09:37,187 - GAugM EPNet train, Epoch [158/190]: loss 0.7208, auc 0.4532, ap 0.4764
2024-01-10 22:09:37,269 - GAugM EPNet train, Epoch [159/190]: loss 0.7208, auc 0.4411, ap 0.4863
2024-01-10 22:09:37,356 - GAugM EPNet train, Epoch [160/190]: loss 0.7209, auc 0.4560, ap 0.4952
2024-01-10 22:09:37,433 - GAugM EPNet train, Epoch [161/190]: loss 0.7209, auc 0.5208, ap 0.5390
2024-01-10 22:09:37,506 - GAugM EPNet train, Epoch [162/190]: loss 0.7209, auc 0.4514, ap 0.4664
2024-01-10 22:09:37,582 - GAugM EPNet train, Epoch [163/190]: loss 0.7209, auc 0.4689, ap 0.4756
2024-01-10 22:09:37,657 - GAugM EPNet train, Epoch [164/190]: loss 0.7211, auc 0.5141, ap 0.5096
2024-01-10 22:09:37,733 - GAugM EPNet train, Epoch [165/190]: loss 0.7210, auc 0.4735, ap 0.5096
2024-01-10 22:09:37,820 - GAugM EPNet train, Epoch [166/190]: loss 0.7208, auc 0.5415, ap 0.5506
2024-01-10 22:09:37,901 - GAugM EPNet train, Epoch [167/190]: loss 0.7209, auc 0.5037, ap 0.5134
2024-01-10 22:09:37,978 - GAugM EPNet train, Epoch [168/190]: loss 0.7209, auc 0.4621, ap 0.5439
2024-01-10 22:09:38,054 - GAugM EPNet train, Epoch [169/190]: loss 0.7209, auc 0.5881, ap 0.5907
2024-01-10 22:09:38,140 - GAugM EPNet train, Epoch [170/190]: loss 0.7210, auc 0.5198, ap 0.5054
2024-01-10 22:09:38,229 - GAugM EPNet train, Epoch [171/190]: loss 0.7209, auc 0.4827, ap 0.4851
2024-01-10 22:09:38,321 - GAugM EPNet train, Epoch [172/190]: loss 0.7208, auc 0.4425, ap 0.4904
2024-01-10 22:09:38,403 - GAugM EPNet train, Epoch [173/190]: loss 0.7209, auc 0.5005, ap 0.5688
2024-01-10 22:09:38,492 - GAugM EPNet train, Epoch [174/190]: loss 0.7209, auc 0.5080, ap 0.5044
2024-01-10 22:09:38,580 - GAugM EPNet train, Epoch [175/190]: loss 0.7209, auc 0.6016, ap 0.5691
2024-01-10 22:09:38,669 - GAugM EPNet train, Epoch [176/190]: loss 0.7209, auc 0.4525, ap 0.4695
2024-01-10 22:09:38,751 - GAugM EPNet train, Epoch [177/190]: loss 0.7210, auc 0.4980, ap 0.5174
2024-01-10 22:09:38,828 - GAugM EPNet train, Epoch [178/190]: loss 0.7210, auc 0.4674, ap 0.5111
2024-01-10 22:09:38,919 - GAugM EPNet train, Epoch [179/190]: loss 0.7210, auc 0.3827, ap 0.4471
2024-01-10 22:09:39,010 - GAugM EPNet train, Epoch [180/190]: loss 0.7210, auc 0.4642, ap 0.5380
2024-01-10 22:09:39,091 - GAugM EPNet train, Epoch [181/190]: loss 0.7209, auc 0.4033, ap 0.4542
2024-01-10 22:09:39,176 - GAugM EPNet train, Epoch [182/190]: loss 0.7209, auc 0.4400, ap 0.4858
2024-01-10 22:09:39,257 - GAugM EPNet train, Epoch [183/190]: loss 0.7210, auc 0.4849, ap 0.5082
2024-01-10 22:09:39,346 - GAugM EPNet train, Epoch [184/190]: loss 0.7209, auc 0.4457, ap 0.5003
2024-01-10 22:09:39,435 - GAugM EPNet train, Epoch [185/190]: loss 0.7209, auc 0.4514, ap 0.5025
2024-01-10 22:09:39,513 - GAugM EPNet train, Epoch [186/190]: loss 0.7208, auc 0.4265, ap 0.5032
2024-01-10 22:09:39,610 - GAugM EPNet train, Epoch [187/190]: loss 0.7209, auc 0.5077, ap 0.5311
2024-01-10 22:09:39,697 - GAugM EPNet train, Epoch [188/190]: loss 0.7209, auc 0.5433, ap 0.5182
2024-01-10 22:09:39,788 - GAugM EPNet train, Epoch [189/190]: loss 0.7209, auc 0.5650, ap 0.5561
2024-01-10 22:09:39,874 - GAugM EPNet train, Epoch [190/190]: loss 0.7209, auc 0.4553, ap 0.4836
2024-01-10 22:09:39,894 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03bfc8d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:09:40,713 - GAugM EPNet train, Epoch [  1/190]: loss 0.7210, auc 0.5577, ap 0.5300
2024-01-10 22:09:40,810 - GAugM EPNet train, Epoch [  2/190]: loss 0.7210, auc 0.5278, ap 0.5217
2024-01-10 22:09:40,903 - GAugM EPNet train, Epoch [  3/190]: loss 0.7209, auc 0.5445, ap 0.5619
2024-01-10 22:09:40,995 - GAugM EPNet train, Epoch [  4/190]: loss 0.7209, auc 0.4388, ap 0.4839
2024-01-10 22:09:41,087 - GAugM EPNet train, Epoch [  5/190]: loss 0.7209, auc 0.5776, ap 0.5807
2024-01-10 22:09:41,184 - GAugM EPNet train, Epoch [  6/190]: loss 0.7209, auc 0.4594, ap 0.4950
2024-01-10 22:09:41,273 - GAugM EPNet train, Epoch [  7/190]: loss 0.7209, auc 0.4986, ap 0.5053
2024-01-10 22:09:41,365 - GAugM EPNet train, Epoch [  8/190]: loss 0.7210, auc 0.4751, ap 0.5117
2024-01-10 22:09:41,456 - GAugM EPNet train, Epoch [  9/190]: loss 0.7209, auc 0.5306, ap 0.5195
2024-01-10 22:09:41,538 - GAugM EPNet train, Epoch [ 10/190]: loss 0.7208, auc 0.4516, ap 0.4832
2024-01-10 22:09:41,620 - GAugM EPNet train, Epoch [ 11/190]: loss 0.7209, auc 0.4562, ap 0.5058
2024-01-10 22:09:41,699 - GAugM EPNet train, Epoch [ 12/190]: loss 0.7210, auc 0.5470, ap 0.5565
2024-01-10 22:09:41,775 - GAugM EPNet train, Epoch [ 13/190]: loss 0.7209, auc 0.5684, ap 0.5887
2024-01-10 22:09:41,859 - GAugM EPNet train, Epoch [ 14/190]: loss 0.7209, auc 0.4986, ap 0.5210
2024-01-10 22:09:41,936 - GAugM EPNet train, Epoch [ 15/190]: loss 0.7210, auc 0.3807, ap 0.4423
2024-01-10 22:09:42,017 - GAugM EPNet train, Epoch [ 16/190]: loss 0.7209, auc 0.5755, ap 0.5594
2024-01-10 22:09:42,093 - GAugM EPNet train, Epoch [ 17/190]: loss 0.7210, auc 0.5602, ap 0.5685
2024-01-10 22:09:42,173 - GAugM EPNet train, Epoch [ 18/190]: loss 0.7210, auc 0.6317, ap 0.6140
2024-01-10 22:09:42,249 - GAugM EPNet train, Epoch [ 19/190]: loss 0.7209, auc 0.5541, ap 0.5427
2024-01-10 22:09:42,338 - GAugM EPNet train, Epoch [ 20/190]: loss 0.7210, auc 0.4847, ap 0.5071
2024-01-10 22:09:42,414 - GAugM EPNet train, Epoch [ 21/190]: loss 0.7209, auc 0.5125, ap 0.5306
2024-01-10 22:09:42,494 - GAugM EPNet train, Epoch [ 22/190]: loss 0.7210, auc 0.3875, ap 0.4254
2024-01-10 22:09:42,571 - GAugM EPNet train, Epoch [ 23/190]: loss 0.7208, auc 0.4687, ap 0.4870
2024-01-10 22:09:42,653 - GAugM EPNet train, Epoch [ 24/190]: loss 0.7209, auc 0.5352, ap 0.5439
2024-01-10 22:09:42,728 - GAugM EPNet train, Epoch [ 25/190]: loss 0.7209, auc 0.4779, ap 0.4828
2024-01-10 22:09:42,808 - GAugM EPNet train, Epoch [ 26/190]: loss 0.7210, auc 0.6068, ap 0.6294
2024-01-10 22:09:42,884 - GAugM EPNet train, Epoch [ 27/190]: loss 0.7209, auc 0.4199, ap 0.4853
2024-01-10 22:09:42,961 - GAugM EPNet train, Epoch [ 28/190]: loss 0.7209, auc 0.5210, ap 0.5551
2024-01-10 22:09:43,042 - GAugM EPNet train, Epoch [ 29/190]: loss 0.7210, auc 0.5306, ap 0.5211
2024-01-10 22:09:43,120 - GAugM EPNet train, Epoch [ 30/190]: loss 0.7209, auc 0.5228, ap 0.5509
2024-01-10 22:09:43,195 - GAugM EPNet train, Epoch [ 31/190]: loss 0.7208, auc 0.5395, ap 0.5442
2024-01-10 22:09:43,278 - GAugM EPNet train, Epoch [ 32/190]: loss 0.7210, auc 0.5527, ap 0.5593
2024-01-10 22:09:43,354 - GAugM EPNet train, Epoch [ 33/190]: loss 0.7209, auc 0.5167, ap 0.5031
2024-01-10 22:09:43,433 - GAugM EPNet train, Epoch [ 34/190]: loss 0.7209, auc 0.4794, ap 0.4991
2024-01-10 22:09:43,509 - GAugM EPNet train, Epoch [ 35/190]: loss 0.7209, auc 0.5171, ap 0.5070
2024-01-10 22:09:43,584 - GAugM EPNet train, Epoch [ 36/190]: loss 0.7209, auc 0.6225, ap 0.5971
2024-01-10 22:09:43,660 - GAugM EPNet train, Epoch [ 37/190]: loss 0.7209, auc 0.4904, ap 0.5086
2024-01-10 22:09:43,744 - GAugM EPNet train, Epoch [ 38/190]: loss 0.7209, auc 0.4954, ap 0.4859
2024-01-10 22:09:43,820 - GAugM EPNet train, Epoch [ 39/190]: loss 0.7208, auc 0.3775, ap 0.4551
2024-01-10 22:09:43,897 - GAugM EPNet train, Epoch [ 40/190]: loss 0.7210, auc 0.4954, ap 0.5006
2024-01-10 22:09:43,972 - GAugM EPNet train, Epoch [ 41/190]: loss 0.7210, auc 0.4363, ap 0.4826
2024-01-10 22:09:44,057 - GAugM EPNet train, Epoch [ 42/190]: loss 0.7209, auc 0.4185, ap 0.4633
2024-01-10 22:09:44,133 - GAugM EPNet train, Epoch [ 43/190]: loss 0.7208, auc 0.4284, ap 0.4909
2024-01-10 22:09:44,207 - GAugM EPNet train, Epoch [ 44/190]: loss 0.7208, auc 0.3323, ap 0.4166
2024-01-10 22:09:44,285 - GAugM EPNet train, Epoch [ 45/190]: loss 0.7209, auc 0.5142, ap 0.5163
2024-01-10 22:09:44,362 - GAugM EPNet train, Epoch [ 46/190]: loss 0.7209, auc 0.4345, ap 0.4957
2024-01-10 22:09:44,438 - GAugM EPNet train, Epoch [ 47/190]: loss 0.7210, auc 0.4185, ap 0.4828
2024-01-10 22:09:44,514 - GAugM EPNet train, Epoch [ 48/190]: loss 0.7210, auc 0.6171, ap 0.6523
2024-01-10 22:09:44,589 - GAugM EPNet train, Epoch [ 49/190]: loss 0.7209, auc 0.4697, ap 0.4968
2024-01-10 22:09:44,668 - GAugM EPNet train, Epoch [ 50/190]: loss 0.7210, auc 0.4701, ap 0.4984
2024-01-10 22:09:44,743 - GAugM EPNet train, Epoch [ 51/190]: loss 0.7210, auc 0.4861, ap 0.5017
2024-01-10 22:09:44,831 - GAugM EPNet train, Epoch [ 52/190]: loss 0.7209, auc 0.4370, ap 0.4873
2024-01-10 22:09:44,914 - GAugM EPNet train, Epoch [ 53/190]: loss 0.7209, auc 0.5815, ap 0.5799
2024-01-10 22:09:45,005 - GAugM EPNet train, Epoch [ 54/190]: loss 0.7211, auc 0.5231, ap 0.5646
2024-01-10 22:09:45,095 - GAugM EPNet train, Epoch [ 55/190]: loss 0.7209, auc 0.6189, ap 0.6136
2024-01-10 22:09:45,187 - GAugM EPNet train, Epoch [ 56/190]: loss 0.7208, auc 0.5502, ap 0.5204
2024-01-10 22:09:45,269 - GAugM EPNet train, Epoch [ 57/190]: loss 0.7209, auc 0.4149, ap 0.4450
2024-01-10 22:09:45,355 - GAugM EPNet train, Epoch [ 58/190]: loss 0.7210, auc 0.5139, ap 0.5743
2024-01-10 22:09:45,446 - GAugM EPNet train, Epoch [ 59/190]: loss 0.7211, auc 0.4633, ap 0.4590
2024-01-10 22:09:45,536 - GAugM EPNet train, Epoch [ 60/190]: loss 0.7210, auc 0.5036, ap 0.5109
2024-01-10 22:09:45,621 - GAugM EPNet train, Epoch [ 61/190]: loss 0.7209, auc 0.5559, ap 0.5723
2024-01-10 22:09:45,709 - GAugM EPNet train, Epoch [ 62/190]: loss 0.7210, auc 0.4964, ap 0.4954
2024-01-10 22:09:45,796 - GAugM EPNet train, Epoch [ 63/190]: loss 0.7208, auc 0.5110, ap 0.4832
2024-01-10 22:09:45,882 - GAugM EPNet train, Epoch [ 64/190]: loss 0.7208, auc 0.5413, ap 0.5683
2024-01-10 22:09:45,973 - GAugM EPNet train, Epoch [ 65/190]: loss 0.7208, auc 0.6040, ap 0.6157
2024-01-10 22:09:46,062 - GAugM EPNet train, Epoch [ 66/190]: loss 0.7209, auc 0.4580, ap 0.5291
2024-01-10 22:09:46,148 - GAugM EPNet train, Epoch [ 67/190]: loss 0.7209, auc 0.4790, ap 0.4871
2024-01-10 22:09:46,234 - GAugM EPNet train, Epoch [ 68/190]: loss 0.7210, auc 0.4345, ap 0.4580
2024-01-10 22:09:46,325 - GAugM EPNet train, Epoch [ 69/190]: loss 0.7210, auc 0.5032, ap 0.5048
2024-01-10 22:09:46,414 - GAugM EPNet train, Epoch [ 70/190]: loss 0.7210, auc 0.3857, ap 0.4347
2024-01-10 22:09:46,508 - GAugM EPNet train, Epoch [ 71/190]: loss 0.7210, auc 0.5324, ap 0.5433
2024-01-10 22:09:46,605 - GAugM EPNet train, Epoch [ 72/190]: loss 0.7210, auc 0.4754, ap 0.5077
2024-01-10 22:09:46,692 - GAugM EPNet train, Epoch [ 73/190]: loss 0.7209, auc 0.4601, ap 0.4694
2024-01-10 22:09:46,782 - GAugM EPNet train, Epoch [ 74/190]: loss 0.7209, auc 0.4708, ap 0.4719
2024-01-10 22:09:46,866 - GAugM EPNet train, Epoch [ 75/190]: loss 0.7210, auc 0.4199, ap 0.4661
2024-01-10 22:09:46,950 - GAugM EPNet train, Epoch [ 76/190]: loss 0.7209, auc 0.4566, ap 0.4789
2024-01-10 22:09:47,040 - GAugM EPNet train, Epoch [ 77/190]: loss 0.7208, auc 0.6513, ap 0.6340
2024-01-10 22:09:47,129 - GAugM EPNet train, Epoch [ 78/190]: loss 0.7209, auc 0.4836, ap 0.4937
2024-01-10 22:09:47,220 - GAugM EPNet train, Epoch [ 79/190]: loss 0.7208, auc 0.5139, ap 0.5300
2024-01-10 22:09:47,308 - GAugM EPNet train, Epoch [ 80/190]: loss 0.7209, auc 0.6004, ap 0.5759
2024-01-10 22:09:47,405 - GAugM EPNet train, Epoch [ 81/190]: loss 0.7209, auc 0.4672, ap 0.4872
2024-01-10 22:09:47,494 - GAugM EPNet train, Epoch [ 82/190]: loss 0.7210, auc 0.4626, ap 0.4712
2024-01-10 22:09:47,582 - GAugM EPNet train, Epoch [ 83/190]: loss 0.7209, auc 0.4345, ap 0.4827
2024-01-10 22:09:47,672 - GAugM EPNet train, Epoch [ 84/190]: loss 0.7209, auc 0.4705, ap 0.4814
2024-01-10 22:09:47,766 - GAugM EPNet train, Epoch [ 85/190]: loss 0.7210, auc 0.3661, ap 0.4181
2024-01-10 22:09:47,857 - GAugM EPNet train, Epoch [ 86/190]: loss 0.7208, auc 0.4915, ap 0.5187
2024-01-10 22:09:47,949 - GAugM EPNet train, Epoch [ 87/190]: loss 0.7209, auc 0.5705, ap 0.5618
2024-01-10 22:09:48,046 - GAugM EPNet train, Epoch [ 88/190]: loss 0.7210, auc 0.4669, ap 0.5119
2024-01-10 22:09:48,140 - GAugM EPNet train, Epoch [ 89/190]: loss 0.7210, auc 0.3914, ap 0.4800
2024-01-10 22:09:48,232 - GAugM EPNet train, Epoch [ 90/190]: loss 0.7209, auc 0.4384, ap 0.5012
2024-01-10 22:09:48,328 - GAugM EPNet train, Epoch [ 91/190]: loss 0.7208, auc 0.5669, ap 0.5385
2024-01-10 22:09:48,425 - GAugM EPNet train, Epoch [ 92/190]: loss 0.7209, auc 0.5598, ap 0.5574
2024-01-10 22:09:48,517 - GAugM EPNet train, Epoch [ 93/190]: loss 0.7209, auc 0.4672, ap 0.4963
2024-01-10 22:09:48,610 - GAugM EPNet train, Epoch [ 94/190]: loss 0.7210, auc 0.4203, ap 0.4701
2024-01-10 22:09:48,701 - GAugM EPNet train, Epoch [ 95/190]: loss 0.7210, auc 0.5481, ap 0.5304
2024-01-10 22:09:48,793 - GAugM EPNet train, Epoch [ 96/190]: loss 0.7209, auc 0.5317, ap 0.5538
2024-01-10 22:09:48,888 - GAugM EPNet train, Epoch [ 97/190]: loss 0.7209, auc 0.4747, ap 0.5028
2024-01-10 22:09:48,979 - GAugM EPNet train, Epoch [ 98/190]: loss 0.7209, auc 0.4288, ap 0.4502
2024-01-10 22:09:49,074 - GAugM EPNet train, Epoch [ 99/190]: loss 0.7209, auc 0.4605, ap 0.5019
2024-01-10 22:09:49,165 - GAugM EPNet train, Epoch [100/190]: loss 0.7210, auc 0.4925, ap 0.5214
2024-01-10 22:09:49,260 - GAugM EPNet train, Epoch [101/190]: loss 0.7210, auc 0.4017, ap 0.4828
2024-01-10 22:09:49,354 - GAugM EPNet train, Epoch [102/190]: loss 0.7209, auc 0.4064, ap 0.4297
2024-01-10 22:09:49,455 - GAugM EPNet train, Epoch [103/190]: loss 0.7209, auc 0.5669, ap 0.5820
2024-01-10 22:09:49,538 - GAugM EPNet train, Epoch [104/190]: loss 0.7209, auc 0.4655, ap 0.4861
2024-01-10 22:09:49,618 - GAugM EPNet train, Epoch [105/190]: loss 0.7209, auc 0.4174, ap 0.4543
2024-01-10 22:09:49,712 - GAugM EPNet train, Epoch [106/190]: loss 0.7210, auc 0.4676, ap 0.4680
2024-01-10 22:09:49,815 - GAugM EPNet train, Epoch [107/190]: loss 0.7210, auc 0.5157, ap 0.5494
2024-01-10 22:09:49,893 - GAugM EPNet train, Epoch [108/190]: loss 0.7208, auc 0.5374, ap 0.5343
2024-01-10 22:09:49,983 - GAugM EPNet train, Epoch [109/190]: loss 0.7210, auc 0.4900, ap 0.5124
2024-01-10 22:09:50,071 - GAugM EPNet train, Epoch [110/190]: loss 0.7209, auc 0.4256, ap 0.4416
2024-01-10 22:09:50,158 - GAugM EPNet train, Epoch [111/190]: loss 0.7210, auc 0.5292, ap 0.5612
2024-01-10 22:09:50,244 - GAugM EPNet train, Epoch [112/190]: loss 0.7209, auc 0.6314, ap 0.6156
2024-01-10 22:09:50,332 - GAugM EPNet train, Epoch [113/190]: loss 0.7210, auc 0.4993, ap 0.5106
2024-01-10 22:09:50,416 - GAugM EPNet train, Epoch [114/190]: loss 0.7209, auc 0.4672, ap 0.4739
2024-01-10 22:09:50,503 - GAugM EPNet train, Epoch [115/190]: loss 0.7210, auc 0.5377, ap 0.5383
2024-01-10 22:09:50,593 - GAugM EPNet train, Epoch [116/190]: loss 0.7209, auc 0.4712, ap 0.4952
2024-01-10 22:09:50,677 - GAugM EPNet train, Epoch [117/190]: loss 0.7208, auc 0.4519, ap 0.4866
2024-01-10 22:09:50,768 - GAugM EPNet train, Epoch [118/190]: loss 0.7209, auc 0.4840, ap 0.5244
2024-01-10 22:09:50,858 - GAugM EPNet train, Epoch [119/190]: loss 0.7209, auc 0.4612, ap 0.5103
2024-01-10 22:09:50,949 - GAugM EPNet train, Epoch [120/190]: loss 0.7210, auc 0.5018, ap 0.4820
2024-01-10 22:09:51,035 - GAugM EPNet train, Epoch [121/190]: loss 0.7210, auc 0.4626, ap 0.4861
2024-01-10 22:09:51,126 - GAugM EPNet train, Epoch [122/190]: loss 0.7209, auc 0.4484, ap 0.4629
2024-01-10 22:09:51,214 - GAugM EPNet train, Epoch [123/190]: loss 0.7209, auc 0.5075, ap 0.5199
2024-01-10 22:09:51,299 - GAugM EPNet train, Epoch [124/190]: loss 0.7210, auc 0.4977, ap 0.5209
2024-01-10 22:09:51,390 - GAugM EPNet train, Epoch [125/190]: loss 0.7209, auc 0.5897, ap 0.5785
2024-01-10 22:09:51,482 - GAugM EPNet train, Epoch [126/190]: loss 0.7210, auc 0.5392, ap 0.5194
2024-01-10 22:09:51,568 - GAugM EPNet train, Epoch [127/190]: loss 0.7209, auc 0.5178, ap 0.5051
2024-01-10 22:09:51,655 - GAugM EPNet train, Epoch [128/190]: loss 0.7210, auc 0.4929, ap 0.5033
2024-01-10 22:09:51,744 - GAugM EPNet train, Epoch [129/190]: loss 0.7208, auc 0.3491, ap 0.4265
2024-01-10 22:09:51,826 - GAugM EPNet train, Epoch [130/190]: loss 0.7210, auc 0.5082, ap 0.5368
2024-01-10 22:09:51,911 - GAugM EPNet train, Epoch [131/190]: loss 0.7210, auc 0.4559, ap 0.4971
2024-01-10 22:09:51,995 - GAugM EPNet train, Epoch [132/190]: loss 0.7209, auc 0.5089, ap 0.5166
2024-01-10 22:09:52,092 - GAugM EPNet train, Epoch [133/190]: loss 0.7209, auc 0.5053, ap 0.5276
2024-01-10 22:09:52,175 - GAugM EPNet train, Epoch [134/190]: loss 0.7210, auc 0.5744, ap 0.5836
2024-01-10 22:09:52,262 - GAugM EPNet train, Epoch [135/190]: loss 0.7209, auc 0.3904, ap 0.4450
2024-01-10 22:09:52,354 - GAugM EPNet train, Epoch [136/190]: loss 0.7209, auc 0.4644, ap 0.5103
2024-01-10 22:09:52,445 - GAugM EPNet train, Epoch [137/190]: loss 0.7210, auc 0.4021, ap 0.4621
2024-01-10 22:09:52,532 - GAugM EPNet train, Epoch [138/190]: loss 0.7210, auc 0.5452, ap 0.5244
2024-01-10 22:09:52,615 - GAugM EPNet train, Epoch [139/190]: loss 0.7210, auc 0.4961, ap 0.5181
2024-01-10 22:09:52,694 - GAugM EPNet train, Epoch [140/190]: loss 0.7209, auc 0.5082, ap 0.5420
2024-01-10 22:09:52,768 - GAugM EPNet train, Epoch [141/190]: loss 0.7209, auc 0.5627, ap 0.5234
2024-01-10 22:09:52,858 - GAugM EPNet train, Epoch [142/190]: loss 0.7209, auc 0.5862, ap 0.5927
2024-01-10 22:09:52,935 - GAugM EPNet train, Epoch [143/190]: loss 0.7209, auc 0.4534, ap 0.4676
2024-01-10 22:09:53,014 - GAugM EPNet train, Epoch [144/190]: loss 0.7209, auc 0.4801, ap 0.4822
2024-01-10 22:09:53,104 - GAugM EPNet train, Epoch [145/190]: loss 0.7209, auc 0.4854, ap 0.5508
2024-01-10 22:09:53,200 - GAugM EPNet train, Epoch [146/190]: loss 0.7209, auc 0.5890, ap 0.6015
2024-01-10 22:09:53,299 - GAugM EPNet train, Epoch [147/190]: loss 0.7209, auc 0.5481, ap 0.5695
2024-01-10 22:09:53,393 - GAugM EPNet train, Epoch [148/190]: loss 0.7209, auc 0.4373, ap 0.4749
2024-01-10 22:09:53,492 - GAugM EPNet train, Epoch [149/190]: loss 0.7208, auc 0.4416, ap 0.4802
2024-01-10 22:09:53,580 - GAugM EPNet train, Epoch [150/190]: loss 0.7209, auc 0.5182, ap 0.5199
2024-01-10 22:09:53,675 - GAugM EPNet train, Epoch [151/190]: loss 0.7209, auc 0.5595, ap 0.5486
2024-01-10 22:09:53,765 - GAugM EPNet train, Epoch [152/190]: loss 0.7209, auc 0.5651, ap 0.5650
2024-01-10 22:09:53,865 - GAugM EPNet train, Epoch [153/190]: loss 0.7209, auc 0.4996, ap 0.5217
2024-01-10 22:09:53,955 - GAugM EPNet train, Epoch [154/190]: loss 0.7209, auc 0.5516, ap 0.6124
2024-01-10 22:09:54,051 - GAugM EPNet train, Epoch [155/190]: loss 0.7209, auc 0.5114, ap 0.5401
2024-01-10 22:09:54,143 - GAugM EPNet train, Epoch [156/190]: loss 0.7209, auc 0.4644, ap 0.4686
2024-01-10 22:09:54,233 - GAugM EPNet train, Epoch [157/190]: loss 0.7209, auc 0.4911, ap 0.4836
2024-01-10 22:09:54,332 - GAugM EPNet train, Epoch [158/190]: loss 0.7208, auc 0.4505, ap 0.4842
2024-01-10 22:09:54,413 - GAugM EPNet train, Epoch [159/190]: loss 0.7208, auc 0.5345, ap 0.5059
2024-01-10 22:09:54,491 - GAugM EPNet train, Epoch [160/190]: loss 0.7209, auc 0.5338, ap 0.5492
2024-01-10 22:09:54,582 - GAugM EPNet train, Epoch [161/190]: loss 0.7209, auc 0.5797, ap 0.5901
2024-01-10 22:09:54,674 - GAugM EPNet train, Epoch [162/190]: loss 0.7209, auc 0.4416, ap 0.4693
2024-01-10 22:09:54,761 - GAugM EPNet train, Epoch [163/190]: loss 0.7209, auc 0.4790, ap 0.4799
2024-01-10 22:09:54,850 - GAugM EPNet train, Epoch [164/190]: loss 0.7211, auc 0.5495, ap 0.5217
2024-01-10 22:09:54,938 - GAugM EPNet train, Epoch [165/190]: loss 0.7210, auc 0.4213, ap 0.4705
2024-01-10 22:09:55,023 - GAugM EPNet train, Epoch [166/190]: loss 0.7208, auc 0.5990, ap 0.5994
2024-01-10 22:09:55,108 - GAugM EPNet train, Epoch [167/190]: loss 0.7209, auc 0.4491, ap 0.4700
2024-01-10 22:09:55,194 - GAugM EPNet train, Epoch [168/190]: loss 0.7209, auc 0.4861, ap 0.5335
2024-01-10 22:09:55,279 - GAugM EPNet train, Epoch [169/190]: loss 0.7209, auc 0.5651, ap 0.5782
2024-01-10 22:09:55,364 - GAugM EPNet train, Epoch [170/190]: loss 0.7210, auc 0.4797, ap 0.4759
2024-01-10 22:09:55,449 - GAugM EPNet train, Epoch [171/190]: loss 0.7209, auc 0.4167, ap 0.4743
2024-01-10 22:09:55,539 - GAugM EPNet train, Epoch [172/190]: loss 0.7208, auc 0.5110, ap 0.5192
2024-01-10 22:09:55,623 - GAugM EPNet train, Epoch [173/190]: loss 0.7209, auc 0.4890, ap 0.5281
2024-01-10 22:09:55,706 - GAugM EPNet train, Epoch [174/190]: loss 0.7209, auc 0.5007, ap 0.5143
2024-01-10 22:09:55,790 - GAugM EPNet train, Epoch [175/190]: loss 0.7209, auc 0.6054, ap 0.5887
2024-01-10 22:09:55,875 - GAugM EPNet train, Epoch [176/190]: loss 0.7209, auc 0.4363, ap 0.4482
2024-01-10 22:09:55,959 - GAugM EPNet train, Epoch [177/190]: loss 0.7210, auc 0.5082, ap 0.4869
2024-01-10 22:09:56,045 - GAugM EPNet train, Epoch [178/190]: loss 0.7210, auc 0.5142, ap 0.5215
2024-01-10 22:09:56,135 - GAugM EPNet train, Epoch [179/190]: loss 0.7210, auc 0.4438, ap 0.5067
2024-01-10 22:09:56,220 - GAugM EPNet train, Epoch [180/190]: loss 0.7210, auc 0.5196, ap 0.5647
2024-01-10 22:09:56,312 - GAugM EPNet train, Epoch [181/190]: loss 0.7209, auc 0.4690, ap 0.4922
2024-01-10 22:09:56,404 - GAugM EPNet train, Epoch [182/190]: loss 0.7209, auc 0.4388, ap 0.4683
2024-01-10 22:09:56,489 - GAugM EPNet train, Epoch [183/190]: loss 0.7210, auc 0.5424, ap 0.5369
2024-01-10 22:09:56,582 - GAugM EPNet train, Epoch [184/190]: loss 0.7209, auc 0.5630, ap 0.5645
2024-01-10 22:09:56,671 - GAugM EPNet train, Epoch [185/190]: loss 0.7209, auc 0.5164, ap 0.5378
2024-01-10 22:09:56,758 - GAugM EPNet train, Epoch [186/190]: loss 0.7208, auc 0.4391, ap 0.4686
2024-01-10 22:09:56,843 - GAugM EPNet train, Epoch [187/190]: loss 0.7209, auc 0.4989, ap 0.5017
2024-01-10 22:09:56,927 - GAugM EPNet train, Epoch [188/190]: loss 0.7209, auc 0.4761, ap 0.4815
2024-01-10 22:09:57,022 - GAugM EPNet train, Epoch [189/190]: loss 0.7209, auc 0.6036, ap 0.6005
2024-01-10 22:09:57,112 - GAugM EPNet train, Epoch [190/190]: loss 0.7209, auc 0.3864, ap 0.4226
2024-01-10 22:09:57,117 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035e58d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:09:57,891 - GAugM EPNet train, Epoch [  1/190]: loss 0.7210, auc 0.4158, ap 0.4550
2024-01-10 22:09:57,979 - GAugM EPNet train, Epoch [  2/190]: loss 0.7210, auc 0.5287, ap 0.5030
2024-01-10 22:09:58,069 - GAugM EPNet train, Epoch [  3/190]: loss 0.7209, auc 0.5315, ap 0.5331
2024-01-10 22:09:58,162 - GAugM EPNet train, Epoch [  4/190]: loss 0.7209, auc 0.5297, ap 0.5535
2024-01-10 22:09:58,246 - GAugM EPNet train, Epoch [  5/190]: loss 0.7209, auc 0.6066, ap 0.6050
2024-01-10 22:09:58,327 - GAugM EPNet train, Epoch [  6/190]: loss 0.7209, auc 0.5201, ap 0.5001
2024-01-10 22:09:58,412 - GAugM EPNet train, Epoch [  7/190]: loss 0.7209, auc 0.3873, ap 0.4341
2024-01-10 22:09:58,486 - GAugM EPNet train, Epoch [  8/190]: loss 0.7210, auc 0.4457, ap 0.4712
2024-01-10 22:09:58,568 - GAugM EPNet train, Epoch [  9/190]: loss 0.7209, auc 0.4795, ap 0.4947
2024-01-10 22:09:58,652 - GAugM EPNet train, Epoch [ 10/190]: loss 0.7208, auc 0.5465, ap 0.5221
2024-01-10 22:09:58,728 - GAugM EPNet train, Epoch [ 11/190]: loss 0.7209, auc 0.5126, ap 0.5413
2024-01-10 22:09:58,818 - GAugM EPNet train, Epoch [ 12/190]: loss 0.7210, auc 0.4279, ap 0.4612
2024-01-10 22:09:58,911 - GAugM EPNet train, Epoch [ 13/190]: loss 0.7209, auc 0.5760, ap 0.5820
2024-01-10 22:09:58,989 - GAugM EPNet train, Epoch [ 14/190]: loss 0.7209, auc 0.5646, ap 0.5397
2024-01-10 22:09:59,082 - GAugM EPNet train, Epoch [ 15/190]: loss 0.7210, auc 0.4115, ap 0.4520
2024-01-10 22:09:59,161 - GAugM EPNet train, Epoch [ 16/190]: loss 0.7209, auc 0.5009, ap 0.5393
2024-01-10 22:09:59,244 - GAugM EPNet train, Epoch [ 17/190]: loss 0.7210, auc 0.5603, ap 0.5388
2024-01-10 22:09:59,320 - GAugM EPNet train, Epoch [ 18/190]: loss 0.7210, auc 0.6013, ap 0.6095
2024-01-10 22:09:59,397 - GAugM EPNet train, Epoch [ 19/190]: loss 0.7209, auc 0.5667, ap 0.5392
2024-01-10 22:09:59,476 - GAugM EPNet train, Epoch [ 20/190]: loss 0.7210, auc 0.4763, ap 0.4997
2024-01-10 22:09:59,552 - GAugM EPNet train, Epoch [ 21/190]: loss 0.7209, auc 0.4635, ap 0.4960
2024-01-10 22:09:59,626 - GAugM EPNet train, Epoch [ 22/190]: loss 0.7210, auc 0.4535, ap 0.4520
2024-01-10 22:09:59,700 - GAugM EPNet train, Epoch [ 23/190]: loss 0.7208, auc 0.5109, ap 0.5236
2024-01-10 22:09:59,774 - GAugM EPNet train, Epoch [ 24/190]: loss 0.7209, auc 0.5233, ap 0.5405
2024-01-10 22:09:59,847 - GAugM EPNet train, Epoch [ 25/190]: loss 0.7209, auc 0.4514, ap 0.4682
2024-01-10 22:09:59,922 - GAugM EPNet train, Epoch [ 26/190]: loss 0.7210, auc 0.5578, ap 0.5462
2024-01-10 22:10:00,001 - GAugM EPNet train, Epoch [ 27/190]: loss 0.7209, auc 0.4671, ap 0.5196
2024-01-10 22:10:00,072 - GAugM EPNet train, Epoch [ 28/190]: loss 0.7209, auc 0.6643, ap 0.6578
2024-01-10 22:10:00,152 - GAugM EPNet train, Epoch [ 29/190]: loss 0.7210, auc 0.5700, ap 0.5758
2024-01-10 22:10:00,225 - GAugM EPNet train, Epoch [ 30/190]: loss 0.7209, auc 0.5351, ap 0.5637
2024-01-10 22:10:00,298 - GAugM EPNet train, Epoch [ 31/190]: loss 0.7208, auc 0.4973, ap 0.5064
2024-01-10 22:10:00,375 - GAugM EPNet train, Epoch [ 32/190]: loss 0.7210, auc 0.5415, ap 0.5260
2024-01-10 22:10:00,451 - GAugM EPNet train, Epoch [ 33/190]: loss 0.7209, auc 0.6148, ap 0.6026
2024-01-10 22:10:00,527 - GAugM EPNet train, Epoch [ 34/190]: loss 0.7209, auc 0.4425, ap 0.4747
2024-01-10 22:10:00,602 - GAugM EPNet train, Epoch [ 35/190]: loss 0.7209, auc 0.5237, ap 0.5127
2024-01-10 22:10:00,674 - GAugM EPNet train, Epoch [ 36/190]: loss 0.7209, auc 0.5685, ap 0.5641
2024-01-10 22:10:00,749 - GAugM EPNet train, Epoch [ 37/190]: loss 0.7209, auc 0.4400, ap 0.4643
2024-01-10 22:10:00,829 - GAugM EPNet train, Epoch [ 38/190]: loss 0.7209, auc 0.4400, ap 0.4585
2024-01-10 22:10:00,915 - GAugM EPNet train, Epoch [ 39/190]: loss 0.7208, auc 0.4475, ap 0.4951
2024-01-10 22:10:00,991 - GAugM EPNet train, Epoch [ 40/190]: loss 0.7210, auc 0.5774, ap 0.5637
2024-01-10 22:10:01,067 - GAugM EPNet train, Epoch [ 41/190]: loss 0.7210, auc 0.5546, ap 0.5356
2024-01-10 22:10:01,144 - GAugM EPNet train, Epoch [ 42/190]: loss 0.7209, auc 0.5422, ap 0.5763
2024-01-10 22:10:01,228 - GAugM EPNet train, Epoch [ 43/190]: loss 0.7208, auc 0.4475, ap 0.4994
2024-01-10 22:10:01,313 - GAugM EPNet train, Epoch [ 44/190]: loss 0.7208, auc 0.3813, ap 0.4342
2024-01-10 22:10:01,392 - GAugM EPNet train, Epoch [ 45/190]: loss 0.7209, auc 0.5593, ap 0.5671
2024-01-10 22:10:01,467 - GAugM EPNet train, Epoch [ 46/190]: loss 0.7209, auc 0.4575, ap 0.4751
2024-01-10 22:10:01,550 - GAugM EPNet train, Epoch [ 47/190]: loss 0.7210, auc 0.5621, ap 0.5363
2024-01-10 22:10:01,627 - GAugM EPNet train, Epoch [ 48/190]: loss 0.7210, auc 0.5931, ap 0.6128
2024-01-10 22:10:01,709 - GAugM EPNet train, Epoch [ 49/190]: loss 0.7209, auc 0.5568, ap 0.5629
2024-01-10 22:10:01,786 - GAugM EPNet train, Epoch [ 50/190]: loss 0.7210, auc 0.4995, ap 0.5104
2024-01-10 22:10:01,859 - GAugM EPNet train, Epoch [ 51/190]: loss 0.7210, auc 0.3571, ap 0.4199
2024-01-10 22:10:01,944 - GAugM EPNet train, Epoch [ 52/190]: loss 0.7209, auc 0.4610, ap 0.4961
2024-01-10 22:10:02,017 - GAugM EPNet train, Epoch [ 53/190]: loss 0.7209, auc 0.5578, ap 0.5675
2024-01-10 22:10:02,092 - GAugM EPNet train, Epoch [ 54/190]: loss 0.7211, auc 0.5771, ap 0.5803
2024-01-10 22:10:02,173 - GAugM EPNet train, Epoch [ 55/190]: loss 0.7209, auc 0.5486, ap 0.5477
2024-01-10 22:10:02,261 - GAugM EPNet train, Epoch [ 56/190]: loss 0.7208, auc 0.4389, ap 0.4663
2024-01-10 22:10:02,344 - GAugM EPNet train, Epoch [ 57/190]: loss 0.7209, auc 0.5080, ap 0.4771
2024-01-10 22:10:02,421 - GAugM EPNet train, Epoch [ 58/190]: loss 0.7210, auc 0.4454, ap 0.4993
2024-01-10 22:10:02,496 - GAugM EPNet train, Epoch [ 59/190]: loss 0.7211, auc 0.5119, ap 0.5053
2024-01-10 22:10:02,581 - GAugM EPNet train, Epoch [ 60/190]: loss 0.7210, auc 0.5618, ap 0.5684
2024-01-10 22:10:02,660 - GAugM EPNet train, Epoch [ 61/190]: loss 0.7209, auc 0.4906, ap 0.4902
2024-01-10 22:10:02,737 - GAugM EPNet train, Epoch [ 62/190]: loss 0.7210, auc 0.5404, ap 0.5514
2024-01-10 22:10:02,813 - GAugM EPNet train, Epoch [ 63/190]: loss 0.7208, auc 0.4361, ap 0.4506
2024-01-10 22:10:02,903 - GAugM EPNet train, Epoch [ 64/190]: loss 0.7208, auc 0.4763, ap 0.4976
2024-01-10 22:10:02,984 - GAugM EPNet train, Epoch [ 65/190]: loss 0.7208, auc 0.5411, ap 0.5502
2024-01-10 22:10:03,059 - GAugM EPNet train, Epoch [ 66/190]: loss 0.7209, auc 0.4553, ap 0.4843
2024-01-10 22:10:03,136 - GAugM EPNet train, Epoch [ 67/190]: loss 0.7209, auc 0.5283, ap 0.5349
2024-01-10 22:10:03,218 - GAugM EPNet train, Epoch [ 68/190]: loss 0.7210, auc 0.5244, ap 0.5532
2024-01-10 22:10:03,299 - GAugM EPNet train, Epoch [ 69/190]: loss 0.7210, auc 0.5347, ap 0.5412
2024-01-10 22:10:03,387 - GAugM EPNet train, Epoch [ 70/190]: loss 0.7210, auc 0.5020, ap 0.4980
2024-01-10 22:10:03,462 - GAugM EPNet train, Epoch [ 71/190]: loss 0.7210, auc 0.5546, ap 0.5480
2024-01-10 22:10:03,542 - GAugM EPNet train, Epoch [ 72/190]: loss 0.7210, auc 0.4446, ap 0.4852
2024-01-10 22:10:03,622 - GAugM EPNet train, Epoch [ 73/190]: loss 0.7209, auc 0.5169, ap 0.5101
2024-01-10 22:10:03,700 - GAugM EPNet train, Epoch [ 74/190]: loss 0.7209, auc 0.4311, ap 0.4901
2024-01-10 22:10:03,777 - GAugM EPNet train, Epoch [ 75/190]: loss 0.7210, auc 0.4906, ap 0.5380
2024-01-10 22:10:03,854 - GAugM EPNet train, Epoch [ 76/190]: loss 0.7209, auc 0.3998, ap 0.4635
2024-01-10 22:10:03,948 - GAugM EPNet train, Epoch [ 77/190]: loss 0.7208, auc 0.5625, ap 0.5620
2024-01-10 22:10:04,027 - GAugM EPNet train, Epoch [ 78/190]: loss 0.7209, auc 0.5461, ap 0.5184
2024-01-10 22:10:04,117 - GAugM EPNet train, Epoch [ 79/190]: loss 0.7208, auc 0.4535, ap 0.4732
2024-01-10 22:10:04,202 - GAugM EPNet train, Epoch [ 80/190]: loss 0.7209, auc 0.6006, ap 0.5736
2024-01-10 22:10:04,291 - GAugM EPNet train, Epoch [ 81/190]: loss 0.7209, auc 0.5037, ap 0.4925
2024-01-10 22:10:04,374 - GAugM EPNet train, Epoch [ 82/190]: loss 0.7210, auc 0.5365, ap 0.5254
2024-01-10 22:10:04,454 - GAugM EPNet train, Epoch [ 83/190]: loss 0.7209, auc 0.4909, ap 0.5338
2024-01-10 22:10:04,551 - GAugM EPNet train, Epoch [ 84/190]: loss 0.7209, auc 0.4030, ap 0.4769
2024-01-10 22:10:04,632 - GAugM EPNet train, Epoch [ 85/190]: loss 0.7210, auc 0.4233, ap 0.4872
2024-01-10 22:10:04,708 - GAugM EPNet train, Epoch [ 86/190]: loss 0.7208, auc 0.5568, ap 0.5441
2024-01-10 22:10:04,788 - GAugM EPNet train, Epoch [ 87/190]: loss 0.7209, auc 0.5532, ap 0.5402
2024-01-10 22:10:04,875 - GAugM EPNet train, Epoch [ 88/190]: loss 0.7210, auc 0.4617, ap 0.4988
2024-01-10 22:10:04,957 - GAugM EPNet train, Epoch [ 89/190]: loss 0.7210, auc 0.4738, ap 0.4810
2024-01-10 22:10:05,034 - GAugM EPNet train, Epoch [ 90/190]: loss 0.7209, auc 0.4030, ap 0.4480
2024-01-10 22:10:05,114 - GAugM EPNet train, Epoch [ 91/190]: loss 0.7208, auc 0.4863, ap 0.4787
2024-01-10 22:10:05,198 - GAugM EPNet train, Epoch [ 92/190]: loss 0.7209, auc 0.6191, ap 0.5998
2024-01-10 22:10:05,277 - GAugM EPNet train, Epoch [ 93/190]: loss 0.7209, auc 0.4016, ap 0.4585
2024-01-10 22:10:05,355 - GAugM EPNet train, Epoch [ 94/190]: loss 0.7210, auc 0.4026, ap 0.4495
2024-01-10 22:10:05,439 - GAugM EPNet train, Epoch [ 95/190]: loss 0.7210, auc 0.4649, ap 0.4770
2024-01-10 22:10:05,516 - GAugM EPNet train, Epoch [ 96/190]: loss 0.7209, auc 0.4920, ap 0.5107
2024-01-10 22:10:05,599 - GAugM EPNet train, Epoch [ 97/190]: loss 0.7209, auc 0.5077, ap 0.5202
2024-01-10 22:10:05,687 - GAugM EPNet train, Epoch [ 98/190]: loss 0.7209, auc 0.5269, ap 0.5327
2024-01-10 22:10:05,777 - GAugM EPNet train, Epoch [ 99/190]: loss 0.7209, auc 0.5222, ap 0.5288
2024-01-10 22:10:05,857 - GAugM EPNet train, Epoch [100/190]: loss 0.7210, auc 0.5319, ap 0.5747
2024-01-10 22:10:05,933 - GAugM EPNet train, Epoch [101/190]: loss 0.7210, auc 0.5133, ap 0.5930
2024-01-10 22:10:06,010 - GAugM EPNet train, Epoch [102/190]: loss 0.7209, auc 0.5603, ap 0.5551
2024-01-10 22:10:06,092 - GAugM EPNet train, Epoch [103/190]: loss 0.7209, auc 0.4475, ap 0.5005
2024-01-10 22:10:06,170 - GAugM EPNet train, Epoch [104/190]: loss 0.7209, auc 0.4731, ap 0.5039
2024-01-10 22:10:06,247 - GAugM EPNet train, Epoch [105/190]: loss 0.7209, auc 0.4115, ap 0.4420
2024-01-10 22:10:06,333 - GAugM EPNet train, Epoch [106/190]: loss 0.7210, auc 0.4998, ap 0.4829
2024-01-10 22:10:06,413 - GAugM EPNet train, Epoch [107/190]: loss 0.7210, auc 0.4525, ap 0.4948
2024-01-10 22:10:06,490 - GAugM EPNet train, Epoch [108/190]: loss 0.7208, auc 0.5098, ap 0.5210
2024-01-10 22:10:06,570 - GAugM EPNet train, Epoch [109/190]: loss 0.7210, auc 0.4197, ap 0.4455
2024-01-10 22:10:06,649 - GAugM EPNet train, Epoch [110/190]: loss 0.7209, auc 0.4664, ap 0.4936
2024-01-10 22:10:06,735 - GAugM EPNet train, Epoch [111/190]: loss 0.7210, auc 0.4874, ap 0.4959
2024-01-10 22:10:06,818 - GAugM EPNet train, Epoch [112/190]: loss 0.7209, auc 0.4503, ap 0.4877
2024-01-10 22:10:06,894 - GAugM EPNet train, Epoch [113/190]: loss 0.7210, auc 0.5393, ap 0.5805
2024-01-10 22:10:06,972 - GAugM EPNet train, Epoch [114/190]: loss 0.7209, auc 0.4660, ap 0.4895
2024-01-10 22:10:07,050 - GAugM EPNet train, Epoch [115/190]: loss 0.7210, auc 0.5934, ap 0.5569
2024-01-10 22:10:07,136 - GAugM EPNet train, Epoch [116/190]: loss 0.7209, auc 0.4956, ap 0.5342
2024-01-10 22:10:07,212 - GAugM EPNet train, Epoch [117/190]: loss 0.7208, auc 0.5344, ap 0.5388
2024-01-10 22:10:07,290 - GAugM EPNet train, Epoch [118/190]: loss 0.7209, auc 0.4211, ap 0.4615
2024-01-10 22:10:07,378 - GAugM EPNet train, Epoch [119/190]: loss 0.7209, auc 0.5059, ap 0.5494
2024-01-10 22:10:07,455 - GAugM EPNet train, Epoch [120/190]: loss 0.7210, auc 0.4521, ap 0.4584
2024-01-10 22:10:07,546 - GAugM EPNet train, Epoch [121/190]: loss 0.7210, auc 0.4098, ap 0.4443
2024-01-10 22:10:07,629 - GAugM EPNet train, Epoch [122/190]: loss 0.7209, auc 0.5408, ap 0.5352
2024-01-10 22:10:07,726 - GAugM EPNet train, Epoch [123/190]: loss 0.7209, auc 0.5180, ap 0.5548
2024-01-10 22:10:07,814 - GAugM EPNet train, Epoch [124/190]: loss 0.7210, auc 0.4859, ap 0.5018
2024-01-10 22:10:07,898 - GAugM EPNet train, Epoch [125/190]: loss 0.7209, auc 0.5027, ap 0.5129
2024-01-10 22:10:07,989 - GAugM EPNet train, Epoch [126/190]: loss 0.7210, auc 0.5169, ap 0.5417
2024-01-10 22:10:08,067 - GAugM EPNet train, Epoch [127/190]: loss 0.7209, auc 0.5760, ap 0.5596
2024-01-10 22:10:08,145 - GAugM EPNet train, Epoch [128/190]: loss 0.7210, auc 0.5635, ap 0.5548
2024-01-10 22:10:08,224 - GAugM EPNet train, Epoch [129/190]: loss 0.7208, auc 0.3980, ap 0.4526
2024-01-10 22:10:08,316 - GAugM EPNet train, Epoch [130/190]: loss 0.7210, auc 0.5297, ap 0.5439
2024-01-10 22:10:08,395 - GAugM EPNet train, Epoch [131/190]: loss 0.7210, auc 0.5222, ap 0.5978
2024-01-10 22:10:08,480 - GAugM EPNet train, Epoch [132/190]: loss 0.7209, auc 0.5279, ap 0.5259
2024-01-10 22:10:08,573 - GAugM EPNet train, Epoch [133/190]: loss 0.7209, auc 0.5066, ap 0.5359
2024-01-10 22:10:08,654 - GAugM EPNet train, Epoch [134/190]: loss 0.7210, auc 0.4891, ap 0.5154
2024-01-10 22:10:08,731 - GAugM EPNet train, Epoch [135/190]: loss 0.7209, auc 0.5052, ap 0.5270
2024-01-10 22:10:08,810 - GAugM EPNet train, Epoch [136/190]: loss 0.7209, auc 0.4372, ap 0.4837
2024-01-10 22:10:08,890 - GAugM EPNet train, Epoch [137/190]: loss 0.7210, auc 0.5425, ap 0.5538
2024-01-10 22:10:08,974 - GAugM EPNet train, Epoch [138/190]: loss 0.7210, auc 0.4778, ap 0.5028
2024-01-10 22:10:09,053 - GAugM EPNet train, Epoch [139/190]: loss 0.7210, auc 0.5578, ap 0.5479
2024-01-10 22:10:09,131 - GAugM EPNet train, Epoch [140/190]: loss 0.7209, auc 0.4660, ap 0.5243
2024-01-10 22:10:09,223 - GAugM EPNet train, Epoch [141/190]: loss 0.7209, auc 0.4802, ap 0.4631
2024-01-10 22:10:09,304 - GAugM EPNet train, Epoch [142/190]: loss 0.7209, auc 0.5215, ap 0.5283
2024-01-10 22:10:09,381 - GAugM EPNet train, Epoch [143/190]: loss 0.7209, auc 0.4457, ap 0.4676
2024-01-10 22:10:09,463 - GAugM EPNet train, Epoch [144/190]: loss 0.7209, auc 0.4767, ap 0.4794
2024-01-10 22:10:09,545 - GAugM EPNet train, Epoch [145/190]: loss 0.7209, auc 0.4685, ap 0.5163
2024-01-10 22:10:09,623 - GAugM EPNet train, Epoch [146/190]: loss 0.7209, auc 0.4995, ap 0.5336
2024-01-10 22:10:09,700 - GAugM EPNet train, Epoch [147/190]: loss 0.7209, auc 0.5230, ap 0.5675
2024-01-10 22:10:09,780 - GAugM EPNet train, Epoch [148/190]: loss 0.7209, auc 0.4058, ap 0.4488
2024-01-10 22:10:09,855 - GAugM EPNet train, Epoch [149/190]: loss 0.7208, auc 0.5433, ap 0.5260
2024-01-10 22:10:09,933 - GAugM EPNet train, Epoch [150/190]: loss 0.7209, auc 0.5735, ap 0.5822
2024-01-10 22:10:10,013 - GAugM EPNet train, Epoch [151/190]: loss 0.7209, auc 0.5440, ap 0.5274
2024-01-10 22:10:10,096 - GAugM EPNet train, Epoch [152/190]: loss 0.7209, auc 0.6173, ap 0.5892
2024-01-10 22:10:10,173 - GAugM EPNet train, Epoch [153/190]: loss 0.7209, auc 0.4984, ap 0.5324
2024-01-10 22:10:10,248 - GAugM EPNet train, Epoch [154/190]: loss 0.7209, auc 0.5596, ap 0.5814
2024-01-10 22:10:10,325 - GAugM EPNet train, Epoch [155/190]: loss 0.7209, auc 0.5222, ap 0.5138
2024-01-10 22:10:10,407 - GAugM EPNet train, Epoch [156/190]: loss 0.7209, auc 0.4557, ap 0.5106
2024-01-10 22:10:10,491 - GAugM EPNet train, Epoch [157/190]: loss 0.7209, auc 0.5294, ap 0.5172
2024-01-10 22:10:10,570 - GAugM EPNet train, Epoch [158/190]: loss 0.7208, auc 0.4432, ap 0.4659
2024-01-10 22:10:10,649 - GAugM EPNet train, Epoch [159/190]: loss 0.7208, auc 0.4653, ap 0.4698
2024-01-10 22:10:10,727 - GAugM EPNet train, Epoch [160/190]: loss 0.7209, auc 0.5571, ap 0.5697
2024-01-10 22:10:10,803 - GAugM EPNet train, Epoch [161/190]: loss 0.7209, auc 0.5119, ap 0.5092
2024-01-10 22:10:10,884 - GAugM EPNet train, Epoch [162/190]: loss 0.7209, auc 0.4678, ap 0.4594
2024-01-10 22:10:10,964 - GAugM EPNet train, Epoch [163/190]: loss 0.7209, auc 0.5066, ap 0.5001
2024-01-10 22:10:11,051 - GAugM EPNet train, Epoch [164/190]: loss 0.7211, auc 0.5522, ap 0.5598
2024-01-10 22:10:11,128 - GAugM EPNet train, Epoch [165/190]: loss 0.7210, auc 0.4425, ap 0.4689
2024-01-10 22:10:11,206 - GAugM EPNet train, Epoch [166/190]: loss 0.7208, auc 0.5393, ap 0.5129
2024-01-10 22:10:11,289 - GAugM EPNet train, Epoch [167/190]: loss 0.7209, auc 0.3898, ap 0.4475
2024-01-10 22:10:11,378 - GAugM EPNet train, Epoch [168/190]: loss 0.7209, auc 0.5041, ap 0.5138
2024-01-10 22:10:11,472 - GAugM EPNet train, Epoch [169/190]: loss 0.7209, auc 0.5838, ap 0.6138
2024-01-10 22:10:11,564 - GAugM EPNet train, Epoch [170/190]: loss 0.7210, auc 0.4204, ap 0.4494
2024-01-10 22:10:11,656 - GAugM EPNet train, Epoch [171/190]: loss 0.7209, auc 0.4703, ap 0.4852
2024-01-10 22:10:11,739 - GAugM EPNet train, Epoch [172/190]: loss 0.7208, auc 0.3891, ap 0.4379
2024-01-10 22:10:11,815 - GAugM EPNet train, Epoch [173/190]: loss 0.7209, auc 0.4792, ap 0.4968
2024-01-10 22:10:11,892 - GAugM EPNet train, Epoch [174/190]: loss 0.7209, auc 0.4774, ap 0.4969
2024-01-10 22:10:11,967 - GAugM EPNet train, Epoch [175/190]: loss 0.7209, auc 0.6347, ap 0.6177
2024-01-10 22:10:12,046 - GAugM EPNet train, Epoch [176/190]: loss 0.7209, auc 0.5005, ap 0.5241
2024-01-10 22:10:12,127 - GAugM EPNet train, Epoch [177/190]: loss 0.7210, auc 0.4891, ap 0.4905
2024-01-10 22:10:12,208 - GAugM EPNet train, Epoch [178/190]: loss 0.7210, auc 0.5667, ap 0.5961
2024-01-10 22:10:12,286 - GAugM EPNet train, Epoch [179/190]: loss 0.7210, auc 0.3841, ap 0.4436
2024-01-10 22:10:12,361 - GAugM EPNet train, Epoch [180/190]: loss 0.7210, auc 0.6209, ap 0.6493
2024-01-10 22:10:12,436 - GAugM EPNet train, Epoch [181/190]: loss 0.7209, auc 0.4614, ap 0.4807
2024-01-10 22:10:12,517 - GAugM EPNet train, Epoch [182/190]: loss 0.7209, auc 0.4931, ap 0.5484
2024-01-10 22:10:12,592 - GAugM EPNet train, Epoch [183/190]: loss 0.7210, auc 0.6173, ap 0.6143
2024-01-10 22:10:12,667 - GAugM EPNet train, Epoch [184/190]: loss 0.7209, auc 0.5429, ap 0.5418
2024-01-10 22:10:12,742 - GAugM EPNet train, Epoch [185/190]: loss 0.7209, auc 0.4881, ap 0.5109
2024-01-10 22:10:12,823 - GAugM EPNet train, Epoch [186/190]: loss 0.7208, auc 0.4368, ap 0.5217
2024-01-10 22:10:12,901 - GAugM EPNet train, Epoch [187/190]: loss 0.7209, auc 0.4963, ap 0.5013
2024-01-10 22:10:12,978 - GAugM EPNet train, Epoch [188/190]: loss 0.7209, auc 0.5084, ap 0.4896
2024-01-10 22:10:13,053 - GAugM EPNet train, Epoch [189/190]: loss 0.7209, auc 0.4877, ap 0.5438
2024-01-10 22:10:13,128 - GAugM EPNet train, Epoch [190/190]: loss 0.7209, auc 0.4169, ap 0.4389
2024-01-10 22:10:13,129 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d061d5690>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:13,854 - GAugM EPNet train, Epoch [  1/190]: loss 0.7210, auc 0.4786, ap 0.4785
2024-01-10 22:10:13,943 - GAugM EPNet train, Epoch [  2/190]: loss 0.7210, auc 0.5701, ap 0.5447
2024-01-10 22:10:14,041 - GAugM EPNet train, Epoch [  3/190]: loss 0.7209, auc 0.5584, ap 0.5512
2024-01-10 22:10:14,132 - GAugM EPNet train, Epoch [  4/190]: loss 0.7209, auc 0.4573, ap 0.5251
2024-01-10 22:10:14,220 - GAugM EPNet train, Epoch [  5/190]: loss 0.7209, auc 0.6040, ap 0.5914
2024-01-10 22:10:14,309 - GAugM EPNet train, Epoch [  6/190]: loss 0.7209, auc 0.4712, ap 0.4635
2024-01-10 22:10:14,404 - GAugM EPNet train, Epoch [  7/190]: loss 0.7209, auc 0.4349, ap 0.4505
2024-01-10 22:10:14,493 - GAugM EPNet train, Epoch [  8/190]: loss 0.7210, auc 0.4865, ap 0.4768
2024-01-10 22:10:14,588 - GAugM EPNet train, Epoch [  9/190]: loss 0.7209, auc 0.4028, ap 0.4447
2024-01-10 22:10:14,681 - GAugM EPNet train, Epoch [ 10/190]: loss 0.7208, auc 0.4195, ap 0.4375
2024-01-10 22:10:14,776 - GAugM EPNet train, Epoch [ 11/190]: loss 0.7209, auc 0.5203, ap 0.5444
2024-01-10 22:10:14,854 - GAugM EPNet train, Epoch [ 12/190]: loss 0.7210, auc 0.4381, ap 0.4446
2024-01-10 22:10:14,939 - GAugM EPNet train, Epoch [ 13/190]: loss 0.7209, auc 0.5203, ap 0.5325
2024-01-10 22:10:15,029 - GAugM EPNet train, Epoch [ 14/190]: loss 0.7209, auc 0.4875, ap 0.5036
2024-01-10 22:10:15,119 - GAugM EPNet train, Epoch [ 15/190]: loss 0.7210, auc 0.4028, ap 0.4659
2024-01-10 22:10:15,204 - GAugM EPNet train, Epoch [ 16/190]: loss 0.7209, auc 0.4893, ap 0.4885
2024-01-10 22:10:15,297 - GAugM EPNet train, Epoch [ 17/190]: loss 0.7210, auc 0.5214, ap 0.5203
2024-01-10 22:10:15,392 - GAugM EPNet train, Epoch [ 18/190]: loss 0.7210, auc 0.5516, ap 0.5434
2024-01-10 22:10:15,482 - GAugM EPNet train, Epoch [ 19/190]: loss 0.7209, auc 0.4804, ap 0.4704
2024-01-10 22:10:15,569 - GAugM EPNet train, Epoch [ 20/190]: loss 0.7210, auc 0.4744, ap 0.5072
2024-01-10 22:10:15,659 - GAugM EPNet train, Epoch [ 21/190]: loss 0.7209, auc 0.4996, ap 0.5106
2024-01-10 22:10:15,749 - GAugM EPNet train, Epoch [ 22/190]: loss 0.7210, auc 0.3512, ap 0.4160
2024-01-10 22:10:15,837 - GAugM EPNet train, Epoch [ 23/190]: loss 0.7208, auc 0.5285, ap 0.5205
2024-01-10 22:10:15,923 - GAugM EPNet train, Epoch [ 24/190]: loss 0.7209, auc 0.5612, ap 0.5384
2024-01-10 22:10:16,010 - GAugM EPNet train, Epoch [ 25/190]: loss 0.7209, auc 0.4402, ap 0.4558
2024-01-10 22:10:16,102 - GAugM EPNet train, Epoch [ 26/190]: loss 0.7210, auc 0.6157, ap 0.5788
2024-01-10 22:10:16,194 - GAugM EPNet train, Epoch [ 27/190]: loss 0.7209, auc 0.5100, ap 0.5634
2024-01-10 22:10:16,282 - GAugM EPNet train, Epoch [ 28/190]: loss 0.7209, auc 0.5427, ap 0.5335
2024-01-10 22:10:16,372 - GAugM EPNet train, Epoch [ 29/190]: loss 0.7210, auc 0.4939, ap 0.5100
2024-01-10 22:10:16,463 - GAugM EPNet train, Epoch [ 30/190]: loss 0.7209, auc 0.5306, ap 0.5455
2024-01-10 22:10:16,549 - GAugM EPNet train, Epoch [ 31/190]: loss 0.7208, auc 0.4697, ap 0.4863
2024-01-10 22:10:16,636 - GAugM EPNet train, Epoch [ 32/190]: loss 0.7210, auc 0.6253, ap 0.5790
2024-01-10 22:10:16,721 - GAugM EPNet train, Epoch [ 33/190]: loss 0.7209, auc 0.5292, ap 0.5475
2024-01-10 22:10:16,814 - GAugM EPNet train, Epoch [ 34/190]: loss 0.7209, auc 0.4765, ap 0.5097
2024-01-10 22:10:16,905 - GAugM EPNet train, Epoch [ 35/190]: loss 0.7209, auc 0.5281, ap 0.5215
2024-01-10 22:10:16,993 - GAugM EPNet train, Epoch [ 36/190]: loss 0.7209, auc 0.6342, ap 0.5988
2024-01-10 22:10:17,082 - GAugM EPNet train, Epoch [ 37/190]: loss 0.7209, auc 0.5061, ap 0.5208
2024-01-10 22:10:17,168 - GAugM EPNet train, Epoch [ 38/190]: loss 0.7209, auc 0.4455, ap 0.4510
2024-01-10 22:10:17,260 - GAugM EPNet train, Epoch [ 39/190]: loss 0.7208, auc 0.4295, ap 0.4778
2024-01-10 22:10:17,351 - GAugM EPNet train, Epoch [ 40/190]: loss 0.7210, auc 0.5648, ap 0.5269
2024-01-10 22:10:17,437 - GAugM EPNet train, Epoch [ 41/190]: loss 0.7210, auc 0.4815, ap 0.5112
2024-01-10 22:10:17,525 - GAugM EPNet train, Epoch [ 42/190]: loss 0.7209, auc 0.4918, ap 0.4912
2024-01-10 22:10:17,614 - GAugM EPNet train, Epoch [ 43/190]: loss 0.7208, auc 0.4530, ap 0.5053
2024-01-10 22:10:17,702 - GAugM EPNet train, Epoch [ 44/190]: loss 0.7208, auc 0.3693, ap 0.4352
2024-01-10 22:10:17,789 - GAugM EPNet train, Epoch [ 45/190]: loss 0.7209, auc 0.5456, ap 0.5333
2024-01-10 22:10:17,875 - GAugM EPNet train, Epoch [ 46/190]: loss 0.7209, auc 0.4811, ap 0.4662
2024-01-10 22:10:17,963 - GAugM EPNet train, Epoch [ 47/190]: loss 0.7210, auc 0.4430, ap 0.4524
2024-01-10 22:10:18,049 - GAugM EPNet train, Epoch [ 48/190]: loss 0.7210, auc 0.5509, ap 0.5749
2024-01-10 22:10:18,134 - GAugM EPNet train, Epoch [ 49/190]: loss 0.7209, auc 0.5566, ap 0.5477
2024-01-10 22:10:18,222 - GAugM EPNet train, Epoch [ 50/190]: loss 0.7210, auc 0.5484, ap 0.5385
2024-01-10 22:10:18,309 - GAugM EPNet train, Epoch [ 51/190]: loss 0.7210, auc 0.4576, ap 0.4568
2024-01-10 22:10:18,399 - GAugM EPNet train, Epoch [ 52/190]: loss 0.7209, auc 0.4640, ap 0.4555
2024-01-10 22:10:18,493 - GAugM EPNet train, Epoch [ 53/190]: loss 0.7209, auc 0.5363, ap 0.5084
2024-01-10 22:10:18,581 - GAugM EPNet train, Epoch [ 54/190]: loss 0.7211, auc 0.5160, ap 0.4956
2024-01-10 22:10:18,672 - GAugM EPNet train, Epoch [ 55/190]: loss 0.7209, auc 0.5449, ap 0.5548
2024-01-10 22:10:18,760 - GAugM EPNet train, Epoch [ 56/190]: loss 0.7208, auc 0.5167, ap 0.5130
2024-01-10 22:10:18,848 - GAugM EPNet train, Epoch [ 57/190]: loss 0.7209, auc 0.4754, ap 0.4548
2024-01-10 22:10:18,938 - GAugM EPNet train, Epoch [ 58/190]: loss 0.7210, auc 0.5128, ap 0.5668
2024-01-10 22:10:19,024 - GAugM EPNet train, Epoch [ 59/190]: loss 0.7211, auc 0.3928, ap 0.4339
2024-01-10 22:10:19,116 - GAugM EPNet train, Epoch [ 60/190]: loss 0.7210, auc 0.5402, ap 0.5256
2024-01-10 22:10:19,204 - GAugM EPNet train, Epoch [ 61/190]: loss 0.7209, auc 0.5470, ap 0.5595
2024-01-10 22:10:19,295 - GAugM EPNet train, Epoch [ 62/190]: loss 0.7210, auc 0.5231, ap 0.5337
2024-01-10 22:10:19,384 - GAugM EPNet train, Epoch [ 63/190]: loss 0.7208, auc 0.3772, ap 0.4246
2024-01-10 22:10:19,470 - GAugM EPNet train, Epoch [ 64/190]: loss 0.7208, auc 0.5132, ap 0.5410
2024-01-10 22:10:19,558 - GAugM EPNet train, Epoch [ 65/190]: loss 0.7208, auc 0.5395, ap 0.5303
2024-01-10 22:10:19,652 - GAugM EPNet train, Epoch [ 66/190]: loss 0.7209, auc 0.4865, ap 0.5112
2024-01-10 22:10:19,739 - GAugM EPNet train, Epoch [ 67/190]: loss 0.7209, auc 0.6225, ap 0.5757
2024-01-10 22:10:19,827 - GAugM EPNet train, Epoch [ 68/190]: loss 0.7210, auc 0.5260, ap 0.5302
2024-01-10 22:10:19,917 - GAugM EPNet train, Epoch [ 69/190]: loss 0.7210, auc 0.5039, ap 0.5096
2024-01-10 22:10:20,005 - GAugM EPNet train, Epoch [ 70/190]: loss 0.7210, auc 0.4900, ap 0.4734
2024-01-10 22:10:20,102 - GAugM EPNet train, Epoch [ 71/190]: loss 0.7210, auc 0.4961, ap 0.4884
2024-01-10 22:10:20,189 - GAugM EPNet train, Epoch [ 72/190]: loss 0.7210, auc 0.4583, ap 0.4540
2024-01-10 22:10:20,275 - GAugM EPNet train, Epoch [ 73/190]: loss 0.7209, auc 0.4886, ap 0.4718
2024-01-10 22:10:20,363 - GAugM EPNet train, Epoch [ 74/190]: loss 0.7209, auc 0.4923, ap 0.4919
2024-01-10 22:10:20,456 - GAugM EPNet train, Epoch [ 75/190]: loss 0.7210, auc 0.4854, ap 0.4877
2024-01-10 22:10:20,545 - GAugM EPNet train, Epoch [ 76/190]: loss 0.7209, auc 0.3946, ap 0.4294
2024-01-10 22:10:20,639 - GAugM EPNet train, Epoch [ 77/190]: loss 0.7208, auc 0.5484, ap 0.5682
2024-01-10 22:10:20,726 - GAugM EPNet train, Epoch [ 78/190]: loss 0.7209, auc 0.5673, ap 0.5312
2024-01-10 22:10:20,812 - GAugM EPNet train, Epoch [ 79/190]: loss 0.7208, auc 0.5292, ap 0.5209
2024-01-10 22:10:20,905 - GAugM EPNet train, Epoch [ 80/190]: loss 0.7209, auc 0.5374, ap 0.5126
2024-01-10 22:10:20,994 - GAugM EPNet train, Epoch [ 81/190]: loss 0.7209, auc 0.4487, ap 0.4699
2024-01-10 22:10:21,080 - GAugM EPNet train, Epoch [ 82/190]: loss 0.7210, auc 0.4783, ap 0.4753
2024-01-10 22:10:21,171 - GAugM EPNet train, Epoch [ 83/190]: loss 0.7209, auc 0.4473, ap 0.4804
2024-01-10 22:10:21,258 - GAugM EPNet train, Epoch [ 84/190]: loss 0.7209, auc 0.4868, ap 0.4668
2024-01-10 22:10:21,350 - GAugM EPNet train, Epoch [ 85/190]: loss 0.7210, auc 0.4370, ap 0.4684
2024-01-10 22:10:21,440 - GAugM EPNet train, Epoch [ 86/190]: loss 0.7208, auc 0.5089, ap 0.5245
2024-01-10 22:10:21,534 - GAugM EPNet train, Epoch [ 87/190]: loss 0.7209, auc 0.5691, ap 0.5631
2024-01-10 22:10:21,621 - GAugM EPNet train, Epoch [ 88/190]: loss 0.7210, auc 0.4106, ap 0.4529
2024-01-10 22:10:21,708 - GAugM EPNet train, Epoch [ 89/190]: loss 0.7210, auc 0.4277, ap 0.4797
2024-01-10 22:10:21,788 - GAugM EPNet train, Epoch [ 90/190]: loss 0.7209, auc 0.5036, ap 0.5222
2024-01-10 22:10:21,869 - GAugM EPNet train, Epoch [ 91/190]: loss 0.7208, auc 0.5028, ap 0.4839
2024-01-10 22:10:21,945 - GAugM EPNet train, Epoch [ 92/190]: loss 0.7209, auc 0.6485, ap 0.6334
2024-01-10 22:10:22,026 - GAugM EPNet train, Epoch [ 93/190]: loss 0.7209, auc 0.4096, ap 0.4520
2024-01-10 22:10:22,107 - GAugM EPNet train, Epoch [ 94/190]: loss 0.7210, auc 0.4171, ap 0.4441
2024-01-10 22:10:22,184 - GAugM EPNet train, Epoch [ 95/190]: loss 0.7210, auc 0.5249, ap 0.5142
2024-01-10 22:10:22,259 - GAugM EPNet train, Epoch [ 96/190]: loss 0.7209, auc 0.5577, ap 0.5667
2024-01-10 22:10:22,334 - GAugM EPNet train, Epoch [ 97/190]: loss 0.7209, auc 0.4203, ap 0.4443
2024-01-10 22:10:22,415 - GAugM EPNet train, Epoch [ 98/190]: loss 0.7209, auc 0.4886, ap 0.4946
2024-01-10 22:10:22,493 - GAugM EPNet train, Epoch [ 99/190]: loss 0.7209, auc 0.4633, ap 0.5127
2024-01-10 22:10:22,579 - GAugM EPNet train, Epoch [100/190]: loss 0.7210, auc 0.4680, ap 0.4866
2024-01-10 22:10:22,656 - GAugM EPNet train, Epoch [101/190]: loss 0.7210, auc 0.4398, ap 0.4603
2024-01-10 22:10:22,733 - GAugM EPNet train, Epoch [102/190]: loss 0.7209, auc 0.5217, ap 0.5282
2024-01-10 22:10:22,809 - GAugM EPNet train, Epoch [103/190]: loss 0.7209, auc 0.5705, ap 0.5774
2024-01-10 22:10:22,893 - GAugM EPNet train, Epoch [104/190]: loss 0.7209, auc 0.4964, ap 0.5169
2024-01-10 22:10:22,971 - GAugM EPNet train, Epoch [105/190]: loss 0.7209, auc 0.4320, ap 0.4516
2024-01-10 22:10:23,048 - GAugM EPNet train, Epoch [106/190]: loss 0.7210, auc 0.4580, ap 0.4751
2024-01-10 22:10:23,128 - GAugM EPNet train, Epoch [107/190]: loss 0.7210, auc 0.5399, ap 0.5341
2024-01-10 22:10:23,207 - GAugM EPNet train, Epoch [108/190]: loss 0.7208, auc 0.5751, ap 0.5525
2024-01-10 22:10:23,306 - GAugM EPNet train, Epoch [109/190]: loss 0.7210, auc 0.4171, ap 0.4412
2024-01-10 22:10:23,401 - GAugM EPNet train, Epoch [110/190]: loss 0.7209, auc 0.4605, ap 0.4651
2024-01-10 22:10:23,484 - GAugM EPNet train, Epoch [111/190]: loss 0.7210, auc 0.4872, ap 0.5016
2024-01-10 22:10:23,578 - GAugM EPNet train, Epoch [112/190]: loss 0.7209, auc 0.4858, ap 0.5020
2024-01-10 22:10:23,666 - GAugM EPNet train, Epoch [113/190]: loss 0.7210, auc 0.4299, ap 0.4523
2024-01-10 22:10:23,759 - GAugM EPNet train, Epoch [114/190]: loss 0.7209, auc 0.4964, ap 0.5049
2024-01-10 22:10:23,845 - GAugM EPNet train, Epoch [115/190]: loss 0.7210, auc 0.4388, ap 0.4663
2024-01-10 22:10:23,928 - GAugM EPNet train, Epoch [116/190]: loss 0.7209, auc 0.5157, ap 0.5250
2024-01-10 22:10:24,017 - GAugM EPNet train, Epoch [117/190]: loss 0.7208, auc 0.4320, ap 0.4534
2024-01-10 22:10:24,105 - GAugM EPNet train, Epoch [118/190]: loss 0.7209, auc 0.4911, ap 0.5127
2024-01-10 22:10:24,191 - GAugM EPNet train, Epoch [119/190]: loss 0.7209, auc 0.5032, ap 0.4979
2024-01-10 22:10:24,281 - GAugM EPNet train, Epoch [120/190]: loss 0.7210, auc 0.4167, ap 0.4266
2024-01-10 22:10:24,367 - GAugM EPNet train, Epoch [121/190]: loss 0.7210, auc 0.4455, ap 0.4585
2024-01-10 22:10:24,451 - GAugM EPNet train, Epoch [122/190]: loss 0.7209, auc 0.5463, ap 0.5375
2024-01-10 22:10:24,539 - GAugM EPNet train, Epoch [123/190]: loss 0.7209, auc 0.5093, ap 0.5417
2024-01-10 22:10:24,626 - GAugM EPNet train, Epoch [124/190]: loss 0.7210, auc 0.4484, ap 0.4824
2024-01-10 22:10:24,726 - GAugM EPNet train, Epoch [125/190]: loss 0.7209, auc 0.5199, ap 0.5066
2024-01-10 22:10:24,804 - GAugM EPNet train, Epoch [126/190]: loss 0.7210, auc 0.4993, ap 0.5053
2024-01-10 22:10:24,882 - GAugM EPNet train, Epoch [127/190]: loss 0.7209, auc 0.5271, ap 0.5137
2024-01-10 22:10:24,967 - GAugM EPNet train, Epoch [128/190]: loss 0.7210, auc 0.5402, ap 0.5124
2024-01-10 22:10:25,045 - GAugM EPNet train, Epoch [129/190]: loss 0.7208, auc 0.3688, ap 0.4240
2024-01-10 22:10:25,123 - GAugM EPNet train, Epoch [130/190]: loss 0.7210, auc 0.4381, ap 0.4647
2024-01-10 22:10:25,203 - GAugM EPNet train, Epoch [131/190]: loss 0.7210, auc 0.5032, ap 0.5022
2024-01-10 22:10:25,285 - GAugM EPNet train, Epoch [132/190]: loss 0.7209, auc 0.4843, ap 0.4907
2024-01-10 22:10:25,364 - GAugM EPNet train, Epoch [133/190]: loss 0.7209, auc 0.5445, ap 0.5408
2024-01-10 22:10:25,440 - GAugM EPNet train, Epoch [134/190]: loss 0.7210, auc 0.5609, ap 0.5444
2024-01-10 22:10:25,521 - GAugM EPNet train, Epoch [135/190]: loss 0.7209, auc 0.4099, ap 0.4531
2024-01-10 22:10:25,611 - GAugM EPNet train, Epoch [136/190]: loss 0.7209, auc 0.5381, ap 0.5464
2024-01-10 22:10:25,695 - GAugM EPNet train, Epoch [137/190]: loss 0.7210, auc 0.4195, ap 0.4500
2024-01-10 22:10:25,774 - GAugM EPNet train, Epoch [138/190]: loss 0.7210, auc 0.5869, ap 0.5557
2024-01-10 22:10:25,854 - GAugM EPNet train, Epoch [139/190]: loss 0.7210, auc 0.5128, ap 0.5113
2024-01-10 22:10:25,937 - GAugM EPNet train, Epoch [140/190]: loss 0.7209, auc 0.5007, ap 0.5322
2024-01-10 22:10:26,016 - GAugM EPNet train, Epoch [141/190]: loss 0.7209, auc 0.5299, ap 0.5316
2024-01-10 22:10:26,102 - GAugM EPNet train, Epoch [142/190]: loss 0.7209, auc 0.4975, ap 0.5047
2024-01-10 22:10:26,191 - GAugM EPNet train, Epoch [143/190]: loss 0.7209, auc 0.4537, ap 0.4780
2024-01-10 22:10:26,281 - GAugM EPNet train, Epoch [144/190]: loss 0.7209, auc 0.4245, ap 0.4441
2024-01-10 22:10:26,374 - GAugM EPNet train, Epoch [145/190]: loss 0.7209, auc 0.4648, ap 0.4970
2024-01-10 22:10:26,467 - GAugM EPNet train, Epoch [146/190]: loss 0.7209, auc 0.4968, ap 0.5141
2024-01-10 22:10:26,563 - GAugM EPNet train, Epoch [147/190]: loss 0.7209, auc 0.6047, ap 0.6160
2024-01-10 22:10:26,656 - GAugM EPNet train, Epoch [148/190]: loss 0.7209, auc 0.5328, ap 0.5422
2024-01-10 22:10:26,741 - GAugM EPNet train, Epoch [149/190]: loss 0.7208, auc 0.5488, ap 0.5309
2024-01-10 22:10:26,819 - GAugM EPNet train, Epoch [150/190]: loss 0.7209, auc 0.5004, ap 0.5012
2024-01-10 22:10:26,903 - GAugM EPNet train, Epoch [151/190]: loss 0.7209, auc 0.5139, ap 0.5110
2024-01-10 22:10:26,994 - GAugM EPNet train, Epoch [152/190]: loss 0.7209, auc 0.4890, ap 0.5002
2024-01-10 22:10:27,086 - GAugM EPNet train, Epoch [153/190]: loss 0.7209, auc 0.3957, ap 0.4605
2024-01-10 22:10:27,180 - GAugM EPNet train, Epoch [154/190]: loss 0.7209, auc 0.5317, ap 0.5527
2024-01-10 22:10:27,277 - GAugM EPNet train, Epoch [155/190]: loss 0.7209, auc 0.5021, ap 0.5086
2024-01-10 22:10:27,369 - GAugM EPNet train, Epoch [156/190]: loss 0.7209, auc 0.4676, ap 0.4841
2024-01-10 22:10:27,461 - GAugM EPNet train, Epoch [157/190]: loss 0.7209, auc 0.4804, ap 0.4830
2024-01-10 22:10:27,555 - GAugM EPNet train, Epoch [158/190]: loss 0.7208, auc 0.4608, ap 0.4765
2024-01-10 22:10:27,632 - GAugM EPNet train, Epoch [159/190]: loss 0.7208, auc 0.4733, ap 0.4688
2024-01-10 22:10:27,709 - GAugM EPNet train, Epoch [160/190]: loss 0.7209, auc 0.5630, ap 0.5616
2024-01-10 22:10:27,786 - GAugM EPNet train, Epoch [161/190]: loss 0.7209, auc 0.5057, ap 0.5074
2024-01-10 22:10:27,869 - GAugM EPNet train, Epoch [162/190]: loss 0.7209, auc 0.4178, ap 0.4415
2024-01-10 22:10:27,945 - GAugM EPNet train, Epoch [163/190]: loss 0.7209, auc 0.5513, ap 0.5356
2024-01-10 22:10:28,024 - GAugM EPNet train, Epoch [164/190]: loss 0.7211, auc 0.5506, ap 0.5490
2024-01-10 22:10:28,111 - GAugM EPNet train, Epoch [165/190]: loss 0.7210, auc 0.5171, ap 0.5118
2024-01-10 22:10:28,191 - GAugM EPNet train, Epoch [166/190]: loss 0.7208, auc 0.5598, ap 0.5291
2024-01-10 22:10:28,270 - GAugM EPNet train, Epoch [167/190]: loss 0.7209, auc 0.4630, ap 0.4800
2024-01-10 22:10:28,360 - GAugM EPNet train, Epoch [168/190]: loss 0.7209, auc 0.5146, ap 0.5347
2024-01-10 22:10:28,452 - GAugM EPNet train, Epoch [169/190]: loss 0.7209, auc 0.4761, ap 0.4745
2024-01-10 22:10:28,546 - GAugM EPNet train, Epoch [170/190]: loss 0.7210, auc 0.5078, ap 0.4970
2024-01-10 22:10:28,637 - GAugM EPNet train, Epoch [171/190]: loss 0.7209, auc 0.4573, ap 0.4859
2024-01-10 22:10:28,730 - GAugM EPNet train, Epoch [172/190]: loss 0.7208, auc 0.3426, ap 0.4037
2024-01-10 22:10:28,819 - GAugM EPNet train, Epoch [173/190]: loss 0.7209, auc 0.4167, ap 0.4514
2024-01-10 22:10:28,908 - GAugM EPNet train, Epoch [174/190]: loss 0.7209, auc 0.4398, ap 0.4480
2024-01-10 22:10:28,998 - GAugM EPNet train, Epoch [175/190]: loss 0.7209, auc 0.5459, ap 0.5320
2024-01-10 22:10:29,088 - GAugM EPNet train, Epoch [176/190]: loss 0.7209, auc 0.5110, ap 0.5040
2024-01-10 22:10:29,176 - GAugM EPNet train, Epoch [177/190]: loss 0.7210, auc 0.5360, ap 0.5197
2024-01-10 22:10:29,270 - GAugM EPNet train, Epoch [178/190]: loss 0.7210, auc 0.5367, ap 0.5710
2024-01-10 22:10:29,363 - GAugM EPNet train, Epoch [179/190]: loss 0.7210, auc 0.5441, ap 0.5311
2024-01-10 22:10:29,452 - GAugM EPNet train, Epoch [180/190]: loss 0.7210, auc 0.4694, ap 0.5151
2024-01-10 22:10:29,540 - GAugM EPNet train, Epoch [181/190]: loss 0.7209, auc 0.3804, ap 0.4274
2024-01-10 22:10:29,631 - GAugM EPNet train, Epoch [182/190]: loss 0.7209, auc 0.4598, ap 0.4672
2024-01-10 22:10:29,719 - GAugM EPNet train, Epoch [183/190]: loss 0.7210, auc 0.6093, ap 0.5526
2024-01-10 22:10:29,809 - GAugM EPNet train, Epoch [184/190]: loss 0.7209, auc 0.5765, ap 0.5597
2024-01-10 22:10:29,901 - GAugM EPNet train, Epoch [185/190]: loss 0.7209, auc 0.4744, ap 0.4854
2024-01-10 22:10:29,992 - GAugM EPNet train, Epoch [186/190]: loss 0.7208, auc 0.4349, ap 0.4942
2024-01-10 22:10:30,081 - GAugM EPNet train, Epoch [187/190]: loss 0.7209, auc 0.5192, ap 0.5239
2024-01-10 22:10:30,171 - GAugM EPNet train, Epoch [188/190]: loss 0.7209, auc 0.4138, ap 0.4437
2024-01-10 22:10:30,264 - GAugM EPNet train, Epoch [189/190]: loss 0.7209, auc 0.5993, ap 0.6193
2024-01-10 22:10:30,355 - GAugM EPNet train, Epoch [190/190]: loss 0.7209, auc 0.3861, ap 0.4170
2024-01-10 22:10:30,366 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035fbe50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:31,128 - GAugM EPNet train, Epoch [  1/15]: loss 0.7210, auc 0.4891, ap 0.4752
2024-01-10 22:10:31,218 - GAugM EPNet train, Epoch [  2/15]: loss 0.7210, auc 0.5304, ap 0.4985
2024-01-10 22:10:31,306 - GAugM EPNet train, Epoch [  3/15]: loss 0.7209, auc 0.5449, ap 0.5085
2024-01-10 22:10:31,391 - GAugM EPNet train, Epoch [  4/15]: loss 0.7209, auc 0.4989, ap 0.4766
2024-01-10 22:10:31,472 - GAugM EPNet train, Epoch [  5/15]: loss 0.7209, auc 0.5803, ap 0.5653
2024-01-10 22:10:31,551 - GAugM EPNet train, Epoch [  6/15]: loss 0.7209, auc 0.5066, ap 0.4919
2024-01-10 22:10:31,626 - GAugM EPNet train, Epoch [  7/15]: loss 0.7209, auc 0.4393, ap 0.4379
2024-01-10 22:10:31,708 - GAugM EPNet train, Epoch [  8/15]: loss 0.7210, auc 0.5392, ap 0.5178
2024-01-10 22:10:31,820 - GAugM EPNet train, Epoch [  9/15]: loss 0.7209, auc 0.4797, ap 0.4610
2024-01-10 22:10:31,921 - GAugM EPNet train, Epoch [ 10/15]: loss 0.7208, auc 0.4906, ap 0.5000
2024-01-10 22:10:32,009 - GAugM EPNet train, Epoch [ 11/15]: loss 0.7209, auc 0.5157, ap 0.4985
2024-01-10 22:10:32,104 - GAugM EPNet train, Epoch [ 12/15]: loss 0.7210, auc 0.4233, ap 0.4357
2024-01-10 22:10:32,191 - GAugM EPNet train, Epoch [ 13/15]: loss 0.7209, auc 0.6016, ap 0.5653
2024-01-10 22:10:32,280 - GAugM EPNet train, Epoch [ 14/15]: loss 0.7209, auc 0.5190, ap 0.5106
2024-01-10 22:10:32,379 - GAugM EPNet train, Epoch [ 15/15]: loss 0.7210, auc 0.3645, ap 0.4225
2024-01-10 22:10:32,379 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035e58d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:33,107 - GAugM EPNet train, Epoch [  1/15]: loss 0.7210, auc 0.4941, ap 0.4934
2024-01-10 22:10:33,193 - GAugM EPNet train, Epoch [  2/15]: loss 0.7210, auc 0.5500, ap 0.5203
2024-01-10 22:10:33,282 - GAugM EPNet train, Epoch [  3/15]: loss 0.7209, auc 0.5255, ap 0.5253
2024-01-10 22:10:33,370 - GAugM EPNet train, Epoch [  4/15]: loss 0.7209, auc 0.4941, ap 0.5344
2024-01-10 22:10:33,460 - GAugM EPNet train, Epoch [  5/15]: loss 0.7209, auc 0.5532, ap 0.5787
2024-01-10 22:10:33,551 - GAugM EPNet train, Epoch [  6/15]: loss 0.7209, auc 0.5732, ap 0.5558
2024-01-10 22:10:33,638 - GAugM EPNet train, Epoch [  7/15]: loss 0.7209, auc 0.4446, ap 0.4722
2024-01-10 22:10:33,726 - GAugM EPNet train, Epoch [  8/15]: loss 0.7210, auc 0.4952, ap 0.5153
2024-01-10 22:10:33,814 - GAugM EPNet train, Epoch [  9/15]: loss 0.7209, auc 0.4856, ap 0.5083
2024-01-10 22:10:33,902 - GAugM EPNet train, Epoch [ 10/15]: loss 0.7208, auc 0.5262, ap 0.5396
2024-01-10 22:10:33,999 - GAugM EPNet train, Epoch [ 11/15]: loss 0.7209, auc 0.5465, ap 0.5774
2024-01-10 22:10:34,089 - GAugM EPNet train, Epoch [ 12/15]: loss 0.7210, auc 0.4785, ap 0.4798
2024-01-10 22:10:34,177 - GAugM EPNet train, Epoch [ 13/15]: loss 0.7209, auc 0.5717, ap 0.5747
2024-01-10 22:10:34,271 - GAugM EPNet train, Epoch [ 14/15]: loss 0.7209, auc 0.5657, ap 0.5660
2024-01-10 22:10:34,363 - GAugM EPNet train, Epoch [ 15/15]: loss 0.7210, auc 0.4009, ap 0.4594
2024-01-10 22:10:34,364 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d0353d590>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:35,062 - GAugM EPNet train, Epoch [  1/15]: loss 0.7210, auc 0.5174, ap 0.5108
2024-01-10 22:10:35,150 - GAugM EPNet train, Epoch [  2/15]: loss 0.7210, auc 0.5573, ap 0.5195
2024-01-10 22:10:35,235 - GAugM EPNet train, Epoch [  3/15]: loss 0.7209, auc 0.6253, ap 0.5629
2024-01-10 22:10:35,321 - GAugM EPNet train, Epoch [  4/15]: loss 0.7209, auc 0.5011, ap 0.5169
2024-01-10 22:10:35,412 - GAugM EPNet train, Epoch [  5/15]: loss 0.7209, auc 0.5609, ap 0.5417
2024-01-10 22:10:35,507 - GAugM EPNet train, Epoch [  6/15]: loss 0.7209, auc 0.5158, ap 0.4958
2024-01-10 22:10:35,600 - GAugM EPNet train, Epoch [  7/15]: loss 0.7209, auc 0.4320, ap 0.4610
2024-01-10 22:10:35,691 - GAugM EPNet train, Epoch [  8/15]: loss 0.7210, auc 0.4833, ap 0.4837
2024-01-10 22:10:35,782 - GAugM EPNet train, Epoch [  9/15]: loss 0.7209, auc 0.4705, ap 0.4758
2024-01-10 22:10:35,875 - GAugM EPNet train, Epoch [ 10/15]: loss 0.7208, auc 0.4603, ap 0.4591
2024-01-10 22:10:35,968 - GAugM EPNet train, Epoch [ 11/15]: loss 0.7209, auc 0.4845, ap 0.4839
2024-01-10 22:10:36,067 - GAugM EPNet train, Epoch [ 12/15]: loss 0.7210, auc 0.4664, ap 0.4644
2024-01-10 22:10:36,159 - GAugM EPNet train, Epoch [ 13/15]: loss 0.7209, auc 0.4913, ap 0.5030
2024-01-10 22:10:36,259 - GAugM EPNet train, Epoch [ 14/15]: loss 0.7209, auc 0.5596, ap 0.5321
2024-01-10 22:10:36,351 - GAugM EPNet train, Epoch [ 15/15]: loss 0.7210, auc 0.4074, ap 0.4606
2024-01-10 22:10:36,367 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d03560c50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:37,034 - GAugM EPNet train, Epoch [  1/15]: loss 0.7210, auc 0.4913, ap 0.4835
2024-01-10 22:10:37,118 - GAugM EPNet train, Epoch [  2/15]: loss 0.7210, auc 0.4890, ap 0.4815
2024-01-10 22:10:37,200 - GAugM EPNet train, Epoch [  3/15]: loss 0.7209, auc 0.5265, ap 0.5270
2024-01-10 22:10:37,282 - GAugM EPNet train, Epoch [  4/15]: loss 0.7209, auc 0.5219, ap 0.5268
2024-01-10 22:10:37,363 - GAugM EPNet train, Epoch [  5/15]: loss 0.7209, auc 0.5324, ap 0.5083
2024-01-10 22:10:37,453 - GAugM EPNet train, Epoch [  6/15]: loss 0.7209, auc 0.4923, ap 0.4877
2024-01-10 22:10:37,537 - GAugM EPNet train, Epoch [  7/15]: loss 0.7209, auc 0.4808, ap 0.4595
2024-01-10 22:10:37,620 - GAugM EPNet train, Epoch [  8/15]: loss 0.7210, auc 0.5292, ap 0.5016
2024-01-10 22:10:37,704 - GAugM EPNet train, Epoch [  9/15]: loss 0.7209, auc 0.4706, ap 0.4902
2024-01-10 22:10:37,791 - GAugM EPNet train, Epoch [ 10/15]: loss 0.7208, auc 0.5050, ap 0.5077
2024-01-10 22:10:37,879 - GAugM EPNet train, Epoch [ 11/15]: loss 0.7209, auc 0.5091, ap 0.4989
2024-01-10 22:10:37,960 - GAugM EPNet train, Epoch [ 12/15]: loss 0.7210, auc 0.5158, ap 0.5142
2024-01-10 22:10:38,042 - GAugM EPNet train, Epoch [ 13/15]: loss 0.7209, auc 0.5555, ap 0.5491
2024-01-10 22:10:38,132 - GAugM EPNet train, Epoch [ 14/15]: loss 0.7209, auc 0.5527, ap 0.5512
2024-01-10 22:10:38,212 - GAugM EPNet train, Epoch [ 15/15]: loss 0.7210, auc 0.3996, ap 0.4450
2024-01-10 22:10:38,219 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d06766b50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:38,901 - GAugM EPNet train, Epoch [  1/15]: loss 0.7210, auc 0.4557, ap 0.4596
2024-01-10 22:10:38,988 - GAugM EPNet train, Epoch [  2/15]: loss 0.7210, auc 0.4272, ap 0.4663
2024-01-10 22:10:39,068 - GAugM EPNet train, Epoch [  3/15]: loss 0.7209, auc 0.5269, ap 0.5350
2024-01-10 22:10:39,162 - GAugM EPNet train, Epoch [  4/15]: loss 0.7209, auc 0.4802, ap 0.5118
2024-01-10 22:10:39,250 - GAugM EPNet train, Epoch [  5/15]: loss 0.7209, auc 0.5340, ap 0.5432
2024-01-10 22:10:39,339 - GAugM EPNet train, Epoch [  6/15]: loss 0.7209, auc 0.4802, ap 0.4750
2024-01-10 22:10:39,423 - GAugM EPNet train, Epoch [  7/15]: loss 0.7209, auc 0.4236, ap 0.4460
2024-01-10 22:10:39,508 - GAugM EPNet train, Epoch [  8/15]: loss 0.7210, auc 0.4553, ap 0.4854
2024-01-10 22:10:39,596 - GAugM EPNet train, Epoch [  9/15]: loss 0.7209, auc 0.5066, ap 0.4957
2024-01-10 22:10:39,681 - GAugM EPNet train, Epoch [ 10/15]: loss 0.7208, auc 0.4756, ap 0.5041
2024-01-10 22:10:39,763 - GAugM EPNet train, Epoch [ 11/15]: loss 0.7209, auc 0.4539, ap 0.4877
2024-01-10 22:10:39,837 - GAugM EPNet train, Epoch [ 12/15]: loss 0.7210, auc 0.5034, ap 0.5030
2024-01-10 22:10:39,929 - GAugM EPNet train, Epoch [ 13/15]: loss 0.7209, auc 0.5493, ap 0.5794
2024-01-10 22:10:40,019 - GAugM EPNet train, Epoch [ 14/15]: loss 0.7209, auc 0.5052, ap 0.5242
2024-01-10 22:10:40,112 - GAugM EPNet train, Epoch [ 15/15]: loss 0.7210, auc 0.5012, ap 0.5275
2024-01-10 22:10:40,131 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa0f1f90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:40,835 - GAugM EPNet train, Epoch [  1/15]: loss 0.7210, auc 0.4608, ap 0.4723
2024-01-10 22:10:40,923 - GAugM EPNet train, Epoch [  2/15]: loss 0.7210, auc 0.5190, ap 0.4970
2024-01-10 22:10:41,007 - GAugM EPNet train, Epoch [  3/15]: loss 0.7209, auc 0.5262, ap 0.5329
2024-01-10 22:10:41,096 - GAugM EPNet train, Epoch [  4/15]: loss 0.7209, auc 0.5032, ap 0.5326
2024-01-10 22:10:41,178 - GAugM EPNet train, Epoch [  5/15]: loss 0.7209, auc 0.6198, ap 0.6576
2024-01-10 22:10:41,264 - GAugM EPNet train, Epoch [  6/15]: loss 0.7209, auc 0.4372, ap 0.4469
2024-01-10 22:10:41,345 - GAugM EPNet train, Epoch [  7/15]: loss 0.7209, auc 0.4484, ap 0.4494
2024-01-10 22:10:41,425 - GAugM EPNet train, Epoch [  8/15]: loss 0.7210, auc 0.4852, ap 0.4975
2024-01-10 22:10:41,506 - GAugM EPNet train, Epoch [  9/15]: loss 0.7209, auc 0.4539, ap 0.4854
2024-01-10 22:10:41,591 - GAugM EPNet train, Epoch [ 10/15]: loss 0.7208, auc 0.5146, ap 0.5356
2024-01-10 22:10:41,672 - GAugM EPNet train, Epoch [ 11/15]: loss 0.7209, auc 0.5308, ap 0.5620
2024-01-10 22:10:41,753 - GAugM EPNet train, Epoch [ 12/15]: loss 0.7210, auc 0.4229, ap 0.4392
2024-01-10 22:10:41,833 - GAugM EPNet train, Epoch [ 13/15]: loss 0.7209, auc 0.5224, ap 0.5448
2024-01-10 22:10:41,916 - GAugM EPNet train, Epoch [ 14/15]: loss 0.7209, auc 0.5367, ap 0.5324
2024-01-10 22:10:41,996 - GAugM EPNet train, Epoch [ 15/15]: loss 0.7210, auc 0.3640, ap 0.4612
2024-01-10 22:10:42,002 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035c8b90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:42,690 - GAugM EPNet train, Epoch [  1/15]: loss 0.7210, auc 0.3832, ap 0.4237
2024-01-10 22:10:42,777 - GAugM EPNet train, Epoch [  2/15]: loss 0.7210, auc 0.4838, ap 0.4896
2024-01-10 22:10:42,865 - GAugM EPNet train, Epoch [  3/15]: loss 0.7209, auc 0.5920, ap 0.5672
2024-01-10 22:10:42,947 - GAugM EPNet train, Epoch [  4/15]: loss 0.7209, auc 0.4454, ap 0.4566
2024-01-10 22:10:43,035 - GAugM EPNet train, Epoch [  5/15]: loss 0.7209, auc 0.5938, ap 0.6051
2024-01-10 22:10:43,119 - GAugM EPNet train, Epoch [  6/15]: loss 0.7209, auc 0.4719, ap 0.4651
2024-01-10 22:10:43,200 - GAugM EPNet train, Epoch [  7/15]: loss 0.7209, auc 0.4066, ap 0.4229
2024-01-10 22:10:43,275 - GAugM EPNet train, Epoch [  8/15]: loss 0.7210, auc 0.4820, ap 0.4967
2024-01-10 22:10:43,360 - GAugM EPNet train, Epoch [  9/15]: loss 0.7209, auc 0.4838, ap 0.4711
2024-01-10 22:10:43,436 - GAugM EPNet train, Epoch [ 10/15]: loss 0.7208, auc 0.4979, ap 0.5065
2024-01-10 22:10:43,508 - GAugM EPNet train, Epoch [ 11/15]: loss 0.7209, auc 0.4414, ap 0.4663
2024-01-10 22:10:43,581 - GAugM EPNet train, Epoch [ 12/15]: loss 0.7210, auc 0.4201, ap 0.4446
2024-01-10 22:10:43,660 - GAugM EPNet train, Epoch [ 13/15]: loss 0.7209, auc 0.6162, ap 0.6094
2024-01-10 22:10:43,744 - GAugM EPNet train, Epoch [ 14/15]: loss 0.7209, auc 0.5489, ap 0.5473
2024-01-10 22:10:43,827 - GAugM EPNet train, Epoch [ 15/15]: loss 0.7210, auc 0.4624, ap 0.5075
2024-01-10 22:10:43,840 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035e4d50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:44,544 - GAugM EPNet train, Epoch [  1/15]: loss 0.7210, auc 0.4758, ap 0.4756
2024-01-10 22:10:44,638 - GAugM EPNet train, Epoch [  2/15]: loss 0.7210, auc 0.4993, ap 0.4965
2024-01-10 22:10:44,728 - GAugM EPNet train, Epoch [  3/15]: loss 0.7209, auc 0.5587, ap 0.5433
2024-01-10 22:10:44,815 - GAugM EPNet train, Epoch [  4/15]: loss 0.7209, auc 0.5119, ap 0.5140
2024-01-10 22:10:44,901 - GAugM EPNet train, Epoch [  5/15]: loss 0.7209, auc 0.5470, ap 0.5255
2024-01-10 22:10:44,989 - GAugM EPNet train, Epoch [  6/15]: loss 0.7209, auc 0.5251, ap 0.5241
2024-01-10 22:10:45,073 - GAugM EPNet train, Epoch [  7/15]: loss 0.7209, auc 0.4633, ap 0.4910
2024-01-10 22:10:45,163 - GAugM EPNet train, Epoch [  8/15]: loss 0.7210, auc 0.5703, ap 0.5645
2024-01-10 22:10:45,258 - GAugM EPNet train, Epoch [  9/15]: loss 0.7209, auc 0.5489, ap 0.5530
2024-01-10 22:10:45,350 - GAugM EPNet train, Epoch [ 10/15]: loss 0.7208, auc 0.5037, ap 0.5023
2024-01-10 22:10:45,438 - GAugM EPNet train, Epoch [ 11/15]: loss 0.7209, auc 0.4696, ap 0.5155
2024-01-10 22:10:45,524 - GAugM EPNet train, Epoch [ 12/15]: loss 0.7210, auc 0.4874, ap 0.4936
2024-01-10 22:10:45,617 - GAugM EPNet train, Epoch [ 13/15]: loss 0.7209, auc 0.5397, ap 0.5386
2024-01-10 22:10:45,706 - GAugM EPNet train, Epoch [ 14/15]: loss 0.7209, auc 0.4884, ap 0.4970
2024-01-10 22:10:45,795 - GAugM EPNet train, Epoch [ 15/15]: loss 0.7210, auc 0.4801, ap 0.5143
2024-01-10 22:10:45,811 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035ecd50>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:46,495 - GAugM EPNet train, Epoch [  1/15]: loss 0.7210, auc 0.5117, ap 0.4778
2024-01-10 22:10:46,582 - GAugM EPNet train, Epoch [  2/15]: loss 0.7210, auc 0.4959, ap 0.5004
2024-01-10 22:10:46,667 - GAugM EPNet train, Epoch [  3/15]: loss 0.7209, auc 0.4936, ap 0.5000
2024-01-10 22:10:46,754 - GAugM EPNet train, Epoch [  4/15]: loss 0.7209, auc 0.4105, ap 0.4593
2024-01-10 22:10:46,840 - GAugM EPNet train, Epoch [  5/15]: loss 0.7209, auc 0.5304, ap 0.5484
2024-01-10 22:10:46,923 - GAugM EPNet train, Epoch [  6/15]: loss 0.7209, auc 0.5046, ap 0.4937
2024-01-10 22:10:47,014 - GAugM EPNet train, Epoch [  7/15]: loss 0.7209, auc 0.4400, ap 0.4593
2024-01-10 22:10:47,098 - GAugM EPNet train, Epoch [  8/15]: loss 0.7210, auc 0.5089, ap 0.5393
2024-01-10 22:10:47,181 - GAugM EPNet train, Epoch [  9/15]: loss 0.7209, auc 0.4891, ap 0.5212
2024-01-10 22:10:47,263 - GAugM EPNet train, Epoch [ 10/15]: loss 0.7208, auc 0.5315, ap 0.5232
2024-01-10 22:10:47,348 - GAugM EPNet train, Epoch [ 11/15]: loss 0.7209, auc 0.4767, ap 0.4817
2024-01-10 22:10:47,430 - GAugM EPNet train, Epoch [ 12/15]: loss 0.7210, auc 0.4532, ap 0.4721
2024-01-10 22:10:47,518 - GAugM EPNet train, Epoch [ 13/15]: loss 0.7209, auc 0.5433, ap 0.5342
2024-01-10 22:10:47,603 - GAugM EPNet train, Epoch [ 14/15]: loss 0.7209, auc 0.5874, ap 0.5558
2024-01-10 22:10:47,690 - GAugM EPNet train, Epoch [ 15/15]: loss 0.7210, auc 0.3710, ap 0.4249
2024-01-10 22:10:47,691 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d068d6b90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:48,356 - GAugM EPNet train, Epoch [  1/15]: loss 0.7210, auc 0.4854, ap 0.5023
2024-01-10 22:10:48,439 - GAugM EPNet train, Epoch [  2/15]: loss 0.7210, auc 0.5260, ap 0.5053
2024-01-10 22:10:48,522 - GAugM EPNet train, Epoch [  3/15]: loss 0.7209, auc 0.5449, ap 0.5337
2024-01-10 22:10:48,606 - GAugM EPNet train, Epoch [  4/15]: loss 0.7209, auc 0.6000, ap 0.6078
2024-01-10 22:10:48,690 - GAugM EPNet train, Epoch [  5/15]: loss 0.7209, auc 0.6242, ap 0.6331
2024-01-10 22:10:48,772 - GAugM EPNet train, Epoch [  6/15]: loss 0.7209, auc 0.4174, ap 0.4323
2024-01-10 22:10:48,859 - GAugM EPNet train, Epoch [  7/15]: loss 0.7209, auc 0.4765, ap 0.4689
2024-01-10 22:10:48,942 - GAugM EPNet train, Epoch [  8/15]: loss 0.7210, auc 0.5310, ap 0.5382
2024-01-10 22:10:49,024 - GAugM EPNet train, Epoch [  9/15]: loss 0.7209, auc 0.5117, ap 0.4996
2024-01-10 22:10:49,106 - GAugM EPNet train, Epoch [ 10/15]: loss 0.7208, auc 0.4890, ap 0.5056
2024-01-10 22:10:49,189 - GAugM EPNet train, Epoch [ 11/15]: loss 0.7209, auc 0.4754, ap 0.5050
2024-01-10 22:10:49,289 - GAugM EPNet train, Epoch [ 12/15]: loss 0.7210, auc 0.4295, ap 0.4460
2024-01-10 22:10:49,375 - GAugM EPNet train, Epoch [ 13/15]: loss 0.7209, auc 0.4954, ap 0.5282
2024-01-10 22:10:49,462 - GAugM EPNet train, Epoch [ 14/15]: loss 0.7209, auc 0.5392, ap 0.5266
2024-01-10 22:10:49,549 - GAugM EPNet train, Epoch [ 15/15]: loss 0.7210, auc 0.4171, ap 0.4627
2024-01-10 22:10:49,562 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa0d4bd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:10:50,236 - GAugM EPNet train, Epoch [  1/250]: loss 0.7210, auc 0.4717, ap 0.4631
2024-01-10 22:10:50,322 - GAugM EPNet train, Epoch [  2/250]: loss 0.7210, auc 0.5247, ap 0.4992
2024-01-10 22:10:50,412 - GAugM EPNet train, Epoch [  3/250]: loss 0.7209, auc 0.5101, ap 0.4857
2024-01-10 22:10:50,499 - GAugM EPNet train, Epoch [  4/250]: loss 0.7209, auc 0.4468, ap 0.5152
2024-01-10 22:10:50,581 - GAugM EPNet train, Epoch [  5/250]: loss 0.7209, auc 0.5472, ap 0.5316
2024-01-10 22:10:50,663 - GAugM EPNet train, Epoch [  6/250]: loss 0.7209, auc 0.5109, ap 0.4863
2024-01-10 22:10:50,746 - GAugM EPNet train, Epoch [  7/250]: loss 0.7209, auc 0.4014, ap 0.4183
2024-01-10 22:10:50,827 - GAugM EPNet train, Epoch [  8/250]: loss 0.7210, auc 0.4557, ap 0.4544
2024-01-10 22:10:50,923 - GAugM EPNet train, Epoch [  9/250]: loss 0.7209, auc 0.5087, ap 0.4785
2024-01-10 22:10:51,006 - GAugM EPNet train, Epoch [ 10/250]: loss 0.7208, auc 0.5059, ap 0.5255
2024-01-10 22:10:51,088 - GAugM EPNet train, Epoch [ 11/250]: loss 0.7209, auc 0.5785, ap 0.5596
2024-01-10 22:10:51,171 - GAugM EPNet train, Epoch [ 12/250]: loss 0.7210, auc 0.4802, ap 0.4939
2024-01-10 22:10:51,255 - GAugM EPNet train, Epoch [ 13/250]: loss 0.7209, auc 0.5611, ap 0.5278
2024-01-10 22:10:51,337 - GAugM EPNet train, Epoch [ 14/250]: loss 0.7209, auc 0.5308, ap 0.5180
2024-01-10 22:10:51,421 - GAugM EPNet train, Epoch [ 15/250]: loss 0.7210, auc 0.4236, ap 0.4456
2024-01-10 22:10:51,508 - GAugM EPNet train, Epoch [ 16/250]: loss 0.7209, auc 0.4817, ap 0.5068
2024-01-10 22:10:51,589 - GAugM EPNet train, Epoch [ 17/250]: loss 0.7210, auc 0.4532, ap 0.4803
2024-01-10 22:10:51,672 - GAugM EPNet train, Epoch [ 18/250]: loss 0.7210, auc 0.5824, ap 0.5563
2024-01-10 22:10:51,755 - GAugM EPNet train, Epoch [ 19/250]: loss 0.7209, auc 0.5133, ap 0.4862
2024-01-10 22:10:51,839 - GAugM EPNet train, Epoch [ 20/250]: loss 0.7210, auc 0.5037, ap 0.5230
2024-01-10 22:10:51,915 - GAugM EPNet train, Epoch [ 21/250]: loss 0.7209, auc 0.5657, ap 0.5778
2024-01-10 22:10:51,991 - GAugM EPNet train, Epoch [ 22/250]: loss 0.7210, auc 0.4012, ap 0.4261
2024-01-10 22:10:52,066 - GAugM EPNet train, Epoch [ 23/250]: loss 0.7208, auc 0.4763, ap 0.4889
2024-01-10 22:10:52,146 - GAugM EPNet train, Epoch [ 24/250]: loss 0.7209, auc 0.5322, ap 0.4830
2024-01-10 22:10:52,221 - GAugM EPNet train, Epoch [ 25/250]: loss 0.7209, auc 0.4984, ap 0.4853
2024-01-10 22:10:52,302 - GAugM EPNet train, Epoch [ 26/250]: loss 0.7210, auc 0.5500, ap 0.5421
2024-01-10 22:10:52,377 - GAugM EPNet train, Epoch [ 27/250]: loss 0.7209, auc 0.3994, ap 0.4775
2024-01-10 22:10:52,462 - GAugM EPNet train, Epoch [ 28/250]: loss 0.7209, auc 0.5358, ap 0.5355
2024-01-10 22:10:52,540 - GAugM EPNet train, Epoch [ 29/250]: loss 0.7210, auc 0.5262, ap 0.4999
2024-01-10 22:10:52,616 - GAugM EPNet train, Epoch [ 30/250]: loss 0.7209, auc 0.5073, ap 0.5024
2024-01-10 22:10:52,697 - GAugM EPNet train, Epoch [ 31/250]: loss 0.7208, auc 0.4671, ap 0.4784
2024-01-10 22:10:52,774 - GAugM EPNet train, Epoch [ 32/250]: loss 0.7210, auc 0.5400, ap 0.5422
2024-01-10 22:10:52,849 - GAugM EPNet train, Epoch [ 33/250]: loss 0.7209, auc 0.5589, ap 0.5308
2024-01-10 22:10:52,935 - GAugM EPNet train, Epoch [ 34/250]: loss 0.7209, auc 0.4229, ap 0.4475
2024-01-10 22:10:53,014 - GAugM EPNet train, Epoch [ 35/250]: loss 0.7209, auc 0.5408, ap 0.5368
2024-01-10 22:10:53,094 - GAugM EPNet train, Epoch [ 36/250]: loss 0.7209, auc 0.5600, ap 0.5513
2024-01-10 22:10:53,172 - GAugM EPNet train, Epoch [ 37/250]: loss 0.7209, auc 0.4749, ap 0.4854
2024-01-10 22:10:53,250 - GAugM EPNet train, Epoch [ 38/250]: loss 0.7209, auc 0.5667, ap 0.5106
2024-01-10 22:10:53,332 - GAugM EPNet train, Epoch [ 39/250]: loss 0.7208, auc 0.4514, ap 0.4850
2024-01-10 22:10:53,409 - GAugM EPNet train, Epoch [ 40/250]: loss 0.7210, auc 0.5582, ap 0.5373
2024-01-10 22:10:53,492 - GAugM EPNet train, Epoch [ 41/250]: loss 0.7210, auc 0.4258, ap 0.4666
2024-01-10 22:10:53,579 - GAugM EPNet train, Epoch [ 42/250]: loss 0.7209, auc 0.4988, ap 0.5019
2024-01-10 22:10:53,661 - GAugM EPNet train, Epoch [ 43/250]: loss 0.7208, auc 0.4407, ap 0.4880
2024-01-10 22:10:53,752 - GAugM EPNet train, Epoch [ 44/250]: loss 0.7208, auc 0.3681, ap 0.4252
2024-01-10 22:10:53,832 - GAugM EPNet train, Epoch [ 45/250]: loss 0.7209, auc 0.5215, ap 0.5153
2024-01-10 22:10:53,915 - GAugM EPNet train, Epoch [ 46/250]: loss 0.7209, auc 0.4503, ap 0.4848
2024-01-10 22:10:53,999 - GAugM EPNet train, Epoch [ 47/250]: loss 0.7210, auc 0.4350, ap 0.4586
2024-01-10 22:10:54,074 - GAugM EPNet train, Epoch [ 48/250]: loss 0.7210, auc 0.6134, ap 0.6085
2024-01-10 22:10:54,152 - GAugM EPNet train, Epoch [ 49/250]: loss 0.7209, auc 0.5333, ap 0.5123
2024-01-10 22:10:54,232 - GAugM EPNet train, Epoch [ 50/250]: loss 0.7210, auc 0.5012, ap 0.4981
2024-01-10 22:10:54,307 - GAugM EPNet train, Epoch [ 51/250]: loss 0.7210, auc 0.5297, ap 0.5268
2024-01-10 22:10:54,390 - GAugM EPNet train, Epoch [ 52/250]: loss 0.7209, auc 0.4813, ap 0.5278
2024-01-10 22:10:54,467 - GAugM EPNet train, Epoch [ 53/250]: loss 0.7209, auc 0.5012, ap 0.5100
2024-01-10 22:10:54,547 - GAugM EPNet train, Epoch [ 54/250]: loss 0.7211, auc 0.5675, ap 0.5269
2024-01-10 22:10:54,628 - GAugM EPNet train, Epoch [ 55/250]: loss 0.7209, auc 0.5952, ap 0.5743
2024-01-10 22:10:54,705 - GAugM EPNet train, Epoch [ 56/250]: loss 0.7208, auc 0.5479, ap 0.5194
2024-01-10 22:10:54,781 - GAugM EPNet train, Epoch [ 57/250]: loss 0.7209, auc 0.4998, ap 0.4899
2024-01-10 22:10:54,859 - GAugM EPNet train, Epoch [ 58/250]: loss 0.7210, auc 0.4874, ap 0.5339
2024-01-10 22:10:54,932 - GAugM EPNet train, Epoch [ 59/250]: loss 0.7211, auc 0.4824, ap 0.4806
2024-01-10 22:10:55,014 - GAugM EPNet train, Epoch [ 60/250]: loss 0.7210, auc 0.5554, ap 0.5385
2024-01-10 22:10:55,094 - GAugM EPNet train, Epoch [ 61/250]: loss 0.7209, auc 0.5084, ap 0.4949
2024-01-10 22:10:55,181 - GAugM EPNet train, Epoch [ 62/250]: loss 0.7210, auc 0.5539, ap 0.5756
2024-01-10 22:10:55,255 - GAugM EPNet train, Epoch [ 63/250]: loss 0.7208, auc 0.4785, ap 0.4691
2024-01-10 22:10:55,332 - GAugM EPNet train, Epoch [ 64/250]: loss 0.7208, auc 0.4745, ap 0.5030
2024-01-10 22:10:55,408 - GAugM EPNet train, Epoch [ 65/250]: loss 0.7208, auc 0.5522, ap 0.5328
2024-01-10 22:10:55,484 - GAugM EPNet train, Epoch [ 66/250]: loss 0.7209, auc 0.4414, ap 0.4743
2024-01-10 22:10:55,564 - GAugM EPNet train, Epoch [ 67/250]: loss 0.7209, auc 0.5226, ap 0.5033
2024-01-10 22:10:55,638 - GAugM EPNet train, Epoch [ 68/250]: loss 0.7210, auc 0.5835, ap 0.5838
2024-01-10 22:10:55,713 - GAugM EPNet train, Epoch [ 69/250]: loss 0.7210, auc 0.5094, ap 0.5022
2024-01-10 22:10:55,796 - GAugM EPNet train, Epoch [ 70/250]: loss 0.7210, auc 0.4518, ap 0.4464
2024-01-10 22:10:55,873 - GAugM EPNet train, Epoch [ 71/250]: loss 0.7210, auc 0.4806, ap 0.4716
2024-01-10 22:10:55,953 - GAugM EPNet train, Epoch [ 72/250]: loss 0.7210, auc 0.4347, ap 0.4454
2024-01-10 22:10:56,041 - GAugM EPNet train, Epoch [ 73/250]: loss 0.7209, auc 0.4774, ap 0.4722
2024-01-10 22:10:56,120 - GAugM EPNet train, Epoch [ 74/250]: loss 0.7209, auc 0.4528, ap 0.4593
2024-01-10 22:10:56,195 - GAugM EPNet train, Epoch [ 75/250]: loss 0.7210, auc 0.4713, ap 0.5182
2024-01-10 22:10:56,282 - GAugM EPNet train, Epoch [ 76/250]: loss 0.7209, auc 0.4076, ap 0.4357
2024-01-10 22:10:56,361 - GAugM EPNet train, Epoch [ 77/250]: loss 0.7208, auc 0.5308, ap 0.5341
2024-01-10 22:10:56,440 - GAugM EPNet train, Epoch [ 78/250]: loss 0.7209, auc 0.5233, ap 0.4989
2024-01-10 22:10:56,527 - GAugM EPNet train, Epoch [ 79/250]: loss 0.7208, auc 0.5077, ap 0.5011
2024-01-10 22:10:56,602 - GAugM EPNet train, Epoch [ 80/250]: loss 0.7209, auc 0.5162, ap 0.4983
2024-01-10 22:10:56,681 - GAugM EPNet train, Epoch [ 81/250]: loss 0.7209, auc 0.5101, ap 0.5088
2024-01-10 22:10:56,766 - GAugM EPNet train, Epoch [ 82/250]: loss 0.7210, auc 0.5942, ap 0.5578
2024-01-10 22:10:56,842 - GAugM EPNet train, Epoch [ 83/250]: loss 0.7209, auc 0.4350, ap 0.4537
2024-01-10 22:10:56,919 - GAugM EPNet train, Epoch [ 84/250]: loss 0.7209, auc 0.4543, ap 0.4525
2024-01-10 22:10:56,997 - GAugM EPNet train, Epoch [ 85/250]: loss 0.7210, auc 0.4276, ap 0.4715
2024-01-10 22:10:57,075 - GAugM EPNet train, Epoch [ 86/250]: loss 0.7208, auc 0.4966, ap 0.4991
2024-01-10 22:10:57,162 - GAugM EPNet train, Epoch [ 87/250]: loss 0.7209, auc 0.5582, ap 0.5315
2024-01-10 22:10:57,240 - GAugM EPNet train, Epoch [ 88/250]: loss 0.7210, auc 0.4988, ap 0.5406
2024-01-10 22:10:57,319 - GAugM EPNet train, Epoch [ 89/250]: loss 0.7210, auc 0.3941, ap 0.4214
2024-01-10 22:10:57,396 - GAugM EPNet train, Epoch [ 90/250]: loss 0.7209, auc 0.4493, ap 0.4649
2024-01-10 22:10:57,473 - GAugM EPNet train, Epoch [ 91/250]: loss 0.7208, auc 0.5344, ap 0.5064
2024-01-10 22:10:57,550 - GAugM EPNet train, Epoch [ 92/250]: loss 0.7209, auc 0.5311, ap 0.5220
2024-01-10 22:10:57,628 - GAugM EPNet train, Epoch [ 93/250]: loss 0.7209, auc 0.3396, ap 0.3984
2024-01-10 22:10:57,713 - GAugM EPNet train, Epoch [ 94/250]: loss 0.7210, auc 0.4361, ap 0.4704
2024-01-10 22:10:57,793 - GAugM EPNet train, Epoch [ 95/250]: loss 0.7210, auc 0.4980, ap 0.5010
2024-01-10 22:10:57,874 - GAugM EPNet train, Epoch [ 96/250]: loss 0.7209, auc 0.5564, ap 0.5286
2024-01-10 22:10:57,950 - GAugM EPNet train, Epoch [ 97/250]: loss 0.7209, auc 0.4276, ap 0.4372
2024-01-10 22:10:58,036 - GAugM EPNet train, Epoch [ 98/250]: loss 0.7209, auc 0.4852, ap 0.4800
2024-01-10 22:10:58,113 - GAugM EPNet train, Epoch [ 99/250]: loss 0.7209, auc 0.5198, ap 0.5482
2024-01-10 22:10:58,187 - GAugM EPNet train, Epoch [100/250]: loss 0.7210, auc 0.4895, ap 0.4899
2024-01-10 22:10:58,267 - GAugM EPNet train, Epoch [101/250]: loss 0.7210, auc 0.4642, ap 0.5006
2024-01-10 22:10:58,345 - GAugM EPNet train, Epoch [102/250]: loss 0.7209, auc 0.4318, ap 0.4591
2024-01-10 22:10:58,422 - GAugM EPNet train, Epoch [103/250]: loss 0.7209, auc 0.4745, ap 0.5026
2024-01-10 22:10:58,496 - GAugM EPNet train, Epoch [104/250]: loss 0.7209, auc 0.4357, ap 0.4530
2024-01-10 22:10:58,574 - GAugM EPNet train, Epoch [105/250]: loss 0.7209, auc 0.4187, ap 0.4350
2024-01-10 22:10:58,648 - GAugM EPNet train, Epoch [106/250]: loss 0.7210, auc 0.4689, ap 0.4502
2024-01-10 22:10:58,728 - GAugM EPNet train, Epoch [107/250]: loss 0.7210, auc 0.5333, ap 0.5487
2024-01-10 22:10:58,804 - GAugM EPNet train, Epoch [108/250]: loss 0.7208, auc 0.5354, ap 0.5093
2024-01-10 22:10:58,882 - GAugM EPNet train, Epoch [109/250]: loss 0.7210, auc 0.5219, ap 0.4996
2024-01-10 22:10:58,960 - GAugM EPNet train, Epoch [110/250]: loss 0.7209, auc 0.4874, ap 0.5047
2024-01-10 22:10:59,063 - GAugM EPNet train, Epoch [111/250]: loss 0.7210, auc 0.4550, ap 0.4674
2024-01-10 22:10:59,159 - GAugM EPNet train, Epoch [112/250]: loss 0.7209, auc 0.4770, ap 0.4988
2024-01-10 22:10:59,241 - GAugM EPNet train, Epoch [113/250]: loss 0.7210, auc 0.4767, ap 0.5063
2024-01-10 22:10:59,323 - GAugM EPNet train, Epoch [114/250]: loss 0.7209, auc 0.4126, ap 0.4457
2024-01-10 22:10:59,411 - GAugM EPNet train, Epoch [115/250]: loss 0.7210, auc 0.4393, ap 0.4439
2024-01-10 22:10:59,491 - GAugM EPNet train, Epoch [116/250]: loss 0.7209, auc 0.4984, ap 0.5103
2024-01-10 22:10:59,577 - GAugM EPNet train, Epoch [117/250]: loss 0.7208, auc 0.4482, ap 0.4626
2024-01-10 22:10:59,659 - GAugM EPNet train, Epoch [118/250]: loss 0.7209, auc 0.5133, ap 0.5229
2024-01-10 22:10:59,740 - GAugM EPNet train, Epoch [119/250]: loss 0.7209, auc 0.4585, ap 0.4793
2024-01-10 22:10:59,821 - GAugM EPNet train, Epoch [120/250]: loss 0.7210, auc 0.4340, ap 0.4341
2024-01-10 22:10:59,905 - GAugM EPNet train, Epoch [121/250]: loss 0.7210, auc 0.4607, ap 0.4631
2024-01-10 22:10:59,990 - GAugM EPNet train, Epoch [122/250]: loss 0.7209, auc 0.5226, ap 0.5178
2024-01-10 22:11:00,072 - GAugM EPNet train, Epoch [123/250]: loss 0.7209, auc 0.5002, ap 0.4987
2024-01-10 22:11:00,156 - GAugM EPNet train, Epoch [124/250]: loss 0.7210, auc 0.4489, ap 0.4789
2024-01-10 22:11:00,236 - GAugM EPNet train, Epoch [125/250]: loss 0.7209, auc 0.5101, ap 0.4845
2024-01-10 22:11:00,327 - GAugM EPNet train, Epoch [126/250]: loss 0.7210, auc 0.5005, ap 0.4827
2024-01-10 22:11:00,423 - GAugM EPNet train, Epoch [127/250]: loss 0.7209, auc 0.4763, ap 0.4681
2024-01-10 22:11:00,509 - GAugM EPNet train, Epoch [128/250]: loss 0.7210, auc 0.5500, ap 0.5263
2024-01-10 22:11:00,593 - GAugM EPNet train, Epoch [129/250]: loss 0.7208, auc 0.4080, ap 0.4378
2024-01-10 22:11:00,675 - GAugM EPNet train, Epoch [130/250]: loss 0.7210, auc 0.4585, ap 0.4937
2024-01-10 22:11:00,766 - GAugM EPNet train, Epoch [131/250]: loss 0.7210, auc 0.5390, ap 0.5538
2024-01-10 22:11:00,849 - GAugM EPNet train, Epoch [132/250]: loss 0.7209, auc 0.5240, ap 0.5128
2024-01-10 22:11:00,932 - GAugM EPNet train, Epoch [133/250]: loss 0.7209, auc 0.4664, ap 0.4840
2024-01-10 22:11:01,017 - GAugM EPNet train, Epoch [134/250]: loss 0.7210, auc 0.4505, ap 0.4479
2024-01-10 22:11:01,104 - GAugM EPNet train, Epoch [135/250]: loss 0.7209, auc 0.3930, ap 0.4291
2024-01-10 22:11:01,190 - GAugM EPNet train, Epoch [136/250]: loss 0.7209, auc 0.5201, ap 0.5195
2024-01-10 22:11:01,271 - GAugM EPNet train, Epoch [137/250]: loss 0.7210, auc 0.5062, ap 0.5107
2024-01-10 22:11:01,355 - GAugM EPNet train, Epoch [138/250]: loss 0.7210, auc 0.5240, ap 0.5072
2024-01-10 22:11:01,443 - GAugM EPNet train, Epoch [139/250]: loss 0.7210, auc 0.4240, ap 0.4410
2024-01-10 22:11:01,529 - GAugM EPNet train, Epoch [140/250]: loss 0.7209, auc 0.5372, ap 0.5496
2024-01-10 22:11:01,613 - GAugM EPNet train, Epoch [141/250]: loss 0.7209, auc 0.5247, ap 0.4907
2024-01-10 22:11:01,693 - GAugM EPNet train, Epoch [142/250]: loss 0.7209, auc 0.5507, ap 0.5298
2024-01-10 22:11:01,779 - GAugM EPNet train, Epoch [143/250]: loss 0.7209, auc 0.4272, ap 0.4400
2024-01-10 22:11:01,861 - GAugM EPNet train, Epoch [144/250]: loss 0.7209, auc 0.4685, ap 0.4805
2024-01-10 22:11:01,951 - GAugM EPNet train, Epoch [145/250]: loss 0.7209, auc 0.4991, ap 0.5320
2024-01-10 22:11:02,040 - GAugM EPNet train, Epoch [146/250]: loss 0.7209, auc 0.5568, ap 0.5532
2024-01-10 22:11:02,122 - GAugM EPNet train, Epoch [147/250]: loss 0.7209, auc 0.5497, ap 0.5424
2024-01-10 22:11:02,205 - GAugM EPNet train, Epoch [148/250]: loss 0.7209, auc 0.3944, ap 0.4348
2024-01-10 22:11:02,295 - GAugM EPNet train, Epoch [149/250]: loss 0.7208, auc 0.5457, ap 0.5556
2024-01-10 22:11:02,379 - GAugM EPNet train, Epoch [150/250]: loss 0.7209, auc 0.5361, ap 0.5021
2024-01-10 22:11:02,464 - GAugM EPNet train, Epoch [151/250]: loss 0.7209, auc 0.5810, ap 0.5489
2024-01-10 22:11:02,543 - GAugM EPNet train, Epoch [152/250]: loss 0.7209, auc 0.5269, ap 0.4934
2024-01-10 22:11:02,635 - GAugM EPNet train, Epoch [153/250]: loss 0.7209, auc 0.4788, ap 0.4634
2024-01-10 22:11:02,718 - GAugM EPNet train, Epoch [154/250]: loss 0.7209, auc 0.5091, ap 0.5304
2024-01-10 22:11:02,798 - GAugM EPNet train, Epoch [155/250]: loss 0.7209, auc 0.4596, ap 0.4732
2024-01-10 22:11:02,879 - GAugM EPNet train, Epoch [156/250]: loss 0.7209, auc 0.4706, ap 0.4890
2024-01-10 22:11:02,970 - GAugM EPNet train, Epoch [157/250]: loss 0.7209, auc 0.4664, ap 0.4802
2024-01-10 22:11:03,061 - GAugM EPNet train, Epoch [158/250]: loss 0.7208, auc 0.4539, ap 0.4659
2024-01-10 22:11:03,143 - GAugM EPNet train, Epoch [159/250]: loss 0.7208, auc 0.5005, ap 0.4853
2024-01-10 22:11:03,226 - GAugM EPNet train, Epoch [160/250]: loss 0.7209, auc 0.5913, ap 0.5822
2024-01-10 22:11:03,307 - GAugM EPNet train, Epoch [161/250]: loss 0.7209, auc 0.5450, ap 0.5320
2024-01-10 22:11:03,405 - GAugM EPNet train, Epoch [162/250]: loss 0.7209, auc 0.4792, ap 0.4788
2024-01-10 22:11:03,499 - GAugM EPNet train, Epoch [163/250]: loss 0.7209, auc 0.4571, ap 0.4611
2024-01-10 22:11:03,595 - GAugM EPNet train, Epoch [164/250]: loss 0.7211, auc 0.5183, ap 0.4924
2024-01-10 22:11:03,687 - GAugM EPNet train, Epoch [165/250]: loss 0.7210, auc 0.4290, ap 0.4447
2024-01-10 22:11:03,788 - GAugM EPNet train, Epoch [166/250]: loss 0.7208, auc 0.5262, ap 0.4977
2024-01-10 22:11:03,882 - GAugM EPNet train, Epoch [167/250]: loss 0.7209, auc 0.5034, ap 0.4985
2024-01-10 22:11:03,973 - GAugM EPNet train, Epoch [168/250]: loss 0.7209, auc 0.4874, ap 0.5272
2024-01-10 22:11:04,066 - GAugM EPNet train, Epoch [169/250]: loss 0.7209, auc 0.5116, ap 0.5242
2024-01-10 22:11:04,149 - GAugM EPNet train, Epoch [170/250]: loss 0.7210, auc 0.5133, ap 0.4783
2024-01-10 22:11:04,234 - GAugM EPNet train, Epoch [171/250]: loss 0.7209, auc 0.4941, ap 0.4956
2024-01-10 22:11:04,310 - GAugM EPNet train, Epoch [172/250]: loss 0.7208, auc 0.4817, ap 0.4739
2024-01-10 22:11:04,398 - GAugM EPNet train, Epoch [173/250]: loss 0.7209, auc 0.5593, ap 0.5307
2024-01-10 22:11:04,477 - GAugM EPNet train, Epoch [174/250]: loss 0.7209, auc 0.4653, ap 0.4617
2024-01-10 22:11:04,555 - GAugM EPNet train, Epoch [175/250]: loss 0.7209, auc 0.5568, ap 0.5305
2024-01-10 22:11:04,630 - GAugM EPNet train, Epoch [176/250]: loss 0.7209, auc 0.3948, ap 0.4404
2024-01-10 22:11:04,707 - GAugM EPNet train, Epoch [177/250]: loss 0.7210, auc 0.5497, ap 0.5167
2024-01-10 22:11:04,785 - GAugM EPNet train, Epoch [178/250]: loss 0.7210, auc 0.4952, ap 0.5074
2024-01-10 22:11:04,869 - GAugM EPNet train, Epoch [179/250]: loss 0.7210, auc 0.4051, ap 0.4820
2024-01-10 22:11:04,955 - GAugM EPNet train, Epoch [180/250]: loss 0.7210, auc 0.4966, ap 0.5031
2024-01-10 22:11:05,034 - GAugM EPNet train, Epoch [181/250]: loss 0.7209, auc 0.4137, ap 0.4615
2024-01-10 22:11:05,111 - GAugM EPNet train, Epoch [182/250]: loss 0.7209, auc 0.4318, ap 0.4368
2024-01-10 22:11:05,187 - GAugM EPNet train, Epoch [183/250]: loss 0.7210, auc 0.5347, ap 0.5551
2024-01-10 22:11:05,269 - GAugM EPNet train, Epoch [184/250]: loss 0.7209, auc 0.5005, ap 0.5085
2024-01-10 22:11:05,348 - GAugM EPNet train, Epoch [185/250]: loss 0.7209, auc 0.5336, ap 0.5157
2024-01-10 22:11:05,437 - GAugM EPNet train, Epoch [186/250]: loss 0.7208, auc 0.4831, ap 0.5182
2024-01-10 22:11:05,521 - GAugM EPNet train, Epoch [187/250]: loss 0.7209, auc 0.4938, ap 0.5023
2024-01-10 22:11:05,607 - GAugM EPNet train, Epoch [188/250]: loss 0.7209, auc 0.4436, ap 0.4517
2024-01-10 22:11:05,693 - GAugM EPNet train, Epoch [189/250]: loss 0.7209, auc 0.6130, ap 0.5966
2024-01-10 22:11:05,782 - GAugM EPNet train, Epoch [190/250]: loss 0.7209, auc 0.3888, ap 0.4172
2024-01-10 22:11:05,864 - GAugM EPNet train, Epoch [191/250]: loss 0.7209, auc 0.4382, ap 0.4927
2024-01-10 22:11:05,959 - GAugM EPNet train, Epoch [192/250]: loss 0.7209, auc 0.4639, ap 0.4544
2024-01-10 22:11:06,042 - GAugM EPNet train, Epoch [193/250]: loss 0.7209, auc 0.5479, ap 0.5094
2024-01-10 22:11:06,123 - GAugM EPNet train, Epoch [194/250]: loss 0.7209, auc 0.4432, ap 0.4476
2024-01-10 22:11:06,206 - GAugM EPNet train, Epoch [195/250]: loss 0.7209, auc 0.4329, ap 0.4439
2024-01-10 22:11:06,286 - GAugM EPNet train, Epoch [196/250]: loss 0.7208, auc 0.5379, ap 0.5055
2024-01-10 22:11:06,380 - GAugM EPNet train, Epoch [197/250]: loss 0.7210, auc 0.4721, ap 0.4870
2024-01-10 22:11:06,464 - GAugM EPNet train, Epoch [198/250]: loss 0.7210, auc 0.5625, ap 0.5353
2024-01-10 22:11:06,544 - GAugM EPNet train, Epoch [199/250]: loss 0.7209, auc 0.4899, ap 0.4865
2024-01-10 22:11:06,626 - GAugM EPNet train, Epoch [200/250]: loss 0.7210, auc 0.4778, ap 0.4803
2024-01-10 22:11:06,711 - GAugM EPNet train, Epoch [201/250]: loss 0.7209, auc 0.5034, ap 0.4982
2024-01-10 22:11:06,796 - GAugM EPNet train, Epoch [202/250]: loss 0.7210, auc 0.5358, ap 0.5202
2024-01-10 22:11:06,877 - GAugM EPNet train, Epoch [203/250]: loss 0.7210, auc 0.5173, ap 0.5288
2024-01-10 22:11:06,971 - GAugM EPNet train, Epoch [204/250]: loss 0.7209, auc 0.4429, ap 0.4711
2024-01-10 22:11:07,055 - GAugM EPNet train, Epoch [205/250]: loss 0.7209, auc 0.4738, ap 0.5049
2024-01-10 22:11:07,142 - GAugM EPNet train, Epoch [206/250]: loss 0.7209, auc 0.4478, ap 0.4509
2024-01-10 22:11:07,229 - GAugM EPNet train, Epoch [207/250]: loss 0.7210, auc 0.4439, ap 0.4685
2024-01-10 22:11:07,311 - GAugM EPNet train, Epoch [208/250]: loss 0.7209, auc 0.4386, ap 0.4625
2024-01-10 22:11:07,401 - GAugM EPNet train, Epoch [209/250]: loss 0.7210, auc 0.5714, ap 0.5582
2024-01-10 22:11:07,486 - GAugM EPNet train, Epoch [210/250]: loss 0.7209, auc 0.4617, ap 0.4586
2024-01-10 22:11:07,571 - GAugM EPNet train, Epoch [211/250]: loss 0.7210, auc 0.4973, ap 0.5014
2024-01-10 22:11:07,662 - GAugM EPNet train, Epoch [212/250]: loss 0.7210, auc 0.4724, ap 0.4615
2024-01-10 22:11:07,747 - GAugM EPNet train, Epoch [213/250]: loss 0.7208, auc 0.6276, ap 0.6316
2024-01-10 22:11:07,837 - GAugM EPNet train, Epoch [214/250]: loss 0.7210, auc 0.4493, ap 0.4494
2024-01-10 22:11:07,926 - GAugM EPNet train, Epoch [215/250]: loss 0.7210, auc 0.4970, ap 0.4947
2024-01-10 22:11:08,010 - GAugM EPNet train, Epoch [216/250]: loss 0.7209, auc 0.5311, ap 0.5131
2024-01-10 22:11:08,092 - GAugM EPNet train, Epoch [217/250]: loss 0.7209, auc 0.6387, ap 0.6111
2024-01-10 22:11:08,175 - GAugM EPNet train, Epoch [218/250]: loss 0.7209, auc 0.5247, ap 0.5688
2024-01-10 22:11:08,257 - GAugM EPNet train, Epoch [219/250]: loss 0.7208, auc 0.4980, ap 0.4881
2024-01-10 22:11:08,348 - GAugM EPNet train, Epoch [220/250]: loss 0.7210, auc 0.4799, ap 0.5214
2024-01-10 22:11:08,430 - GAugM EPNet train, Epoch [221/250]: loss 0.7209, auc 0.5315, ap 0.4967
2024-01-10 22:11:08,511 - GAugM EPNet train, Epoch [222/250]: loss 0.7209, auc 0.4418, ap 0.4505
2024-01-10 22:11:08,598 - GAugM EPNet train, Epoch [223/250]: loss 0.7209, auc 0.5561, ap 0.5351
2024-01-10 22:11:08,680 - GAugM EPNet train, Epoch [224/250]: loss 0.7210, auc 0.4514, ap 0.4611
2024-01-10 22:11:08,764 - GAugM EPNet train, Epoch [225/250]: loss 0.7209, auc 0.4112, ap 0.4476
2024-01-10 22:11:08,848 - GAugM EPNet train, Epoch [226/250]: loss 0.7210, auc 0.5048, ap 0.5298
2024-01-10 22:11:08,930 - GAugM EPNet train, Epoch [227/250]: loss 0.7210, auc 0.5358, ap 0.5367
2024-01-10 22:11:09,011 - GAugM EPNet train, Epoch [228/250]: loss 0.7209, auc 0.5489, ap 0.5257
2024-01-10 22:11:09,107 - GAugM EPNet train, Epoch [229/250]: loss 0.7209, auc 0.5557, ap 0.5325
2024-01-10 22:11:09,192 - GAugM EPNet train, Epoch [230/250]: loss 0.7209, auc 0.4108, ap 0.4523
2024-01-10 22:11:09,276 - GAugM EPNet train, Epoch [231/250]: loss 0.7209, auc 0.5354, ap 0.5293
2024-01-10 22:11:09,364 - GAugM EPNet train, Epoch [232/250]: loss 0.7209, auc 0.5589, ap 0.5431
2024-01-10 22:11:09,456 - GAugM EPNet train, Epoch [233/250]: loss 0.7210, auc 0.5582, ap 0.5455
2024-01-10 22:11:09,541 - GAugM EPNet train, Epoch [234/250]: loss 0.7209, auc 0.4422, ap 0.4757
2024-01-10 22:11:09,629 - GAugM EPNet train, Epoch [235/250]: loss 0.7209, auc 0.4322, ap 0.4594
2024-01-10 22:11:09,711 - GAugM EPNet train, Epoch [236/250]: loss 0.7209, auc 0.4511, ap 0.4924
2024-01-10 22:11:09,795 - GAugM EPNet train, Epoch [237/250]: loss 0.7210, auc 0.4945, ap 0.5261
2024-01-10 22:11:09,877 - GAugM EPNet train, Epoch [238/250]: loss 0.7210, auc 0.5240, ap 0.5203
2024-01-10 22:11:09,959 - GAugM EPNet train, Epoch [239/250]: loss 0.7209, auc 0.4044, ap 0.4649
2024-01-10 22:11:10,040 - GAugM EPNet train, Epoch [240/250]: loss 0.7209, auc 0.5279, ap 0.4900
2024-01-10 22:11:10,125 - GAugM EPNet train, Epoch [241/250]: loss 0.7209, auc 0.4922, ap 0.4841
2024-01-10 22:11:10,204 - GAugM EPNet train, Epoch [242/250]: loss 0.7210, auc 0.4802, ap 0.4782
2024-01-10 22:11:10,296 - GAugM EPNet train, Epoch [243/250]: loss 0.7210, auc 0.5525, ap 0.6070
2024-01-10 22:11:10,372 - GAugM EPNet train, Epoch [244/250]: loss 0.7209, auc 0.5682, ap 0.5652
2024-01-10 22:11:10,461 - GAugM EPNet train, Epoch [245/250]: loss 0.7210, auc 0.4300, ap 0.4527
2024-01-10 22:11:10,547 - GAugM EPNet train, Epoch [246/250]: loss 0.7208, auc 0.5251, ap 0.5149
2024-01-10 22:11:10,628 - GAugM EPNet train, Epoch [247/250]: loss 0.7209, auc 0.4806, ap 0.4754
2024-01-10 22:11:10,710 - GAugM EPNet train, Epoch [248/250]: loss 0.7211, auc 0.5109, ap 0.5240
2024-01-10 22:11:10,796 - GAugM EPNet train, Epoch [249/250]: loss 0.7209, auc 0.4539, ap 0.4738
2024-01-10 22:11:10,879 - GAugM EPNet train, Epoch [250/250]: loss 0.7208, auc 0.4753, ap 0.4723
2024-01-10 22:11:10,894 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035e03d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:11:11,604 - GAugM EPNet train, Epoch [  1/250]: loss 0.7210, auc 0.4678, ap 0.4703
2024-01-10 22:11:11,689 - GAugM EPNet train, Epoch [  2/250]: loss 0.7210, auc 0.5700, ap 0.5458
2024-01-10 22:11:11,780 - GAugM EPNet train, Epoch [  3/250]: loss 0.7209, auc 0.6282, ap 0.5810
2024-01-10 22:11:11,871 - GAugM EPNet train, Epoch [  4/250]: loss 0.7209, auc 0.5034, ap 0.5297
2024-01-10 22:11:11,949 - GAugM EPNet train, Epoch [  5/250]: loss 0.7209, auc 0.5235, ap 0.5456
2024-01-10 22:11:12,031 - GAugM EPNet train, Epoch [  6/250]: loss 0.7209, auc 0.5707, ap 0.5484
2024-01-10 22:11:12,105 - GAugM EPNet train, Epoch [  7/250]: loss 0.7209, auc 0.4559, ap 0.4655
2024-01-10 22:11:12,179 - GAugM EPNet train, Epoch [  8/250]: loss 0.7210, auc 0.5292, ap 0.5239
2024-01-10 22:11:12,260 - GAugM EPNet train, Epoch [  9/250]: loss 0.7209, auc 0.4745, ap 0.4899
2024-01-10 22:11:12,332 - GAugM EPNet train, Epoch [ 10/250]: loss 0.7208, auc 0.5326, ap 0.5208
2024-01-10 22:11:12,426 - GAugM EPNet train, Epoch [ 11/250]: loss 0.7209, auc 0.4815, ap 0.5382
2024-01-10 22:11:12,517 - GAugM EPNet train, Epoch [ 12/250]: loss 0.7210, auc 0.4632, ap 0.4727
2024-01-10 22:11:12,602 - GAugM EPNet train, Epoch [ 13/250]: loss 0.7209, auc 0.5988, ap 0.5528
2024-01-10 22:11:12,677 - GAugM EPNet train, Epoch [ 14/250]: loss 0.7209, auc 0.5269, ap 0.5396
2024-01-10 22:11:12,761 - GAugM EPNet train, Epoch [ 15/250]: loss 0.7210, auc 0.3800, ap 0.4461
2024-01-10 22:11:12,840 - GAugM EPNet train, Epoch [ 16/250]: loss 0.7209, auc 0.5128, ap 0.5041
2024-01-10 22:11:12,917 - GAugM EPNet train, Epoch [ 17/250]: loss 0.7210, auc 0.5214, ap 0.5010
2024-01-10 22:11:12,993 - GAugM EPNet train, Epoch [ 18/250]: loss 0.7210, auc 0.6379, ap 0.6095
2024-01-10 22:11:13,068 - GAugM EPNet train, Epoch [ 19/250]: loss 0.7209, auc 0.5351, ap 0.4982
2024-01-10 22:11:13,141 - GAugM EPNet train, Epoch [ 20/250]: loss 0.7210, auc 0.4502, ap 0.4823
2024-01-10 22:11:13,216 - GAugM EPNet train, Epoch [ 21/250]: loss 0.7209, auc 0.5390, ap 0.5460
2024-01-10 22:11:13,298 - GAugM EPNet train, Epoch [ 22/250]: loss 0.7210, auc 0.4923, ap 0.4934
2024-01-10 22:11:13,375 - GAugM EPNet train, Epoch [ 23/250]: loss 0.7208, auc 0.5308, ap 0.5336
2024-01-10 22:11:13,451 - GAugM EPNet train, Epoch [ 24/250]: loss 0.7209, auc 0.5233, ap 0.5057
2024-01-10 22:11:13,525 - GAugM EPNet train, Epoch [ 25/250]: loss 0.7209, auc 0.4916, ap 0.5028
2024-01-10 22:11:13,600 - GAugM EPNet train, Epoch [ 26/250]: loss 0.7210, auc 0.5116, ap 0.5335
2024-01-10 22:11:13,675 - GAugM EPNet train, Epoch [ 27/250]: loss 0.7209, auc 0.5379, ap 0.5885
2024-01-10 22:11:13,753 - GAugM EPNet train, Epoch [ 28/250]: loss 0.7209, auc 0.6552, ap 0.6371
2024-01-10 22:11:13,829 - GAugM EPNet train, Epoch [ 29/250]: loss 0.7210, auc 0.5667, ap 0.5520
2024-01-10 22:11:13,904 - GAugM EPNet train, Epoch [ 30/250]: loss 0.7209, auc 0.5806, ap 0.6037
2024-01-10 22:11:13,986 - GAugM EPNet train, Epoch [ 31/250]: loss 0.7208, auc 0.5068, ap 0.5121
2024-01-10 22:11:14,061 - GAugM EPNet train, Epoch [ 32/250]: loss 0.7210, auc 0.6714, ap 0.6211
2024-01-10 22:11:14,135 - GAugM EPNet train, Epoch [ 33/250]: loss 0.7209, auc 0.5297, ap 0.5336
2024-01-10 22:11:14,210 - GAugM EPNet train, Epoch [ 34/250]: loss 0.7209, auc 0.4591, ap 0.5046
2024-01-10 22:11:14,282 - GAugM EPNet train, Epoch [ 35/250]: loss 0.7209, auc 0.5721, ap 0.5318
2024-01-10 22:11:14,354 - GAugM EPNet train, Epoch [ 36/250]: loss 0.7209, auc 0.5945, ap 0.6038
2024-01-10 22:11:14,430 - GAugM EPNet train, Epoch [ 37/250]: loss 0.7209, auc 0.4906, ap 0.5133
2024-01-10 22:11:14,516 - GAugM EPNet train, Epoch [ 38/250]: loss 0.7209, auc 0.4756, ap 0.4825
2024-01-10 22:11:14,589 - GAugM EPNet train, Epoch [ 39/250]: loss 0.7208, auc 0.4614, ap 0.5112
2024-01-10 22:11:14,669 - GAugM EPNet train, Epoch [ 40/250]: loss 0.7210, auc 0.6061, ap 0.5714
2024-01-10 22:11:14,756 - GAugM EPNet train, Epoch [ 41/250]: loss 0.7210, auc 0.4692, ap 0.5067
2024-01-10 22:11:14,839 - GAugM EPNet train, Epoch [ 42/250]: loss 0.7209, auc 0.5000, ap 0.5321
2024-01-10 22:11:14,924 - GAugM EPNet train, Epoch [ 43/250]: loss 0.7208, auc 0.5361, ap 0.5921
2024-01-10 22:11:15,003 - GAugM EPNet train, Epoch [ 44/250]: loss 0.7208, auc 0.3975, ap 0.4578
2024-01-10 22:11:15,079 - GAugM EPNet train, Epoch [ 45/250]: loss 0.7209, auc 0.5109, ap 0.5217
2024-01-10 22:11:15,152 - GAugM EPNet train, Epoch [ 46/250]: loss 0.7209, auc 0.4313, ap 0.4507
2024-01-10 22:11:15,237 - GAugM EPNet train, Epoch [ 47/250]: loss 0.7210, auc 0.5598, ap 0.5663
2024-01-10 22:11:15,321 - GAugM EPNet train, Epoch [ 48/250]: loss 0.7210, auc 0.6045, ap 0.6137
2024-01-10 22:11:15,407 - GAugM EPNet train, Epoch [ 49/250]: loss 0.7209, auc 0.4829, ap 0.4863
2024-01-10 22:11:15,489 - GAugM EPNet train, Epoch [ 50/250]: loss 0.7210, auc 0.4988, ap 0.5113
2024-01-10 22:11:15,571 - GAugM EPNet train, Epoch [ 51/250]: loss 0.7210, auc 0.5509, ap 0.5498
2024-01-10 22:11:15,658 - GAugM EPNet train, Epoch [ 52/250]: loss 0.7209, auc 0.4245, ap 0.4806
2024-01-10 22:11:15,739 - GAugM EPNet train, Epoch [ 53/250]: loss 0.7209, auc 0.6050, ap 0.5757
2024-01-10 22:11:15,829 - GAugM EPNet train, Epoch [ 54/250]: loss 0.7211, auc 0.5123, ap 0.5552
2024-01-10 22:11:15,911 - GAugM EPNet train, Epoch [ 55/250]: loss 0.7209, auc 0.5493, ap 0.5467
2024-01-10 22:11:15,996 - GAugM EPNet train, Epoch [ 56/250]: loss 0.7208, auc 0.4676, ap 0.4705
2024-01-10 22:11:16,079 - GAugM EPNet train, Epoch [ 57/250]: loss 0.7209, auc 0.5536, ap 0.5257
2024-01-10 22:11:16,161 - GAugM EPNet train, Epoch [ 58/250]: loss 0.7210, auc 0.5543, ap 0.5854
2024-01-10 22:11:16,244 - GAugM EPNet train, Epoch [ 59/250]: loss 0.7211, auc 0.5525, ap 0.5517
2024-01-10 22:11:16,330 - GAugM EPNet train, Epoch [ 60/250]: loss 0.7210, auc 0.5383, ap 0.5354
2024-01-10 22:11:16,414 - GAugM EPNet train, Epoch [ 61/250]: loss 0.7209, auc 0.5497, ap 0.5420
2024-01-10 22:11:16,500 - GAugM EPNet train, Epoch [ 62/250]: loss 0.7210, auc 0.5112, ap 0.5474
2024-01-10 22:11:16,580 - GAugM EPNet train, Epoch [ 63/250]: loss 0.7208, auc 0.4227, ap 0.4533
2024-01-10 22:11:16,664 - GAugM EPNet train, Epoch [ 64/250]: loss 0.7208, auc 0.3603, ap 0.4213
2024-01-10 22:11:16,745 - GAugM EPNet train, Epoch [ 65/250]: loss 0.7208, auc 0.6169, ap 0.5818
2024-01-10 22:11:16,832 - GAugM EPNet train, Epoch [ 66/250]: loss 0.7209, auc 0.4432, ap 0.4779
2024-01-10 22:11:16,919 - GAugM EPNet train, Epoch [ 67/250]: loss 0.7209, auc 0.4909, ap 0.5068
2024-01-10 22:11:17,001 - GAugM EPNet train, Epoch [ 68/250]: loss 0.7210, auc 0.5249, ap 0.5343
2024-01-10 22:11:17,088 - GAugM EPNet train, Epoch [ 69/250]: loss 0.7210, auc 0.4938, ap 0.4986
2024-01-10 22:11:17,164 - GAugM EPNet train, Epoch [ 70/250]: loss 0.7210, auc 0.4943, ap 0.4900
2024-01-10 22:11:17,238 - GAugM EPNet train, Epoch [ 71/250]: loss 0.7210, auc 0.5384, ap 0.5458
2024-01-10 22:11:17,324 - GAugM EPNet train, Epoch [ 72/250]: loss 0.7210, auc 0.4607, ap 0.4877
2024-01-10 22:11:17,412 - GAugM EPNet train, Epoch [ 73/250]: loss 0.7209, auc 0.5320, ap 0.5250
2024-01-10 22:11:17,504 - GAugM EPNet train, Epoch [ 74/250]: loss 0.7209, auc 0.4801, ap 0.4968
2024-01-10 22:11:17,595 - GAugM EPNet train, Epoch [ 75/250]: loss 0.7210, auc 0.5041, ap 0.5183
2024-01-10 22:11:17,685 - GAugM EPNet train, Epoch [ 76/250]: loss 0.7209, auc 0.4336, ap 0.4684
2024-01-10 22:11:17,776 - GAugM EPNet train, Epoch [ 77/250]: loss 0.7208, auc 0.5662, ap 0.5795
2024-01-10 22:11:17,865 - GAugM EPNet train, Epoch [ 78/250]: loss 0.7209, auc 0.4608, ap 0.4871
2024-01-10 22:11:17,957 - GAugM EPNet train, Epoch [ 79/250]: loss 0.7208, auc 0.5219, ap 0.5150
2024-01-10 22:11:18,044 - GAugM EPNet train, Epoch [ 80/250]: loss 0.7209, auc 0.6246, ap 0.5747
2024-01-10 22:11:18,128 - GAugM EPNet train, Epoch [ 81/250]: loss 0.7209, auc 0.4952, ap 0.4909
2024-01-10 22:11:18,221 - GAugM EPNet train, Epoch [ 82/250]: loss 0.7210, auc 0.5214, ap 0.5133
2024-01-10 22:11:18,313 - GAugM EPNet train, Epoch [ 83/250]: loss 0.7209, auc 0.4268, ap 0.4987
2024-01-10 22:11:18,406 - GAugM EPNet train, Epoch [ 84/250]: loss 0.7209, auc 0.4096, ap 0.4418
2024-01-10 22:11:18,492 - GAugM EPNet train, Epoch [ 85/250]: loss 0.7210, auc 0.4429, ap 0.4659
2024-01-10 22:11:18,594 - GAugM EPNet train, Epoch [ 86/250]: loss 0.7208, auc 0.5233, ap 0.5139
2024-01-10 22:11:18,683 - GAugM EPNet train, Epoch [ 87/250]: loss 0.7209, auc 0.5956, ap 0.5967
2024-01-10 22:11:18,772 - GAugM EPNet train, Epoch [ 88/250]: loss 0.7210, auc 0.4571, ap 0.4628
2024-01-10 22:11:18,859 - GAugM EPNet train, Epoch [ 89/250]: loss 0.7210, auc 0.4939, ap 0.5067
2024-01-10 22:11:18,948 - GAugM EPNet train, Epoch [ 90/250]: loss 0.7209, auc 0.4785, ap 0.4966
2024-01-10 22:11:19,040 - GAugM EPNet train, Epoch [ 91/250]: loss 0.7208, auc 0.5511, ap 0.5242
2024-01-10 22:11:19,121 - GAugM EPNet train, Epoch [ 92/250]: loss 0.7209, auc 0.5826, ap 0.5701
2024-01-10 22:11:19,195 - GAugM EPNet train, Epoch [ 93/250]: loss 0.7209, auc 0.3936, ap 0.4398
2024-01-10 22:11:19,276 - GAugM EPNet train, Epoch [ 94/250]: loss 0.7210, auc 0.4527, ap 0.4727
2024-01-10 22:11:19,349 - GAugM EPNet train, Epoch [ 95/250]: loss 0.7210, auc 0.5333, ap 0.5055
2024-01-10 22:11:19,426 - GAugM EPNet train, Epoch [ 96/250]: loss 0.7209, auc 0.5541, ap 0.5522
2024-01-10 22:11:19,501 - GAugM EPNet train, Epoch [ 97/250]: loss 0.7209, auc 0.4833, ap 0.5215
2024-01-10 22:11:19,594 - GAugM EPNet train, Epoch [ 98/250]: loss 0.7209, auc 0.4242, ap 0.4502
2024-01-10 22:11:19,680 - GAugM EPNet train, Epoch [ 99/250]: loss 0.7209, auc 0.4667, ap 0.4846
2024-01-10 22:11:19,766 - GAugM EPNet train, Epoch [100/250]: loss 0.7210, auc 0.4811, ap 0.5043
2024-01-10 22:11:19,860 - GAugM EPNet train, Epoch [101/250]: loss 0.7210, auc 0.4897, ap 0.5321
2024-01-10 22:11:19,946 - GAugM EPNet train, Epoch [102/250]: loss 0.7209, auc 0.5534, ap 0.5476
2024-01-10 22:11:20,038 - GAugM EPNet train, Epoch [103/250]: loss 0.7209, auc 0.4555, ap 0.4936
2024-01-10 22:11:20,128 - GAugM EPNet train, Epoch [104/250]: loss 0.7209, auc 0.4881, ap 0.5148
2024-01-10 22:11:20,212 - GAugM EPNet train, Epoch [105/250]: loss 0.7209, auc 0.4854, ap 0.5006
2024-01-10 22:11:20,302 - GAugM EPNet train, Epoch [106/250]: loss 0.7210, auc 0.4032, ap 0.4441
2024-01-10 22:11:20,387 - GAugM EPNet train, Epoch [107/250]: loss 0.7210, auc 0.4804, ap 0.5224
2024-01-10 22:11:20,475 - GAugM EPNet train, Epoch [108/250]: loss 0.7208, auc 0.4676, ap 0.5034
2024-01-10 22:11:20,565 - GAugM EPNet train, Epoch [109/250]: loss 0.7210, auc 0.5012, ap 0.5150
2024-01-10 22:11:20,642 - GAugM EPNet train, Epoch [110/250]: loss 0.7209, auc 0.4897, ap 0.5213
2024-01-10 22:11:20,729 - GAugM EPNet train, Epoch [111/250]: loss 0.7210, auc 0.4678, ap 0.4776
2024-01-10 22:11:20,815 - GAugM EPNet train, Epoch [112/250]: loss 0.7209, auc 0.5940, ap 0.5935
2024-01-10 22:11:20,908 - GAugM EPNet train, Epoch [113/250]: loss 0.7210, auc 0.4514, ap 0.5105
2024-01-10 22:11:20,992 - GAugM EPNet train, Epoch [114/250]: loss 0.7209, auc 0.5707, ap 0.5507
2024-01-10 22:11:21,075 - GAugM EPNet train, Epoch [115/250]: loss 0.7210, auc 0.4594, ap 0.4969
2024-01-10 22:11:21,152 - GAugM EPNet train, Epoch [116/250]: loss 0.7209, auc 0.5999, ap 0.6191
2024-01-10 22:11:21,227 - GAugM EPNet train, Epoch [117/250]: loss 0.7208, auc 0.5059, ap 0.5003
2024-01-10 22:11:21,305 - GAugM EPNet train, Epoch [118/250]: loss 0.7209, auc 0.4776, ap 0.5060
2024-01-10 22:11:21,382 - GAugM EPNet train, Epoch [119/250]: loss 0.7209, auc 0.5513, ap 0.5572
2024-01-10 22:11:21,501 - GAugM EPNet train, Epoch [120/250]: loss 0.7210, auc 0.4724, ap 0.4709
2024-01-10 22:11:21,591 - GAugM EPNet train, Epoch [121/250]: loss 0.7210, auc 0.4804, ap 0.4862
2024-01-10 22:11:21,669 - GAugM EPNet train, Epoch [122/250]: loss 0.7209, auc 0.4884, ap 0.5086
2024-01-10 22:11:21,748 - GAugM EPNet train, Epoch [123/250]: loss 0.7209, auc 0.4870, ap 0.5174
2024-01-10 22:11:21,842 - GAugM EPNet train, Epoch [124/250]: loss 0.7210, auc 0.4448, ap 0.4623
2024-01-10 22:11:21,934 - GAugM EPNet train, Epoch [125/250]: loss 0.7209, auc 0.5066, ap 0.5149
2024-01-10 22:11:22,026 - GAugM EPNet train, Epoch [126/250]: loss 0.7210, auc 0.4188, ap 0.4400
2024-01-10 22:11:22,119 - GAugM EPNet train, Epoch [127/250]: loss 0.7209, auc 0.5290, ap 0.5374
2024-01-10 22:11:22,197 - GAugM EPNet train, Epoch [128/250]: loss 0.7210, auc 0.5066, ap 0.5017
2024-01-10 22:11:22,294 - GAugM EPNet train, Epoch [129/250]: loss 0.7208, auc 0.4252, ap 0.4722
2024-01-10 22:11:22,382 - GAugM EPNet train, Epoch [130/250]: loss 0.7210, auc 0.5746, ap 0.5830
2024-01-10 22:11:22,468 - GAugM EPNet train, Epoch [131/250]: loss 0.7210, auc 0.5586, ap 0.5906
2024-01-10 22:11:22,565 - GAugM EPNet train, Epoch [132/250]: loss 0.7209, auc 0.5546, ap 0.5432
2024-01-10 22:11:22,651 - GAugM EPNet train, Epoch [133/250]: loss 0.7209, auc 0.5107, ap 0.5437
2024-01-10 22:11:22,734 - GAugM EPNet train, Epoch [134/250]: loss 0.7210, auc 0.4744, ap 0.5092
2024-01-10 22:11:22,827 - GAugM EPNet train, Epoch [135/250]: loss 0.7209, auc 0.4236, ap 0.4645
2024-01-10 22:11:22,913 - GAugM EPNet train, Epoch [136/250]: loss 0.7209, auc 0.5351, ap 0.5170
2024-01-10 22:11:23,005 - GAugM EPNet train, Epoch [137/250]: loss 0.7210, auc 0.3893, ap 0.4272
2024-01-10 22:11:23,093 - GAugM EPNet train, Epoch [138/250]: loss 0.7210, auc 0.5301, ap 0.5406
2024-01-10 22:11:23,182 - GAugM EPNet train, Epoch [139/250]: loss 0.7210, auc 0.4813, ap 0.4956
2024-01-10 22:11:23,261 - GAugM EPNet train, Epoch [140/250]: loss 0.7209, auc 0.4459, ap 0.5234
2024-01-10 22:11:23,341 - GAugM EPNet train, Epoch [141/250]: loss 0.7209, auc 0.4375, ap 0.4591
2024-01-10 22:11:23,428 - GAugM EPNet train, Epoch [142/250]: loss 0.7209, auc 0.5596, ap 0.5676
2024-01-10 22:11:23,531 - GAugM EPNet train, Epoch [143/250]: loss 0.7209, auc 0.4519, ap 0.4575
2024-01-10 22:11:23,621 - GAugM EPNet train, Epoch [144/250]: loss 0.7209, auc 0.5502, ap 0.5206
2024-01-10 22:11:23,706 - GAugM EPNet train, Epoch [145/250]: loss 0.7209, auc 0.4375, ap 0.4592
2024-01-10 22:11:23,795 - GAugM EPNet train, Epoch [146/250]: loss 0.7209, auc 0.4865, ap 0.5239
2024-01-10 22:11:23,880 - GAugM EPNet train, Epoch [147/250]: loss 0.7209, auc 0.5158, ap 0.5615
2024-01-10 22:11:23,964 - GAugM EPNet train, Epoch [148/250]: loss 0.7209, auc 0.3921, ap 0.4295
2024-01-10 22:11:24,052 - GAugM EPNet train, Epoch [149/250]: loss 0.7208, auc 0.5151, ap 0.5195
2024-01-10 22:11:24,143 - GAugM EPNet train, Epoch [150/250]: loss 0.7209, auc 0.5130, ap 0.5289
2024-01-10 22:11:24,231 - GAugM EPNet train, Epoch [151/250]: loss 0.7209, auc 0.5468, ap 0.5379
2024-01-10 22:11:24,322 - GAugM EPNet train, Epoch [152/250]: loss 0.7209, auc 0.5525, ap 0.5620
2024-01-10 22:11:24,411 - GAugM EPNet train, Epoch [153/250]: loss 0.7209, auc 0.4920, ap 0.5578
2024-01-10 22:11:24,498 - GAugM EPNet train, Epoch [154/250]: loss 0.7209, auc 0.5376, ap 0.5430
2024-01-10 22:11:24,588 - GAugM EPNet train, Epoch [155/250]: loss 0.7209, auc 0.5360, ap 0.5405
2024-01-10 22:11:24,677 - GAugM EPNet train, Epoch [156/250]: loss 0.7209, auc 0.4204, ap 0.4379
2024-01-10 22:11:24,756 - GAugM EPNet train, Epoch [157/250]: loss 0.7209, auc 0.4715, ap 0.4829
2024-01-10 22:11:24,834 - GAugM EPNet train, Epoch [158/250]: loss 0.7208, auc 0.3946, ap 0.4491
2024-01-10 22:11:24,913 - GAugM EPNet train, Epoch [159/250]: loss 0.7208, auc 0.4434, ap 0.4551
2024-01-10 22:11:24,993 - GAugM EPNet train, Epoch [160/250]: loss 0.7209, auc 0.5635, ap 0.5567
2024-01-10 22:11:25,069 - GAugM EPNet train, Epoch [161/250]: loss 0.7209, auc 0.4961, ap 0.5137
2024-01-10 22:11:25,150 - GAugM EPNet train, Epoch [162/250]: loss 0.7209, auc 0.4066, ap 0.4353
2024-01-10 22:11:25,231 - GAugM EPNet train, Epoch [163/250]: loss 0.7209, auc 0.5812, ap 0.5602
2024-01-10 22:11:25,310 - GAugM EPNet train, Epoch [164/250]: loss 0.7211, auc 0.4891, ap 0.4937
2024-01-10 22:11:25,400 - GAugM EPNet train, Epoch [165/250]: loss 0.7210, auc 0.4455, ap 0.4654
2024-01-10 22:11:25,485 - GAugM EPNet train, Epoch [166/250]: loss 0.7208, auc 0.5477, ap 0.5470
2024-01-10 22:11:25,570 - GAugM EPNet train, Epoch [167/250]: loss 0.7209, auc 0.4427, ap 0.4633
2024-01-10 22:11:25,660 - GAugM EPNet train, Epoch [168/250]: loss 0.7209, auc 0.5091, ap 0.5609
2024-01-10 22:11:25,747 - GAugM EPNet train, Epoch [169/250]: loss 0.7209, auc 0.5461, ap 0.5683
2024-01-10 22:11:25,825 - GAugM EPNet train, Epoch [170/250]: loss 0.7210, auc 0.5279, ap 0.5096
2024-01-10 22:11:25,904 - GAugM EPNet train, Epoch [171/250]: loss 0.7209, auc 0.4687, ap 0.4910
2024-01-10 22:11:25,987 - GAugM EPNet train, Epoch [172/250]: loss 0.7208, auc 0.4272, ap 0.4404
2024-01-10 22:11:26,061 - GAugM EPNet train, Epoch [173/250]: loss 0.7209, auc 0.5607, ap 0.5560
2024-01-10 22:11:26,136 - GAugM EPNet train, Epoch [174/250]: loss 0.7209, auc 0.4619, ap 0.4560
2024-01-10 22:11:26,212 - GAugM EPNet train, Epoch [175/250]: loss 0.7209, auc 0.6200, ap 0.6235
2024-01-10 22:11:26,282 - GAugM EPNet train, Epoch [176/250]: loss 0.7209, auc 0.4742, ap 0.4788
2024-01-10 22:11:26,364 - GAugM EPNet train, Epoch [177/250]: loss 0.7210, auc 0.5452, ap 0.5283
2024-01-10 22:11:26,440 - GAugM EPNet train, Epoch [178/250]: loss 0.7210, auc 0.5504, ap 0.5556
2024-01-10 22:11:26,520 - GAugM EPNet train, Epoch [179/250]: loss 0.7210, auc 0.3895, ap 0.4300
2024-01-10 22:11:26,610 - GAugM EPNet train, Epoch [180/250]: loss 0.7210, auc 0.5303, ap 0.5696
2024-01-10 22:11:26,687 - GAugM EPNet train, Epoch [181/250]: loss 0.7209, auc 0.4441, ap 0.4723
2024-01-10 22:11:26,770 - GAugM EPNet train, Epoch [182/250]: loss 0.7209, auc 0.4719, ap 0.4807
2024-01-10 22:11:26,866 - GAugM EPNet train, Epoch [183/250]: loss 0.7210, auc 0.5676, ap 0.5649
2024-01-10 22:11:26,951 - GAugM EPNet train, Epoch [184/250]: loss 0.7209, auc 0.5153, ap 0.5693
2024-01-10 22:11:27,035 - GAugM EPNet train, Epoch [185/250]: loss 0.7209, auc 0.4639, ap 0.5041
2024-01-10 22:11:27,122 - GAugM EPNet train, Epoch [186/250]: loss 0.7208, auc 0.4425, ap 0.4749
2024-01-10 22:11:27,215 - GAugM EPNet train, Epoch [187/250]: loss 0.7209, auc 0.5112, ap 0.5159
2024-01-10 22:11:27,301 - GAugM EPNet train, Epoch [188/250]: loss 0.7209, auc 0.4820, ap 0.4976
2024-01-10 22:11:27,386 - GAugM EPNet train, Epoch [189/250]: loss 0.7209, auc 0.4988, ap 0.5340
2024-01-10 22:11:27,471 - GAugM EPNet train, Epoch [190/250]: loss 0.7209, auc 0.4384, ap 0.4492
2024-01-10 22:11:27,558 - GAugM EPNet train, Epoch [191/250]: loss 0.7209, auc 0.4144, ap 0.4836
2024-01-10 22:11:27,635 - GAugM EPNet train, Epoch [192/250]: loss 0.7209, auc 0.5203, ap 0.4809
2024-01-10 22:11:27,714 - GAugM EPNet train, Epoch [193/250]: loss 0.7209, auc 0.4899, ap 0.4814
2024-01-10 22:11:27,793 - GAugM EPNet train, Epoch [194/250]: loss 0.7209, auc 0.4308, ap 0.4679
2024-01-10 22:11:27,880 - GAugM EPNet train, Epoch [195/250]: loss 0.7209, auc 0.4811, ap 0.5005
2024-01-10 22:11:27,958 - GAugM EPNet train, Epoch [196/250]: loss 0.7208, auc 0.5228, ap 0.5176
2024-01-10 22:11:28,036 - GAugM EPNet train, Epoch [197/250]: loss 0.7210, auc 0.4108, ap 0.4548
2024-01-10 22:11:28,114 - GAugM EPNet train, Epoch [198/250]: loss 0.7210, auc 0.5365, ap 0.5380
2024-01-10 22:11:28,190 - GAugM EPNet train, Epoch [199/250]: loss 0.7209, auc 0.5228, ap 0.5424
2024-01-10 22:11:28,281 - GAugM EPNet train, Epoch [200/250]: loss 0.7210, auc 0.4288, ap 0.4618
2024-01-10 22:11:28,356 - GAugM EPNet train, Epoch [201/250]: loss 0.7209, auc 0.4114, ap 0.4430
2024-01-10 22:11:28,434 - GAugM EPNet train, Epoch [202/250]: loss 0.7210, auc 0.4422, ap 0.4975
2024-01-10 22:11:28,509 - GAugM EPNet train, Epoch [203/250]: loss 0.7210, auc 0.5110, ap 0.5417
2024-01-10 22:11:28,599 - GAugM EPNet train, Epoch [204/250]: loss 0.7209, auc 0.4098, ap 0.4529
2024-01-10 22:11:28,681 - GAugM EPNet train, Epoch [205/250]: loss 0.7209, auc 0.4884, ap 0.5244
2024-01-10 22:11:28,764 - GAugM EPNet train, Epoch [206/250]: loss 0.7209, auc 0.4559, ap 0.4932
2024-01-10 22:11:28,850 - GAugM EPNet train, Epoch [207/250]: loss 0.7210, auc 0.5189, ap 0.4992
2024-01-10 22:11:28,937 - GAugM EPNet train, Epoch [208/250]: loss 0.7209, auc 0.4778, ap 0.5209
2024-01-10 22:11:29,023 - GAugM EPNet train, Epoch [209/250]: loss 0.7210, auc 0.5561, ap 0.5163
2024-01-10 22:11:29,106 - GAugM EPNet train, Epoch [210/250]: loss 0.7209, auc 0.5103, ap 0.5188
2024-01-10 22:11:29,190 - GAugM EPNet train, Epoch [211/250]: loss 0.7210, auc 0.5256, ap 0.5315
2024-01-10 22:11:29,269 - GAugM EPNet train, Epoch [212/250]: loss 0.7210, auc 0.5037, ap 0.5295
2024-01-10 22:11:29,351 - GAugM EPNet train, Epoch [213/250]: loss 0.7208, auc 0.5810, ap 0.5956
2024-01-10 22:11:29,431 - GAugM EPNet train, Epoch [214/250]: loss 0.7210, auc 0.4929, ap 0.5028
2024-01-10 22:11:29,510 - GAugM EPNet train, Epoch [215/250]: loss 0.7210, auc 0.4033, ap 0.4653
2024-01-10 22:11:29,583 - GAugM EPNet train, Epoch [216/250]: loss 0.7209, auc 0.5185, ap 0.5211
2024-01-10 22:11:29,663 - GAugM EPNet train, Epoch [217/250]: loss 0.7209, auc 0.5014, ap 0.5339
2024-01-10 22:11:29,749 - GAugM EPNet train, Epoch [218/250]: loss 0.7209, auc 0.5885, ap 0.6168
2024-01-10 22:11:29,839 - GAugM EPNet train, Epoch [219/250]: loss 0.7208, auc 0.5632, ap 0.5564
2024-01-10 22:11:29,923 - GAugM EPNet train, Epoch [220/250]: loss 0.7210, auc 0.4721, ap 0.5054
2024-01-10 22:11:30,026 - GAugM EPNet train, Epoch [221/250]: loss 0.7209, auc 0.5210, ap 0.5219
2024-01-10 22:11:30,115 - GAugM EPNet train, Epoch [222/250]: loss 0.7209, auc 0.5708, ap 0.5614
2024-01-10 22:11:30,201 - GAugM EPNet train, Epoch [223/250]: loss 0.7209, auc 0.6201, ap 0.6139
2024-01-10 22:11:30,283 - GAugM EPNet train, Epoch [224/250]: loss 0.7210, auc 0.5208, ap 0.5040
2024-01-10 22:11:30,368 - GAugM EPNet train, Epoch [225/250]: loss 0.7209, auc 0.4715, ap 0.4860
2024-01-10 22:11:30,454 - GAugM EPNet train, Epoch [226/250]: loss 0.7210, auc 0.4745, ap 0.5085
2024-01-10 22:11:30,550 - GAugM EPNet train, Epoch [227/250]: loss 0.7210, auc 0.5650, ap 0.5429
2024-01-10 22:11:30,637 - GAugM EPNet train, Epoch [228/250]: loss 0.7209, auc 0.4781, ap 0.5150
2024-01-10 22:11:30,720 - GAugM EPNet train, Epoch [229/250]: loss 0.7209, auc 0.5673, ap 0.5640
2024-01-10 22:11:30,807 - GAugM EPNet train, Epoch [230/250]: loss 0.7209, auc 0.4468, ap 0.4984
2024-01-10 22:11:30,889 - GAugM EPNet train, Epoch [231/250]: loss 0.7209, auc 0.4808, ap 0.5029
2024-01-10 22:11:30,976 - GAugM EPNet train, Epoch [232/250]: loss 0.7209, auc 0.5027, ap 0.5226
2024-01-10 22:11:31,074 - GAugM EPNet train, Epoch [233/250]: loss 0.7210, auc 0.4961, ap 0.4871
2024-01-10 22:11:31,162 - GAugM EPNet train, Epoch [234/250]: loss 0.7209, auc 0.3973, ap 0.4550
2024-01-10 22:11:31,248 - GAugM EPNet train, Epoch [235/250]: loss 0.7209, auc 0.4171, ap 0.4403
2024-01-10 22:11:31,332 - GAugM EPNet train, Epoch [236/250]: loss 0.7209, auc 0.5708, ap 0.5761
2024-01-10 22:11:31,419 - GAugM EPNet train, Epoch [237/250]: loss 0.7210, auc 0.4706, ap 0.4956
2024-01-10 22:11:31,500 - GAugM EPNet train, Epoch [238/250]: loss 0.7210, auc 0.4895, ap 0.4830
2024-01-10 22:11:31,584 - GAugM EPNet train, Epoch [239/250]: loss 0.7209, auc 0.5429, ap 0.5584
2024-01-10 22:11:31,674 - GAugM EPNet train, Epoch [240/250]: loss 0.7209, auc 0.5151, ap 0.4981
2024-01-10 22:11:31,759 - GAugM EPNet train, Epoch [241/250]: loss 0.7209, auc 0.5411, ap 0.5148
2024-01-10 22:11:31,842 - GAugM EPNet train, Epoch [242/250]: loss 0.7210, auc 0.4331, ap 0.4902
2024-01-10 22:11:31,928 - GAugM EPNet train, Epoch [243/250]: loss 0.7210, auc 0.5249, ap 0.5389
2024-01-10 22:11:32,013 - GAugM EPNet train, Epoch [244/250]: loss 0.7209, auc 0.5160, ap 0.5489
2024-01-10 22:11:32,093 - GAugM EPNet train, Epoch [245/250]: loss 0.7210, auc 0.4909, ap 0.5145
2024-01-10 22:11:32,170 - GAugM EPNet train, Epoch [246/250]: loss 0.7208, auc 0.5297, ap 0.5307
2024-01-10 22:11:32,252 - GAugM EPNet train, Epoch [247/250]: loss 0.7209, auc 0.5176, ap 0.5002
2024-01-10 22:11:32,333 - GAugM EPNet train, Epoch [248/250]: loss 0.7211, auc 0.4856, ap 0.4803
2024-01-10 22:11:32,412 - GAugM EPNet train, Epoch [249/250]: loss 0.7209, auc 0.5434, ap 0.5488
2024-01-10 22:11:32,492 - GAugM EPNet train, Epoch [250/250]: loss 0.7208, auc 0.5630, ap 0.5630
2024-01-10 22:11:32,494 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa00f210>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:11:33,326 - GAugM EPNet train, Epoch [  1/250]: loss 0.7210, auc 0.5071, ap 0.5007
2024-01-10 22:11:33,416 - GAugM EPNet train, Epoch [  2/250]: loss 0.7210, auc 0.5210, ap 0.5110
2024-01-10 22:11:33,510 - GAugM EPNet train, Epoch [  3/250]: loss 0.7209, auc 0.5260, ap 0.5104
2024-01-10 22:11:33,602 - GAugM EPNet train, Epoch [  4/250]: loss 0.7209, auc 0.5242, ap 0.5303
2024-01-10 22:11:33,689 - GAugM EPNet train, Epoch [  5/250]: loss 0.7209, auc 0.5132, ap 0.5461
2024-01-10 22:11:33,777 - GAugM EPNet train, Epoch [  6/250]: loss 0.7209, auc 0.5271, ap 0.5107
2024-01-10 22:11:33,860 - GAugM EPNet train, Epoch [  7/250]: loss 0.7209, auc 0.4046, ap 0.4305
2024-01-10 22:11:33,943 - GAugM EPNet train, Epoch [  8/250]: loss 0.7210, auc 0.5278, ap 0.5365
2024-01-10 22:11:34,018 - GAugM EPNet train, Epoch [  9/250]: loss 0.7209, auc 0.5142, ap 0.5145
2024-01-10 22:11:34,100 - GAugM EPNet train, Epoch [ 10/250]: loss 0.7208, auc 0.5068, ap 0.5174
2024-01-10 22:11:34,176 - GAugM EPNet train, Epoch [ 11/250]: loss 0.7209, auc 0.4840, ap 0.5166
2024-01-10 22:11:34,251 - GAugM EPNet train, Epoch [ 12/250]: loss 0.7210, auc 0.4227, ap 0.4684
2024-01-10 22:11:34,328 - GAugM EPNet train, Epoch [ 13/250]: loss 0.7209, auc 0.5420, ap 0.5719
2024-01-10 22:11:34,404 - GAugM EPNet train, Epoch [ 14/250]: loss 0.7209, auc 0.5463, ap 0.5385
2024-01-10 22:11:34,479 - GAugM EPNet train, Epoch [ 15/250]: loss 0.7210, auc 0.4705, ap 0.5228
2024-01-10 22:11:34,558 - GAugM EPNet train, Epoch [ 16/250]: loss 0.7209, auc 0.5203, ap 0.5566
2024-01-10 22:11:34,649 - GAugM EPNet train, Epoch [ 17/250]: loss 0.7210, auc 0.6250, ap 0.6087
2024-01-10 22:11:34,738 - GAugM EPNet train, Epoch [ 18/250]: loss 0.7210, auc 0.5751, ap 0.5643
2024-01-10 22:11:34,820 - GAugM EPNet train, Epoch [ 19/250]: loss 0.7209, auc 0.5146, ap 0.5229
2024-01-10 22:11:34,904 - GAugM EPNet train, Epoch [ 20/250]: loss 0.7210, auc 0.5516, ap 0.5494
2024-01-10 22:11:34,990 - GAugM EPNet train, Epoch [ 21/250]: loss 0.7209, auc 0.4925, ap 0.5012
2024-01-10 22:11:35,075 - GAugM EPNet train, Epoch [ 22/250]: loss 0.7210, auc 0.3103, ap 0.3869
2024-01-10 22:11:35,158 - GAugM EPNet train, Epoch [ 23/250]: loss 0.7208, auc 0.4640, ap 0.4650
2024-01-10 22:11:35,245 - GAugM EPNet train, Epoch [ 24/250]: loss 0.7209, auc 0.5417, ap 0.5140
2024-01-10 22:11:35,326 - GAugM EPNet train, Epoch [ 25/250]: loss 0.7209, auc 0.4576, ap 0.4811
2024-01-10 22:11:35,407 - GAugM EPNet train, Epoch [ 26/250]: loss 0.7210, auc 0.6274, ap 0.5802
2024-01-10 22:11:35,490 - GAugM EPNet train, Epoch [ 27/250]: loss 0.7209, auc 0.4466, ap 0.4962
2024-01-10 22:11:35,573 - GAugM EPNet train, Epoch [ 28/250]: loss 0.7209, auc 0.5701, ap 0.5600
2024-01-10 22:11:35,661 - GAugM EPNet train, Epoch [ 29/250]: loss 0.7210, auc 0.5110, ap 0.5138
2024-01-10 22:11:35,745 - GAugM EPNet train, Epoch [ 30/250]: loss 0.7209, auc 0.5463, ap 0.5249
2024-01-10 22:11:35,828 - GAugM EPNet train, Epoch [ 31/250]: loss 0.7208, auc 0.4381, ap 0.4656
2024-01-10 22:11:35,909 - GAugM EPNet train, Epoch [ 32/250]: loss 0.7210, auc 0.5762, ap 0.5558
2024-01-10 22:11:35,997 - GAugM EPNet train, Epoch [ 33/250]: loss 0.7209, auc 0.5150, ap 0.5248
2024-01-10 22:11:36,072 - GAugM EPNet train, Epoch [ 34/250]: loss 0.7209, auc 0.4811, ap 0.5154
2024-01-10 22:11:36,147 - GAugM EPNet train, Epoch [ 35/250]: loss 0.7209, auc 0.5477, ap 0.5440
2024-01-10 22:11:36,222 - GAugM EPNet train, Epoch [ 36/250]: loss 0.7209, auc 0.6000, ap 0.6007
2024-01-10 22:11:36,299 - GAugM EPNet train, Epoch [ 37/250]: loss 0.7209, auc 0.5032, ap 0.5215
2024-01-10 22:11:36,381 - GAugM EPNet train, Epoch [ 38/250]: loss 0.7209, auc 0.5125, ap 0.4999
2024-01-10 22:11:36,455 - GAugM EPNet train, Epoch [ 39/250]: loss 0.7208, auc 0.4042, ap 0.4658
2024-01-10 22:11:36,531 - GAugM EPNet train, Epoch [ 40/250]: loss 0.7210, auc 0.5324, ap 0.5125
2024-01-10 22:11:36,607 - GAugM EPNet train, Epoch [ 41/250]: loss 0.7210, auc 0.3971, ap 0.4458
2024-01-10 22:11:36,685 - GAugM EPNet train, Epoch [ 42/250]: loss 0.7209, auc 0.4858, ap 0.5223
2024-01-10 22:11:36,759 - GAugM EPNet train, Epoch [ 43/250]: loss 0.7208, auc 0.4416, ap 0.4940
2024-01-10 22:11:36,838 - GAugM EPNet train, Epoch [ 44/250]: loss 0.7208, auc 0.4313, ap 0.4791
2024-01-10 22:11:36,918 - GAugM EPNet train, Epoch [ 45/250]: loss 0.7209, auc 0.5377, ap 0.5085
2024-01-10 22:11:36,994 - GAugM EPNet train, Epoch [ 46/250]: loss 0.7209, auc 0.4349, ap 0.4630
2024-01-10 22:11:37,069 - GAugM EPNet train, Epoch [ 47/250]: loss 0.7210, auc 0.5025, ap 0.5044
2024-01-10 22:11:37,144 - GAugM EPNet train, Epoch [ 48/250]: loss 0.7210, auc 0.6193, ap 0.6417
2024-01-10 22:11:37,219 - GAugM EPNet train, Epoch [ 49/250]: loss 0.7209, auc 0.5869, ap 0.5765
2024-01-10 22:11:37,299 - GAugM EPNet train, Epoch [ 50/250]: loss 0.7210, auc 0.5829, ap 0.5656
2024-01-10 22:11:37,378 - GAugM EPNet train, Epoch [ 51/250]: loss 0.7210, auc 0.4989, ap 0.5320
2024-01-10 22:11:37,452 - GAugM EPNet train, Epoch [ 52/250]: loss 0.7209, auc 0.4160, ap 0.4700
2024-01-10 22:11:37,533 - GAugM EPNet train, Epoch [ 53/250]: loss 0.7209, auc 0.5602, ap 0.5881
2024-01-10 22:11:37,607 - GAugM EPNet train, Epoch [ 54/250]: loss 0.7211, auc 0.5271, ap 0.5466
2024-01-10 22:11:37,682 - GAugM EPNet train, Epoch [ 55/250]: loss 0.7209, auc 0.4986, ap 0.5389
2024-01-10 22:11:37,759 - GAugM EPNet train, Epoch [ 56/250]: loss 0.7208, auc 0.5231, ap 0.5173
2024-01-10 22:11:37,834 - GAugM EPNet train, Epoch [ 57/250]: loss 0.7209, auc 0.4413, ap 0.4675
2024-01-10 22:11:37,915 - GAugM EPNet train, Epoch [ 58/250]: loss 0.7210, auc 0.4619, ap 0.5238
2024-01-10 22:11:37,990 - GAugM EPNet train, Epoch [ 59/250]: loss 0.7211, auc 0.5331, ap 0.5162
2024-01-10 22:11:38,063 - GAugM EPNet train, Epoch [ 60/250]: loss 0.7210, auc 0.5142, ap 0.5170
2024-01-10 22:11:38,138 - GAugM EPNet train, Epoch [ 61/250]: loss 0.7209, auc 0.4907, ap 0.4948
2024-01-10 22:11:38,223 - GAugM EPNet train, Epoch [ 62/250]: loss 0.7210, auc 0.5374, ap 0.5774
2024-01-10 22:11:38,299 - GAugM EPNet train, Epoch [ 63/250]: loss 0.7208, auc 0.5117, ap 0.5194
2024-01-10 22:11:38,378 - GAugM EPNet train, Epoch [ 64/250]: loss 0.7208, auc 0.3736, ap 0.4429
2024-01-10 22:11:38,458 - GAugM EPNet train, Epoch [ 65/250]: loss 0.7208, auc 0.4729, ap 0.5050
2024-01-10 22:11:38,533 - GAugM EPNet train, Epoch [ 66/250]: loss 0.7209, auc 0.4847, ap 0.5245
2024-01-10 22:11:38,609 - GAugM EPNet train, Epoch [ 67/250]: loss 0.7209, auc 0.5495, ap 0.5264
2024-01-10 22:11:38,684 - GAugM EPNet train, Epoch [ 68/250]: loss 0.7210, auc 0.4904, ap 0.5111
2024-01-10 22:11:38,766 - GAugM EPNet train, Epoch [ 69/250]: loss 0.7210, auc 0.5085, ap 0.5567
2024-01-10 22:11:38,844 - GAugM EPNet train, Epoch [ 70/250]: loss 0.7210, auc 0.4843, ap 0.4850
2024-01-10 22:11:38,922 - GAugM EPNet train, Epoch [ 71/250]: loss 0.7210, auc 0.5164, ap 0.5027
2024-01-10 22:11:39,002 - GAugM EPNet train, Epoch [ 72/250]: loss 0.7210, auc 0.4726, ap 0.5043
2024-01-10 22:11:39,081 - GAugM EPNet train, Epoch [ 73/250]: loss 0.7209, auc 0.5132, ap 0.5066
2024-01-10 22:11:39,161 - GAugM EPNet train, Epoch [ 74/250]: loss 0.7209, auc 0.4769, ap 0.5118
2024-01-10 22:11:39,238 - GAugM EPNet train, Epoch [ 75/250]: loss 0.7210, auc 0.4669, ap 0.4946
2024-01-10 22:11:39,324 - GAugM EPNet train, Epoch [ 76/250]: loss 0.7209, auc 0.4313, ap 0.4650
2024-01-10 22:11:39,401 - GAugM EPNet train, Epoch [ 77/250]: loss 0.7208, auc 0.6492, ap 0.6535
2024-01-10 22:11:39,479 - GAugM EPNet train, Epoch [ 78/250]: loss 0.7209, auc 0.4637, ap 0.4888
2024-01-10 22:11:39,556 - GAugM EPNet train, Epoch [ 79/250]: loss 0.7208, auc 0.4858, ap 0.5009
2024-01-10 22:11:39,633 - GAugM EPNet train, Epoch [ 80/250]: loss 0.7209, auc 0.6093, ap 0.5662
2024-01-10 22:11:39,710 - GAugM EPNet train, Epoch [ 81/250]: loss 0.7209, auc 0.5110, ap 0.5276
2024-01-10 22:11:39,792 - GAugM EPNet train, Epoch [ 82/250]: loss 0.7210, auc 0.6079, ap 0.5673
2024-01-10 22:11:39,869 - GAugM EPNet train, Epoch [ 83/250]: loss 0.7209, auc 0.3619, ap 0.4511
2024-01-10 22:11:39,947 - GAugM EPNet train, Epoch [ 84/250]: loss 0.7209, auc 0.4569, ap 0.4875
2024-01-10 22:11:40,028 - GAugM EPNet train, Epoch [ 85/250]: loss 0.7210, auc 0.4010, ap 0.4431
2024-01-10 22:11:40,105 - GAugM EPNet train, Epoch [ 86/250]: loss 0.7208, auc 0.4722, ap 0.4911
2024-01-10 22:11:40,184 - GAugM EPNet train, Epoch [ 87/250]: loss 0.7209, auc 0.5046, ap 0.5022
2024-01-10 22:11:40,259 - GAugM EPNet train, Epoch [ 88/250]: loss 0.7210, auc 0.4772, ap 0.5374
2024-01-10 22:11:40,338 - GAugM EPNet train, Epoch [ 89/250]: loss 0.7210, auc 0.5598, ap 0.5888
2024-01-10 22:11:40,415 - GAugM EPNet train, Epoch [ 90/250]: loss 0.7209, auc 0.5310, ap 0.5441
2024-01-10 22:11:40,491 - GAugM EPNet train, Epoch [ 91/250]: loss 0.7208, auc 0.4922, ap 0.4876
2024-01-10 22:11:40,567 - GAugM EPNet train, Epoch [ 92/250]: loss 0.7209, auc 0.6228, ap 0.5993
2024-01-10 22:11:40,642 - GAugM EPNet train, Epoch [ 93/250]: loss 0.7209, auc 0.3996, ap 0.4543
2024-01-10 22:11:40,718 - GAugM EPNet train, Epoch [ 94/250]: loss 0.7210, auc 0.4893, ap 0.4925
2024-01-10 22:11:40,800 - GAugM EPNet train, Epoch [ 95/250]: loss 0.7210, auc 0.5431, ap 0.5676
2024-01-10 22:11:40,876 - GAugM EPNet train, Epoch [ 96/250]: loss 0.7209, auc 0.5196, ap 0.5153
2024-01-10 22:11:40,955 - GAugM EPNet train, Epoch [ 97/250]: loss 0.7209, auc 0.4808, ap 0.5088
2024-01-10 22:11:41,032 - GAugM EPNet train, Epoch [ 98/250]: loss 0.7209, auc 0.4580, ap 0.4618
2024-01-10 22:11:41,109 - GAugM EPNet train, Epoch [ 99/250]: loss 0.7209, auc 0.4206, ap 0.4843
2024-01-10 22:11:41,190 - GAugM EPNet train, Epoch [100/250]: loss 0.7210, auc 0.5078, ap 0.5414
2024-01-10 22:11:41,263 - GAugM EPNet train, Epoch [101/250]: loss 0.7210, auc 0.4007, ap 0.4476
2024-01-10 22:11:41,340 - GAugM EPNet train, Epoch [102/250]: loss 0.7209, auc 0.5121, ap 0.5275
2024-01-10 22:11:41,423 - GAugM EPNet train, Epoch [103/250]: loss 0.7209, auc 0.5235, ap 0.5659
2024-01-10 22:11:41,502 - GAugM EPNet train, Epoch [104/250]: loss 0.7209, auc 0.4060, ap 0.4473
2024-01-10 22:11:41,578 - GAugM EPNet train, Epoch [105/250]: loss 0.7209, auc 0.4555, ap 0.4650
2024-01-10 22:11:41,655 - GAugM EPNet train, Epoch [106/250]: loss 0.7210, auc 0.5210, ap 0.4974
2024-01-10 22:11:41,729 - GAugM EPNet train, Epoch [107/250]: loss 0.7210, auc 0.4466, ap 0.5016
2024-01-10 22:11:41,808 - GAugM EPNet train, Epoch [108/250]: loss 0.7208, auc 0.5612, ap 0.5672
2024-01-10 22:11:41,883 - GAugM EPNet train, Epoch [109/250]: loss 0.7210, auc 0.4900, ap 0.5186
2024-01-10 22:11:41,958 - GAugM EPNet train, Epoch [110/250]: loss 0.7209, auc 0.4900, ap 0.5148
2024-01-10 22:11:42,033 - GAugM EPNet train, Epoch [111/250]: loss 0.7210, auc 0.5192, ap 0.5594
2024-01-10 22:11:42,108 - GAugM EPNet train, Epoch [112/250]: loss 0.7209, auc 0.5306, ap 0.5367
2024-01-10 22:11:42,185 - GAugM EPNet train, Epoch [113/250]: loss 0.7210, auc 0.5274, ap 0.5634
2024-01-10 22:11:42,261 - GAugM EPNet train, Epoch [114/250]: loss 0.7209, auc 0.4633, ap 0.4912
2024-01-10 22:11:42,349 - GAugM EPNet train, Epoch [115/250]: loss 0.7210, auc 0.4669, ap 0.5237
2024-01-10 22:11:42,427 - GAugM EPNet train, Epoch [116/250]: loss 0.7209, auc 0.5281, ap 0.5551
2024-01-10 22:11:42,504 - GAugM EPNet train, Epoch [117/250]: loss 0.7208, auc 0.5370, ap 0.5462
2024-01-10 22:11:42,578 - GAugM EPNet train, Epoch [118/250]: loss 0.7209, auc 0.4316, ap 0.4560
2024-01-10 22:11:42,653 - GAugM EPNet train, Epoch [119/250]: loss 0.7209, auc 0.4021, ap 0.4838
2024-01-10 22:11:42,728 - GAugM EPNet train, Epoch [120/250]: loss 0.7210, auc 0.4907, ap 0.4979
2024-01-10 22:11:42,805 - GAugM EPNet train, Epoch [121/250]: loss 0.7210, auc 0.4381, ap 0.4594
2024-01-10 22:11:42,884 - GAugM EPNet train, Epoch [122/250]: loss 0.7209, auc 0.4359, ap 0.4564
2024-01-10 22:11:42,959 - GAugM EPNet train, Epoch [123/250]: loss 0.7209, auc 0.5470, ap 0.5694
2024-01-10 22:11:43,033 - GAugM EPNet train, Epoch [124/250]: loss 0.7210, auc 0.4669, ap 0.4817
2024-01-10 22:11:43,115 - GAugM EPNet train, Epoch [125/250]: loss 0.7209, auc 0.5135, ap 0.5225
2024-01-10 22:11:43,189 - GAugM EPNet train, Epoch [126/250]: loss 0.7210, auc 0.4687, ap 0.5024
2024-01-10 22:11:43,273 - GAugM EPNet train, Epoch [127/250]: loss 0.7209, auc 0.5231, ap 0.5024
2024-01-10 22:11:43,355 - GAugM EPNet train, Epoch [128/250]: loss 0.7210, auc 0.5267, ap 0.4906
2024-01-10 22:11:43,430 - GAugM EPNet train, Epoch [129/250]: loss 0.7208, auc 0.3836, ap 0.4305
2024-01-10 22:11:43,512 - GAugM EPNet train, Epoch [130/250]: loss 0.7210, auc 0.4797, ap 0.4856
2024-01-10 22:11:43,592 - GAugM EPNet train, Epoch [131/250]: loss 0.7210, auc 0.5374, ap 0.5908
2024-01-10 22:11:43,671 - GAugM EPNet train, Epoch [132/250]: loss 0.7209, auc 0.5342, ap 0.5373
2024-01-10 22:11:43,752 - GAugM EPNet train, Epoch [133/250]: loss 0.7209, auc 0.4662, ap 0.5519
2024-01-10 22:11:43,837 - GAugM EPNet train, Epoch [134/250]: loss 0.7210, auc 0.4836, ap 0.5321
2024-01-10 22:11:43,918 - GAugM EPNet train, Epoch [135/250]: loss 0.7209, auc 0.4160, ap 0.4559
2024-01-10 22:11:44,006 - GAugM EPNet train, Epoch [136/250]: loss 0.7209, auc 0.5046, ap 0.5144
2024-01-10 22:11:44,090 - GAugM EPNet train, Epoch [137/250]: loss 0.7210, auc 0.4434, ap 0.5263
2024-01-10 22:11:44,173 - GAugM EPNet train, Epoch [138/250]: loss 0.7210, auc 0.5676, ap 0.5451
2024-01-10 22:11:44,248 - GAugM EPNet train, Epoch [139/250]: loss 0.7210, auc 0.4729, ap 0.5114
2024-01-10 22:11:44,324 - GAugM EPNet train, Epoch [140/250]: loss 0.7209, auc 0.5381, ap 0.5524
2024-01-10 22:11:44,418 - GAugM EPNet train, Epoch [141/250]: loss 0.7209, auc 0.5164, ap 0.5411
2024-01-10 22:11:44,511 - GAugM EPNet train, Epoch [142/250]: loss 0.7209, auc 0.5374, ap 0.5693
2024-01-10 22:11:44,596 - GAugM EPNet train, Epoch [143/250]: loss 0.7209, auc 0.5399, ap 0.5360
2024-01-10 22:11:44,676 - GAugM EPNet train, Epoch [144/250]: loss 0.7209, auc 0.4972, ap 0.4928
2024-01-10 22:11:44,754 - GAugM EPNet train, Epoch [145/250]: loss 0.7209, auc 0.3188, ap 0.4223
2024-01-10 22:11:44,837 - GAugM EPNet train, Epoch [146/250]: loss 0.7209, auc 0.5459, ap 0.5672
2024-01-10 22:11:44,938 - GAugM EPNet train, Epoch [147/250]: loss 0.7209, auc 0.6086, ap 0.6280
2024-01-10 22:11:45,033 - GAugM EPNet train, Epoch [148/250]: loss 0.7209, auc 0.4957, ap 0.5528
2024-01-10 22:11:45,127 - GAugM EPNet train, Epoch [149/250]: loss 0.7208, auc 0.5007, ap 0.5283
2024-01-10 22:11:45,217 - GAugM EPNet train, Epoch [150/250]: loss 0.7209, auc 0.5616, ap 0.5534
2024-01-10 22:11:45,307 - GAugM EPNet train, Epoch [151/250]: loss 0.7209, auc 0.5481, ap 0.5242
2024-01-10 22:11:45,397 - GAugM EPNet train, Epoch [152/250]: loss 0.7209, auc 0.4996, ap 0.5025
2024-01-10 22:11:45,488 - GAugM EPNet train, Epoch [153/250]: loss 0.7209, auc 0.4438, ap 0.4963
2024-01-10 22:11:45,577 - GAugM EPNet train, Epoch [154/250]: loss 0.7209, auc 0.5128, ap 0.5381
2024-01-10 22:11:45,671 - GAugM EPNet train, Epoch [155/250]: loss 0.7209, auc 0.5139, ap 0.5379
2024-01-10 22:11:45,760 - GAugM EPNet train, Epoch [156/250]: loss 0.7209, auc 0.4619, ap 0.5072
2024-01-10 22:11:45,854 - GAugM EPNet train, Epoch [157/250]: loss 0.7209, auc 0.4950, ap 0.5171
2024-01-10 22:11:45,949 - GAugM EPNet train, Epoch [158/250]: loss 0.7208, auc 0.4850, ap 0.4894
2024-01-10 22:11:46,040 - GAugM EPNet train, Epoch [159/250]: loss 0.7208, auc 0.5271, ap 0.5281
2024-01-10 22:11:46,131 - GAugM EPNet train, Epoch [160/250]: loss 0.7209, auc 0.5495, ap 0.5797
2024-01-10 22:11:46,220 - GAugM EPNet train, Epoch [161/250]: loss 0.7209, auc 0.4886, ap 0.4939
2024-01-10 22:11:46,312 - GAugM EPNet train, Epoch [162/250]: loss 0.7209, auc 0.4138, ap 0.4403
2024-01-10 22:11:46,408 - GAugM EPNet train, Epoch [163/250]: loss 0.7209, auc 0.5712, ap 0.5277
2024-01-10 22:11:46,503 - GAugM EPNet train, Epoch [164/250]: loss 0.7211, auc 0.5708, ap 0.5369
2024-01-10 22:11:46,595 - GAugM EPNet train, Epoch [165/250]: loss 0.7210, auc 0.4676, ap 0.4812
2024-01-10 22:11:46,687 - GAugM EPNet train, Epoch [166/250]: loss 0.7208, auc 0.5317, ap 0.5427
2024-01-10 22:11:46,777 - GAugM EPNet train, Epoch [167/250]: loss 0.7209, auc 0.4316, ap 0.4611
2024-01-10 22:11:46,867 - GAugM EPNet train, Epoch [168/250]: loss 0.7209, auc 0.4694, ap 0.5257
2024-01-10 22:11:46,962 - GAugM EPNet train, Epoch [169/250]: loss 0.7209, auc 0.5997, ap 0.6007
2024-01-10 22:11:47,050 - GAugM EPNet train, Epoch [170/250]: loss 0.7210, auc 0.5730, ap 0.5349
2024-01-10 22:11:47,142 - GAugM EPNet train, Epoch [171/250]: loss 0.7209, auc 0.4662, ap 0.4929
2024-01-10 22:11:47,233 - GAugM EPNet train, Epoch [172/250]: loss 0.7208, auc 0.4701, ap 0.4789
2024-01-10 22:11:47,324 - GAugM EPNet train, Epoch [173/250]: loss 0.7209, auc 0.4982, ap 0.5079
2024-01-10 22:11:47,416 - GAugM EPNet train, Epoch [174/250]: loss 0.7209, auc 0.4430, ap 0.4702
2024-01-10 22:11:47,507 - GAugM EPNet train, Epoch [175/250]: loss 0.7209, auc 0.6442, ap 0.6172
2024-01-10 22:11:47,598 - GAugM EPNet train, Epoch [176/250]: loss 0.7209, auc 0.5039, ap 0.5095
2024-01-10 22:11:47,690 - GAugM EPNet train, Epoch [177/250]: loss 0.7210, auc 0.5061, ap 0.5182
2024-01-10 22:11:47,777 - GAugM EPNet train, Epoch [178/250]: loss 0.7210, auc 0.5862, ap 0.5938
2024-01-10 22:11:47,878 - GAugM EPNet train, Epoch [179/250]: loss 0.7210, auc 0.4854, ap 0.5469
2024-01-10 22:11:47,960 - GAugM EPNet train, Epoch [180/250]: loss 0.7210, auc 0.4640, ap 0.5200
2024-01-10 22:11:48,040 - GAugM EPNet train, Epoch [181/250]: loss 0.7209, auc 0.4163, ap 0.4540
2024-01-10 22:11:48,119 - GAugM EPNet train, Epoch [182/250]: loss 0.7209, auc 0.5157, ap 0.5338
2024-01-10 22:11:48,211 - GAugM EPNet train, Epoch [183/250]: loss 0.7210, auc 0.5299, ap 0.5071
2024-01-10 22:11:48,302 - GAugM EPNet train, Epoch [184/250]: loss 0.7209, auc 0.5445, ap 0.5665
2024-01-10 22:11:48,382 - GAugM EPNet train, Epoch [185/250]: loss 0.7209, auc 0.4420, ap 0.4873
2024-01-10 22:11:48,458 - GAugM EPNet train, Epoch [186/250]: loss 0.7208, auc 0.4566, ap 0.5189
2024-01-10 22:11:48,535 - GAugM EPNet train, Epoch [187/250]: loss 0.7209, auc 0.5463, ap 0.5276
2024-01-10 22:11:48,624 - GAugM EPNet train, Epoch [188/250]: loss 0.7209, auc 0.3882, ap 0.4181
2024-01-10 22:11:48,711 - GAugM EPNet train, Epoch [189/250]: loss 0.7209, auc 0.6011, ap 0.6297
2024-01-10 22:11:48,792 - GAugM EPNet train, Epoch [190/250]: loss 0.7209, auc 0.3993, ap 0.4367
2024-01-10 22:11:48,881 - GAugM EPNet train, Epoch [191/250]: loss 0.7209, auc 0.3807, ap 0.4319
2024-01-10 22:11:48,971 - GAugM EPNet train, Epoch [192/250]: loss 0.7209, auc 0.5424, ap 0.4995
2024-01-10 22:11:49,064 - GAugM EPNet train, Epoch [193/250]: loss 0.7209, auc 0.4733, ap 0.4981
2024-01-10 22:11:49,153 - GAugM EPNet train, Epoch [194/250]: loss 0.7209, auc 0.4306, ap 0.4666
2024-01-10 22:11:49,251 - GAugM EPNet train, Epoch [195/250]: loss 0.7209, auc 0.4487, ap 0.4586
2024-01-10 22:11:49,339 - GAugM EPNet train, Epoch [196/250]: loss 0.7208, auc 0.5142, ap 0.5117
2024-01-10 22:11:49,429 - GAugM EPNet train, Epoch [197/250]: loss 0.7210, auc 0.5061, ap 0.5127
2024-01-10 22:11:49,513 - GAugM EPNet train, Epoch [198/250]: loss 0.7210, auc 0.5865, ap 0.5682
2024-01-10 22:11:49,601 - GAugM EPNet train, Epoch [199/250]: loss 0.7209, auc 0.5178, ap 0.5333
2024-01-10 22:11:49,683 - GAugM EPNet train, Epoch [200/250]: loss 0.7210, auc 0.4893, ap 0.4898
2024-01-10 22:11:49,771 - GAugM EPNet train, Epoch [201/250]: loss 0.7209, auc 0.4267, ap 0.4602
2024-01-10 22:11:49,859 - GAugM EPNet train, Epoch [202/250]: loss 0.7210, auc 0.5593, ap 0.5852
2024-01-10 22:11:49,947 - GAugM EPNet train, Epoch [203/250]: loss 0.7210, auc 0.5684, ap 0.5906
2024-01-10 22:11:50,035 - GAugM EPNet train, Epoch [204/250]: loss 0.7209, auc 0.4309, ap 0.4602
2024-01-10 22:11:50,111 - GAugM EPNet train, Epoch [205/250]: loss 0.7209, auc 0.5559, ap 0.5899
2024-01-10 22:11:50,189 - GAugM EPNet train, Epoch [206/250]: loss 0.7209, auc 0.4021, ap 0.4289
2024-01-10 22:11:50,267 - GAugM EPNet train, Epoch [207/250]: loss 0.7210, auc 0.4238, ap 0.4709
2024-01-10 22:11:50,355 - GAugM EPNet train, Epoch [208/250]: loss 0.7209, auc 0.4402, ap 0.4954
2024-01-10 22:11:50,446 - GAugM EPNet train, Epoch [209/250]: loss 0.7210, auc 0.5829, ap 0.5987
2024-01-10 22:11:50,535 - GAugM EPNet train, Epoch [210/250]: loss 0.7209, auc 0.4598, ap 0.4910
2024-01-10 22:11:50,628 - GAugM EPNet train, Epoch [211/250]: loss 0.7210, auc 0.4719, ap 0.5116
2024-01-10 22:11:50,719 - GAugM EPNet train, Epoch [212/250]: loss 0.7210, auc 0.5007, ap 0.5129
2024-01-10 22:11:50,807 - GAugM EPNet train, Epoch [213/250]: loss 0.7208, auc 0.6862, ap 0.7093
2024-01-10 22:11:50,897 - GAugM EPNet train, Epoch [214/250]: loss 0.7210, auc 0.4756, ap 0.4874
2024-01-10 22:11:50,987 - GAugM EPNet train, Epoch [215/250]: loss 0.7210, auc 0.5203, ap 0.5302
2024-01-10 22:11:51,077 - GAugM EPNet train, Epoch [216/250]: loss 0.7209, auc 0.5260, ap 0.5324
2024-01-10 22:11:51,169 - GAugM EPNet train, Epoch [217/250]: loss 0.7209, auc 0.5360, ap 0.5973
2024-01-10 22:11:51,249 - GAugM EPNet train, Epoch [218/250]: loss 0.7209, auc 0.5477, ap 0.6018
2024-01-10 22:11:51,326 - GAugM EPNet train, Epoch [219/250]: loss 0.7208, auc 0.5089, ap 0.5073
2024-01-10 22:11:51,407 - GAugM EPNet train, Epoch [220/250]: loss 0.7210, auc 0.4883, ap 0.5391
2024-01-10 22:11:51,498 - GAugM EPNet train, Epoch [221/250]: loss 0.7209, auc 0.5577, ap 0.5474
2024-01-10 22:11:51,578 - GAugM EPNet train, Epoch [222/250]: loss 0.7209, auc 0.4405, ap 0.4693
2024-01-10 22:11:51,654 - GAugM EPNet train, Epoch [223/250]: loss 0.7209, auc 0.5206, ap 0.5503
2024-01-10 22:11:51,732 - GAugM EPNet train, Epoch [224/250]: loss 0.7210, auc 0.4434, ap 0.4721
2024-01-10 22:11:51,807 - GAugM EPNet train, Epoch [225/250]: loss 0.7209, auc 0.4690, ap 0.4642
2024-01-10 22:11:51,887 - GAugM EPNet train, Epoch [226/250]: loss 0.7210, auc 0.4779, ap 0.4848
2024-01-10 22:11:51,974 - GAugM EPNet train, Epoch [227/250]: loss 0.7210, auc 0.5050, ap 0.5119
2024-01-10 22:11:52,065 - GAugM EPNet train, Epoch [228/250]: loss 0.7209, auc 0.4067, ap 0.4419
2024-01-10 22:11:52,153 - GAugM EPNet train, Epoch [229/250]: loss 0.7209, auc 0.5566, ap 0.5437
2024-01-10 22:11:52,241 - GAugM EPNet train, Epoch [230/250]: loss 0.7209, auc 0.5032, ap 0.5303
2024-01-10 22:11:52,329 - GAugM EPNet train, Epoch [231/250]: loss 0.7209, auc 0.4583, ap 0.4701
2024-01-10 22:11:52,428 - GAugM EPNet train, Epoch [232/250]: loss 0.7209, auc 0.5427, ap 0.5421
2024-01-10 22:11:52,520 - GAugM EPNet train, Epoch [233/250]: loss 0.7210, auc 0.5239, ap 0.5221
2024-01-10 22:11:52,612 - GAugM EPNet train, Epoch [234/250]: loss 0.7209, auc 0.4640, ap 0.4887
2024-01-10 22:11:52,703 - GAugM EPNet train, Epoch [235/250]: loss 0.7209, auc 0.4267, ap 0.4528
2024-01-10 22:11:52,792 - GAugM EPNet train, Epoch [236/250]: loss 0.7209, auc 0.4626, ap 0.4674
2024-01-10 22:11:52,879 - GAugM EPNet train, Epoch [237/250]: loss 0.7210, auc 0.5438, ap 0.5575
2024-01-10 22:11:52,967 - GAugM EPNet train, Epoch [238/250]: loss 0.7210, auc 0.4591, ap 0.4724
2024-01-10 22:11:53,049 - GAugM EPNet train, Epoch [239/250]: loss 0.7209, auc 0.5374, ap 0.5578
2024-01-10 22:11:53,128 - GAugM EPNet train, Epoch [240/250]: loss 0.7209, auc 0.5306, ap 0.5019
2024-01-10 22:11:53,211 - GAugM EPNet train, Epoch [241/250]: loss 0.7209, auc 0.5132, ap 0.5099
2024-01-10 22:11:53,295 - GAugM EPNet train, Epoch [242/250]: loss 0.7210, auc 0.5142, ap 0.5223
2024-01-10 22:11:53,382 - GAugM EPNet train, Epoch [243/250]: loss 0.7210, auc 0.4865, ap 0.5446
2024-01-10 22:11:53,467 - GAugM EPNet train, Epoch [244/250]: loss 0.7209, auc 0.5687, ap 0.5831
2024-01-10 22:11:53,556 - GAugM EPNet train, Epoch [245/250]: loss 0.7210, auc 0.4644, ap 0.4935
2024-01-10 22:11:53,644 - GAugM EPNet train, Epoch [246/250]: loss 0.7208, auc 0.5616, ap 0.5519
2024-01-10 22:11:53,734 - GAugM EPNet train, Epoch [247/250]: loss 0.7209, auc 0.5203, ap 0.5188
2024-01-10 22:11:53,819 - GAugM EPNet train, Epoch [248/250]: loss 0.7211, auc 0.5231, ap 0.5367
2024-01-10 22:11:53,905 - GAugM EPNet train, Epoch [249/250]: loss 0.7209, auc 0.5253, ap 0.5423
2024-01-10 22:11:53,992 - GAugM EPNet train, Epoch [250/250]: loss 0.7208, auc 0.5260, ap 0.5326
2024-01-10 22:11:53,993 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9e1ea90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:11:54,717 - GAugM EPNet train, Epoch [  1/250]: loss 0.7210, auc 0.4114, ap 0.4589
2024-01-10 22:11:54,808 - GAugM EPNet train, Epoch [  2/250]: loss 0.7210, auc 0.4760, ap 0.4902
2024-01-10 22:11:54,891 - GAugM EPNet train, Epoch [  3/250]: loss 0.7209, auc 0.5384, ap 0.5184
2024-01-10 22:11:54,980 - GAugM EPNet train, Epoch [  4/250]: loss 0.7209, auc 0.3975, ap 0.4698
2024-01-10 22:11:55,070 - GAugM EPNet train, Epoch [  5/250]: loss 0.7209, auc 0.6007, ap 0.5904
2024-01-10 22:11:55,159 - GAugM EPNet train, Epoch [  6/250]: loss 0.7209, auc 0.5303, ap 0.5096
2024-01-10 22:11:55,247 - GAugM EPNet train, Epoch [  7/250]: loss 0.7209, auc 0.4628, ap 0.4706
2024-01-10 22:11:55,332 - GAugM EPNet train, Epoch [  8/250]: loss 0.7210, auc 0.5465, ap 0.5506
2024-01-10 22:11:55,417 - GAugM EPNet train, Epoch [  9/250]: loss 0.7209, auc 0.4818, ap 0.4838
2024-01-10 22:11:55,507 - GAugM EPNet train, Epoch [ 10/250]: loss 0.7208, auc 0.4902, ap 0.5400
2024-01-10 22:11:55,590 - GAugM EPNet train, Epoch [ 11/250]: loss 0.7209, auc 0.5071, ap 0.5219
2024-01-10 22:11:55,676 - GAugM EPNet train, Epoch [ 12/250]: loss 0.7210, auc 0.4867, ap 0.4977
2024-01-10 22:11:55,763 - GAugM EPNet train, Epoch [ 13/250]: loss 0.7209, auc 0.5657, ap 0.5542
2024-01-10 22:11:55,845 - GAugM EPNet train, Epoch [ 14/250]: loss 0.7209, auc 0.5055, ap 0.5483
2024-01-10 22:11:55,930 - GAugM EPNet train, Epoch [ 15/250]: loss 0.7210, auc 0.4069, ap 0.4769
2024-01-10 22:11:56,013 - GAugM EPNet train, Epoch [ 16/250]: loss 0.7209, auc 0.5867, ap 0.5834
2024-01-10 22:11:56,092 - GAugM EPNet train, Epoch [ 17/250]: loss 0.7210, auc 0.4838, ap 0.4988
2024-01-10 22:11:56,171 - GAugM EPNet train, Epoch [ 18/250]: loss 0.7210, auc 0.5769, ap 0.5851
2024-01-10 22:11:56,248 - GAugM EPNet train, Epoch [ 19/250]: loss 0.7209, auc 0.4715, ap 0.4701
2024-01-10 22:11:56,324 - GAugM EPNet train, Epoch [ 20/250]: loss 0.7210, auc 0.4745, ap 0.5141
2024-01-10 22:11:56,405 - GAugM EPNet train, Epoch [ 21/250]: loss 0.7209, auc 0.4642, ap 0.4740
2024-01-10 22:11:56,482 - GAugM EPNet train, Epoch [ 22/250]: loss 0.7210, auc 0.4316, ap 0.4515
2024-01-10 22:11:56,565 - GAugM EPNet train, Epoch [ 23/250]: loss 0.7208, auc 0.5183, ap 0.5142
2024-01-10 22:11:56,640 - GAugM EPNet train, Epoch [ 24/250]: loss 0.7209, auc 0.5634, ap 0.5344
2024-01-10 22:11:56,721 - GAugM EPNet train, Epoch [ 25/250]: loss 0.7209, auc 0.4176, ap 0.4640
2024-01-10 22:11:56,800 - GAugM EPNet train, Epoch [ 26/250]: loss 0.7210, auc 0.5634, ap 0.5543
2024-01-10 22:11:56,883 - GAugM EPNet train, Epoch [ 27/250]: loss 0.7209, auc 0.5178, ap 0.5884
2024-01-10 22:11:56,965 - GAugM EPNet train, Epoch [ 28/250]: loss 0.7209, auc 0.5614, ap 0.5586
2024-01-10 22:11:57,040 - GAugM EPNet train, Epoch [ 29/250]: loss 0.7210, auc 0.5372, ap 0.5108
2024-01-10 22:11:57,124 - GAugM EPNet train, Epoch [ 30/250]: loss 0.7209, auc 0.5402, ap 0.5815
2024-01-10 22:11:57,205 - GAugM EPNet train, Epoch [ 31/250]: loss 0.7208, auc 0.4523, ap 0.4934
2024-01-10 22:11:57,284 - GAugM EPNet train, Epoch [ 32/250]: loss 0.7210, auc 0.5215, ap 0.5154
2024-01-10 22:11:57,360 - GAugM EPNet train, Epoch [ 33/250]: loss 0.7209, auc 0.4338, ap 0.4783
2024-01-10 22:11:57,442 - GAugM EPNet train, Epoch [ 34/250]: loss 0.7209, auc 0.4721, ap 0.5137
2024-01-10 22:11:57,521 - GAugM EPNet train, Epoch [ 35/250]: loss 0.7209, auc 0.4897, ap 0.5077
2024-01-10 22:11:57,604 - GAugM EPNet train, Epoch [ 36/250]: loss 0.7209, auc 0.5920, ap 0.6027
2024-01-10 22:11:57,679 - GAugM EPNet train, Epoch [ 37/250]: loss 0.7209, auc 0.4824, ap 0.5373
2024-01-10 22:11:57,762 - GAugM EPNet train, Epoch [ 38/250]: loss 0.7209, auc 0.4790, ap 0.4777
2024-01-10 22:11:57,839 - GAugM EPNet train, Epoch [ 39/250]: loss 0.7208, auc 0.4480, ap 0.5005
2024-01-10 22:11:57,914 - GAugM EPNet train, Epoch [ 40/250]: loss 0.7210, auc 0.6121, ap 0.5830
2024-01-10 22:11:57,990 - GAugM EPNet train, Epoch [ 41/250]: loss 0.7210, auc 0.5036, ap 0.5414
2024-01-10 22:11:58,071 - GAugM EPNet train, Epoch [ 42/250]: loss 0.7209, auc 0.5377, ap 0.5918
2024-01-10 22:11:58,144 - GAugM EPNet train, Epoch [ 43/250]: loss 0.7208, auc 0.4749, ap 0.5293
2024-01-10 22:11:58,228 - GAugM EPNet train, Epoch [ 44/250]: loss 0.7208, auc 0.4867, ap 0.4979
2024-01-10 22:11:58,310 - GAugM EPNet train, Epoch [ 45/250]: loss 0.7209, auc 0.5328, ap 0.5787
2024-01-10 22:11:58,390 - GAugM EPNet train, Epoch [ 46/250]: loss 0.7209, auc 0.5358, ap 0.5570
2024-01-10 22:11:58,471 - GAugM EPNet train, Epoch [ 47/250]: loss 0.7210, auc 0.5043, ap 0.5136
2024-01-10 22:11:58,548 - GAugM EPNet train, Epoch [ 48/250]: loss 0.7210, auc 0.5532, ap 0.5642
2024-01-10 22:11:58,624 - GAugM EPNet train, Epoch [ 49/250]: loss 0.7209, auc 0.4925, ap 0.4952
2024-01-10 22:11:58,701 - GAugM EPNet train, Epoch [ 50/250]: loss 0.7210, auc 0.4448, ap 0.4676
2024-01-10 22:11:58,779 - GAugM EPNet train, Epoch [ 51/250]: loss 0.7210, auc 0.4624, ap 0.4925
2024-01-10 22:11:58,854 - GAugM EPNet train, Epoch [ 52/250]: loss 0.7209, auc 0.4868, ap 0.5572
2024-01-10 22:11:58,928 - GAugM EPNet train, Epoch [ 53/250]: loss 0.7209, auc 0.5457, ap 0.5565
2024-01-10 22:11:59,003 - GAugM EPNet train, Epoch [ 54/250]: loss 0.7211, auc 0.6679, ap 0.6331
2024-01-10 22:11:59,080 - GAugM EPNet train, Epoch [ 55/250]: loss 0.7209, auc 0.5769, ap 0.5864
2024-01-10 22:11:59,153 - GAugM EPNet train, Epoch [ 56/250]: loss 0.7208, auc 0.4478, ap 0.4794
2024-01-10 22:11:59,225 - GAugM EPNet train, Epoch [ 57/250]: loss 0.7209, auc 0.5048, ap 0.5078
2024-01-10 22:11:59,300 - GAugM EPNet train, Epoch [ 58/250]: loss 0.7210, auc 0.5215, ap 0.5468
2024-01-10 22:11:59,378 - GAugM EPNet train, Epoch [ 59/250]: loss 0.7211, auc 0.5112, ap 0.5199
2024-01-10 22:11:59,467 - GAugM EPNet train, Epoch [ 60/250]: loss 0.7210, auc 0.5247, ap 0.5193
2024-01-10 22:11:59,547 - GAugM EPNet train, Epoch [ 61/250]: loss 0.7209, auc 0.5611, ap 0.5686
2024-01-10 22:11:59,620 - GAugM EPNet train, Epoch [ 62/250]: loss 0.7210, auc 0.5331, ap 0.5909
2024-01-10 22:11:59,706 - GAugM EPNet train, Epoch [ 63/250]: loss 0.7208, auc 0.4911, ap 0.4777
2024-01-10 22:11:59,781 - GAugM EPNet train, Epoch [ 64/250]: loss 0.7208, auc 0.5153, ap 0.5486
2024-01-10 22:11:59,855 - GAugM EPNet train, Epoch [ 65/250]: loss 0.7208, auc 0.4868, ap 0.5148
2024-01-10 22:11:59,928 - GAugM EPNet train, Epoch [ 66/250]: loss 0.7209, auc 0.4343, ap 0.4787
2024-01-10 22:12:00,002 - GAugM EPNet train, Epoch [ 67/250]: loss 0.7209, auc 0.5098, ap 0.5085
2024-01-10 22:12:00,081 - GAugM EPNet train, Epoch [ 68/250]: loss 0.7210, auc 0.5217, ap 0.5329
2024-01-10 22:12:00,166 - GAugM EPNet train, Epoch [ 69/250]: loss 0.7210, auc 0.5554, ap 0.5547
2024-01-10 22:12:00,242 - GAugM EPNet train, Epoch [ 70/250]: loss 0.7210, auc 0.4633, ap 0.4685
2024-01-10 22:12:00,329 - GAugM EPNet train, Epoch [ 71/250]: loss 0.7210, auc 0.5513, ap 0.5346
2024-01-10 22:12:00,407 - GAugM EPNet train, Epoch [ 72/250]: loss 0.7210, auc 0.5036, ap 0.5292
2024-01-10 22:12:00,482 - GAugM EPNet train, Epoch [ 73/250]: loss 0.7209, auc 0.5103, ap 0.5013
2024-01-10 22:12:00,561 - GAugM EPNet train, Epoch [ 74/250]: loss 0.7209, auc 0.4350, ap 0.4519
2024-01-10 22:12:00,642 - GAugM EPNet train, Epoch [ 75/250]: loss 0.7210, auc 0.4826, ap 0.4906
2024-01-10 22:12:00,718 - GAugM EPNet train, Epoch [ 76/250]: loss 0.7209, auc 0.3975, ap 0.4367
2024-01-10 22:12:00,791 - GAugM EPNet train, Epoch [ 77/250]: loss 0.7208, auc 0.5746, ap 0.6013
2024-01-10 22:12:00,866 - GAugM EPNet train, Epoch [ 78/250]: loss 0.7209, auc 0.4945, ap 0.5095
2024-01-10 22:12:00,939 - GAugM EPNet train, Epoch [ 79/250]: loss 0.7208, auc 0.5899, ap 0.5722
2024-01-10 22:12:01,012 - GAugM EPNet train, Epoch [ 80/250]: loss 0.7209, auc 0.5555, ap 0.5517
2024-01-10 22:12:01,085 - GAugM EPNet train, Epoch [ 81/250]: loss 0.7209, auc 0.5028, ap 0.5063
2024-01-10 22:12:01,158 - GAugM EPNet train, Epoch [ 82/250]: loss 0.7210, auc 0.5328, ap 0.5209
2024-01-10 22:12:01,233 - GAugM EPNet train, Epoch [ 83/250]: loss 0.7209, auc 0.4315, ap 0.4812
2024-01-10 22:12:01,311 - GAugM EPNet train, Epoch [ 84/250]: loss 0.7209, auc 0.4778, ap 0.4867
2024-01-10 22:12:01,395 - GAugM EPNet train, Epoch [ 85/250]: loss 0.7210, auc 0.3882, ap 0.4541
2024-01-10 22:12:01,480 - GAugM EPNet train, Epoch [ 86/250]: loss 0.7208, auc 0.5646, ap 0.5302
2024-01-10 22:12:01,555 - GAugM EPNet train, Epoch [ 87/250]: loss 0.7209, auc 0.5205, ap 0.5026
2024-01-10 22:12:01,638 - GAugM EPNet train, Epoch [ 88/250]: loss 0.7210, auc 0.4550, ap 0.5148
2024-01-10 22:12:01,715 - GAugM EPNet train, Epoch [ 89/250]: loss 0.7210, auc 0.4425, ap 0.4718
2024-01-10 22:12:01,791 - GAugM EPNet train, Epoch [ 90/250]: loss 0.7209, auc 0.3754, ap 0.4279
2024-01-10 22:12:01,863 - GAugM EPNet train, Epoch [ 91/250]: loss 0.7208, auc 0.5263, ap 0.5041
2024-01-10 22:12:01,938 - GAugM EPNet train, Epoch [ 92/250]: loss 0.7209, auc 0.5027, ap 0.5336
2024-01-10 22:12:02,012 - GAugM EPNet train, Epoch [ 93/250]: loss 0.7209, auc 0.3710, ap 0.4268
2024-01-10 22:12:02,086 - GAugM EPNet train, Epoch [ 94/250]: loss 0.7210, auc 0.5224, ap 0.5178
2024-01-10 22:12:02,165 - GAugM EPNet train, Epoch [ 95/250]: loss 0.7210, auc 0.4728, ap 0.4879
2024-01-10 22:12:02,241 - GAugM EPNet train, Epoch [ 96/250]: loss 0.7209, auc 0.5942, ap 0.5834
2024-01-10 22:12:02,314 - GAugM EPNet train, Epoch [ 97/250]: loss 0.7209, auc 0.4215, ap 0.4971
2024-01-10 22:12:02,388 - GAugM EPNet train, Epoch [ 98/250]: loss 0.7209, auc 0.4420, ap 0.4600
2024-01-10 22:12:02,460 - GAugM EPNet train, Epoch [ 99/250]: loss 0.7209, auc 0.4897, ap 0.5253
2024-01-10 22:12:02,538 - GAugM EPNet train, Epoch [100/250]: loss 0.7210, auc 0.5053, ap 0.5428
2024-01-10 22:12:02,616 - GAugM EPNet train, Epoch [101/250]: loss 0.7210, auc 0.5646, ap 0.5731
2024-01-10 22:12:02,690 - GAugM EPNet train, Epoch [102/250]: loss 0.7209, auc 0.4041, ap 0.4341
2024-01-10 22:12:02,762 - GAugM EPNet train, Epoch [103/250]: loss 0.7209, auc 0.4235, ap 0.4894
2024-01-10 22:12:02,835 - GAugM EPNet train, Epoch [104/250]: loss 0.7209, auc 0.4299, ap 0.4410
2024-01-10 22:12:02,907 - GAugM EPNet train, Epoch [105/250]: loss 0.7209, auc 0.4847, ap 0.5152
2024-01-10 22:12:02,977 - GAugM EPNet train, Epoch [106/250]: loss 0.7210, auc 0.4365, ap 0.4602
2024-01-10 22:12:03,048 - GAugM EPNet train, Epoch [107/250]: loss 0.7210, auc 0.4705, ap 0.5309
2024-01-10 22:12:03,120 - GAugM EPNet train, Epoch [108/250]: loss 0.7208, auc 0.5514, ap 0.5415
2024-01-10 22:12:03,192 - GAugM EPNet train, Epoch [109/250]: loss 0.7210, auc 0.4681, ap 0.4628
2024-01-10 22:12:03,263 - GAugM EPNet train, Epoch [110/250]: loss 0.7209, auc 0.5449, ap 0.5792
2024-01-10 22:12:03,335 - GAugM EPNet train, Epoch [111/250]: loss 0.7210, auc 0.5482, ap 0.5355
2024-01-10 22:12:03,410 - GAugM EPNet train, Epoch [112/250]: loss 0.7209, auc 0.4742, ap 0.5108
2024-01-10 22:12:03,482 - GAugM EPNet train, Epoch [113/250]: loss 0.7210, auc 0.4815, ap 0.5031
2024-01-10 22:12:03,552 - GAugM EPNet train, Epoch [114/250]: loss 0.7209, auc 0.4685, ap 0.4784
2024-01-10 22:12:03,628 - GAugM EPNet train, Epoch [115/250]: loss 0.7210, auc 0.4945, ap 0.5083
2024-01-10 22:12:03,700 - GAugM EPNet train, Epoch [116/250]: loss 0.7209, auc 0.5571, ap 0.5801
2024-01-10 22:12:03,780 - GAugM EPNet train, Epoch [117/250]: loss 0.7208, auc 0.5571, ap 0.5715
2024-01-10 22:12:03,851 - GAugM EPNet train, Epoch [118/250]: loss 0.7209, auc 0.4938, ap 0.5460
2024-01-10 22:12:03,925 - GAugM EPNet train, Epoch [119/250]: loss 0.7209, auc 0.6079, ap 0.5991
2024-01-10 22:12:03,998 - GAugM EPNet train, Epoch [120/250]: loss 0.7210, auc 0.4413, ap 0.4498
2024-01-10 22:12:04,081 - GAugM EPNet train, Epoch [121/250]: loss 0.7210, auc 0.4299, ap 0.4530
2024-01-10 22:12:04,154 - GAugM EPNet train, Epoch [122/250]: loss 0.7209, auc 0.5311, ap 0.5383
2024-01-10 22:12:04,226 - GAugM EPNet train, Epoch [123/250]: loss 0.7209, auc 0.4778, ap 0.5120
2024-01-10 22:12:04,296 - GAugM EPNet train, Epoch [124/250]: loss 0.7210, auc 0.4665, ap 0.5020
2024-01-10 22:12:04,367 - GAugM EPNet train, Epoch [125/250]: loss 0.7209, auc 0.4952, ap 0.5228
2024-01-10 22:12:04,438 - GAugM EPNet train, Epoch [126/250]: loss 0.7210, auc 0.4664, ap 0.4693
2024-01-10 22:12:04,513 - GAugM EPNet train, Epoch [127/250]: loss 0.7209, auc 0.5463, ap 0.5355
2024-01-10 22:12:04,583 - GAugM EPNet train, Epoch [128/250]: loss 0.7210, auc 0.5773, ap 0.5579
2024-01-10 22:12:04,655 - GAugM EPNet train, Epoch [129/250]: loss 0.7208, auc 0.4254, ap 0.4533
2024-01-10 22:12:04,726 - GAugM EPNet train, Epoch [130/250]: loss 0.7210, auc 0.5388, ap 0.5406
2024-01-10 22:12:04,797 - GAugM EPNet train, Epoch [131/250]: loss 0.7210, auc 0.5767, ap 0.6127
2024-01-10 22:12:04,875 - GAugM EPNet train, Epoch [132/250]: loss 0.7209, auc 0.5481, ap 0.5586
2024-01-10 22:12:04,947 - GAugM EPNet train, Epoch [133/250]: loss 0.7209, auc 0.4785, ap 0.5198
2024-01-10 22:12:05,022 - GAugM EPNet train, Epoch [134/250]: loss 0.7210, auc 0.4847, ap 0.5122
2024-01-10 22:12:05,095 - GAugM EPNet train, Epoch [135/250]: loss 0.7209, auc 0.4530, ap 0.4662
2024-01-10 22:12:05,180 - GAugM EPNet train, Epoch [136/250]: loss 0.7209, auc 0.4980, ap 0.5026
2024-01-10 22:12:05,254 - GAugM EPNet train, Epoch [137/250]: loss 0.7210, auc 0.5208, ap 0.5688
2024-01-10 22:12:05,328 - GAugM EPNet train, Epoch [138/250]: loss 0.7210, auc 0.5578, ap 0.5453
2024-01-10 22:12:05,398 - GAugM EPNet train, Epoch [139/250]: loss 0.7210, auc 0.4288, ap 0.4496
2024-01-10 22:12:05,470 - GAugM EPNet train, Epoch [140/250]: loss 0.7209, auc 0.5338, ap 0.5780
2024-01-10 22:12:05,545 - GAugM EPNet train, Epoch [141/250]: loss 0.7209, auc 0.5345, ap 0.5508
2024-01-10 22:12:05,622 - GAugM EPNet train, Epoch [142/250]: loss 0.7209, auc 0.5732, ap 0.5467
2024-01-10 22:12:05,701 - GAugM EPNet train, Epoch [143/250]: loss 0.7209, auc 0.4521, ap 0.4654
2024-01-10 22:12:05,776 - GAugM EPNet train, Epoch [144/250]: loss 0.7209, auc 0.4797, ap 0.4811
2024-01-10 22:12:05,848 - GAugM EPNet train, Epoch [145/250]: loss 0.7209, auc 0.4311, ap 0.4944
2024-01-10 22:12:05,926 - GAugM EPNet train, Epoch [146/250]: loss 0.7209, auc 0.5482, ap 0.5667
2024-01-10 22:12:06,005 - GAugM EPNet train, Epoch [147/250]: loss 0.7209, auc 0.5865, ap 0.6048
2024-01-10 22:12:06,081 - GAugM EPNet train, Epoch [148/250]: loss 0.7209, auc 0.4543, ap 0.5136
2024-01-10 22:12:06,156 - GAugM EPNet train, Epoch [149/250]: loss 0.7208, auc 0.5078, ap 0.5298
2024-01-10 22:12:06,233 - GAugM EPNet train, Epoch [150/250]: loss 0.7209, auc 0.4582, ap 0.4823
2024-01-10 22:12:06,304 - GAugM EPNet train, Epoch [151/250]: loss 0.7209, auc 0.4683, ap 0.4765
2024-01-10 22:12:06,380 - GAugM EPNet train, Epoch [152/250]: loss 0.7209, auc 0.5753, ap 0.6040
2024-01-10 22:12:06,457 - GAugM EPNet train, Epoch [153/250]: loss 0.7209, auc 0.5479, ap 0.5571
2024-01-10 22:12:06,529 - GAugM EPNet train, Epoch [154/250]: loss 0.7209, auc 0.6104, ap 0.6404
2024-01-10 22:12:06,604 - GAugM EPNet train, Epoch [155/250]: loss 0.7209, auc 0.5463, ap 0.5349
2024-01-10 22:12:06,674 - GAugM EPNet train, Epoch [156/250]: loss 0.7209, auc 0.4639, ap 0.4700
2024-01-10 22:12:06,746 - GAugM EPNet train, Epoch [157/250]: loss 0.7209, auc 0.5482, ap 0.5494
2024-01-10 22:12:06,822 - GAugM EPNet train, Epoch [158/250]: loss 0.7208, auc 0.3912, ap 0.4364
2024-01-10 22:12:06,898 - GAugM EPNet train, Epoch [159/250]: loss 0.7208, auc 0.4352, ap 0.4642
2024-01-10 22:12:06,973 - GAugM EPNet train, Epoch [160/250]: loss 0.7209, auc 0.5322, ap 0.5551
2024-01-10 22:12:07,048 - GAugM EPNet train, Epoch [161/250]: loss 0.7209, auc 0.5473, ap 0.5429
2024-01-10 22:12:07,121 - GAugM EPNet train, Epoch [162/250]: loss 0.7209, auc 0.4162, ap 0.4432
2024-01-10 22:12:07,193 - GAugM EPNet train, Epoch [163/250]: loss 0.7209, auc 0.5052, ap 0.5076
2024-01-10 22:12:07,270 - GAugM EPNet train, Epoch [164/250]: loss 0.7211, auc 0.4922, ap 0.5115
2024-01-10 22:12:07,345 - GAugM EPNet train, Epoch [165/250]: loss 0.7210, auc 0.4763, ap 0.4852
2024-01-10 22:12:07,422 - GAugM EPNet train, Epoch [166/250]: loss 0.7208, auc 0.5415, ap 0.5612
2024-01-10 22:12:07,492 - GAugM EPNet train, Epoch [167/250]: loss 0.7209, auc 0.4703, ap 0.4860
2024-01-10 22:12:07,572 - GAugM EPNet train, Epoch [168/250]: loss 0.7209, auc 0.5317, ap 0.5767
2024-01-10 22:12:07,646 - GAugM EPNet train, Epoch [169/250]: loss 0.7209, auc 0.6084, ap 0.6507
2024-01-10 22:12:07,726 - GAugM EPNet train, Epoch [170/250]: loss 0.7210, auc 0.4879, ap 0.4832
2024-01-10 22:12:07,800 - GAugM EPNet train, Epoch [171/250]: loss 0.7209, auc 0.4900, ap 0.5129
2024-01-10 22:12:07,875 - GAugM EPNet train, Epoch [172/250]: loss 0.7208, auc 0.4284, ap 0.4591
2024-01-10 22:12:07,946 - GAugM EPNet train, Epoch [173/250]: loss 0.7209, auc 0.5671, ap 0.5781
2024-01-10 22:12:08,018 - GAugM EPNet train, Epoch [174/250]: loss 0.7209, auc 0.4300, ap 0.4650
2024-01-10 22:12:08,093 - GAugM EPNet train, Epoch [175/250]: loss 0.7209, auc 0.6057, ap 0.6059
2024-01-10 22:12:08,163 - GAugM EPNet train, Epoch [176/250]: loss 0.7209, auc 0.4948, ap 0.4977
2024-01-10 22:12:08,243 - GAugM EPNet train, Epoch [177/250]: loss 0.7210, auc 0.5749, ap 0.5428
2024-01-10 22:12:08,314 - GAugM EPNet train, Epoch [178/250]: loss 0.7210, auc 0.5571, ap 0.5677
2024-01-10 22:12:08,386 - GAugM EPNet train, Epoch [179/250]: loss 0.7210, auc 0.3891, ap 0.4388
2024-01-10 22:12:08,458 - GAugM EPNet train, Epoch [180/250]: loss 0.7210, auc 0.5036, ap 0.5686
2024-01-10 22:12:08,528 - GAugM EPNet train, Epoch [181/250]: loss 0.7209, auc 0.5039, ap 0.5094
2024-01-10 22:12:08,604 - GAugM EPNet train, Epoch [182/250]: loss 0.7209, auc 0.4477, ap 0.4865
2024-01-10 22:12:08,675 - GAugM EPNet train, Epoch [183/250]: loss 0.7210, auc 0.5580, ap 0.5470
2024-01-10 22:12:08,744 - GAugM EPNet train, Epoch [184/250]: loss 0.7209, auc 0.5906, ap 0.5803
2024-01-10 22:12:08,814 - GAugM EPNet train, Epoch [185/250]: loss 0.7209, auc 0.4564, ap 0.4699
2024-01-10 22:12:08,884 - GAugM EPNet train, Epoch [186/250]: loss 0.7208, auc 0.4922, ap 0.5184
2024-01-10 22:12:08,961 - GAugM EPNet train, Epoch [187/250]: loss 0.7209, auc 0.4646, ap 0.4894
2024-01-10 22:12:09,041 - GAugM EPNet train, Epoch [188/250]: loss 0.7209, auc 0.3889, ap 0.4283
2024-01-10 22:12:09,111 - GAugM EPNet train, Epoch [189/250]: loss 0.7209, auc 0.5733, ap 0.6142
2024-01-10 22:12:09,188 - GAugM EPNet train, Epoch [190/250]: loss 0.7209, auc 0.4696, ap 0.4682
2024-01-10 22:12:09,261 - GAugM EPNet train, Epoch [191/250]: loss 0.7209, auc 0.4528, ap 0.5192
2024-01-10 22:12:09,335 - GAugM EPNet train, Epoch [192/250]: loss 0.7209, auc 0.5762, ap 0.5356
2024-01-10 22:12:09,405 - GAugM EPNet train, Epoch [193/250]: loss 0.7209, auc 0.5635, ap 0.5537
2024-01-10 22:12:09,477 - GAugM EPNet train, Epoch [194/250]: loss 0.7209, auc 0.4737, ap 0.4869
2024-01-10 22:12:09,558 - GAugM EPNet train, Epoch [195/250]: loss 0.7209, auc 0.4667, ap 0.4735
2024-01-10 22:12:09,627 - GAugM EPNet train, Epoch [196/250]: loss 0.7208, auc 0.5085, ap 0.5033
2024-01-10 22:12:09,698 - GAugM EPNet train, Epoch [197/250]: loss 0.7210, auc 0.4979, ap 0.5296
2024-01-10 22:12:09,769 - GAugM EPNet train, Epoch [198/250]: loss 0.7210, auc 0.5365, ap 0.5680
2024-01-10 22:12:09,844 - GAugM EPNet train, Epoch [199/250]: loss 0.7209, auc 0.5433, ap 0.5601
2024-01-10 22:12:09,921 - GAugM EPNet train, Epoch [200/250]: loss 0.7210, auc 0.4475, ap 0.4680
2024-01-10 22:12:09,991 - GAugM EPNet train, Epoch [201/250]: loss 0.7209, auc 0.4582, ap 0.4817
2024-01-10 22:12:10,063 - GAugM EPNet train, Epoch [202/250]: loss 0.7210, auc 0.5037, ap 0.5640
2024-01-10 22:12:10,133 - GAugM EPNet train, Epoch [203/250]: loss 0.7210, auc 0.5696, ap 0.5937
2024-01-10 22:12:10,215 - GAugM EPNet train, Epoch [204/250]: loss 0.7209, auc 0.4044, ap 0.4506
2024-01-10 22:12:10,286 - GAugM EPNet train, Epoch [205/250]: loss 0.7209, auc 0.5201, ap 0.5415
2024-01-10 22:12:10,362 - GAugM EPNet train, Epoch [206/250]: loss 0.7209, auc 0.4457, ap 0.4725
2024-01-10 22:12:10,432 - GAugM EPNet train, Epoch [207/250]: loss 0.7210, auc 0.5117, ap 0.5408
2024-01-10 22:12:10,503 - GAugM EPNet train, Epoch [208/250]: loss 0.7209, auc 0.5002, ap 0.5271
2024-01-10 22:12:10,579 - GAugM EPNet train, Epoch [209/250]: loss 0.7210, auc 0.5835, ap 0.5808
2024-01-10 22:12:10,651 - GAugM EPNet train, Epoch [210/250]: loss 0.7209, auc 0.4585, ap 0.4778
2024-01-10 22:12:10,722 - GAugM EPNet train, Epoch [211/250]: loss 0.7210, auc 0.5465, ap 0.5401
2024-01-10 22:12:10,798 - GAugM EPNet train, Epoch [212/250]: loss 0.7210, auc 0.5215, ap 0.5144
2024-01-10 22:12:10,870 - GAugM EPNet train, Epoch [213/250]: loss 0.7208, auc 0.5564, ap 0.5778
2024-01-10 22:12:10,941 - GAugM EPNet train, Epoch [214/250]: loss 0.7210, auc 0.4404, ap 0.4623
2024-01-10 22:12:11,016 - GAugM EPNet train, Epoch [215/250]: loss 0.7210, auc 0.5566, ap 0.5672
2024-01-10 22:12:11,087 - GAugM EPNet train, Epoch [216/250]: loss 0.7209, auc 0.5397, ap 0.5398
2024-01-10 22:12:11,158 - GAugM EPNet train, Epoch [217/250]: loss 0.7209, auc 0.4496, ap 0.5034
2024-01-10 22:12:11,234 - GAugM EPNet train, Epoch [218/250]: loss 0.7209, auc 0.5071, ap 0.5463
2024-01-10 22:12:11,307 - GAugM EPNet train, Epoch [219/250]: loss 0.7208, auc 0.5043, ap 0.5014
2024-01-10 22:12:11,383 - GAugM EPNet train, Epoch [220/250]: loss 0.7210, auc 0.4765, ap 0.5464
2024-01-10 22:12:11,459 - GAugM EPNet train, Epoch [221/250]: loss 0.7209, auc 0.4947, ap 0.5102
2024-01-10 22:12:11,532 - GAugM EPNet train, Epoch [222/250]: loss 0.7209, auc 0.5077, ap 0.5380
2024-01-10 22:12:11,603 - GAugM EPNet train, Epoch [223/250]: loss 0.7209, auc 0.5438, ap 0.5698
2024-01-10 22:12:11,678 - GAugM EPNet train, Epoch [224/250]: loss 0.7210, auc 0.5078, ap 0.4815
2024-01-10 22:12:11,751 - GAugM EPNet train, Epoch [225/250]: loss 0.7209, auc 0.4316, ap 0.4639
2024-01-10 22:12:11,821 - GAugM EPNet train, Epoch [226/250]: loss 0.7210, auc 0.4968, ap 0.5116
2024-01-10 22:12:11,891 - GAugM EPNet train, Epoch [227/250]: loss 0.7210, auc 0.5502, ap 0.5775
2024-01-10 22:12:11,962 - GAugM EPNet train, Epoch [228/250]: loss 0.7209, auc 0.4224, ap 0.5020
2024-01-10 22:12:12,033 - GAugM EPNet train, Epoch [229/250]: loss 0.7209, auc 0.5206, ap 0.5231
2024-01-10 22:12:12,104 - GAugM EPNet train, Epoch [230/250]: loss 0.7209, auc 0.3779, ap 0.4334
2024-01-10 22:12:12,180 - GAugM EPNet train, Epoch [231/250]: loss 0.7209, auc 0.5475, ap 0.5440
2024-01-10 22:12:12,251 - GAugM EPNet train, Epoch [232/250]: loss 0.7209, auc 0.4758, ap 0.4977
2024-01-10 22:12:12,327 - GAugM EPNet train, Epoch [233/250]: loss 0.7210, auc 0.5555, ap 0.5727
2024-01-10 22:12:12,399 - GAugM EPNet train, Epoch [234/250]: loss 0.7209, auc 0.3170, ap 0.4225
2024-01-10 22:12:12,476 - GAugM EPNet train, Epoch [235/250]: loss 0.7209, auc 0.3804, ap 0.4278
2024-01-10 22:12:12,548 - GAugM EPNet train, Epoch [236/250]: loss 0.7209, auc 0.5742, ap 0.5850
2024-01-10 22:12:12,623 - GAugM EPNet train, Epoch [237/250]: loss 0.7210, auc 0.5215, ap 0.5264
2024-01-10 22:12:12,704 - GAugM EPNet train, Epoch [238/250]: loss 0.7210, auc 0.5408, ap 0.5664
2024-01-10 22:12:12,776 - GAugM EPNet train, Epoch [239/250]: loss 0.7209, auc 0.4874, ap 0.5395
2024-01-10 22:12:12,848 - GAugM EPNet train, Epoch [240/250]: loss 0.7209, auc 0.5618, ap 0.5297
2024-01-10 22:12:12,920 - GAugM EPNet train, Epoch [241/250]: loss 0.7209, auc 0.5212, ap 0.5351
2024-01-10 22:12:13,002 - GAugM EPNet train, Epoch [242/250]: loss 0.7210, auc 0.5870, ap 0.5903
2024-01-10 22:12:13,075 - GAugM EPNet train, Epoch [243/250]: loss 0.7210, auc 0.5516, ap 0.6158
2024-01-10 22:12:13,154 - GAugM EPNet train, Epoch [244/250]: loss 0.7209, auc 0.4998, ap 0.5135
2024-01-10 22:12:13,225 - GAugM EPNet train, Epoch [245/250]: loss 0.7210, auc 0.4621, ap 0.4894
2024-01-10 22:12:13,295 - GAugM EPNet train, Epoch [246/250]: loss 0.7208, auc 0.5258, ap 0.5114
2024-01-10 22:12:13,366 - GAugM EPNet train, Epoch [247/250]: loss 0.7209, auc 0.5021, ap 0.5266
2024-01-10 22:12:13,437 - GAugM EPNet train, Epoch [248/250]: loss 0.7211, auc 0.4532, ap 0.4742
2024-01-10 22:12:13,511 - GAugM EPNet train, Epoch [249/250]: loss 0.7209, auc 0.4251, ap 0.4402
2024-01-10 22:12:13,583 - GAugM EPNet train, Epoch [250/250]: loss 0.7208, auc 0.4838, ap 0.5029
2024-01-10 22:12:13,589 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035b58d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:12:14,299 - GAugM EPNet train, Epoch [  1/250]: loss 0.7210, auc 0.4646, ap 0.4895
2024-01-10 22:12:14,391 - GAugM EPNet train, Epoch [  2/250]: loss 0.7210, auc 0.5101, ap 0.5085
2024-01-10 22:12:14,484 - GAugM EPNet train, Epoch [  3/250]: loss 0.7209, auc 0.5158, ap 0.5170
2024-01-10 22:12:14,578 - GAugM EPNet train, Epoch [  4/250]: loss 0.7209, auc 0.4290, ap 0.4949
2024-01-10 22:12:14,666 - GAugM EPNet train, Epoch [  5/250]: loss 0.7209, auc 0.5749, ap 0.5604
2024-01-10 22:12:14,754 - GAugM EPNet train, Epoch [  6/250]: loss 0.7209, auc 0.4884, ap 0.4853
2024-01-10 22:12:14,844 - GAugM EPNet train, Epoch [  7/250]: loss 0.7209, auc 0.4977, ap 0.4829
2024-01-10 22:12:14,933 - GAugM EPNet train, Epoch [  8/250]: loss 0.7210, auc 0.5212, ap 0.5057
2024-01-10 22:12:15,023 - GAugM EPNet train, Epoch [  9/250]: loss 0.7209, auc 0.4535, ap 0.4750
2024-01-10 22:12:15,114 - GAugM EPNet train, Epoch [ 10/250]: loss 0.7208, auc 0.4909, ap 0.5260
2024-01-10 22:12:15,202 - GAugM EPNet train, Epoch [ 11/250]: loss 0.7209, auc 0.4980, ap 0.4848
2024-01-10 22:12:15,290 - GAugM EPNet train, Epoch [ 12/250]: loss 0.7210, auc 0.4347, ap 0.4802
2024-01-10 22:12:15,376 - GAugM EPNet train, Epoch [ 13/250]: loss 0.7209, auc 0.4710, ap 0.5018
2024-01-10 22:12:15,460 - GAugM EPNet train, Epoch [ 14/250]: loss 0.7209, auc 0.4393, ap 0.4564
2024-01-10 22:12:15,548 - GAugM EPNet train, Epoch [ 15/250]: loss 0.7210, auc 0.3987, ap 0.4576
2024-01-10 22:12:15,653 - GAugM EPNet train, Epoch [ 16/250]: loss 0.7209, auc 0.4770, ap 0.4963
2024-01-10 22:12:15,738 - GAugM EPNet train, Epoch [ 17/250]: loss 0.7210, auc 0.5682, ap 0.5591
2024-01-10 22:12:15,825 - GAugM EPNet train, Epoch [ 18/250]: loss 0.7210, auc 0.6312, ap 0.6106
2024-01-10 22:12:15,912 - GAugM EPNet train, Epoch [ 19/250]: loss 0.7209, auc 0.4984, ap 0.5041
2024-01-10 22:12:16,004 - GAugM EPNet train, Epoch [ 20/250]: loss 0.7210, auc 0.5685, ap 0.5922
2024-01-10 22:12:16,100 - GAugM EPNet train, Epoch [ 21/250]: loss 0.7209, auc 0.5400, ap 0.5268
2024-01-10 22:12:16,188 - GAugM EPNet train, Epoch [ 22/250]: loss 0.7210, auc 0.3980, ap 0.4398
2024-01-10 22:12:16,279 - GAugM EPNet train, Epoch [ 23/250]: loss 0.7208, auc 0.4642, ap 0.5089
2024-01-10 22:12:16,369 - GAugM EPNet train, Epoch [ 24/250]: loss 0.7209, auc 0.5881, ap 0.5789
2024-01-10 22:12:16,467 - GAugM EPNet train, Epoch [ 25/250]: loss 0.7209, auc 0.4660, ap 0.4709
2024-01-10 22:12:16,555 - GAugM EPNet train, Epoch [ 26/250]: loss 0.7210, auc 0.5418, ap 0.5406
2024-01-10 22:12:16,647 - GAugM EPNet train, Epoch [ 27/250]: loss 0.7209, auc 0.4026, ap 0.4925
2024-01-10 22:12:16,728 - GAugM EPNet train, Epoch [ 28/250]: loss 0.7209, auc 0.5942, ap 0.6055
2024-01-10 22:12:16,810 - GAugM EPNet train, Epoch [ 29/250]: loss 0.7210, auc 0.5450, ap 0.5472
2024-01-10 22:12:16,886 - GAugM EPNet train, Epoch [ 30/250]: loss 0.7209, auc 0.4778, ap 0.5212
2024-01-10 22:12:16,971 - GAugM EPNet train, Epoch [ 31/250]: loss 0.7208, auc 0.5347, ap 0.5576
2024-01-10 22:12:17,063 - GAugM EPNet train, Epoch [ 32/250]: loss 0.7210, auc 0.5514, ap 0.5402
2024-01-10 22:12:17,149 - GAugM EPNet train, Epoch [ 33/250]: loss 0.7209, auc 0.4884, ap 0.5244
2024-01-10 22:12:17,241 - GAugM EPNet train, Epoch [ 34/250]: loss 0.7209, auc 0.4867, ap 0.4817
2024-01-10 22:12:17,316 - GAugM EPNet train, Epoch [ 35/250]: loss 0.7209, auc 0.4934, ap 0.4874
2024-01-10 22:12:17,393 - GAugM EPNet train, Epoch [ 36/250]: loss 0.7209, auc 0.6173, ap 0.6109
2024-01-10 22:12:17,468 - GAugM EPNet train, Epoch [ 37/250]: loss 0.7209, auc 0.5479, ap 0.5520
2024-01-10 22:12:17,549 - GAugM EPNet train, Epoch [ 38/250]: loss 0.7209, auc 0.5109, ap 0.5025
2024-01-10 22:12:17,625 - GAugM EPNet train, Epoch [ 39/250]: loss 0.7208, auc 0.4539, ap 0.5069
2024-01-10 22:12:17,707 - GAugM EPNet train, Epoch [ 40/250]: loss 0.7210, auc 0.5379, ap 0.5254
2024-01-10 22:12:17,779 - GAugM EPNet train, Epoch [ 41/250]: loss 0.7210, auc 0.4842, ap 0.5437
2024-01-10 22:12:17,853 - GAugM EPNet train, Epoch [ 42/250]: loss 0.7209, auc 0.5525, ap 0.5816
2024-01-10 22:12:17,936 - GAugM EPNet train, Epoch [ 43/250]: loss 0.7208, auc 0.4514, ap 0.5039
2024-01-10 22:12:18,031 - GAugM EPNet train, Epoch [ 44/250]: loss 0.7208, auc 0.3962, ap 0.4392
2024-01-10 22:12:18,128 - GAugM EPNet train, Epoch [ 45/250]: loss 0.7209, auc 0.5717, ap 0.6104
2024-01-10 22:12:18,213 - GAugM EPNet train, Epoch [ 46/250]: loss 0.7209, auc 0.4532, ap 0.4790
2024-01-10 22:12:18,292 - GAugM EPNet train, Epoch [ 47/250]: loss 0.7210, auc 0.4550, ap 0.5178
2024-01-10 22:12:18,368 - GAugM EPNet train, Epoch [ 48/250]: loss 0.7210, auc 0.5030, ap 0.5579
2024-01-10 22:12:18,455 - GAugM EPNet train, Epoch [ 49/250]: loss 0.7209, auc 0.4706, ap 0.4983
2024-01-10 22:12:18,533 - GAugM EPNet train, Epoch [ 50/250]: loss 0.7210, auc 0.5611, ap 0.5612
2024-01-10 22:12:18,618 - GAugM EPNet train, Epoch [ 51/250]: loss 0.7210, auc 0.5390, ap 0.5847
2024-01-10 22:12:18,695 - GAugM EPNet train, Epoch [ 52/250]: loss 0.7209, auc 0.4778, ap 0.5342
2024-01-10 22:12:18,768 - GAugM EPNet train, Epoch [ 53/250]: loss 0.7209, auc 0.3962, ap 0.4302
2024-01-10 22:12:18,848 - GAugM EPNet train, Epoch [ 54/250]: loss 0.7211, auc 0.5101, ap 0.5015
2024-01-10 22:12:18,925 - GAugM EPNet train, Epoch [ 55/250]: loss 0.7209, auc 0.5639, ap 0.6094
2024-01-10 22:12:19,006 - GAugM EPNet train, Epoch [ 56/250]: loss 0.7208, auc 0.4795, ap 0.5059
2024-01-10 22:12:19,081 - GAugM EPNet train, Epoch [ 57/250]: loss 0.7209, auc 0.4418, ap 0.4638
2024-01-10 22:12:19,155 - GAugM EPNet train, Epoch [ 58/250]: loss 0.7210, auc 0.5244, ap 0.5588
2024-01-10 22:12:19,229 - GAugM EPNet train, Epoch [ 59/250]: loss 0.7211, auc 0.4863, ap 0.4835
2024-01-10 22:12:19,315 - GAugM EPNet train, Epoch [ 60/250]: loss 0.7210, auc 0.4902, ap 0.5166
2024-01-10 22:12:19,390 - GAugM EPNet train, Epoch [ 61/250]: loss 0.7209, auc 0.5354, ap 0.5639
2024-01-10 22:12:19,474 - GAugM EPNet train, Epoch [ 62/250]: loss 0.7210, auc 0.4810, ap 0.5179
2024-01-10 22:12:19,550 - GAugM EPNet train, Epoch [ 63/250]: loss 0.7208, auc 0.4578, ap 0.4591
2024-01-10 22:12:19,621 - GAugM EPNet train, Epoch [ 64/250]: loss 0.7208, auc 0.4973, ap 0.5013
2024-01-10 22:12:19,698 - GAugM EPNet train, Epoch [ 65/250]: loss 0.7208, auc 0.5482, ap 0.5691
2024-01-10 22:12:19,782 - GAugM EPNet train, Epoch [ 66/250]: loss 0.7209, auc 0.4340, ap 0.5048
2024-01-10 22:12:19,872 - GAugM EPNet train, Epoch [ 67/250]: loss 0.7209, auc 0.5867, ap 0.5807
2024-01-10 22:12:19,956 - GAugM EPNet train, Epoch [ 68/250]: loss 0.7210, auc 0.5728, ap 0.5977
2024-01-10 22:12:20,040 - GAugM EPNet train, Epoch [ 69/250]: loss 0.7210, auc 0.4318, ap 0.4820
2024-01-10 22:12:20,125 - GAugM EPNet train, Epoch [ 70/250]: loss 0.7210, auc 0.4749, ap 0.4797
2024-01-10 22:12:20,209 - GAugM EPNet train, Epoch [ 71/250]: loss 0.7210, auc 0.5322, ap 0.5525
2024-01-10 22:12:20,303 - GAugM EPNet train, Epoch [ 72/250]: loss 0.7210, auc 0.4432, ap 0.5060
2024-01-10 22:12:20,387 - GAugM EPNet train, Epoch [ 73/250]: loss 0.7209, auc 0.5582, ap 0.5434
2024-01-10 22:12:20,475 - GAugM EPNet train, Epoch [ 74/250]: loss 0.7209, auc 0.4589, ap 0.5051
2024-01-10 22:12:20,558 - GAugM EPNet train, Epoch [ 75/250]: loss 0.7210, auc 0.4756, ap 0.5124
2024-01-10 22:12:20,643 - GAugM EPNet train, Epoch [ 76/250]: loss 0.7209, auc 0.4340, ap 0.5031
2024-01-10 22:12:20,733 - GAugM EPNet train, Epoch [ 77/250]: loss 0.7208, auc 0.5105, ap 0.5471
2024-01-10 22:12:20,819 - GAugM EPNet train, Epoch [ 78/250]: loss 0.7209, auc 0.5376, ap 0.5297
2024-01-10 22:12:20,903 - GAugM EPNet train, Epoch [ 79/250]: loss 0.7208, auc 0.4838, ap 0.5111
2024-01-10 22:12:20,986 - GAugM EPNet train, Epoch [ 80/250]: loss 0.7209, auc 0.4980, ap 0.5159
2024-01-10 22:12:21,070 - GAugM EPNet train, Epoch [ 81/250]: loss 0.7209, auc 0.4219, ap 0.4476
2024-01-10 22:12:21,155 - GAugM EPNet train, Epoch [ 82/250]: loss 0.7210, auc 0.5101, ap 0.5074
2024-01-10 22:12:21,243 - GAugM EPNet train, Epoch [ 83/250]: loss 0.7209, auc 0.4325, ap 0.4803
2024-01-10 22:12:21,325 - GAugM EPNet train, Epoch [ 84/250]: loss 0.7209, auc 0.4318, ap 0.4901
2024-01-10 22:12:21,414 - GAugM EPNet train, Epoch [ 85/250]: loss 0.7210, auc 0.4329, ap 0.4567
2024-01-10 22:12:21,511 - GAugM EPNet train, Epoch [ 86/250]: loss 0.7208, auc 0.5002, ap 0.5332
2024-01-10 22:12:21,591 - GAugM EPNet train, Epoch [ 87/250]: loss 0.7209, auc 0.5365, ap 0.5510
2024-01-10 22:12:21,690 - GAugM EPNet train, Epoch [ 88/250]: loss 0.7210, auc 0.4696, ap 0.4825
2024-01-10 22:12:21,779 - GAugM EPNet train, Epoch [ 89/250]: loss 0.7210, auc 0.5030, ap 0.5443
2024-01-10 22:12:21,860 - GAugM EPNet train, Epoch [ 90/250]: loss 0.7209, auc 0.4457, ap 0.5054
2024-01-10 22:12:21,949 - GAugM EPNet train, Epoch [ 91/250]: loss 0.7208, auc 0.5443, ap 0.5177
2024-01-10 22:12:22,029 - GAugM EPNet train, Epoch [ 92/250]: loss 0.7209, auc 0.6365, ap 0.6159
2024-01-10 22:12:22,105 - GAugM EPNet train, Epoch [ 93/250]: loss 0.7209, auc 0.3314, ap 0.4076
2024-01-10 22:12:22,179 - GAugM EPNet train, Epoch [ 94/250]: loss 0.7210, auc 0.4418, ap 0.4453
2024-01-10 22:12:22,256 - GAugM EPNet train, Epoch [ 95/250]: loss 0.7210, auc 0.4578, ap 0.4781
2024-01-10 22:12:22,340 - GAugM EPNet train, Epoch [ 96/250]: loss 0.7209, auc 0.5304, ap 0.5230
2024-01-10 22:12:22,417 - GAugM EPNet train, Epoch [ 97/250]: loss 0.7209, auc 0.4781, ap 0.5420
2024-01-10 22:12:22,500 - GAugM EPNet train, Epoch [ 98/250]: loss 0.7209, auc 0.4571, ap 0.4813
2024-01-10 22:12:22,580 - GAugM EPNet train, Epoch [ 99/250]: loss 0.7209, auc 0.4578, ap 0.4920
2024-01-10 22:12:22,665 - GAugM EPNet train, Epoch [100/250]: loss 0.7210, auc 0.4899, ap 0.5319
2024-01-10 22:12:22,741 - GAugM EPNet train, Epoch [101/250]: loss 0.7210, auc 0.4770, ap 0.5204
2024-01-10 22:12:22,817 - GAugM EPNet train, Epoch [102/250]: loss 0.7209, auc 0.5212, ap 0.5431
2024-01-10 22:12:22,892 - GAugM EPNet train, Epoch [103/250]: loss 0.7209, auc 0.5429, ap 0.5707
2024-01-10 22:12:22,964 - GAugM EPNet train, Epoch [104/250]: loss 0.7209, auc 0.4895, ap 0.5378
2024-01-10 22:12:23,046 - GAugM EPNet train, Epoch [105/250]: loss 0.7209, auc 0.4560, ap 0.4718
2024-01-10 22:12:23,125 - GAugM EPNet train, Epoch [106/250]: loss 0.7210, auc 0.4806, ap 0.5017
2024-01-10 22:12:23,206 - GAugM EPNet train, Epoch [107/250]: loss 0.7210, auc 0.4347, ap 0.4783
2024-01-10 22:12:23,286 - GAugM EPNet train, Epoch [108/250]: loss 0.7208, auc 0.5052, ap 0.4896
2024-01-10 22:12:23,363 - GAugM EPNet train, Epoch [109/250]: loss 0.7210, auc 0.4578, ap 0.4886
2024-01-10 22:12:23,439 - GAugM EPNet train, Epoch [110/250]: loss 0.7209, auc 0.5205, ap 0.5195
2024-01-10 22:12:23,526 - GAugM EPNet train, Epoch [111/250]: loss 0.7210, auc 0.5158, ap 0.5303
2024-01-10 22:12:23,618 - GAugM EPNet train, Epoch [112/250]: loss 0.7209, auc 0.5269, ap 0.5347
2024-01-10 22:12:23,698 - GAugM EPNet train, Epoch [113/250]: loss 0.7210, auc 0.4190, ap 0.4706
2024-01-10 22:12:23,772 - GAugM EPNet train, Epoch [114/250]: loss 0.7209, auc 0.4867, ap 0.4831
2024-01-10 22:12:23,846 - GAugM EPNet train, Epoch [115/250]: loss 0.7210, auc 0.5500, ap 0.5584
2024-01-10 22:12:23,918 - GAugM EPNet train, Epoch [116/250]: loss 0.7209, auc 0.5952, ap 0.6016
2024-01-10 22:12:23,993 - GAugM EPNet train, Epoch [117/250]: loss 0.7208, auc 0.5133, ap 0.5171
2024-01-10 22:12:24,067 - GAugM EPNet train, Epoch [118/250]: loss 0.7209, auc 0.5262, ap 0.5653
2024-01-10 22:12:24,154 - GAugM EPNet train, Epoch [119/250]: loss 0.7209, auc 0.5180, ap 0.5596
2024-01-10 22:12:24,237 - GAugM EPNet train, Epoch [120/250]: loss 0.7210, auc 0.4457, ap 0.4540
2024-01-10 22:12:24,318 - GAugM EPNet train, Epoch [121/250]: loss 0.7210, auc 0.4493, ap 0.5060
2024-01-10 22:12:24,391 - GAugM EPNet train, Epoch [122/250]: loss 0.7209, auc 0.5112, ap 0.5533
2024-01-10 22:12:24,469 - GAugM EPNet train, Epoch [123/250]: loss 0.7209, auc 0.5728, ap 0.5791
2024-01-10 22:12:24,545 - GAugM EPNet train, Epoch [124/250]: loss 0.7210, auc 0.4632, ap 0.4817
2024-01-10 22:12:24,620 - GAugM EPNet train, Epoch [125/250]: loss 0.7209, auc 0.5326, ap 0.5516
2024-01-10 22:12:24,695 - GAugM EPNet train, Epoch [126/250]: loss 0.7210, auc 0.5119, ap 0.5167
2024-01-10 22:12:24,771 - GAugM EPNet train, Epoch [127/250]: loss 0.7209, auc 0.4995, ap 0.4981
2024-01-10 22:12:24,849 - GAugM EPNet train, Epoch [128/250]: loss 0.7210, auc 0.5397, ap 0.5463
2024-01-10 22:12:24,929 - GAugM EPNet train, Epoch [129/250]: loss 0.7208, auc 0.4300, ap 0.4689
2024-01-10 22:12:25,016 - GAugM EPNet train, Epoch [130/250]: loss 0.7210, auc 0.4311, ap 0.4864
2024-01-10 22:12:25,108 - GAugM EPNet train, Epoch [131/250]: loss 0.7210, auc 0.5650, ap 0.5991
2024-01-10 22:12:25,204 - GAugM EPNet train, Epoch [132/250]: loss 0.7209, auc 0.4468, ap 0.4829
2024-01-10 22:12:25,286 - GAugM EPNet train, Epoch [133/250]: loss 0.7209, auc 0.4998, ap 0.5202
2024-01-10 22:12:25,379 - GAugM EPNet train, Epoch [134/250]: loss 0.7210, auc 0.4681, ap 0.4887
2024-01-10 22:12:25,467 - GAugM EPNet train, Epoch [135/250]: loss 0.7209, auc 0.3635, ap 0.4270
2024-01-10 22:12:25,556 - GAugM EPNet train, Epoch [136/250]: loss 0.7209, auc 0.4927, ap 0.4940
2024-01-10 22:12:25,643 - GAugM EPNet train, Epoch [137/250]: loss 0.7210, auc 0.5119, ap 0.5604
2024-01-10 22:12:25,732 - GAugM EPNet train, Epoch [138/250]: loss 0.7210, auc 0.5536, ap 0.5369
2024-01-10 22:12:25,838 - GAugM EPNet train, Epoch [139/250]: loss 0.7210, auc 0.4692, ap 0.5074
2024-01-10 22:12:25,918 - GAugM EPNet train, Epoch [140/250]: loss 0.7209, auc 0.5344, ap 0.5839
2024-01-10 22:12:26,005 - GAugM EPNet train, Epoch [141/250]: loss 0.7209, auc 0.5554, ap 0.5300
2024-01-10 22:12:26,092 - GAugM EPNet train, Epoch [142/250]: loss 0.7209, auc 0.5073, ap 0.5499
2024-01-10 22:12:26,183 - GAugM EPNet train, Epoch [143/250]: loss 0.7209, auc 0.5208, ap 0.5211
2024-01-10 22:12:26,269 - GAugM EPNet train, Epoch [144/250]: loss 0.7209, auc 0.4763, ap 0.4927
2024-01-10 22:12:26,357 - GAugM EPNet train, Epoch [145/250]: loss 0.7209, auc 0.4436, ap 0.4991
2024-01-10 22:12:26,443 - GAugM EPNet train, Epoch [146/250]: loss 0.7209, auc 0.4867, ap 0.5473
2024-01-10 22:12:26,528 - GAugM EPNet train, Epoch [147/250]: loss 0.7209, auc 0.5835, ap 0.6218
2024-01-10 22:12:26,611 - GAugM EPNet train, Epoch [148/250]: loss 0.7209, auc 0.4774, ap 0.5121
2024-01-10 22:12:26,700 - GAugM EPNet train, Epoch [149/250]: loss 0.7208, auc 0.5611, ap 0.5856
2024-01-10 22:12:26,786 - GAugM EPNet train, Epoch [150/250]: loss 0.7209, auc 0.5336, ap 0.5486
2024-01-10 22:12:26,871 - GAugM EPNet train, Epoch [151/250]: loss 0.7209, auc 0.5863, ap 0.5897
2024-01-10 22:12:26,957 - GAugM EPNet train, Epoch [152/250]: loss 0.7209, auc 0.5760, ap 0.5923
2024-01-10 22:12:27,041 - GAugM EPNet train, Epoch [153/250]: loss 0.7209, auc 0.3823, ap 0.4357
2024-01-10 22:12:27,127 - GAugM EPNet train, Epoch [154/250]: loss 0.7209, auc 0.5326, ap 0.5820
2024-01-10 22:12:27,212 - GAugM EPNet train, Epoch [155/250]: loss 0.7209, auc 0.4703, ap 0.5238
2024-01-10 22:12:27,297 - GAugM EPNet train, Epoch [156/250]: loss 0.7209, auc 0.5105, ap 0.5489
2024-01-10 22:12:27,383 - GAugM EPNet train, Epoch [157/250]: loss 0.7209, auc 0.5400, ap 0.5445
2024-01-10 22:12:27,469 - GAugM EPNet train, Epoch [158/250]: loss 0.7208, auc 0.4575, ap 0.4781
2024-01-10 22:12:27,561 - GAugM EPNet train, Epoch [159/250]: loss 0.7208, auc 0.4653, ap 0.4762
2024-01-10 22:12:27,644 - GAugM EPNet train, Epoch [160/250]: loss 0.7209, auc 0.5361, ap 0.5711
2024-01-10 22:12:27,730 - GAugM EPNet train, Epoch [161/250]: loss 0.7209, auc 0.5700, ap 0.5805
2024-01-10 22:12:27,818 - GAugM EPNet train, Epoch [162/250]: loss 0.7209, auc 0.5276, ap 0.5268
2024-01-10 22:12:27,904 - GAugM EPNet train, Epoch [163/250]: loss 0.7209, auc 0.5333, ap 0.5080
2024-01-10 22:12:27,994 - GAugM EPNet train, Epoch [164/250]: loss 0.7211, auc 0.5315, ap 0.5322
2024-01-10 22:12:28,082 - GAugM EPNet train, Epoch [165/250]: loss 0.7210, auc 0.4689, ap 0.4983
2024-01-10 22:12:28,166 - GAugM EPNet train, Epoch [166/250]: loss 0.7208, auc 0.5977, ap 0.5689
2024-01-10 22:12:28,258 - GAugM EPNet train, Epoch [167/250]: loss 0.7209, auc 0.5148, ap 0.5204
2024-01-10 22:12:28,343 - GAugM EPNet train, Epoch [168/250]: loss 0.7209, auc 0.5354, ap 0.5427
2024-01-10 22:12:28,429 - GAugM EPNet train, Epoch [169/250]: loss 0.7209, auc 0.5247, ap 0.5374
2024-01-10 22:12:28,526 - GAugM EPNet train, Epoch [170/250]: loss 0.7210, auc 0.5600, ap 0.5398
2024-01-10 22:12:28,614 - GAugM EPNet train, Epoch [171/250]: loss 0.7209, auc 0.4867, ap 0.4980
2024-01-10 22:12:28,707 - GAugM EPNet train, Epoch [172/250]: loss 0.7208, auc 0.5052, ap 0.5285
2024-01-10 22:12:28,795 - GAugM EPNet train, Epoch [173/250]: loss 0.7209, auc 0.4906, ap 0.5047
2024-01-10 22:12:28,880 - GAugM EPNet train, Epoch [174/250]: loss 0.7209, auc 0.5507, ap 0.5361
2024-01-10 22:12:28,963 - GAugM EPNet train, Epoch [175/250]: loss 0.7209, auc 0.6162, ap 0.5863
2024-01-10 22:12:29,049 - GAugM EPNet train, Epoch [176/250]: loss 0.7209, auc 0.5262, ap 0.5504
2024-01-10 22:12:29,134 - GAugM EPNet train, Epoch [177/250]: loss 0.7210, auc 0.5625, ap 0.5543
2024-01-10 22:12:29,222 - GAugM EPNet train, Epoch [178/250]: loss 0.7210, auc 0.5621, ap 0.5976
2024-01-10 22:12:29,309 - GAugM EPNet train, Epoch [179/250]: loss 0.7210, auc 0.4493, ap 0.5203
2024-01-10 22:12:29,394 - GAugM EPNet train, Epoch [180/250]: loss 0.7210, auc 0.5415, ap 0.5742
2024-01-10 22:12:29,478 - GAugM EPNet train, Epoch [181/250]: loss 0.7209, auc 0.4030, ap 0.4527
2024-01-10 22:12:29,567 - GAugM EPNet train, Epoch [182/250]: loss 0.7209, auc 0.4902, ap 0.5231
2024-01-10 22:12:29,657 - GAugM EPNet train, Epoch [183/250]: loss 0.7210, auc 0.4696, ap 0.4974
2024-01-10 22:12:29,748 - GAugM EPNet train, Epoch [184/250]: loss 0.7209, auc 0.5166, ap 0.5481
2024-01-10 22:12:29,828 - GAugM EPNet train, Epoch [185/250]: loss 0.7209, auc 0.4785, ap 0.5403
2024-01-10 22:12:29,921 - GAugM EPNet train, Epoch [186/250]: loss 0.7208, auc 0.4870, ap 0.5504
2024-01-10 22:12:30,016 - GAugM EPNet train, Epoch [187/250]: loss 0.7209, auc 0.5028, ap 0.5226
2024-01-10 22:12:30,107 - GAugM EPNet train, Epoch [188/250]: loss 0.7209, auc 0.5283, ap 0.5261
2024-01-10 22:12:30,186 - GAugM EPNet train, Epoch [189/250]: loss 0.7209, auc 0.5578, ap 0.5977
2024-01-10 22:12:30,281 - GAugM EPNet train, Epoch [190/250]: loss 0.7209, auc 0.4293, ap 0.4520
2024-01-10 22:12:30,371 - GAugM EPNet train, Epoch [191/250]: loss 0.7209, auc 0.4749, ap 0.5436
2024-01-10 22:12:30,464 - GAugM EPNet train, Epoch [192/250]: loss 0.7209, auc 0.4923, ap 0.4775
2024-01-10 22:12:30,555 - GAugM EPNet train, Epoch [193/250]: loss 0.7209, auc 0.4607, ap 0.4944
2024-01-10 22:12:30,639 - GAugM EPNet train, Epoch [194/250]: loss 0.7209, auc 0.4575, ap 0.4982
2024-01-10 22:12:30,717 - GAugM EPNet train, Epoch [195/250]: loss 0.7209, auc 0.4738, ap 0.5090
2024-01-10 22:12:30,809 - GAugM EPNet train, Epoch [196/250]: loss 0.7208, auc 0.5190, ap 0.4971
2024-01-10 22:12:30,896 - GAugM EPNet train, Epoch [197/250]: loss 0.7210, auc 0.4735, ap 0.4787
2024-01-10 22:12:30,974 - GAugM EPNet train, Epoch [198/250]: loss 0.7210, auc 0.4923, ap 0.4895
2024-01-10 22:12:31,051 - GAugM EPNet train, Epoch [199/250]: loss 0.7209, auc 0.5625, ap 0.5847
2024-01-10 22:12:31,143 - GAugM EPNet train, Epoch [200/250]: loss 0.7210, auc 0.5472, ap 0.5561
2024-01-10 22:12:31,231 - GAugM EPNet train, Epoch [201/250]: loss 0.7209, auc 0.4685, ap 0.5118
2024-01-10 22:12:31,318 - GAugM EPNet train, Epoch [202/250]: loss 0.7210, auc 0.5828, ap 0.6227
2024-01-10 22:12:31,400 - GAugM EPNet train, Epoch [203/250]: loss 0.7210, auc 0.5436, ap 0.5533
2024-01-10 22:12:31,489 - GAugM EPNet train, Epoch [204/250]: loss 0.7209, auc 0.4820, ap 0.5137
2024-01-10 22:12:31,582 - GAugM EPNet train, Epoch [205/250]: loss 0.7209, auc 0.5020, ap 0.5467
2024-01-10 22:12:31,663 - GAugM EPNet train, Epoch [206/250]: loss 0.7209, auc 0.4585, ap 0.4821
2024-01-10 22:12:31,739 - GAugM EPNet train, Epoch [207/250]: loss 0.7210, auc 0.5240, ap 0.5570
2024-01-10 22:12:31,824 - GAugM EPNet train, Epoch [208/250]: loss 0.7209, auc 0.4090, ap 0.4916
2024-01-10 22:12:31,916 - GAugM EPNet train, Epoch [209/250]: loss 0.7210, auc 0.5109, ap 0.5217
2024-01-10 22:12:31,996 - GAugM EPNet train, Epoch [210/250]: loss 0.7209, auc 0.5077, ap 0.4989
2024-01-10 22:12:32,075 - GAugM EPNet train, Epoch [211/250]: loss 0.7210, auc 0.5336, ap 0.5509
2024-01-10 22:12:32,164 - GAugM EPNet train, Epoch [212/250]: loss 0.7210, auc 0.5315, ap 0.5611
2024-01-10 22:12:32,251 - GAugM EPNet train, Epoch [213/250]: loss 0.7208, auc 0.6625, ap 0.7001
2024-01-10 22:12:32,342 - GAugM EPNet train, Epoch [214/250]: loss 0.7210, auc 0.4788, ap 0.5093
2024-01-10 22:12:32,422 - GAugM EPNet train, Epoch [215/250]: loss 0.7210, auc 0.5023, ap 0.5107
2024-01-10 22:12:32,510 - GAugM EPNet train, Epoch [216/250]: loss 0.7209, auc 0.6187, ap 0.6061
2024-01-10 22:12:32,585 - GAugM EPNet train, Epoch [217/250]: loss 0.7209, auc 0.5491, ap 0.5652
2024-01-10 22:12:32,665 - GAugM EPNet train, Epoch [218/250]: loss 0.7209, auc 0.4970, ap 0.5323
2024-01-10 22:12:32,748 - GAugM EPNet train, Epoch [219/250]: loss 0.7208, auc 0.4589, ap 0.4895
2024-01-10 22:12:32,828 - GAugM EPNet train, Epoch [220/250]: loss 0.7210, auc 0.4842, ap 0.5427
2024-01-10 22:12:32,914 - GAugM EPNet train, Epoch [221/250]: loss 0.7209, auc 0.5479, ap 0.5563
2024-01-10 22:12:33,008 - GAugM EPNet train, Epoch [222/250]: loss 0.7209, auc 0.5525, ap 0.5308
2024-01-10 22:12:33,099 - GAugM EPNet train, Epoch [223/250]: loss 0.7209, auc 0.5692, ap 0.5799
2024-01-10 22:12:33,185 - GAugM EPNet train, Epoch [224/250]: loss 0.7210, auc 0.4033, ap 0.4601
2024-01-10 22:12:33,272 - GAugM EPNet train, Epoch [225/250]: loss 0.7209, auc 0.4902, ap 0.4917
2024-01-10 22:12:33,359 - GAugM EPNet train, Epoch [226/250]: loss 0.7210, auc 0.5539, ap 0.5734
2024-01-10 22:12:33,446 - GAugM EPNet train, Epoch [227/250]: loss 0.7210, auc 0.5571, ap 0.5773
2024-01-10 22:12:33,537 - GAugM EPNet train, Epoch [228/250]: loss 0.7209, auc 0.5564, ap 0.5634
2024-01-10 22:12:33,626 - GAugM EPNet train, Epoch [229/250]: loss 0.7209, auc 0.5315, ap 0.5616
2024-01-10 22:12:33,712 - GAugM EPNet train, Epoch [230/250]: loss 0.7209, auc 0.5319, ap 0.5479
2024-01-10 22:12:33,808 - GAugM EPNet train, Epoch [231/250]: loss 0.7209, auc 0.5358, ap 0.5485
2024-01-10 22:12:33,895 - GAugM EPNet train, Epoch [232/250]: loss 0.7209, auc 0.6529, ap 0.6339
2024-01-10 22:12:33,986 - GAugM EPNet train, Epoch [233/250]: loss 0.7210, auc 0.5835, ap 0.6012
2024-01-10 22:12:34,075 - GAugM EPNet train, Epoch [234/250]: loss 0.7209, auc 0.4439, ap 0.4998
2024-01-10 22:12:34,165 - GAugM EPNet train, Epoch [235/250]: loss 0.7209, auc 0.4963, ap 0.5218
2024-01-10 22:12:34,252 - GAugM EPNet train, Epoch [236/250]: loss 0.7209, auc 0.5226, ap 0.5383
2024-01-10 22:12:34,344 - GAugM EPNet train, Epoch [237/250]: loss 0.7210, auc 0.4674, ap 0.5085
2024-01-10 22:12:34,439 - GAugM EPNet train, Epoch [238/250]: loss 0.7210, auc 0.4236, ap 0.4578
2024-01-10 22:12:34,529 - GAugM EPNet train, Epoch [239/250]: loss 0.7209, auc 0.4478, ap 0.5414
2024-01-10 22:12:34,621 - GAugM EPNet train, Epoch [240/250]: loss 0.7209, auc 0.5027, ap 0.4910
2024-01-10 22:12:34,720 - GAugM EPNet train, Epoch [241/250]: loss 0.7209, auc 0.5098, ap 0.5315
2024-01-10 22:12:34,809 - GAugM EPNet train, Epoch [242/250]: loss 0.7210, auc 0.4564, ap 0.4975
2024-01-10 22:12:34,899 - GAugM EPNet train, Epoch [243/250]: loss 0.7210, auc 0.5258, ap 0.5939
2024-01-10 22:12:34,990 - GAugM EPNet train, Epoch [244/250]: loss 0.7209, auc 0.5030, ap 0.5166
2024-01-10 22:12:35,086 - GAugM EPNet train, Epoch [245/250]: loss 0.7210, auc 0.4721, ap 0.4969
2024-01-10 22:12:35,173 - GAugM EPNet train, Epoch [246/250]: loss 0.7208, auc 0.5002, ap 0.5336
2024-01-10 22:12:35,260 - GAugM EPNet train, Epoch [247/250]: loss 0.7209, auc 0.5265, ap 0.5389
2024-01-10 22:12:35,352 - GAugM EPNet train, Epoch [248/250]: loss 0.7211, auc 0.5511, ap 0.5674
2024-01-10 22:12:35,443 - GAugM EPNet train, Epoch [249/250]: loss 0.7209, auc 0.4884, ap 0.4947
2024-01-10 22:12:35,534 - GAugM EPNet train, Epoch [250/250]: loss 0.7208, auc 0.5376, ap 0.5322
2024-01-10 22:12:35,543 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0d035c1d90>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:12:36,305 - GAugM EPNet train, Epoch [  1/250]: loss 0.7210, auc 0.4414, ap 0.4556
2024-01-10 22:12:36,390 - GAugM EPNet train, Epoch [  2/250]: loss 0.7210, auc 0.4562, ap 0.4668
2024-01-10 22:12:36,475 - GAugM EPNet train, Epoch [  3/250]: loss 0.7209, auc 0.5169, ap 0.5054
2024-01-10 22:12:36,559 - GAugM EPNet train, Epoch [  4/250]: loss 0.7209, auc 0.4893, ap 0.5311
2024-01-10 22:12:36,642 - GAugM EPNet train, Epoch [  5/250]: loss 0.7209, auc 0.5920, ap 0.5891
2024-01-10 22:12:36,726 - GAugM EPNet train, Epoch [  6/250]: loss 0.7209, auc 0.5249, ap 0.5217
2024-01-10 22:12:36,817 - GAugM EPNet train, Epoch [  7/250]: loss 0.7209, auc 0.4286, ap 0.4490
2024-01-10 22:12:36,901 - GAugM EPNet train, Epoch [  8/250]: loss 0.7210, auc 0.4452, ap 0.4695
2024-01-10 22:12:36,978 - GAugM EPNet train, Epoch [  9/250]: loss 0.7209, auc 0.5675, ap 0.5417
2024-01-10 22:12:37,055 - GAugM EPNet train, Epoch [ 10/250]: loss 0.7208, auc 0.4064, ap 0.4393
2024-01-10 22:12:37,133 - GAugM EPNet train, Epoch [ 11/250]: loss 0.7209, auc 0.4276, ap 0.4886
2024-01-10 22:12:37,213 - GAugM EPNet train, Epoch [ 12/250]: loss 0.7210, auc 0.4331, ap 0.4580
2024-01-10 22:12:37,291 - GAugM EPNet train, Epoch [ 13/250]: loss 0.7209, auc 0.5507, ap 0.5356
2024-01-10 22:12:37,374 - GAugM EPNet train, Epoch [ 14/250]: loss 0.7209, auc 0.5139, ap 0.5224
2024-01-10 22:12:37,464 - GAugM EPNet train, Epoch [ 15/250]: loss 0.7210, auc 0.4600, ap 0.4952
2024-01-10 22:12:37,544 - GAugM EPNet train, Epoch [ 16/250]: loss 0.7209, auc 0.5080, ap 0.5476
2024-01-10 22:12:37,623 - GAugM EPNet train, Epoch [ 17/250]: loss 0.7210, auc 0.6100, ap 0.5848
2024-01-10 22:12:37,702 - GAugM EPNet train, Epoch [ 18/250]: loss 0.7210, auc 0.5673, ap 0.5751
2024-01-10 22:12:37,777 - GAugM EPNet train, Epoch [ 19/250]: loss 0.7209, auc 0.5133, ap 0.5236
2024-01-10 22:12:37,858 - GAugM EPNet train, Epoch [ 20/250]: loss 0.7210, auc 0.4470, ap 0.4909
2024-01-10 22:12:37,938 - GAugM EPNet train, Epoch [ 21/250]: loss 0.7209, auc 0.4954, ap 0.5199
2024-01-10 22:12:38,017 - GAugM EPNet train, Epoch [ 22/250]: loss 0.7210, auc 0.4167, ap 0.4531
2024-01-10 22:12:38,099 - GAugM EPNet train, Epoch [ 23/250]: loss 0.7208, auc 0.5050, ap 0.5033
2024-01-10 22:12:38,177 - GAugM EPNet train, Epoch [ 24/250]: loss 0.7209, auc 0.4729, ap 0.4959
2024-01-10 22:12:38,257 - GAugM EPNet train, Epoch [ 25/250]: loss 0.7209, auc 0.4366, ap 0.4795
2024-01-10 22:12:38,335 - GAugM EPNet train, Epoch [ 26/250]: loss 0.7210, auc 0.5285, ap 0.5574
2024-01-10 22:12:38,410 - GAugM EPNet train, Epoch [ 27/250]: loss 0.7209, auc 0.4721, ap 0.5024
2024-01-10 22:12:38,489 - GAugM EPNet train, Epoch [ 28/250]: loss 0.7209, auc 0.6189, ap 0.6278
2024-01-10 22:12:38,566 - GAugM EPNet train, Epoch [ 29/250]: loss 0.7210, auc 0.4872, ap 0.4937
2024-01-10 22:12:38,655 - GAugM EPNet train, Epoch [ 30/250]: loss 0.7209, auc 0.5616, ap 0.5946
2024-01-10 22:12:38,737 - GAugM EPNet train, Epoch [ 31/250]: loss 0.7208, auc 0.4372, ap 0.4887
2024-01-10 22:12:38,824 - GAugM EPNet train, Epoch [ 32/250]: loss 0.7210, auc 0.5310, ap 0.5403
2024-01-10 22:12:38,902 - GAugM EPNet train, Epoch [ 33/250]: loss 0.7209, auc 0.5233, ap 0.5279
2024-01-10 22:12:38,981 - GAugM EPNet train, Epoch [ 34/250]: loss 0.7209, auc 0.4644, ap 0.4862
2024-01-10 22:12:39,070 - GAugM EPNet train, Epoch [ 35/250]: loss 0.7209, auc 0.6153, ap 0.5927
2024-01-10 22:12:39,149 - GAugM EPNet train, Epoch [ 36/250]: loss 0.7209, auc 0.6018, ap 0.6254
2024-01-10 22:12:39,224 - GAugM EPNet train, Epoch [ 37/250]: loss 0.7209, auc 0.5320, ap 0.5230
2024-01-10 22:12:39,309 - GAugM EPNet train, Epoch [ 38/250]: loss 0.7209, auc 0.5078, ap 0.5110
2024-01-10 22:12:39,390 - GAugM EPNet train, Epoch [ 39/250]: loss 0.7208, auc 0.4158, ap 0.4687
2024-01-10 22:12:39,471 - GAugM EPNet train, Epoch [ 40/250]: loss 0.7210, auc 0.5578, ap 0.5367
2024-01-10 22:12:39,547 - GAugM EPNet train, Epoch [ 41/250]: loss 0.7210, auc 0.4692, ap 0.5193
2024-01-10 22:12:39,630 - GAugM EPNet train, Epoch [ 42/250]: loss 0.7209, auc 0.5415, ap 0.5658
2024-01-10 22:12:39,710 - GAugM EPNet train, Epoch [ 43/250]: loss 0.7208, auc 0.5424, ap 0.5766
2024-01-10 22:12:39,785 - GAugM EPNet train, Epoch [ 44/250]: loss 0.7208, auc 0.4576, ap 0.4771
2024-01-10 22:12:39,860 - GAugM EPNet train, Epoch [ 45/250]: loss 0.7209, auc 0.5271, ap 0.5718
2024-01-10 22:12:39,936 - GAugM EPNet train, Epoch [ 46/250]: loss 0.7209, auc 0.4660, ap 0.4985
2024-01-10 22:12:40,015 - GAugM EPNet train, Epoch [ 47/250]: loss 0.7210, auc 0.5320, ap 0.5530
2024-01-10 22:12:40,104 - GAugM EPNet train, Epoch [ 48/250]: loss 0.7210, auc 0.6655, ap 0.6830
2024-01-10 22:12:40,182 - GAugM EPNet train, Epoch [ 49/250]: loss 0.7209, auc 0.5817, ap 0.6029
2024-01-10 22:12:40,258 - GAugM EPNet train, Epoch [ 50/250]: loss 0.7210, auc 0.6089, ap 0.6031
2024-01-10 22:12:40,334 - GAugM EPNet train, Epoch [ 51/250]: loss 0.7210, auc 0.4473, ap 0.4934
2024-01-10 22:12:40,417 - GAugM EPNet train, Epoch [ 52/250]: loss 0.7209, auc 0.4233, ap 0.4558
2024-01-10 22:12:40,502 - GAugM EPNet train, Epoch [ 53/250]: loss 0.7209, auc 0.4831, ap 0.5418
2024-01-10 22:12:40,576 - GAugM EPNet train, Epoch [ 54/250]: loss 0.7211, auc 0.5842, ap 0.5845
2024-01-10 22:12:40,651 - GAugM EPNet train, Epoch [ 55/250]: loss 0.7209, auc 0.5940, ap 0.6429
2024-01-10 22:12:40,727 - GAugM EPNet train, Epoch [ 56/250]: loss 0.7208, auc 0.4220, ap 0.4494
2024-01-10 22:12:40,802 - GAugM EPNet train, Epoch [ 57/250]: loss 0.7209, auc 0.4555, ap 0.4669
2024-01-10 22:12:40,876 - GAugM EPNet train, Epoch [ 58/250]: loss 0.7210, auc 0.4576, ap 0.5179
2024-01-10 22:12:40,952 - GAugM EPNet train, Epoch [ 59/250]: loss 0.7211, auc 0.5625, ap 0.5322
2024-01-10 22:12:41,028 - GAugM EPNet train, Epoch [ 60/250]: loss 0.7210, auc 0.5287, ap 0.5483
2024-01-10 22:12:41,103 - GAugM EPNet train, Epoch [ 61/250]: loss 0.7209, auc 0.5824, ap 0.5885
2024-01-10 22:12:41,181 - GAugM EPNet train, Epoch [ 62/250]: loss 0.7210, auc 0.5431, ap 0.5739
2024-01-10 22:12:41,258 - GAugM EPNet train, Epoch [ 63/250]: loss 0.7208, auc 0.3786, ap 0.4317
2024-01-10 22:12:41,335 - GAugM EPNet train, Epoch [ 64/250]: loss 0.7208, auc 0.4534, ap 0.4878
2024-01-10 22:12:41,410 - GAugM EPNet train, Epoch [ 65/250]: loss 0.7208, auc 0.5764, ap 0.5849
2024-01-10 22:12:41,483 - GAugM EPNet train, Epoch [ 66/250]: loss 0.7209, auc 0.4324, ap 0.4793
2024-01-10 22:12:41,564 - GAugM EPNet train, Epoch [ 67/250]: loss 0.7209, auc 0.5303, ap 0.5394
2024-01-10 22:12:41,640 - GAugM EPNet train, Epoch [ 68/250]: loss 0.7210, auc 0.6109, ap 0.6343
2024-01-10 22:12:41,718 - GAugM EPNet train, Epoch [ 69/250]: loss 0.7210, auc 0.5491, ap 0.5676
2024-01-10 22:12:41,794 - GAugM EPNet train, Epoch [ 70/250]: loss 0.7210, auc 0.4786, ap 0.4942
2024-01-10 22:12:41,868 - GAugM EPNet train, Epoch [ 71/250]: loss 0.7210, auc 0.5422, ap 0.5417
2024-01-10 22:12:41,944 - GAugM EPNet train, Epoch [ 72/250]: loss 0.7210, auc 0.4923, ap 0.5115
2024-01-10 22:12:42,021 - GAugM EPNet train, Epoch [ 73/250]: loss 0.7209, auc 0.5164, ap 0.5094
2024-01-10 22:12:42,101 - GAugM EPNet train, Epoch [ 74/250]: loss 0.7209, auc 0.4776, ap 0.5193
2024-01-10 22:12:42,189 - GAugM EPNet train, Epoch [ 75/250]: loss 0.7210, auc 0.4381, ap 0.5073
2024-01-10 22:12:42,268 - GAugM EPNet train, Epoch [ 76/250]: loss 0.7209, auc 0.4121, ap 0.4796
2024-01-10 22:12:42,342 - GAugM EPNet train, Epoch [ 77/250]: loss 0.7208, auc 0.6205, ap 0.6378
2024-01-10 22:12:42,422 - GAugM EPNet train, Epoch [ 78/250]: loss 0.7209, auc 0.4984, ap 0.5117
2024-01-10 22:12:42,500 - GAugM EPNet train, Epoch [ 79/250]: loss 0.7208, auc 0.5214, ap 0.5259
2024-01-10 22:12:42,575 - GAugM EPNet train, Epoch [ 80/250]: loss 0.7209, auc 0.5612, ap 0.5293
2024-01-10 22:12:42,651 - GAugM EPNet train, Epoch [ 81/250]: loss 0.7209, auc 0.5244, ap 0.5160
2024-01-10 22:12:42,732 - GAugM EPNet train, Epoch [ 82/250]: loss 0.7210, auc 0.5429, ap 0.5202
2024-01-10 22:12:42,808 - GAugM EPNet train, Epoch [ 83/250]: loss 0.7209, auc 0.4229, ap 0.4855
2024-01-10 22:12:42,898 - GAugM EPNet train, Epoch [ 84/250]: loss 0.7209, auc 0.4692, ap 0.5103
2024-01-10 22:12:42,974 - GAugM EPNet train, Epoch [ 85/250]: loss 0.7210, auc 0.4466, ap 0.4989
2024-01-10 22:12:43,050 - GAugM EPNet train, Epoch [ 86/250]: loss 0.7208, auc 0.6038, ap 0.5815
2024-01-10 22:12:43,130 - GAugM EPNet train, Epoch [ 87/250]: loss 0.7209, auc 0.4769, ap 0.4817
2024-01-10 22:12:43,207 - GAugM EPNet train, Epoch [ 88/250]: loss 0.7210, auc 0.4206, ap 0.4731
2024-01-10 22:12:43,285 - GAugM EPNet train, Epoch [ 89/250]: loss 0.7210, auc 0.4970, ap 0.5448
2024-01-10 22:12:43,368 - GAugM EPNet train, Epoch [ 90/250]: loss 0.7209, auc 0.3941, ap 0.4647
2024-01-10 22:12:43,458 - GAugM EPNet train, Epoch [ 91/250]: loss 0.7208, auc 0.5899, ap 0.5580
2024-01-10 22:12:43,543 - GAugM EPNet train, Epoch [ 92/250]: loss 0.7209, auc 0.6020, ap 0.6066
2024-01-10 22:12:43,632 - GAugM EPNet train, Epoch [ 93/250]: loss 0.7209, auc 0.4381, ap 0.4754
2024-01-10 22:12:43,720 - GAugM EPNet train, Epoch [ 94/250]: loss 0.7210, auc 0.4941, ap 0.5223
2024-01-10 22:12:43,807 - GAugM EPNet train, Epoch [ 95/250]: loss 0.7210, auc 0.4567, ap 0.5203
2024-01-10 22:12:43,888 - GAugM EPNet train, Epoch [ 96/250]: loss 0.7209, auc 0.5395, ap 0.5533
2024-01-10 22:12:43,972 - GAugM EPNet train, Epoch [ 97/250]: loss 0.7209, auc 0.4292, ap 0.4703
2024-01-10 22:12:44,052 - GAugM EPNet train, Epoch [ 98/250]: loss 0.7209, auc 0.4664, ap 0.4959
2024-01-10 22:12:44,135 - GAugM EPNet train, Epoch [ 99/250]: loss 0.7209, auc 0.5052, ap 0.5525
2024-01-10 22:12:44,216 - GAugM EPNet train, Epoch [100/250]: loss 0.7210, auc 0.4945, ap 0.5257
2024-01-10 22:12:44,295 - GAugM EPNet train, Epoch [101/250]: loss 0.7210, auc 0.4564, ap 0.5050
2024-01-10 22:12:44,374 - GAugM EPNet train, Epoch [102/250]: loss 0.7209, auc 0.5214, ap 0.5501
2024-01-10 22:12:44,457 - GAugM EPNet train, Epoch [103/250]: loss 0.7209, auc 0.5025, ap 0.5548
2024-01-10 22:12:44,537 - GAugM EPNet train, Epoch [104/250]: loss 0.7209, auc 0.4658, ap 0.4974
2024-01-10 22:12:44,615 - GAugM EPNet train, Epoch [105/250]: loss 0.7209, auc 0.4587, ap 0.4663
2024-01-10 22:12:44,699 - GAugM EPNet train, Epoch [106/250]: loss 0.7210, auc 0.5212, ap 0.5247
2024-01-10 22:12:44,781 - GAugM EPNet train, Epoch [107/250]: loss 0.7210, auc 0.5484, ap 0.5842
2024-01-10 22:12:44,866 - GAugM EPNet train, Epoch [108/250]: loss 0.7208, auc 0.5215, ap 0.5178
2024-01-10 22:12:44,952 - GAugM EPNet train, Epoch [109/250]: loss 0.7210, auc 0.4098, ap 0.4573
2024-01-10 22:12:45,039 - GAugM EPNet train, Epoch [110/250]: loss 0.7209, auc 0.5123, ap 0.5263
2024-01-10 22:12:45,121 - GAugM EPNet train, Epoch [111/250]: loss 0.7210, auc 0.4354, ap 0.4871
2024-01-10 22:12:45,199 - GAugM EPNet train, Epoch [112/250]: loss 0.7209, auc 0.4628, ap 0.4841
2024-01-10 22:12:45,277 - GAugM EPNet train, Epoch [113/250]: loss 0.7210, auc 0.4455, ap 0.5132
2024-01-10 22:12:45,364 - GAugM EPNet train, Epoch [114/250]: loss 0.7209, auc 0.4252, ap 0.4564
2024-01-10 22:12:45,440 - GAugM EPNet train, Epoch [115/250]: loss 0.7210, auc 0.5094, ap 0.5262
2024-01-10 22:12:45,520 - GAugM EPNet train, Epoch [116/250]: loss 0.7209, auc 0.5073, ap 0.5289
2024-01-10 22:12:45,597 - GAugM EPNet train, Epoch [117/250]: loss 0.7208, auc 0.4468, ap 0.4897
2024-01-10 22:12:45,675 - GAugM EPNet train, Epoch [118/250]: loss 0.7209, auc 0.4715, ap 0.4999
2024-01-10 22:12:45,759 - GAugM EPNet train, Epoch [119/250]: loss 0.7209, auc 0.5174, ap 0.5431
2024-01-10 22:12:45,836 - GAugM EPNet train, Epoch [120/250]: loss 0.7210, auc 0.4740, ap 0.5043
2024-01-10 22:12:45,912 - GAugM EPNet train, Epoch [121/250]: loss 0.7210, auc 0.5016, ap 0.5070
2024-01-10 22:12:45,992 - GAugM EPNet train, Epoch [122/250]: loss 0.7209, auc 0.5094, ap 0.5361
2024-01-10 22:12:46,065 - GAugM EPNet train, Epoch [123/250]: loss 0.7209, auc 0.5438, ap 0.5745
2024-01-10 22:12:46,143 - GAugM EPNet train, Epoch [124/250]: loss 0.7210, auc 0.4329, ap 0.4871
2024-01-10 22:12:46,218 - GAugM EPNet train, Epoch [125/250]: loss 0.7209, auc 0.4829, ap 0.5161
2024-01-10 22:12:46,297 - GAugM EPNet train, Epoch [126/250]: loss 0.7210, auc 0.4824, ap 0.4917
2024-01-10 22:12:46,379 - GAugM EPNet train, Epoch [127/250]: loss 0.7209, auc 0.4735, ap 0.4841
2024-01-10 22:12:46,457 - GAugM EPNet train, Epoch [128/250]: loss 0.7210, auc 0.4979, ap 0.4945
2024-01-10 22:12:46,539 - GAugM EPNet train, Epoch [129/250]: loss 0.7208, auc 0.4292, ap 0.4659
2024-01-10 22:12:46,615 - GAugM EPNet train, Epoch [130/250]: loss 0.7210, auc 0.5251, ap 0.5500
2024-01-10 22:12:46,692 - GAugM EPNet train, Epoch [131/250]: loss 0.7210, auc 0.5591, ap 0.5847
2024-01-10 22:12:46,768 - GAugM EPNet train, Epoch [132/250]: loss 0.7209, auc 0.5303, ap 0.5497
2024-01-10 22:12:46,853 - GAugM EPNet train, Epoch [133/250]: loss 0.7209, auc 0.4877, ap 0.5497
2024-01-10 22:12:46,942 - GAugM EPNet train, Epoch [134/250]: loss 0.7210, auc 0.5376, ap 0.5506
2024-01-10 22:12:47,028 - GAugM EPNet train, Epoch [135/250]: loss 0.7209, auc 0.3946, ap 0.4415
2024-01-10 22:12:47,114 - GAugM EPNet train, Epoch [136/250]: loss 0.7209, auc 0.5125, ap 0.5128
2024-01-10 22:12:47,201 - GAugM EPNet train, Epoch [137/250]: loss 0.7210, auc 0.4085, ap 0.4476
2024-01-10 22:12:47,284 - GAugM EPNet train, Epoch [138/250]: loss 0.7210, auc 0.5007, ap 0.4985
2024-01-10 22:12:47,370 - GAugM EPNet train, Epoch [139/250]: loss 0.7210, auc 0.4899, ap 0.5314
2024-01-10 22:12:47,455 - GAugM EPNet train, Epoch [140/250]: loss 0.7209, auc 0.5789, ap 0.6102
2024-01-10 22:12:47,539 - GAugM EPNet train, Epoch [141/250]: loss 0.7209, auc 0.4911, ap 0.4938
2024-01-10 22:12:47,626 - GAugM EPNet train, Epoch [142/250]: loss 0.7209, auc 0.5705, ap 0.5915
2024-01-10 22:12:47,710 - GAugM EPNet train, Epoch [143/250]: loss 0.7209, auc 0.4464, ap 0.4852
2024-01-10 22:12:47,801 - GAugM EPNet train, Epoch [144/250]: loss 0.7209, auc 0.5144, ap 0.5086
2024-01-10 22:12:47,884 - GAugM EPNet train, Epoch [145/250]: loss 0.7209, auc 0.4023, ap 0.4621
2024-01-10 22:12:47,972 - GAugM EPNet train, Epoch [146/250]: loss 0.7209, auc 0.4598, ap 0.4916
2024-01-10 22:12:48,064 - GAugM EPNet train, Epoch [147/250]: loss 0.7209, auc 0.5651, ap 0.6111
2024-01-10 22:12:48,152 - GAugM EPNet train, Epoch [148/250]: loss 0.7209, auc 0.3937, ap 0.4347
2024-01-10 22:12:48,241 - GAugM EPNet train, Epoch [149/250]: loss 0.7208, auc 0.5258, ap 0.5123
2024-01-10 22:12:48,333 - GAugM EPNet train, Epoch [150/250]: loss 0.7209, auc 0.5452, ap 0.5457
2024-01-10 22:12:48,420 - GAugM EPNet train, Epoch [151/250]: loss 0.7209, auc 0.5265, ap 0.5063
2024-01-10 22:12:48,510 - GAugM EPNet train, Epoch [152/250]: loss 0.7209, auc 0.4915, ap 0.5064
2024-01-10 22:12:48,598 - GAugM EPNet train, Epoch [153/250]: loss 0.7209, auc 0.4324, ap 0.4977
2024-01-10 22:12:48,691 - GAugM EPNet train, Epoch [154/250]: loss 0.7209, auc 0.5475, ap 0.6166
2024-01-10 22:12:48,779 - GAugM EPNet train, Epoch [155/250]: loss 0.7209, auc 0.5422, ap 0.5713
2024-01-10 22:12:48,870 - GAugM EPNet train, Epoch [156/250]: loss 0.7209, auc 0.4826, ap 0.4933
2024-01-10 22:12:48,958 - GAugM EPNet train, Epoch [157/250]: loss 0.7209, auc 0.5454, ap 0.5478
2024-01-10 22:12:49,042 - GAugM EPNet train, Epoch [158/250]: loss 0.7208, auc 0.4826, ap 0.4941
2024-01-10 22:12:49,127 - GAugM EPNet train, Epoch [159/250]: loss 0.7208, auc 0.4847, ap 0.5026
2024-01-10 22:12:49,213 - GAugM EPNet train, Epoch [160/250]: loss 0.7209, auc 0.5650, ap 0.5772
2024-01-10 22:12:49,298 - GAugM EPNet train, Epoch [161/250]: loss 0.7209, auc 0.5351, ap 0.5589
2024-01-10 22:12:49,390 - GAugM EPNet train, Epoch [162/250]: loss 0.7209, auc 0.5174, ap 0.5134
2024-01-10 22:12:49,479 - GAugM EPNet train, Epoch [163/250]: loss 0.7209, auc 0.4988, ap 0.5097
2024-01-10 22:12:49,567 - GAugM EPNet train, Epoch [164/250]: loss 0.7211, auc 0.4261, ap 0.4522
2024-01-10 22:12:49,662 - GAugM EPNet train, Epoch [165/250]: loss 0.7210, auc 0.4176, ap 0.4453
2024-01-10 22:12:49,750 - GAugM EPNet train, Epoch [166/250]: loss 0.7208, auc 0.5148, ap 0.5316
2024-01-10 22:12:49,838 - GAugM EPNet train, Epoch [167/250]: loss 0.7209, auc 0.4041, ap 0.4486
2024-01-10 22:12:49,925 - GAugM EPNet train, Epoch [168/250]: loss 0.7209, auc 0.4532, ap 0.5200
2024-01-10 22:12:50,010 - GAugM EPNet train, Epoch [169/250]: loss 0.7209, auc 0.5808, ap 0.6068
2024-01-10 22:12:50,097 - GAugM EPNet train, Epoch [170/250]: loss 0.7210, auc 0.4947, ap 0.4812
2024-01-10 22:12:50,183 - GAugM EPNet train, Epoch [171/250]: loss 0.7209, auc 0.4183, ap 0.4554
2024-01-10 22:12:50,285 - GAugM EPNet train, Epoch [172/250]: loss 0.7208, auc 0.4462, ap 0.4739
2024-01-10 22:12:50,372 - GAugM EPNet train, Epoch [173/250]: loss 0.7209, auc 0.4836, ap 0.5328
2024-01-10 22:12:50,461 - GAugM EPNet train, Epoch [174/250]: loss 0.7209, auc 0.5043, ap 0.5303
2024-01-10 22:12:50,549 - GAugM EPNet train, Epoch [175/250]: loss 0.7209, auc 0.5927, ap 0.5706
2024-01-10 22:12:50,634 - GAugM EPNet train, Epoch [176/250]: loss 0.7209, auc 0.4968, ap 0.5125
2024-01-10 22:12:50,723 - GAugM EPNet train, Epoch [177/250]: loss 0.7210, auc 0.5194, ap 0.5198
2024-01-10 22:12:50,809 - GAugM EPNet train, Epoch [178/250]: loss 0.7210, auc 0.4925, ap 0.5621
2024-01-10 22:12:50,899 - GAugM EPNet train, Epoch [179/250]: loss 0.7210, auc 0.4409, ap 0.4961
2024-01-10 22:12:50,992 - GAugM EPNet train, Epoch [180/250]: loss 0.7210, auc 0.5192, ap 0.5744
2024-01-10 22:12:51,078 - GAugM EPNet train, Epoch [181/250]: loss 0.7209, auc 0.4350, ap 0.4897
2024-01-10 22:12:51,168 - GAugM EPNet train, Epoch [182/250]: loss 0.7209, auc 0.4623, ap 0.5092
2024-01-10 22:12:51,252 - GAugM EPNet train, Epoch [183/250]: loss 0.7210, auc 0.5924, ap 0.5769
2024-01-10 22:12:51,349 - GAugM EPNet train, Epoch [184/250]: loss 0.7209, auc 0.5274, ap 0.5334
2024-01-10 22:12:51,435 - GAugM EPNet train, Epoch [185/250]: loss 0.7209, auc 0.5504, ap 0.5547
2024-01-10 22:12:51,522 - GAugM EPNet train, Epoch [186/250]: loss 0.7208, auc 0.4493, ap 0.5168
2024-01-10 22:12:51,609 - GAugM EPNet train, Epoch [187/250]: loss 0.7209, auc 0.4448, ap 0.4901
2024-01-10 22:12:51,703 - GAugM EPNet train, Epoch [188/250]: loss 0.7209, auc 0.5146, ap 0.4922
2024-01-10 22:12:51,790 - GAugM EPNet train, Epoch [189/250]: loss 0.7209, auc 0.5892, ap 0.5902
2024-01-10 22:12:51,877 - GAugM EPNet train, Epoch [190/250]: loss 0.7209, auc 0.4731, ap 0.4926
2024-01-10 22:12:51,962 - GAugM EPNet train, Epoch [191/250]: loss 0.7209, auc 0.4986, ap 0.5443
2024-01-10 22:12:52,049 - GAugM EPNet train, Epoch [192/250]: loss 0.7209, auc 0.4863, ap 0.4857
2024-01-10 22:12:52,139 - GAugM EPNet train, Epoch [193/250]: loss 0.7209, auc 0.5055, ap 0.5121
2024-01-10 22:12:52,225 - GAugM EPNet train, Epoch [194/250]: loss 0.7209, auc 0.5123, ap 0.5107
2024-01-10 22:12:52,310 - GAugM EPNet train, Epoch [195/250]: loss 0.7209, auc 0.4197, ap 0.4570
2024-01-10 22:12:52,403 - GAugM EPNet train, Epoch [196/250]: loss 0.7208, auc 0.5162, ap 0.5149
2024-01-10 22:12:52,491 - GAugM EPNet train, Epoch [197/250]: loss 0.7210, auc 0.4425, ap 0.4894
2024-01-10 22:12:52,579 - GAugM EPNet train, Epoch [198/250]: loss 0.7210, auc 0.5764, ap 0.5709
2024-01-10 22:12:52,662 - GAugM EPNet train, Epoch [199/250]: loss 0.7209, auc 0.4856, ap 0.5289
2024-01-10 22:12:52,761 - GAugM EPNet train, Epoch [200/250]: loss 0.7210, auc 0.4482, ap 0.4804
2024-01-10 22:12:52,845 - GAugM EPNet train, Epoch [201/250]: loss 0.7209, auc 0.4489, ap 0.4818
2024-01-10 22:12:52,933 - GAugM EPNet train, Epoch [202/250]: loss 0.7210, auc 0.4432, ap 0.4996
2024-01-10 22:12:53,016 - GAugM EPNet train, Epoch [203/250]: loss 0.7210, auc 0.4585, ap 0.5052
2024-01-10 22:12:53,100 - GAugM EPNet train, Epoch [204/250]: loss 0.7209, auc 0.3898, ap 0.4342
2024-01-10 22:12:53,187 - GAugM EPNet train, Epoch [205/250]: loss 0.7209, auc 0.5251, ap 0.5514
2024-01-10 22:12:53,277 - GAugM EPNet train, Epoch [206/250]: loss 0.7209, auc 0.4778, ap 0.4852
2024-01-10 22:12:53,360 - GAugM EPNet train, Epoch [207/250]: loss 0.7210, auc 0.4359, ap 0.4798
2024-01-10 22:12:53,443 - GAugM EPNet train, Epoch [208/250]: loss 0.7209, auc 0.4470, ap 0.5130
2024-01-10 22:12:53,531 - GAugM EPNet train, Epoch [209/250]: loss 0.7210, auc 0.6157, ap 0.6264
2024-01-10 22:12:53,615 - GAugM EPNet train, Epoch [210/250]: loss 0.7209, auc 0.4827, ap 0.5057
2024-01-10 22:12:53,707 - GAugM EPNet train, Epoch [211/250]: loss 0.7210, auc 0.5183, ap 0.5415
2024-01-10 22:12:53,793 - GAugM EPNet train, Epoch [212/250]: loss 0.7210, auc 0.4943, ap 0.5106
2024-01-10 22:12:53,884 - GAugM EPNet train, Epoch [213/250]: loss 0.7208, auc 0.5821, ap 0.6264
2024-01-10 22:12:53,974 - GAugM EPNet train, Epoch [214/250]: loss 0.7210, auc 0.4785, ap 0.4992
2024-01-10 22:12:54,059 - GAugM EPNet train, Epoch [215/250]: loss 0.7210, auc 0.5085, ap 0.5063
2024-01-10 22:12:54,155 - GAugM EPNet train, Epoch [216/250]: loss 0.7209, auc 0.5109, ap 0.5201
2024-01-10 22:12:54,245 - GAugM EPNet train, Epoch [217/250]: loss 0.7209, auc 0.5536, ap 0.5925
2024-01-10 22:12:54,327 - GAugM EPNet train, Epoch [218/250]: loss 0.7209, auc 0.4939, ap 0.5316
2024-01-10 22:12:54,407 - GAugM EPNet train, Epoch [219/250]: loss 0.7208, auc 0.3991, ap 0.4491
2024-01-10 22:12:54,487 - GAugM EPNet train, Epoch [220/250]: loss 0.7210, auc 0.4694, ap 0.5137
2024-01-10 22:12:54,577 - GAugM EPNet train, Epoch [221/250]: loss 0.7209, auc 0.5675, ap 0.5429
2024-01-10 22:12:54,661 - GAugM EPNet train, Epoch [222/250]: loss 0.7209, auc 0.5141, ap 0.5460
2024-01-10 22:12:54,751 - GAugM EPNet train, Epoch [223/250]: loss 0.7209, auc 0.5557, ap 0.5966
2024-01-10 22:12:54,833 - GAugM EPNet train, Epoch [224/250]: loss 0.7210, auc 0.5002, ap 0.5324
2024-01-10 22:12:54,923 - GAugM EPNet train, Epoch [225/250]: loss 0.7209, auc 0.5477, ap 0.5665
2024-01-10 22:12:55,001 - GAugM EPNet train, Epoch [226/250]: loss 0.7210, auc 0.4712, ap 0.5015
2024-01-10 22:12:55,077 - GAugM EPNet train, Epoch [227/250]: loss 0.7210, auc 0.4964, ap 0.5035
2024-01-10 22:12:55,168 - GAugM EPNet train, Epoch [228/250]: loss 0.7209, auc 0.5023, ap 0.5088
2024-01-10 22:12:55,250 - GAugM EPNet train, Epoch [229/250]: loss 0.7209, auc 0.5712, ap 0.5984
2024-01-10 22:12:55,334 - GAugM EPNet train, Epoch [230/250]: loss 0.7209, auc 0.5986, ap 0.6143
2024-01-10 22:12:55,419 - GAugM EPNet train, Epoch [231/250]: loss 0.7209, auc 0.4941, ap 0.5101
2024-01-10 22:12:55,505 - GAugM EPNet train, Epoch [232/250]: loss 0.7209, auc 0.4135, ap 0.4605
2024-01-10 22:12:55,592 - GAugM EPNet train, Epoch [233/250]: loss 0.7210, auc 0.4537, ap 0.4826
2024-01-10 22:12:55,680 - GAugM EPNet train, Epoch [234/250]: loss 0.7209, auc 0.3740, ap 0.4479
2024-01-10 22:12:55,768 - GAugM EPNet train, Epoch [235/250]: loss 0.7209, auc 0.4402, ap 0.4561
2024-01-10 22:12:55,858 - GAugM EPNet train, Epoch [236/250]: loss 0.7209, auc 0.5091, ap 0.5277
2024-01-10 22:12:55,946 - GAugM EPNet train, Epoch [237/250]: loss 0.7210, auc 0.5326, ap 0.5550
2024-01-10 22:12:56,032 - GAugM EPNet train, Epoch [238/250]: loss 0.7210, auc 0.4409, ap 0.4941
2024-01-10 22:12:56,116 - GAugM EPNet train, Epoch [239/250]: loss 0.7209, auc 0.4847, ap 0.5778
2024-01-10 22:12:56,196 - GAugM EPNet train, Epoch [240/250]: loss 0.7209, auc 0.5187, ap 0.5079
2024-01-10 22:12:56,273 - GAugM EPNet train, Epoch [241/250]: loss 0.7209, auc 0.5041, ap 0.5342
2024-01-10 22:12:56,365 - GAugM EPNet train, Epoch [242/250]: loss 0.7210, auc 0.5103, ap 0.5449
2024-01-10 22:12:56,450 - GAugM EPNet train, Epoch [243/250]: loss 0.7210, auc 0.5303, ap 0.5765
2024-01-10 22:12:56,534 - GAugM EPNet train, Epoch [244/250]: loss 0.7209, auc 0.4843, ap 0.5150
2024-01-10 22:12:56,611 - GAugM EPNet train, Epoch [245/250]: loss 0.7210, auc 0.4434, ap 0.4605
2024-01-10 22:12:56,688 - GAugM EPNet train, Epoch [246/250]: loss 0.7208, auc 0.4710, ap 0.4974
2024-01-10 22:12:56,779 - GAugM EPNet train, Epoch [247/250]: loss 0.7209, auc 0.5224, ap 0.5403
2024-01-10 22:12:56,868 - GAugM EPNet train, Epoch [248/250]: loss 0.7211, auc 0.5011, ap 0.5287
2024-01-10 22:12:56,956 - GAugM EPNet train, Epoch [249/250]: loss 0.7209, auc 0.4436, ap 0.4603
2024-01-10 22:12:57,047 - GAugM EPNet train, Epoch [250/250]: loss 0.7208, auc 0.5032, ap 0.5005
2024-01-10 22:12:57,052 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa0b9b10>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:12:57,915 - GAugM EPNet train, Epoch [  1/250]: loss 0.7210, auc 0.5061, ap 0.4979
2024-01-10 22:12:58,017 - GAugM EPNet train, Epoch [  2/250]: loss 0.7210, auc 0.5322, ap 0.5267
2024-01-10 22:12:58,110 - GAugM EPNet train, Epoch [  3/250]: loss 0.7209, auc 0.5644, ap 0.5886
2024-01-10 22:12:58,209 - GAugM EPNet train, Epoch [  4/250]: loss 0.7209, auc 0.4423, ap 0.4834
2024-01-10 22:12:58,309 - GAugM EPNet train, Epoch [  5/250]: loss 0.7209, auc 0.6326, ap 0.5959
2024-01-10 22:12:58,404 - GAugM EPNet train, Epoch [  6/250]: loss 0.7209, auc 0.5267, ap 0.5015
2024-01-10 22:12:58,493 - GAugM EPNet train, Epoch [  7/250]: loss 0.7209, auc 0.4904, ap 0.4908
2024-01-10 22:12:58,579 - GAugM EPNet train, Epoch [  8/250]: loss 0.7210, auc 0.4804, ap 0.4778
2024-01-10 22:12:58,672 - GAugM EPNet train, Epoch [  9/250]: loss 0.7209, auc 0.4443, ap 0.4591
2024-01-10 22:12:58,758 - GAugM EPNet train, Epoch [ 10/250]: loss 0.7208, auc 0.4489, ap 0.5013
2024-01-10 22:12:58,852 - GAugM EPNet train, Epoch [ 11/250]: loss 0.7209, auc 0.4144, ap 0.4474
2024-01-10 22:12:58,946 - GAugM EPNet train, Epoch [ 12/250]: loss 0.7210, auc 0.4810, ap 0.4746
2024-01-10 22:12:59,035 - GAugM EPNet train, Epoch [ 13/250]: loss 0.7209, auc 0.6130, ap 0.6243
2024-01-10 22:12:59,126 - GAugM EPNet train, Epoch [ 14/250]: loss 0.7209, auc 0.5595, ap 0.5245
2024-01-10 22:12:59,212 - GAugM EPNet train, Epoch [ 15/250]: loss 0.7210, auc 0.3572, ap 0.4390
2024-01-10 22:12:59,293 - GAugM EPNet train, Epoch [ 16/250]: loss 0.7209, auc 0.5157, ap 0.5102
2024-01-10 22:12:59,381 - GAugM EPNet train, Epoch [ 17/250]: loss 0.7210, auc 0.5441, ap 0.5248
2024-01-10 22:12:59,470 - GAugM EPNet train, Epoch [ 18/250]: loss 0.7210, auc 0.5297, ap 0.5394
2024-01-10 22:12:59,555 - GAugM EPNet train, Epoch [ 19/250]: loss 0.7209, auc 0.5021, ap 0.5133
2024-01-10 22:12:59,642 - GAugM EPNet train, Epoch [ 20/250]: loss 0.7210, auc 0.4886, ap 0.5402
2024-01-10 22:12:59,730 - GAugM EPNet train, Epoch [ 21/250]: loss 0.7209, auc 0.4872, ap 0.5149
2024-01-10 22:12:59,821 - GAugM EPNet train, Epoch [ 22/250]: loss 0.7210, auc 0.3733, ap 0.4365
2024-01-10 22:12:59,913 - GAugM EPNet train, Epoch [ 23/250]: loss 0.7208, auc 0.5290, ap 0.5311
2024-01-10 22:13:00,010 - GAugM EPNet train, Epoch [ 24/250]: loss 0.7209, auc 0.5897, ap 0.5303
2024-01-10 22:13:00,108 - GAugM EPNet train, Epoch [ 25/250]: loss 0.7209, auc 0.4583, ap 0.4730
2024-01-10 22:13:00,194 - GAugM EPNet train, Epoch [ 26/250]: loss 0.7210, auc 0.4822, ap 0.5286
2024-01-10 22:13:00,278 - GAugM EPNet train, Epoch [ 27/250]: loss 0.7209, auc 0.5135, ap 0.5182
2024-01-10 22:13:00,360 - GAugM EPNet train, Epoch [ 28/250]: loss 0.7209, auc 0.5109, ap 0.5338
2024-01-10 22:13:00,443 - GAugM EPNet train, Epoch [ 29/250]: loss 0.7210, auc 0.4623, ap 0.4765
2024-01-10 22:13:00,519 - GAugM EPNet train, Epoch [ 30/250]: loss 0.7209, auc 0.5101, ap 0.4996
2024-01-10 22:13:00,614 - GAugM EPNet train, Epoch [ 31/250]: loss 0.7208, auc 0.4818, ap 0.5165
2024-01-10 22:13:00,694 - GAugM EPNet train, Epoch [ 32/250]: loss 0.7210, auc 0.5397, ap 0.5220
2024-01-10 22:13:00,774 - GAugM EPNet train, Epoch [ 33/250]: loss 0.7209, auc 0.5390, ap 0.5470
2024-01-10 22:13:00,855 - GAugM EPNet train, Epoch [ 34/250]: loss 0.7209, auc 0.4607, ap 0.4796
2024-01-10 22:13:00,938 - GAugM EPNet train, Epoch [ 35/250]: loss 0.7209, auc 0.5559, ap 0.5302
2024-01-10 22:13:01,024 - GAugM EPNet train, Epoch [ 36/250]: loss 0.7209, auc 0.5449, ap 0.5379
2024-01-10 22:13:01,107 - GAugM EPNet train, Epoch [ 37/250]: loss 0.7209, auc 0.4624, ap 0.4769
2024-01-10 22:13:01,208 - GAugM EPNet train, Epoch [ 38/250]: loss 0.7209, auc 0.5235, ap 0.5107
2024-01-10 22:13:01,291 - GAugM EPNet train, Epoch [ 39/250]: loss 0.7208, auc 0.4765, ap 0.5077
2024-01-10 22:13:01,371 - GAugM EPNet train, Epoch [ 40/250]: loss 0.7210, auc 0.5573, ap 0.5267
2024-01-10 22:13:01,450 - GAugM EPNet train, Epoch [ 41/250]: loss 0.7210, auc 0.4797, ap 0.5010
2024-01-10 22:13:01,530 - GAugM EPNet train, Epoch [ 42/250]: loss 0.7209, auc 0.5774, ap 0.5937
2024-01-10 22:13:01,607 - GAugM EPNet train, Epoch [ 43/250]: loss 0.7208, auc 0.4544, ap 0.4676
2024-01-10 22:13:01,697 - GAugM EPNet train, Epoch [ 44/250]: loss 0.7208, auc 0.3464, ap 0.4236
2024-01-10 22:13:01,775 - GAugM EPNet train, Epoch [ 45/250]: loss 0.7209, auc 0.5239, ap 0.5231
2024-01-10 22:13:01,857 - GAugM EPNet train, Epoch [ 46/250]: loss 0.7209, auc 0.4715, ap 0.4949
2024-01-10 22:13:01,938 - GAugM EPNet train, Epoch [ 47/250]: loss 0.7210, auc 0.4067, ap 0.4540
2024-01-10 22:13:02,021 - GAugM EPNet train, Epoch [ 48/250]: loss 0.7210, auc 0.5489, ap 0.5710
2024-01-10 22:13:02,100 - GAugM EPNet train, Epoch [ 49/250]: loss 0.7209, auc 0.5292, ap 0.5240
2024-01-10 22:13:02,176 - GAugM EPNet train, Epoch [ 50/250]: loss 0.7210, auc 0.5481, ap 0.5484
2024-01-10 22:13:02,252 - GAugM EPNet train, Epoch [ 51/250]: loss 0.7210, auc 0.4713, ap 0.5082
2024-01-10 22:13:02,335 - GAugM EPNet train, Epoch [ 52/250]: loss 0.7209, auc 0.4850, ap 0.5321
2024-01-10 22:13:02,420 - GAugM EPNet train, Epoch [ 53/250]: loss 0.7209, auc 0.5137, ap 0.5290
2024-01-10 22:13:02,495 - GAugM EPNet train, Epoch [ 54/250]: loss 0.7211, auc 0.5598, ap 0.5590
2024-01-10 22:13:02,572 - GAugM EPNet train, Epoch [ 55/250]: loss 0.7209, auc 0.5374, ap 0.5724
2024-01-10 22:13:02,665 - GAugM EPNet train, Epoch [ 56/250]: loss 0.7208, auc 0.5091, ap 0.5086
2024-01-10 22:13:02,754 - GAugM EPNet train, Epoch [ 57/250]: loss 0.7209, auc 0.4861, ap 0.4917
2024-01-10 22:13:02,839 - GAugM EPNet train, Epoch [ 58/250]: loss 0.7210, auc 0.4760, ap 0.5400
2024-01-10 22:13:02,927 - GAugM EPNet train, Epoch [ 59/250]: loss 0.7211, auc 0.4893, ap 0.4884
2024-01-10 22:13:03,011 - GAugM EPNet train, Epoch [ 60/250]: loss 0.7210, auc 0.4534, ap 0.4760
2024-01-10 22:13:03,105 - GAugM EPNet train, Epoch [ 61/250]: loss 0.7209, auc 0.5710, ap 0.5715
2024-01-10 22:13:03,188 - GAugM EPNet train, Epoch [ 62/250]: loss 0.7210, auc 0.5027, ap 0.5279
2024-01-10 22:13:03,280 - GAugM EPNet train, Epoch [ 63/250]: loss 0.7208, auc 0.4968, ap 0.4981
2024-01-10 22:13:03,363 - GAugM EPNet train, Epoch [ 64/250]: loss 0.7208, auc 0.5602, ap 0.5748
2024-01-10 22:13:03,447 - GAugM EPNet train, Epoch [ 65/250]: loss 0.7208, auc 0.5748, ap 0.6082
2024-01-10 22:13:03,536 - GAugM EPNet train, Epoch [ 66/250]: loss 0.7209, auc 0.4820, ap 0.4968
2024-01-10 22:13:03,619 - GAugM EPNet train, Epoch [ 67/250]: loss 0.7209, auc 0.5310, ap 0.5223
2024-01-10 22:13:03,708 - GAugM EPNet train, Epoch [ 68/250]: loss 0.7210, auc 0.5516, ap 0.5519
2024-01-10 22:13:03,791 - GAugM EPNet train, Epoch [ 69/250]: loss 0.7210, auc 0.5344, ap 0.5328
2024-01-10 22:13:03,880 - GAugM EPNet train, Epoch [ 70/250]: loss 0.7210, auc 0.4573, ap 0.4625
2024-01-10 22:13:03,955 - GAugM EPNet train, Epoch [ 71/250]: loss 0.7210, auc 0.6023, ap 0.5982
2024-01-10 22:13:04,029 - GAugM EPNet train, Epoch [ 72/250]: loss 0.7210, auc 0.4316, ap 0.4593
2024-01-10 22:13:04,101 - GAugM EPNet train, Epoch [ 73/250]: loss 0.7209, auc 0.5461, ap 0.5140
2024-01-10 22:13:04,172 - GAugM EPNet train, Epoch [ 74/250]: loss 0.7209, auc 0.4171, ap 0.4533
2024-01-10 22:13:04,248 - GAugM EPNet train, Epoch [ 75/250]: loss 0.7210, auc 0.3742, ap 0.4290
2024-01-10 22:13:04,335 - GAugM EPNet train, Epoch [ 76/250]: loss 0.7209, auc 0.4235, ap 0.4481
2024-01-10 22:13:04,427 - GAugM EPNet train, Epoch [ 77/250]: loss 0.7208, auc 0.5057, ap 0.5486
2024-01-10 22:13:04,505 - GAugM EPNet train, Epoch [ 78/250]: loss 0.7209, auc 0.5117, ap 0.5097
2024-01-10 22:13:04,579 - GAugM EPNet train, Epoch [ 79/250]: loss 0.7208, auc 0.4989, ap 0.5338
2024-01-10 22:13:04,666 - GAugM EPNet train, Epoch [ 80/250]: loss 0.7209, auc 0.5927, ap 0.5690
2024-01-10 22:13:04,741 - GAugM EPNet train, Epoch [ 81/250]: loss 0.7209, auc 0.4943, ap 0.5088
2024-01-10 22:13:04,816 - GAugM EPNet train, Epoch [ 82/250]: loss 0.7210, auc 0.5132, ap 0.5247
2024-01-10 22:13:04,890 - GAugM EPNet train, Epoch [ 83/250]: loss 0.7209, auc 0.4610, ap 0.5067
2024-01-10 22:13:04,962 - GAugM EPNet train, Epoch [ 84/250]: loss 0.7209, auc 0.4651, ap 0.4738
2024-01-10 22:13:05,042 - GAugM EPNet train, Epoch [ 85/250]: loss 0.7210, auc 0.4737, ap 0.4713
2024-01-10 22:13:05,116 - GAugM EPNet train, Epoch [ 86/250]: loss 0.7208, auc 0.5196, ap 0.5569
2024-01-10 22:13:05,188 - GAugM EPNet train, Epoch [ 87/250]: loss 0.7209, auc 0.5835, ap 0.5907
2024-01-10 22:13:05,270 - GAugM EPNet train, Epoch [ 88/250]: loss 0.7210, auc 0.4858, ap 0.5242
2024-01-10 22:13:05,342 - GAugM EPNet train, Epoch [ 89/250]: loss 0.7210, auc 0.4883, ap 0.5171
2024-01-10 22:13:05,416 - GAugM EPNet train, Epoch [ 90/250]: loss 0.7209, auc 0.3809, ap 0.4257
2024-01-10 22:13:05,500 - GAugM EPNet train, Epoch [ 91/250]: loss 0.7208, auc 0.5304, ap 0.5139
2024-01-10 22:13:05,584 - GAugM EPNet train, Epoch [ 92/250]: loss 0.7209, auc 0.5559, ap 0.5438
2024-01-10 22:13:05,665 - GAugM EPNet train, Epoch [ 93/250]: loss 0.7209, auc 0.4411, ap 0.4855
2024-01-10 22:13:05,757 - GAugM EPNet train, Epoch [ 94/250]: loss 0.7210, auc 0.4701, ap 0.5045
2024-01-10 22:13:05,847 - GAugM EPNet train, Epoch [ 95/250]: loss 0.7210, auc 0.5504, ap 0.5646
2024-01-10 22:13:05,936 - GAugM EPNet train, Epoch [ 96/250]: loss 0.7209, auc 0.5650, ap 0.5552
2024-01-10 22:13:06,035 - GAugM EPNet train, Epoch [ 97/250]: loss 0.7209, auc 0.4701, ap 0.4890
2024-01-10 22:13:06,122 - GAugM EPNet train, Epoch [ 98/250]: loss 0.7209, auc 0.4413, ap 0.4803
2024-01-10 22:13:06,209 - GAugM EPNet train, Epoch [ 99/250]: loss 0.7209, auc 0.4245, ap 0.4691
2024-01-10 22:13:06,295 - GAugM EPNet train, Epoch [100/250]: loss 0.7210, auc 0.5498, ap 0.5415
2024-01-10 22:13:06,382 - GAugM EPNet train, Epoch [101/250]: loss 0.7210, auc 0.5043, ap 0.5614
2024-01-10 22:13:06,468 - GAugM EPNet train, Epoch [102/250]: loss 0.7209, auc 0.4710, ap 0.4965
2024-01-10 22:13:06,568 - GAugM EPNet train, Epoch [103/250]: loss 0.7209, auc 0.4724, ap 0.5338
2024-01-10 22:13:06,658 - GAugM EPNet train, Epoch [104/250]: loss 0.7209, auc 0.4753, ap 0.4834
2024-01-10 22:13:06,746 - GAugM EPNet train, Epoch [105/250]: loss 0.7209, auc 0.4263, ap 0.4468
2024-01-10 22:13:06,826 - GAugM EPNet train, Epoch [106/250]: loss 0.7210, auc 0.4333, ap 0.4506
2024-01-10 22:13:06,913 - GAugM EPNet train, Epoch [107/250]: loss 0.7210, auc 0.5780, ap 0.5531
2024-01-10 22:13:06,999 - GAugM EPNet train, Epoch [108/250]: loss 0.7208, auc 0.4765, ap 0.4899
2024-01-10 22:13:07,087 - GAugM EPNet train, Epoch [109/250]: loss 0.7210, auc 0.4537, ap 0.4871
2024-01-10 22:13:07,180 - GAugM EPNet train, Epoch [110/250]: loss 0.7209, auc 0.5292, ap 0.5378
2024-01-10 22:13:07,265 - GAugM EPNet train, Epoch [111/250]: loss 0.7210, auc 0.5021, ap 0.5288
2024-01-10 22:13:07,352 - GAugM EPNet train, Epoch [112/250]: loss 0.7209, auc 0.4931, ap 0.5389
2024-01-10 22:13:07,440 - GAugM EPNet train, Epoch [113/250]: loss 0.7210, auc 0.5473, ap 0.5513
2024-01-10 22:13:07,528 - GAugM EPNet train, Epoch [114/250]: loss 0.7209, auc 0.4195, ap 0.4472
2024-01-10 22:13:07,617 - GAugM EPNet train, Epoch [115/250]: loss 0.7210, auc 0.4957, ap 0.5249
2024-01-10 22:13:07,717 - GAugM EPNet train, Epoch [116/250]: loss 0.7209, auc 0.4852, ap 0.4759
2024-01-10 22:13:07,806 - GAugM EPNet train, Epoch [117/250]: loss 0.7208, auc 0.4548, ap 0.4741
2024-01-10 22:13:07,895 - GAugM EPNet train, Epoch [118/250]: loss 0.7209, auc 0.5061, ap 0.5192
2024-01-10 22:13:07,980 - GAugM EPNet train, Epoch [119/250]: loss 0.7209, auc 0.5151, ap 0.5293
2024-01-10 22:13:08,074 - GAugM EPNet train, Epoch [120/250]: loss 0.7210, auc 0.4681, ap 0.4951
2024-01-10 22:13:08,162 - GAugM EPNet train, Epoch [121/250]: loss 0.7210, auc 0.4763, ap 0.4788
2024-01-10 22:13:08,263 - GAugM EPNet train, Epoch [122/250]: loss 0.7209, auc 0.5121, ap 0.5203
2024-01-10 22:13:08,352 - GAugM EPNet train, Epoch [123/250]: loss 0.7209, auc 0.5502, ap 0.5630
2024-01-10 22:13:08,439 - GAugM EPNet train, Epoch [124/250]: loss 0.7210, auc 0.5278, ap 0.5492
2024-01-10 22:13:08,522 - GAugM EPNet train, Epoch [125/250]: loss 0.7209, auc 0.5203, ap 0.5208
2024-01-10 22:13:08,610 - GAugM EPNet train, Epoch [126/250]: loss 0.7210, auc 0.4948, ap 0.4909
2024-01-10 22:13:08,701 - GAugM EPNet train, Epoch [127/250]: loss 0.7209, auc 0.4669, ap 0.4728
2024-01-10 22:13:08,795 - GAugM EPNet train, Epoch [128/250]: loss 0.7210, auc 0.5372, ap 0.5181
2024-01-10 22:13:08,881 - GAugM EPNet train, Epoch [129/250]: loss 0.7208, auc 0.4820, ap 0.4751
2024-01-10 22:13:08,966 - GAugM EPNet train, Epoch [130/250]: loss 0.7210, auc 0.5020, ap 0.5307
2024-01-10 22:13:09,055 - GAugM EPNet train, Epoch [131/250]: loss 0.7210, auc 0.5708, ap 0.6205
2024-01-10 22:13:09,140 - GAugM EPNet train, Epoch [132/250]: loss 0.7209, auc 0.5667, ap 0.5422
2024-01-10 22:13:09,239 - GAugM EPNet train, Epoch [133/250]: loss 0.7209, auc 0.5126, ap 0.5617
2024-01-10 22:13:09,327 - GAugM EPNet train, Epoch [134/250]: loss 0.7210, auc 0.4671, ap 0.4908
2024-01-10 22:13:09,415 - GAugM EPNet train, Epoch [135/250]: loss 0.7209, auc 0.3670, ap 0.4205
2024-01-10 22:13:09,511 - GAugM EPNet train, Epoch [136/250]: loss 0.7209, auc 0.4849, ap 0.4888
2024-01-10 22:13:09,600 - GAugM EPNet train, Epoch [137/250]: loss 0.7210, auc 0.4705, ap 0.5128
2024-01-10 22:13:09,687 - GAugM EPNet train, Epoch [138/250]: loss 0.7210, auc 0.5783, ap 0.5483
2024-01-10 22:13:09,772 - GAugM EPNet train, Epoch [139/250]: loss 0.7210, auc 0.4340, ap 0.4602
2024-01-10 22:13:09,858 - GAugM EPNet train, Epoch [140/250]: loss 0.7209, auc 0.5023, ap 0.5100
2024-01-10 22:13:09,944 - GAugM EPNet train, Epoch [141/250]: loss 0.7209, auc 0.4713, ap 0.4589
2024-01-10 22:13:10,035 - GAugM EPNet train, Epoch [142/250]: loss 0.7209, auc 0.5611, ap 0.5829
2024-01-10 22:13:10,122 - GAugM EPNet train, Epoch [143/250]: loss 0.7209, auc 0.4489, ap 0.4596
2024-01-10 22:13:10,214 - GAugM EPNet train, Epoch [144/250]: loss 0.7209, auc 0.4847, ap 0.4941
2024-01-10 22:13:10,309 - GAugM EPNet train, Epoch [145/250]: loss 0.7209, auc 0.4455, ap 0.4699
2024-01-10 22:13:10,397 - GAugM EPNet train, Epoch [146/250]: loss 0.7209, auc 0.4703, ap 0.5024
2024-01-10 22:13:10,482 - GAugM EPNet train, Epoch [147/250]: loss 0.7209, auc 0.5902, ap 0.5938
2024-01-10 22:13:10,578 - GAugM EPNet train, Epoch [148/250]: loss 0.7209, auc 0.4304, ap 0.4896
2024-01-10 22:13:10,660 - GAugM EPNet train, Epoch [149/250]: loss 0.7208, auc 0.4092, ap 0.4359
2024-01-10 22:13:10,742 - GAugM EPNet train, Epoch [150/250]: loss 0.7209, auc 0.5945, ap 0.5942
2024-01-10 22:13:10,834 - GAugM EPNet train, Epoch [151/250]: loss 0.7209, auc 0.5215, ap 0.5372
2024-01-10 22:13:10,922 - GAugM EPNet train, Epoch [152/250]: loss 0.7209, auc 0.5999, ap 0.5949
2024-01-10 22:13:11,009 - GAugM EPNet train, Epoch [153/250]: loss 0.7209, auc 0.4494, ap 0.5167
2024-01-10 22:13:11,103 - GAugM EPNet train, Epoch [154/250]: loss 0.7209, auc 0.5687, ap 0.6134
2024-01-10 22:13:11,190 - GAugM EPNet train, Epoch [155/250]: loss 0.7209, auc 0.5452, ap 0.5515
2024-01-10 22:13:11,279 - GAugM EPNet train, Epoch [156/250]: loss 0.7209, auc 0.4327, ap 0.4736
2024-01-10 22:13:11,366 - GAugM EPNet train, Epoch [157/250]: loss 0.7209, auc 0.5532, ap 0.5400
2024-01-10 22:13:11,462 - GAugM EPNet train, Epoch [158/250]: loss 0.7208, auc 0.5041, ap 0.4998
2024-01-10 22:13:11,552 - GAugM EPNet train, Epoch [159/250]: loss 0.7208, auc 0.4203, ap 0.4435
2024-01-10 22:13:11,647 - GAugM EPNet train, Epoch [160/250]: loss 0.7209, auc 0.6335, ap 0.6491
2024-01-10 22:13:11,735 - GAugM EPNet train, Epoch [161/250]: loss 0.7209, auc 0.5860, ap 0.5728
2024-01-10 22:13:11,822 - GAugM EPNet train, Epoch [162/250]: loss 0.7209, auc 0.4039, ap 0.4309
2024-01-10 22:13:11,911 - GAugM EPNet train, Epoch [163/250]: loss 0.7209, auc 0.5406, ap 0.5429
2024-01-10 22:13:11,997 - GAugM EPNet train, Epoch [164/250]: loss 0.7211, auc 0.4309, ap 0.4507
2024-01-10 22:13:12,091 - GAugM EPNet train, Epoch [165/250]: loss 0.7210, auc 0.4742, ap 0.5105
2024-01-10 22:13:12,192 - GAugM EPNet train, Epoch [166/250]: loss 0.7208, auc 0.4998, ap 0.4851
2024-01-10 22:13:12,289 - GAugM EPNet train, Epoch [167/250]: loss 0.7209, auc 0.5066, ap 0.5004
2024-01-10 22:13:12,381 - GAugM EPNet train, Epoch [168/250]: loss 0.7209, auc 0.5069, ap 0.5395
2024-01-10 22:13:12,469 - GAugM EPNet train, Epoch [169/250]: loss 0.7209, auc 0.4906, ap 0.5303
2024-01-10 22:13:12,562 - GAugM EPNet train, Epoch [170/250]: loss 0.7210, auc 0.4603, ap 0.4770
2024-01-10 22:13:12,653 - GAugM EPNet train, Epoch [171/250]: loss 0.7209, auc 0.5150, ap 0.5069
2024-01-10 22:13:12,741 - GAugM EPNet train, Epoch [172/250]: loss 0.7208, auc 0.4300, ap 0.4542
2024-01-10 22:13:12,835 - GAugM EPNet train, Epoch [173/250]: loss 0.7209, auc 0.4913, ap 0.4942
2024-01-10 22:13:12,926 - GAugM EPNet train, Epoch [174/250]: loss 0.7209, auc 0.4760, ap 0.4811
2024-01-10 22:13:13,012 - GAugM EPNet train, Epoch [175/250]: loss 0.7209, auc 0.6104, ap 0.5681
2024-01-10 22:13:13,099 - GAugM EPNet train, Epoch [176/250]: loss 0.7209, auc 0.5046, ap 0.5021
2024-01-10 22:13:13,187 - GAugM EPNet train, Epoch [177/250]: loss 0.7210, auc 0.4801, ap 0.4847
2024-01-10 22:13:13,276 - GAugM EPNet train, Epoch [178/250]: loss 0.7210, auc 0.5546, ap 0.5860
2024-01-10 22:13:13,364 - GAugM EPNet train, Epoch [179/250]: loss 0.7210, auc 0.3854, ap 0.4426
2024-01-10 22:13:13,449 - GAugM EPNet train, Epoch [180/250]: loss 0.7210, auc 0.5543, ap 0.5964
2024-01-10 22:13:13,539 - GAugM EPNet train, Epoch [181/250]: loss 0.7209, auc 0.4523, ap 0.4570
2024-01-10 22:13:13,626 - GAugM EPNet train, Epoch [182/250]: loss 0.7209, auc 0.4840, ap 0.5088
2024-01-10 22:13:13,716 - GAugM EPNet train, Epoch [183/250]: loss 0.7210, auc 0.5107, ap 0.5173
2024-01-10 22:13:13,801 - GAugM EPNet train, Epoch [184/250]: loss 0.7209, auc 0.5434, ap 0.5578
2024-01-10 22:13:13,886 - GAugM EPNet train, Epoch [185/250]: loss 0.7209, auc 0.5986, ap 0.6261
2024-01-10 22:13:13,972 - GAugM EPNet train, Epoch [186/250]: loss 0.7208, auc 0.5091, ap 0.5778
2024-01-10 22:13:14,061 - GAugM EPNet train, Epoch [187/250]: loss 0.7209, auc 0.5094, ap 0.5483
2024-01-10 22:13:14,156 - GAugM EPNet train, Epoch [188/250]: loss 0.7209, auc 0.4770, ap 0.4782
2024-01-10 22:13:14,242 - GAugM EPNet train, Epoch [189/250]: loss 0.7209, auc 0.5749, ap 0.5781
2024-01-10 22:13:14,328 - GAugM EPNet train, Epoch [190/250]: loss 0.7209, auc 0.4487, ap 0.4720
2024-01-10 22:13:14,414 - GAugM EPNet train, Epoch [191/250]: loss 0.7209, auc 0.4795, ap 0.5100
2024-01-10 22:13:14,505 - GAugM EPNet train, Epoch [192/250]: loss 0.7209, auc 0.6214, ap 0.5716
2024-01-10 22:13:14,589 - GAugM EPNet train, Epoch [193/250]: loss 0.7209, auc 0.4788, ap 0.4747
2024-01-10 22:13:14,677 - GAugM EPNet train, Epoch [194/250]: loss 0.7209, auc 0.4242, ap 0.4784
2024-01-10 22:13:14,771 - GAugM EPNet train, Epoch [195/250]: loss 0.7209, auc 0.4064, ap 0.4556
2024-01-10 22:13:14,862 - GAugM EPNet train, Epoch [196/250]: loss 0.7208, auc 0.5110, ap 0.5068
2024-01-10 22:13:14,951 - GAugM EPNet train, Epoch [197/250]: loss 0.7210, auc 0.4778, ap 0.5045
2024-01-10 22:13:15,041 - GAugM EPNet train, Epoch [198/250]: loss 0.7210, auc 0.5408, ap 0.5074
2024-01-10 22:13:15,140 - GAugM EPNet train, Epoch [199/250]: loss 0.7209, auc 0.4893, ap 0.5082
2024-01-10 22:13:15,232 - GAugM EPNet train, Epoch [200/250]: loss 0.7210, auc 0.5101, ap 0.5195
2024-01-10 22:13:15,326 - GAugM EPNet train, Epoch [201/250]: loss 0.7209, auc 0.4733, ap 0.5044
2024-01-10 22:13:15,405 - GAugM EPNet train, Epoch [202/250]: loss 0.7210, auc 0.5075, ap 0.5677
2024-01-10 22:13:15,496 - GAugM EPNet train, Epoch [203/250]: loss 0.7210, auc 0.4569, ap 0.4902
2024-01-10 22:13:15,584 - GAugM EPNet train, Epoch [204/250]: loss 0.7209, auc 0.3612, ap 0.4209
2024-01-10 22:13:15,667 - GAugM EPNet train, Epoch [205/250]: loss 0.7209, auc 0.4555, ap 0.4966
2024-01-10 22:13:15,760 - GAugM EPNet train, Epoch [206/250]: loss 0.7209, auc 0.3797, ap 0.4249
2024-01-10 22:13:15,855 - GAugM EPNet train, Epoch [207/250]: loss 0.7210, auc 0.4587, ap 0.4924
2024-01-10 22:13:15,946 - GAugM EPNet train, Epoch [208/250]: loss 0.7209, auc 0.5101, ap 0.5654
2024-01-10 22:13:16,035 - GAugM EPNet train, Epoch [209/250]: loss 0.7210, auc 0.5646, ap 0.5680
2024-01-10 22:13:16,128 - GAugM EPNet train, Epoch [210/250]: loss 0.7209, auc 0.5117, ap 0.5354
2024-01-10 22:13:16,220 - GAugM EPNet train, Epoch [211/250]: loss 0.7210, auc 0.5066, ap 0.5360
2024-01-10 22:13:16,309 - GAugM EPNet train, Epoch [212/250]: loss 0.7210, auc 0.4527, ap 0.4847
2024-01-10 22:13:16,400 - GAugM EPNet train, Epoch [213/250]: loss 0.7208, auc 0.5872, ap 0.6288
2024-01-10 22:13:16,478 - GAugM EPNet train, Epoch [214/250]: loss 0.7210, auc 0.4735, ap 0.4754
2024-01-10 22:13:16,556 - GAugM EPNet train, Epoch [215/250]: loss 0.7210, auc 0.4778, ap 0.4715
2024-01-10 22:13:16,639 - GAugM EPNet train, Epoch [216/250]: loss 0.7209, auc 0.5732, ap 0.5767
2024-01-10 22:13:16,724 - GAugM EPNet train, Epoch [217/250]: loss 0.7209, auc 0.5835, ap 0.6124
2024-01-10 22:13:16,822 - GAugM EPNet train, Epoch [218/250]: loss 0.7209, auc 0.4368, ap 0.5045
2024-01-10 22:13:16,913 - GAugM EPNet train, Epoch [219/250]: loss 0.7208, auc 0.5059, ap 0.5227
2024-01-10 22:13:16,999 - GAugM EPNet train, Epoch [220/250]: loss 0.7210, auc 0.4468, ap 0.4848
2024-01-10 22:13:17,090 - GAugM EPNet train, Epoch [221/250]: loss 0.7209, auc 0.5680, ap 0.5442
2024-01-10 22:13:17,191 - GAugM EPNet train, Epoch [222/250]: loss 0.7209, auc 0.4591, ap 0.4888
2024-01-10 22:13:17,281 - GAugM EPNet train, Epoch [223/250]: loss 0.7209, auc 0.5997, ap 0.5751
2024-01-10 22:13:17,373 - GAugM EPNet train, Epoch [224/250]: loss 0.7210, auc 0.4683, ap 0.4609
2024-01-10 22:13:17,460 - GAugM EPNet train, Epoch [225/250]: loss 0.7209, auc 0.4970, ap 0.4993
2024-01-10 22:13:17,546 - GAugM EPNet train, Epoch [226/250]: loss 0.7210, auc 0.5881, ap 0.5865
2024-01-10 22:13:17,635 - GAugM EPNet train, Epoch [227/250]: loss 0.7210, auc 0.6123, ap 0.6238
2024-01-10 22:13:17,720 - GAugM EPNet train, Epoch [228/250]: loss 0.7209, auc 0.4708, ap 0.4890
2024-01-10 22:13:17,811 - GAugM EPNet train, Epoch [229/250]: loss 0.7209, auc 0.4571, ap 0.4557
2024-01-10 22:13:17,901 - GAugM EPNet train, Epoch [230/250]: loss 0.7209, auc 0.4993, ap 0.5136
2024-01-10 22:13:17,989 - GAugM EPNet train, Epoch [231/250]: loss 0.7209, auc 0.4916, ap 0.5168
2024-01-10 22:13:18,074 - GAugM EPNet train, Epoch [232/250]: loss 0.7209, auc 0.5625, ap 0.5559
2024-01-10 22:13:18,166 - GAugM EPNet train, Epoch [233/250]: loss 0.7210, auc 0.5573, ap 0.5598
2024-01-10 22:13:18,253 - GAugM EPNet train, Epoch [234/250]: loss 0.7209, auc 0.4112, ap 0.4611
2024-01-10 22:13:18,340 - GAugM EPNet train, Epoch [235/250]: loss 0.7209, auc 0.5333, ap 0.5249
2024-01-10 22:13:18,429 - GAugM EPNet train, Epoch [236/250]: loss 0.7209, auc 0.4998, ap 0.5476
2024-01-10 22:13:18,515 - GAugM EPNet train, Epoch [237/250]: loss 0.7210, auc 0.4751, ap 0.4931
2024-01-10 22:13:18,610 - GAugM EPNet train, Epoch [238/250]: loss 0.7210, auc 0.5294, ap 0.5209
2024-01-10 22:13:18,691 - GAugM EPNet train, Epoch [239/250]: loss 0.7209, auc 0.5231, ap 0.5711
2024-01-10 22:13:18,777 - GAugM EPNet train, Epoch [240/250]: loss 0.7209, auc 0.4963, ap 0.4883
2024-01-10 22:13:18,861 - GAugM EPNet train, Epoch [241/250]: loss 0.7209, auc 0.5840, ap 0.5787
2024-01-10 22:13:18,947 - GAugM EPNet train, Epoch [242/250]: loss 0.7210, auc 0.4719, ap 0.4896
2024-01-10 22:13:19,040 - GAugM EPNet train, Epoch [243/250]: loss 0.7210, auc 0.4721, ap 0.5472
2024-01-10 22:13:19,128 - GAugM EPNet train, Epoch [244/250]: loss 0.7209, auc 0.5628, ap 0.5383
2024-01-10 22:13:19,220 - GAugM EPNet train, Epoch [245/250]: loss 0.7210, auc 0.4258, ap 0.4659
2024-01-10 22:13:19,310 - GAugM EPNet train, Epoch [246/250]: loss 0.7208, auc 0.4833, ap 0.4946
2024-01-10 22:13:19,397 - GAugM EPNet train, Epoch [247/250]: loss 0.7209, auc 0.4872, ap 0.5115
2024-01-10 22:13:19,488 - GAugM EPNet train, Epoch [248/250]: loss 0.7211, auc 0.4956, ap 0.5109
2024-01-10 22:13:19,577 - GAugM EPNet train, Epoch [249/250]: loss 0.7209, auc 0.5075, ap 0.5080
2024-01-10 22:13:19,669 - GAugM EPNet train, Epoch [250/250]: loss 0.7208, auc 0.5756, ap 0.5438
2024-01-10 22:13:19,670 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9e5a650>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:13:20,475 - GAugM EPNet train, Epoch [  1/250]: loss 0.7210, auc 0.4416, ap 0.4659
2024-01-10 22:13:20,562 - GAugM EPNet train, Epoch [  2/250]: loss 0.7210, auc 0.5084, ap 0.5065
2024-01-10 22:13:20,647 - GAugM EPNet train, Epoch [  3/250]: loss 0.7209, auc 0.5340, ap 0.5227
2024-01-10 22:13:20,731 - GAugM EPNet train, Epoch [  4/250]: loss 0.7209, auc 0.4815, ap 0.4770
2024-01-10 22:13:20,817 - GAugM EPNet train, Epoch [  5/250]: loss 0.7209, auc 0.5237, ap 0.5664
2024-01-10 22:13:20,901 - GAugM EPNet train, Epoch [  6/250]: loss 0.7209, auc 0.5091, ap 0.4836
2024-01-10 22:13:20,986 - GAugM EPNet train, Epoch [  7/250]: loss 0.7209, auc 0.4519, ap 0.4555
2024-01-10 22:13:21,080 - GAugM EPNet train, Epoch [  8/250]: loss 0.7210, auc 0.5082, ap 0.5211
2024-01-10 22:13:21,162 - GAugM EPNet train, Epoch [  9/250]: loss 0.7209, auc 0.4514, ap 0.4639
2024-01-10 22:13:21,248 - GAugM EPNet train, Epoch [ 10/250]: loss 0.7208, auc 0.4548, ap 0.4791
2024-01-10 22:13:21,333 - GAugM EPNet train, Epoch [ 11/250]: loss 0.7209, auc 0.4717, ap 0.5119
2024-01-10 22:13:21,417 - GAugM EPNet train, Epoch [ 12/250]: loss 0.7210, auc 0.4295, ap 0.4605
2024-01-10 22:13:21,503 - GAugM EPNet train, Epoch [ 13/250]: loss 0.7209, auc 0.5664, ap 0.5736
2024-01-10 22:13:21,587 - GAugM EPNet train, Epoch [ 14/250]: loss 0.7209, auc 0.5684, ap 0.5487
2024-01-10 22:13:21,678 - GAugM EPNet train, Epoch [ 15/250]: loss 0.7210, auc 0.4320, ap 0.4865
2024-01-10 22:13:21,762 - GAugM EPNet train, Epoch [ 16/250]: loss 0.7209, auc 0.5020, ap 0.4851
2024-01-10 22:13:21,848 - GAugM EPNet train, Epoch [ 17/250]: loss 0.7210, auc 0.5684, ap 0.5497
2024-01-10 22:13:21,936 - GAugM EPNet train, Epoch [ 18/250]: loss 0.7210, auc 0.5543, ap 0.5602
2024-01-10 22:13:22,025 - GAugM EPNet train, Epoch [ 19/250]: loss 0.7209, auc 0.5361, ap 0.5075
2024-01-10 22:13:22,109 - GAugM EPNet train, Epoch [ 20/250]: loss 0.7210, auc 0.4503, ap 0.5089
2024-01-10 22:13:22,194 - GAugM EPNet train, Epoch [ 21/250]: loss 0.7209, auc 0.4872, ap 0.4739
2024-01-10 22:13:22,278 - GAugM EPNet train, Epoch [ 22/250]: loss 0.7210, auc 0.3092, ap 0.3957
2024-01-10 22:13:22,364 - GAugM EPNet train, Epoch [ 23/250]: loss 0.7208, auc 0.5913, ap 0.5592
2024-01-10 22:13:22,455 - GAugM EPNet train, Epoch [ 24/250]: loss 0.7209, auc 0.5324, ap 0.4894
2024-01-10 22:13:22,538 - GAugM EPNet train, Epoch [ 25/250]: loss 0.7209, auc 0.4883, ap 0.4848
2024-01-10 22:13:22,619 - GAugM EPNet train, Epoch [ 26/250]: loss 0.7210, auc 0.6136, ap 0.5673
2024-01-10 22:13:22,707 - GAugM EPNet train, Epoch [ 27/250]: loss 0.7209, auc 0.4906, ap 0.5586
2024-01-10 22:13:22,787 - GAugM EPNet train, Epoch [ 28/250]: loss 0.7209, auc 0.5968, ap 0.5781
2024-01-10 22:13:22,868 - GAugM EPNet train, Epoch [ 29/250]: loss 0.7210, auc 0.5360, ap 0.5281
2024-01-10 22:13:22,952 - GAugM EPNet train, Epoch [ 30/250]: loss 0.7209, auc 0.5837, ap 0.5758
2024-01-10 22:13:23,033 - GAugM EPNet train, Epoch [ 31/250]: loss 0.7208, auc 0.5150, ap 0.5404
2024-01-10 22:13:23,114 - GAugM EPNet train, Epoch [ 32/250]: loss 0.7210, auc 0.5888, ap 0.5625
2024-01-10 22:13:23,199 - GAugM EPNet train, Epoch [ 33/250]: loss 0.7209, auc 0.5052, ap 0.5295
2024-01-10 22:13:23,286 - GAugM EPNet train, Epoch [ 34/250]: loss 0.7209, auc 0.4890, ap 0.5251
2024-01-10 22:13:23,371 - GAugM EPNet train, Epoch [ 35/250]: loss 0.7209, auc 0.5459, ap 0.5385
2024-01-10 22:13:23,452 - GAugM EPNet train, Epoch [ 36/250]: loss 0.7209, auc 0.5237, ap 0.5205
2024-01-10 22:13:23,533 - GAugM EPNet train, Epoch [ 37/250]: loss 0.7209, auc 0.5473, ap 0.5493
2024-01-10 22:13:23,615 - GAugM EPNet train, Epoch [ 38/250]: loss 0.7209, auc 0.4850, ap 0.4692
2024-01-10 22:13:23,695 - GAugM EPNet train, Epoch [ 39/250]: loss 0.7208, auc 0.4393, ap 0.4746
2024-01-10 22:13:23,780 - GAugM EPNet train, Epoch [ 40/250]: loss 0.7210, auc 0.5637, ap 0.5541
2024-01-10 22:13:23,862 - GAugM EPNet train, Epoch [ 41/250]: loss 0.7210, auc 0.4858, ap 0.5231
2024-01-10 22:13:23,944 - GAugM EPNet train, Epoch [ 42/250]: loss 0.7209, auc 0.5077, ap 0.5468
2024-01-10 22:13:24,030 - GAugM EPNet train, Epoch [ 43/250]: loss 0.7208, auc 0.4573, ap 0.5119
2024-01-10 22:13:24,111 - GAugM EPNet train, Epoch [ 44/250]: loss 0.7208, auc 0.3971, ap 0.4455
2024-01-10 22:13:24,192 - GAugM EPNet train, Epoch [ 45/250]: loss 0.7209, auc 0.5354, ap 0.5181
2024-01-10 22:13:24,275 - GAugM EPNet train, Epoch [ 46/250]: loss 0.7209, auc 0.5363, ap 0.5327
2024-01-10 22:13:24,359 - GAugM EPNet train, Epoch [ 47/250]: loss 0.7210, auc 0.4806, ap 0.4874
2024-01-10 22:13:24,441 - GAugM EPNet train, Epoch [ 48/250]: loss 0.7210, auc 0.6296, ap 0.6260
2024-01-10 22:13:24,526 - GAugM EPNet train, Epoch [ 49/250]: loss 0.7209, auc 0.5146, ap 0.5065
2024-01-10 22:13:24,608 - GAugM EPNet train, Epoch [ 50/250]: loss 0.7210, auc 0.4350, ap 0.4527
2024-01-10 22:13:24,699 - GAugM EPNet train, Epoch [ 51/250]: loss 0.7210, auc 0.4779, ap 0.5215
2024-01-10 22:13:24,781 - GAugM EPNet train, Epoch [ 52/250]: loss 0.7209, auc 0.4874, ap 0.5233
2024-01-10 22:13:24,864 - GAugM EPNet train, Epoch [ 53/250]: loss 0.7209, auc 0.5440, ap 0.5279
2024-01-10 22:13:24,945 - GAugM EPNet train, Epoch [ 54/250]: loss 0.7211, auc 0.5406, ap 0.5616
2024-01-10 22:13:25,023 - GAugM EPNet train, Epoch [ 55/250]: loss 0.7209, auc 0.6182, ap 0.6189
2024-01-10 22:13:25,115 - GAugM EPNet train, Epoch [ 56/250]: loss 0.7208, auc 0.4724, ap 0.4722
2024-01-10 22:13:25,197 - GAugM EPNet train, Epoch [ 57/250]: loss 0.7209, auc 0.5109, ap 0.4741
2024-01-10 22:13:25,280 - GAugM EPNet train, Epoch [ 58/250]: loss 0.7210, auc 0.4742, ap 0.5288
2024-01-10 22:13:25,363 - GAugM EPNet train, Epoch [ 59/250]: loss 0.7211, auc 0.4915, ap 0.5056
2024-01-10 22:13:25,450 - GAugM EPNet train, Epoch [ 60/250]: loss 0.7210, auc 0.4229, ap 0.4532
2024-01-10 22:13:25,532 - GAugM EPNet train, Epoch [ 61/250]: loss 0.7209, auc 0.6056, ap 0.5881
2024-01-10 22:13:25,614 - GAugM EPNet train, Epoch [ 62/250]: loss 0.7210, auc 0.5162, ap 0.5611
2024-01-10 22:13:25,695 - GAugM EPNet train, Epoch [ 63/250]: loss 0.7208, auc 0.4140, ap 0.4524
2024-01-10 22:13:25,783 - GAugM EPNet train, Epoch [ 64/250]: loss 0.7208, auc 0.4478, ap 0.4733
2024-01-10 22:13:25,865 - GAugM EPNet train, Epoch [ 65/250]: loss 0.7208, auc 0.5119, ap 0.5318
2024-01-10 22:13:25,951 - GAugM EPNet train, Epoch [ 66/250]: loss 0.7209, auc 0.4626, ap 0.4943
2024-01-10 22:13:26,036 - GAugM EPNet train, Epoch [ 67/250]: loss 0.7209, auc 0.5199, ap 0.5031
2024-01-10 22:13:26,132 - GAugM EPNet train, Epoch [ 68/250]: loss 0.7210, auc 0.4927, ap 0.5189
2024-01-10 22:13:26,217 - GAugM EPNet train, Epoch [ 69/250]: loss 0.7210, auc 0.5004, ap 0.5261
2024-01-10 22:13:26,300 - GAugM EPNet train, Epoch [ 70/250]: loss 0.7210, auc 0.5210, ap 0.5022
2024-01-10 22:13:26,383 - GAugM EPNet train, Epoch [ 71/250]: loss 0.7210, auc 0.5078, ap 0.5035
2024-01-10 22:13:26,468 - GAugM EPNet train, Epoch [ 72/250]: loss 0.7210, auc 0.4820, ap 0.4850
2024-01-10 22:13:26,550 - GAugM EPNet train, Epoch [ 73/250]: loss 0.7209, auc 0.5506, ap 0.5371
2024-01-10 22:13:26,637 - GAugM EPNet train, Epoch [ 74/250]: loss 0.7209, auc 0.4176, ap 0.4611
2024-01-10 22:13:26,718 - GAugM EPNet train, Epoch [ 75/250]: loss 0.7210, auc 0.4742, ap 0.4939
2024-01-10 22:13:26,799 - GAugM EPNet train, Epoch [ 76/250]: loss 0.7209, auc 0.4523, ap 0.4959
2024-01-10 22:13:26,881 - GAugM EPNet train, Epoch [ 77/250]: loss 0.7208, auc 0.6048, ap 0.6204
2024-01-10 22:13:26,969 - GAugM EPNet train, Epoch [ 78/250]: loss 0.7209, auc 0.4915, ap 0.4871
2024-01-10 22:13:27,051 - GAugM EPNet train, Epoch [ 79/250]: loss 0.7208, auc 0.4817, ap 0.5079
2024-01-10 22:13:27,132 - GAugM EPNet train, Epoch [ 80/250]: loss 0.7209, auc 0.5283, ap 0.5117
2024-01-10 22:13:27,223 - GAugM EPNet train, Epoch [ 81/250]: loss 0.7209, auc 0.4594, ap 0.4829
2024-01-10 22:13:27,304 - GAugM EPNet train, Epoch [ 82/250]: loss 0.7210, auc 0.5146, ap 0.4975
2024-01-10 22:13:27,385 - GAugM EPNet train, Epoch [ 83/250]: loss 0.7209, auc 0.4591, ap 0.4970
2024-01-10 22:13:27,465 - GAugM EPNet train, Epoch [ 84/250]: loss 0.7209, auc 0.4324, ap 0.4539
2024-01-10 22:13:27,546 - GAugM EPNet train, Epoch [ 85/250]: loss 0.7210, auc 0.4087, ap 0.4653
2024-01-10 22:13:27,629 - GAugM EPNet train, Epoch [ 86/250]: loss 0.7208, auc 0.5114, ap 0.5353
2024-01-10 22:13:27,711 - GAugM EPNet train, Epoch [ 87/250]: loss 0.7209, auc 0.5431, ap 0.5508
2024-01-10 22:13:27,793 - GAugM EPNet train, Epoch [ 88/250]: loss 0.7210, auc 0.4350, ap 0.4415
2024-01-10 22:13:27,884 - GAugM EPNet train, Epoch [ 89/250]: loss 0.7210, auc 0.4648, ap 0.5044
2024-01-10 22:13:27,967 - GAugM EPNet train, Epoch [ 90/250]: loss 0.7209, auc 0.4747, ap 0.5079
2024-01-10 22:13:28,051 - GAugM EPNet train, Epoch [ 91/250]: loss 0.7208, auc 0.5520, ap 0.5198
2024-01-10 22:13:28,134 - GAugM EPNet train, Epoch [ 92/250]: loss 0.7209, auc 0.6066, ap 0.6224
2024-01-10 22:13:28,216 - GAugM EPNet train, Epoch [ 93/250]: loss 0.7209, auc 0.3804, ap 0.4358
2024-01-10 22:13:28,297 - GAugM EPNet train, Epoch [ 94/250]: loss 0.7210, auc 0.4090, ap 0.4307
2024-01-10 22:13:28,385 - GAugM EPNet train, Epoch [ 95/250]: loss 0.7210, auc 0.5221, ap 0.5228
2024-01-10 22:13:28,466 - GAugM EPNet train, Epoch [ 96/250]: loss 0.7209, auc 0.5616, ap 0.5634
2024-01-10 22:13:28,548 - GAugM EPNet train, Epoch [ 97/250]: loss 0.7209, auc 0.4448, ap 0.4898
2024-01-10 22:13:28,629 - GAugM EPNet train, Epoch [ 98/250]: loss 0.7209, auc 0.4836, ap 0.4905
2024-01-10 22:13:28,714 - GAugM EPNet train, Epoch [ 99/250]: loss 0.7209, auc 0.5174, ap 0.5365
2024-01-10 22:13:28,800 - GAugM EPNet train, Epoch [100/250]: loss 0.7210, auc 0.4194, ap 0.4469
2024-01-10 22:13:28,888 - GAugM EPNet train, Epoch [101/250]: loss 0.7210, auc 0.4413, ap 0.4881
2024-01-10 22:13:28,972 - GAugM EPNet train, Epoch [102/250]: loss 0.7209, auc 0.5125, ap 0.5400
2024-01-10 22:13:29,052 - GAugM EPNet train, Epoch [103/250]: loss 0.7209, auc 0.4769, ap 0.5323
2024-01-10 22:13:29,138 - GAugM EPNet train, Epoch [104/250]: loss 0.7209, auc 0.4616, ap 0.4867
2024-01-10 22:13:29,218 - GAugM EPNet train, Epoch [105/250]: loss 0.7209, auc 0.4436, ap 0.4479
2024-01-10 22:13:29,303 - GAugM EPNet train, Epoch [106/250]: loss 0.7210, auc 0.5087, ap 0.4995
2024-01-10 22:13:29,390 - GAugM EPNet train, Epoch [107/250]: loss 0.7210, auc 0.5256, ap 0.5776
2024-01-10 22:13:29,473 - GAugM EPNet train, Epoch [108/250]: loss 0.7208, auc 0.4756, ap 0.4937
2024-01-10 22:13:29,555 - GAugM EPNet train, Epoch [109/250]: loss 0.7210, auc 0.4891, ap 0.5184
2024-01-10 22:13:29,634 - GAugM EPNet train, Epoch [110/250]: loss 0.7209, auc 0.4722, ap 0.5083
2024-01-10 22:13:29,724 - GAugM EPNet train, Epoch [111/250]: loss 0.7210, auc 0.4804, ap 0.4940
2024-01-10 22:13:29,806 - GAugM EPNet train, Epoch [112/250]: loss 0.7209, auc 0.5050, ap 0.5054
2024-01-10 22:13:29,887 - GAugM EPNet train, Epoch [113/250]: loss 0.7210, auc 0.5554, ap 0.5417
2024-01-10 22:13:29,968 - GAugM EPNet train, Epoch [114/250]: loss 0.7209, auc 0.4806, ap 0.4860
2024-01-10 22:13:30,050 - GAugM EPNet train, Epoch [115/250]: loss 0.7210, auc 0.4290, ap 0.4488
2024-01-10 22:13:30,131 - GAugM EPNet train, Epoch [116/250]: loss 0.7209, auc 0.5573, ap 0.5761
2024-01-10 22:13:30,219 - GAugM EPNet train, Epoch [117/250]: loss 0.7208, auc 0.5075, ap 0.5212
2024-01-10 22:13:30,300 - GAugM EPNet train, Epoch [118/250]: loss 0.7209, auc 0.4689, ap 0.4764
2024-01-10 22:13:30,386 - GAugM EPNet train, Epoch [119/250]: loss 0.7209, auc 0.4468, ap 0.4680
2024-01-10 22:13:30,470 - GAugM EPNet train, Epoch [120/250]: loss 0.7210, auc 0.4462, ap 0.4601
2024-01-10 22:13:30,551 - GAugM EPNet train, Epoch [121/250]: loss 0.7210, auc 0.4742, ap 0.4773
2024-01-10 22:13:30,637 - GAugM EPNet train, Epoch [122/250]: loss 0.7209, auc 0.5077, ap 0.5011
2024-01-10 22:13:30,722 - GAugM EPNet train, Epoch [123/250]: loss 0.7209, auc 0.4925, ap 0.5315
2024-01-10 22:13:30,811 - GAugM EPNet train, Epoch [124/250]: loss 0.7210, auc 0.4603, ap 0.4791
2024-01-10 22:13:30,894 - GAugM EPNet train, Epoch [125/250]: loss 0.7209, auc 0.4915, ap 0.5050
2024-01-10 22:13:30,981 - GAugM EPNet train, Epoch [126/250]: loss 0.7210, auc 0.5235, ap 0.5084
2024-01-10 22:13:31,066 - GAugM EPNet train, Epoch [127/250]: loss 0.7209, auc 0.4943, ap 0.4866
2024-01-10 22:13:31,155 - GAugM EPNet train, Epoch [128/250]: loss 0.7210, auc 0.4633, ap 0.4781
2024-01-10 22:13:31,239 - GAugM EPNet train, Epoch [129/250]: loss 0.7208, auc 0.3711, ap 0.4335
2024-01-10 22:13:31,320 - GAugM EPNet train, Epoch [130/250]: loss 0.7210, auc 0.4742, ap 0.5017
2024-01-10 22:13:31,402 - GAugM EPNet train, Epoch [131/250]: loss 0.7210, auc 0.5417, ap 0.5735
2024-01-10 22:13:31,486 - GAugM EPNet train, Epoch [132/250]: loss 0.7209, auc 0.4883, ap 0.5046
2024-01-10 22:13:31,570 - GAugM EPNet train, Epoch [133/250]: loss 0.7209, auc 0.5030, ap 0.5170
2024-01-10 22:13:31,654 - GAugM EPNet train, Epoch [134/250]: loss 0.7210, auc 0.4797, ap 0.4932
2024-01-10 22:13:31,735 - GAugM EPNet train, Epoch [135/250]: loss 0.7209, auc 0.4302, ap 0.4746
2024-01-10 22:13:31,817 - GAugM EPNet train, Epoch [136/250]: loss 0.7209, auc 0.4961, ap 0.4976
2024-01-10 22:13:31,901 - GAugM EPNet train, Epoch [137/250]: loss 0.7210, auc 0.4640, ap 0.4830
2024-01-10 22:13:31,983 - GAugM EPNet train, Epoch [138/250]: loss 0.7210, auc 0.5520, ap 0.5388
2024-01-10 22:13:32,071 - GAugM EPNet train, Epoch [139/250]: loss 0.7210, auc 0.4528, ap 0.4478
2024-01-10 22:13:32,154 - GAugM EPNet train, Epoch [140/250]: loss 0.7209, auc 0.4899, ap 0.5421
2024-01-10 22:13:32,243 - GAugM EPNet train, Epoch [141/250]: loss 0.7209, auc 0.5578, ap 0.5558
2024-01-10 22:13:32,330 - GAugM EPNet train, Epoch [142/250]: loss 0.7209, auc 0.5278, ap 0.5087
2024-01-10 22:13:32,417 - GAugM EPNet train, Epoch [143/250]: loss 0.7209, auc 0.4932, ap 0.5062
2024-01-10 22:13:32,498 - GAugM EPNet train, Epoch [144/250]: loss 0.7209, auc 0.4956, ap 0.4847
2024-01-10 22:13:32,581 - GAugM EPNet train, Epoch [145/250]: loss 0.7209, auc 0.4096, ap 0.4866
2024-01-10 22:13:32,663 - GAugM EPNet train, Epoch [146/250]: loss 0.7209, auc 0.5438, ap 0.5584
2024-01-10 22:13:32,745 - GAugM EPNet train, Epoch [147/250]: loss 0.7209, auc 0.6816, ap 0.6788
2024-01-10 22:13:32,826 - GAugM EPNet train, Epoch [148/250]: loss 0.7209, auc 0.4439, ap 0.5080
2024-01-10 22:13:32,913 - GAugM EPNet train, Epoch [149/250]: loss 0.7208, auc 0.5137, ap 0.5191
2024-01-10 22:13:32,997 - GAugM EPNet train, Epoch [150/250]: loss 0.7209, auc 0.5053, ap 0.5031
2024-01-10 22:13:33,084 - GAugM EPNet train, Epoch [151/250]: loss 0.7209, auc 0.4906, ap 0.4942
2024-01-10 22:13:33,166 - GAugM EPNet train, Epoch [152/250]: loss 0.7209, auc 0.5538, ap 0.5345
2024-01-10 22:13:33,247 - GAugM EPNet train, Epoch [153/250]: loss 0.7209, auc 0.4767, ap 0.5257
2024-01-10 22:13:33,327 - GAugM EPNet train, Epoch [154/250]: loss 0.7209, auc 0.5450, ap 0.5611
2024-01-10 22:13:33,412 - GAugM EPNet train, Epoch [155/250]: loss 0.7209, auc 0.5167, ap 0.5345
2024-01-10 22:13:33,495 - GAugM EPNet train, Epoch [156/250]: loss 0.7209, auc 0.3891, ap 0.4283
2024-01-10 22:13:33,575 - GAugM EPNet train, Epoch [157/250]: loss 0.7209, auc 0.4530, ap 0.4588
2024-01-10 22:13:33,654 - GAugM EPNet train, Epoch [158/250]: loss 0.7208, auc 0.4681, ap 0.4765
2024-01-10 22:13:33,735 - GAugM EPNet train, Epoch [159/250]: loss 0.7208, auc 0.4729, ap 0.4765
2024-01-10 22:13:33,817 - GAugM EPNet train, Epoch [160/250]: loss 0.7209, auc 0.5271, ap 0.5429
2024-01-10 22:13:33,897 - GAugM EPNet train, Epoch [161/250]: loss 0.7209, auc 0.6009, ap 0.5980
2024-01-10 22:13:33,978 - GAugM EPNet train, Epoch [162/250]: loss 0.7209, auc 0.4270, ap 0.4364
2024-01-10 22:13:34,057 - GAugM EPNet train, Epoch [163/250]: loss 0.7209, auc 0.5457, ap 0.5369
2024-01-10 22:13:34,139 - GAugM EPNet train, Epoch [164/250]: loss 0.7211, auc 0.5623, ap 0.5501
2024-01-10 22:13:34,221 - GAugM EPNet train, Epoch [165/250]: loss 0.7210, auc 0.4703, ap 0.4801
2024-01-10 22:13:34,311 - GAugM EPNet train, Epoch [166/250]: loss 0.7208, auc 0.5710, ap 0.5434
2024-01-10 22:13:34,394 - GAugM EPNet train, Epoch [167/250]: loss 0.7209, auc 0.4779, ap 0.4782
2024-01-10 22:13:34,475 - GAugM EPNet train, Epoch [168/250]: loss 0.7209, auc 0.5301, ap 0.5686
2024-01-10 22:13:34,557 - GAugM EPNet train, Epoch [169/250]: loss 0.7209, auc 0.4950, ap 0.5380
2024-01-10 22:13:34,638 - GAugM EPNet train, Epoch [170/250]: loss 0.7210, auc 0.4776, ap 0.4693
2024-01-10 22:13:34,724 - GAugM EPNet train, Epoch [171/250]: loss 0.7209, auc 0.4105, ap 0.4645
2024-01-10 22:13:34,805 - GAugM EPNet train, Epoch [172/250]: loss 0.7208, auc 0.4192, ap 0.4437
2024-01-10 22:13:34,891 - GAugM EPNet train, Epoch [173/250]: loss 0.7209, auc 0.4826, ap 0.5011
2024-01-10 22:13:34,972 - GAugM EPNet train, Epoch [174/250]: loss 0.7209, auc 0.4178, ap 0.4533
2024-01-10 22:13:35,055 - GAugM EPNet train, Epoch [175/250]: loss 0.7209, auc 0.5851, ap 0.5777
2024-01-10 22:13:35,136 - GAugM EPNet train, Epoch [176/250]: loss 0.7209, auc 0.5148, ap 0.5126
2024-01-10 22:13:35,226 - GAugM EPNet train, Epoch [177/250]: loss 0.7210, auc 0.5237, ap 0.5103
2024-01-10 22:13:35,309 - GAugM EPNet train, Epoch [178/250]: loss 0.7210, auc 0.5497, ap 0.5604
2024-01-10 22:13:35,391 - GAugM EPNet train, Epoch [179/250]: loss 0.7210, auc 0.3896, ap 0.4493
2024-01-10 22:13:35,476 - GAugM EPNet train, Epoch [180/250]: loss 0.7210, auc 0.5555, ap 0.5794
2024-01-10 22:13:35,561 - GAugM EPNet train, Epoch [181/250]: loss 0.7209, auc 0.4423, ap 0.4555
2024-01-10 22:13:35,645 - GAugM EPNet train, Epoch [182/250]: loss 0.7209, auc 0.4843, ap 0.4943
2024-01-10 22:13:35,731 - GAugM EPNet train, Epoch [183/250]: loss 0.7210, auc 0.4859, ap 0.4906
2024-01-10 22:13:35,814 - GAugM EPNet train, Epoch [184/250]: loss 0.7209, auc 0.5057, ap 0.5138
2024-01-10 22:13:35,898 - GAugM EPNet train, Epoch [185/250]: loss 0.7209, auc 0.4925, ap 0.5170
2024-01-10 22:13:35,980 - GAugM EPNet train, Epoch [186/250]: loss 0.7208, auc 0.5190, ap 0.5414
2024-01-10 22:13:36,061 - GAugM EPNet train, Epoch [187/250]: loss 0.7209, auc 0.4874, ap 0.4889
2024-01-10 22:13:36,147 - GAugM EPNet train, Epoch [188/250]: loss 0.7209, auc 0.4500, ap 0.4552
2024-01-10 22:13:36,235 - GAugM EPNet train, Epoch [189/250]: loss 0.7209, auc 0.5538, ap 0.5616
2024-01-10 22:13:36,322 - GAugM EPNet train, Epoch [190/250]: loss 0.7209, auc 0.4813, ap 0.4738
2024-01-10 22:13:36,411 - GAugM EPNet train, Epoch [191/250]: loss 0.7209, auc 0.4106, ap 0.4914
2024-01-10 22:13:36,504 - GAugM EPNet train, Epoch [192/250]: loss 0.7209, auc 0.4881, ap 0.4701
2024-01-10 22:13:36,589 - GAugM EPNet train, Epoch [193/250]: loss 0.7209, auc 0.4306, ap 0.4397
2024-01-10 22:13:36,672 - GAugM EPNet train, Epoch [194/250]: loss 0.7209, auc 0.5306, ap 0.5064
2024-01-10 22:13:36,756 - GAugM EPNet train, Epoch [195/250]: loss 0.7209, auc 0.4308, ap 0.4493
2024-01-10 22:13:36,836 - GAugM EPNet train, Epoch [196/250]: loss 0.7208, auc 0.4984, ap 0.4870
2024-01-10 22:13:36,924 - GAugM EPNet train, Epoch [197/250]: loss 0.7210, auc 0.4283, ap 0.4578
2024-01-10 22:13:37,009 - GAugM EPNet train, Epoch [198/250]: loss 0.7210, auc 0.6061, ap 0.5799
2024-01-10 22:13:37,091 - GAugM EPNet train, Epoch [199/250]: loss 0.7209, auc 0.4959, ap 0.4958
2024-01-10 22:13:37,177 - GAugM EPNet train, Epoch [200/250]: loss 0.7210, auc 0.4738, ap 0.4879
2024-01-10 22:13:37,262 - GAugM EPNet train, Epoch [201/250]: loss 0.7209, auc 0.4014, ap 0.4335
2024-01-10 22:13:37,346 - GAugM EPNet train, Epoch [202/250]: loss 0.7210, auc 0.5566, ap 0.5741
2024-01-10 22:13:37,431 - GAugM EPNet train, Epoch [203/250]: loss 0.7210, auc 0.5762, ap 0.5814
2024-01-10 22:13:37,520 - GAugM EPNet train, Epoch [204/250]: loss 0.7209, auc 0.4600, ap 0.4792
2024-01-10 22:13:37,603 - GAugM EPNet train, Epoch [205/250]: loss 0.7209, auc 0.5055, ap 0.5734
2024-01-10 22:13:37,689 - GAugM EPNet train, Epoch [206/250]: loss 0.7209, auc 0.4181, ap 0.4312
2024-01-10 22:13:37,770 - GAugM EPNet train, Epoch [207/250]: loss 0.7210, auc 0.4210, ap 0.4749
2024-01-10 22:13:37,861 - GAugM EPNet train, Epoch [208/250]: loss 0.7209, auc 0.4601, ap 0.5293
2024-01-10 22:13:37,941 - GAugM EPNet train, Epoch [209/250]: loss 0.7210, auc 0.6308, ap 0.6216
2024-01-10 22:13:38,024 - GAugM EPNet train, Epoch [210/250]: loss 0.7209, auc 0.4187, ap 0.4533
2024-01-10 22:13:38,105 - GAugM EPNet train, Epoch [211/250]: loss 0.7210, auc 0.5242, ap 0.5413
2024-01-10 22:13:38,187 - GAugM EPNet train, Epoch [212/250]: loss 0.7210, auc 0.4640, ap 0.4760
2024-01-10 22:13:38,272 - GAugM EPNet train, Epoch [213/250]: loss 0.7208, auc 0.6242, ap 0.6039
2024-01-10 22:13:38,354 - GAugM EPNet train, Epoch [214/250]: loss 0.7210, auc 0.4863, ap 0.4740
2024-01-10 22:13:38,438 - GAugM EPNet train, Epoch [215/250]: loss 0.7210, auc 0.5062, ap 0.5222
2024-01-10 22:13:38,519 - GAugM EPNet train, Epoch [216/250]: loss 0.7209, auc 0.5488, ap 0.5213
2024-01-10 22:13:38,607 - GAugM EPNet train, Epoch [217/250]: loss 0.7209, auc 0.5260, ap 0.5286
2024-01-10 22:13:38,694 - GAugM EPNet train, Epoch [218/250]: loss 0.7209, auc 0.4950, ap 0.5133
2024-01-10 22:13:38,771 - GAugM EPNet train, Epoch [219/250]: loss 0.7208, auc 0.5178, ap 0.5318
2024-01-10 22:13:38,860 - GAugM EPNet train, Epoch [220/250]: loss 0.7210, auc 0.4562, ap 0.5102
2024-01-10 22:13:38,936 - GAugM EPNet train, Epoch [221/250]: loss 0.7209, auc 0.5169, ap 0.5152
2024-01-10 22:13:39,007 - GAugM EPNet train, Epoch [222/250]: loss 0.7209, auc 0.5522, ap 0.5665
2024-01-10 22:13:39,079 - GAugM EPNet train, Epoch [223/250]: loss 0.7209, auc 0.5842, ap 0.5716
2024-01-10 22:13:39,156 - GAugM EPNet train, Epoch [224/250]: loss 0.7210, auc 0.4765, ap 0.5002
2024-01-10 22:13:39,229 - GAugM EPNet train, Epoch [225/250]: loss 0.7209, auc 0.4302, ap 0.4443
2024-01-10 22:13:39,306 - GAugM EPNet train, Epoch [226/250]: loss 0.7210, auc 0.5087, ap 0.5115
2024-01-10 22:13:39,377 - GAugM EPNet train, Epoch [227/250]: loss 0.7210, auc 0.5279, ap 0.5426
2024-01-10 22:13:39,455 - GAugM EPNet train, Epoch [228/250]: loss 0.7209, auc 0.4153, ap 0.4446
2024-01-10 22:13:39,529 - GAugM EPNet train, Epoch [229/250]: loss 0.7209, auc 0.4616, ap 0.4997
2024-01-10 22:13:39,608 - GAugM EPNet train, Epoch [230/250]: loss 0.7209, auc 0.4078, ap 0.4400
2024-01-10 22:13:39,681 - GAugM EPNet train, Epoch [231/250]: loss 0.7209, auc 0.4601, ap 0.4871
2024-01-10 22:13:39,754 - GAugM EPNet train, Epoch [232/250]: loss 0.7209, auc 0.4758, ap 0.4919
2024-01-10 22:13:39,830 - GAugM EPNet train, Epoch [233/250]: loss 0.7210, auc 0.5991, ap 0.6016
2024-01-10 22:13:39,904 - GAugM EPNet train, Epoch [234/250]: loss 0.7209, auc 0.4042, ap 0.4524
2024-01-10 22:13:39,981 - GAugM EPNet train, Epoch [235/250]: loss 0.7209, auc 0.4099, ap 0.4356
2024-01-10 22:13:40,060 - GAugM EPNet train, Epoch [236/250]: loss 0.7209, auc 0.4457, ap 0.4720
2024-01-10 22:13:40,145 - GAugM EPNet train, Epoch [237/250]: loss 0.7210, auc 0.5014, ap 0.4844
2024-01-10 22:13:40,220 - GAugM EPNet train, Epoch [238/250]: loss 0.7210, auc 0.4685, ap 0.4801
2024-01-10 22:13:40,292 - GAugM EPNet train, Epoch [239/250]: loss 0.7209, auc 0.4783, ap 0.5361
2024-01-10 22:13:40,371 - GAugM EPNet train, Epoch [240/250]: loss 0.7209, auc 0.5415, ap 0.5110
2024-01-10 22:13:40,445 - GAugM EPNet train, Epoch [241/250]: loss 0.7209, auc 0.5340, ap 0.5254
2024-01-10 22:13:40,521 - GAugM EPNet train, Epoch [242/250]: loss 0.7210, auc 0.4964, ap 0.5216
2024-01-10 22:13:40,594 - GAugM EPNet train, Epoch [243/250]: loss 0.7210, auc 0.5724, ap 0.6251
2024-01-10 22:13:40,667 - GAugM EPNet train, Epoch [244/250]: loss 0.7209, auc 0.5141, ap 0.5134
2024-01-10 22:13:40,752 - GAugM EPNet train, Epoch [245/250]: loss 0.7210, auc 0.5315, ap 0.5192
2024-01-10 22:13:40,827 - GAugM EPNet train, Epoch [246/250]: loss 0.7208, auc 0.4569, ap 0.4653
2024-01-10 22:13:40,898 - GAugM EPNet train, Epoch [247/250]: loss 0.7209, auc 0.4715, ap 0.4734
2024-01-10 22:13:40,970 - GAugM EPNet train, Epoch [248/250]: loss 0.7211, auc 0.4455, ap 0.4644
2024-01-10 22:13:41,044 - GAugM EPNet train, Epoch [249/250]: loss 0.7209, auc 0.4658, ap 0.4845
2024-01-10 22:13:41,121 - GAugM EPNet train, Epoch [250/250]: loss 0.7208, auc 0.5142, ap 0.5171
2024-01-10 22:13:41,121 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cf9e0cfd0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:13:41,850 - GAugM EPNet train, Epoch [  1/250]: loss 0.7210, auc 0.4831, ap 0.4710
2024-01-10 22:13:41,948 - GAugM EPNet train, Epoch [  2/250]: loss 0.7210, auc 0.5141, ap 0.4956
2024-01-10 22:13:42,044 - GAugM EPNet train, Epoch [  3/250]: loss 0.7209, auc 0.5313, ap 0.5095
2024-01-10 22:13:42,141 - GAugM EPNet train, Epoch [  4/250]: loss 0.7209, auc 0.4829, ap 0.4759
2024-01-10 22:13:42,243 - GAugM EPNet train, Epoch [  5/250]: loss 0.7209, auc 0.5924, ap 0.5620
2024-01-10 22:13:42,340 - GAugM EPNet train, Epoch [  6/250]: loss 0.7209, auc 0.5635, ap 0.5336
2024-01-10 22:13:42,447 - GAugM EPNet train, Epoch [  7/250]: loss 0.7209, auc 0.4804, ap 0.4833
2024-01-10 22:13:42,536 - GAugM EPNet train, Epoch [  8/250]: loss 0.7210, auc 0.4450, ap 0.4770
2024-01-10 22:13:42,619 - GAugM EPNet train, Epoch [  9/250]: loss 0.7209, auc 0.4964, ap 0.4889
2024-01-10 22:13:42,719 - GAugM EPNet train, Epoch [ 10/250]: loss 0.7208, auc 0.4236, ap 0.4391
2024-01-10 22:13:42,803 - GAugM EPNet train, Epoch [ 11/250]: loss 0.7209, auc 0.4939, ap 0.4744
2024-01-10 22:13:42,900 - GAugM EPNet train, Epoch [ 12/250]: loss 0.7210, auc 0.4325, ap 0.4441
2024-01-10 22:13:42,984 - GAugM EPNet train, Epoch [ 13/250]: loss 0.7209, auc 0.5454, ap 0.5508
2024-01-10 22:13:43,063 - GAugM EPNet train, Epoch [ 14/250]: loss 0.7209, auc 0.5489, ap 0.5216
2024-01-10 22:13:43,134 - GAugM EPNet train, Epoch [ 15/250]: loss 0.7210, auc 0.4039, ap 0.4498
2024-01-10 22:13:43,221 - GAugM EPNet train, Epoch [ 16/250]: loss 0.7209, auc 0.4413, ap 0.4610
2024-01-10 22:13:43,299 - GAugM EPNet train, Epoch [ 17/250]: loss 0.7210, auc 0.5408, ap 0.5260
2024-01-10 22:13:43,400 - GAugM EPNet train, Epoch [ 18/250]: loss 0.7210, auc 0.6248, ap 0.5954
2024-01-10 22:13:43,490 - GAugM EPNet train, Epoch [ 19/250]: loss 0.7209, auc 0.5431, ap 0.5072
2024-01-10 22:13:43,576 - GAugM EPNet train, Epoch [ 20/250]: loss 0.7210, auc 0.4539, ap 0.4899
2024-01-10 22:13:43,663 - GAugM EPNet train, Epoch [ 21/250]: loss 0.7209, auc 0.5167, ap 0.5343
2024-01-10 22:13:43,744 - GAugM EPNet train, Epoch [ 22/250]: loss 0.7210, auc 0.3952, ap 0.4429
2024-01-10 22:13:43,825 - GAugM EPNet train, Epoch [ 23/250]: loss 0.7208, auc 0.5400, ap 0.5250
2024-01-10 22:13:43,911 - GAugM EPNet train, Epoch [ 24/250]: loss 0.7209, auc 0.5201, ap 0.5099
2024-01-10 22:13:43,990 - GAugM EPNet train, Epoch [ 25/250]: loss 0.7209, auc 0.4820, ap 0.4794
2024-01-10 22:13:44,074 - GAugM EPNet train, Epoch [ 26/250]: loss 0.7210, auc 0.6216, ap 0.5937
2024-01-10 22:13:44,153 - GAugM EPNet train, Epoch [ 27/250]: loss 0.7209, auc 0.4751, ap 0.4932
2024-01-10 22:13:44,231 - GAugM EPNet train, Epoch [ 28/250]: loss 0.7209, auc 0.6134, ap 0.5921
2024-01-10 22:13:44,307 - GAugM EPNet train, Epoch [ 29/250]: loss 0.7210, auc 0.5461, ap 0.5246
2024-01-10 22:13:44,389 - GAugM EPNet train, Epoch [ 30/250]: loss 0.7209, auc 0.5545, ap 0.5311
2024-01-10 22:13:44,476 - GAugM EPNet train, Epoch [ 31/250]: loss 0.7208, auc 0.4555, ap 0.4732
2024-01-10 22:13:44,557 - GAugM EPNet train, Epoch [ 32/250]: loss 0.7210, auc 0.5039, ap 0.4804
2024-01-10 22:13:44,635 - GAugM EPNet train, Epoch [ 33/250]: loss 0.7209, auc 0.5240, ap 0.5333
2024-01-10 22:13:44,710 - GAugM EPNet train, Epoch [ 34/250]: loss 0.7209, auc 0.3815, ap 0.4146
2024-01-10 22:13:44,790 - GAugM EPNet train, Epoch [ 35/250]: loss 0.7209, auc 0.5000, ap 0.5136
2024-01-10 22:13:44,870 - GAugM EPNet train, Epoch [ 36/250]: loss 0.7209, auc 0.6403, ap 0.5808
2024-01-10 22:13:44,945 - GAugM EPNet train, Epoch [ 37/250]: loss 0.7209, auc 0.4532, ap 0.4518
2024-01-10 22:13:45,022 - GAugM EPNet train, Epoch [ 38/250]: loss 0.7209, auc 0.4806, ap 0.4637
2024-01-10 22:13:45,100 - GAugM EPNet train, Epoch [ 39/250]: loss 0.7208, auc 0.4883, ap 0.4999
2024-01-10 22:13:45,179 - GAugM EPNet train, Epoch [ 40/250]: loss 0.7210, auc 0.5214, ap 0.5032
2024-01-10 22:13:45,254 - GAugM EPNet train, Epoch [ 41/250]: loss 0.7210, auc 0.4810, ap 0.4934
2024-01-10 22:13:45,334 - GAugM EPNet train, Epoch [ 42/250]: loss 0.7209, auc 0.5685, ap 0.5717
2024-01-10 22:13:45,414 - GAugM EPNet train, Epoch [ 43/250]: loss 0.7208, auc 0.4617, ap 0.4684
2024-01-10 22:13:45,486 - GAugM EPNet train, Epoch [ 44/250]: loss 0.7208, auc 0.4382, ap 0.4452
2024-01-10 22:13:45,565 - GAugM EPNet train, Epoch [ 45/250]: loss 0.7209, auc 0.5166, ap 0.5020
2024-01-10 22:13:45,643 - GAugM EPNet train, Epoch [ 46/250]: loss 0.7209, auc 0.4557, ap 0.4610
2024-01-10 22:13:45,720 - GAugM EPNet train, Epoch [ 47/250]: loss 0.7210, auc 0.4737, ap 0.4702
2024-01-10 22:13:45,796 - GAugM EPNet train, Epoch [ 48/250]: loss 0.7210, auc 0.5778, ap 0.5650
2024-01-10 22:13:45,876 - GAugM EPNet train, Epoch [ 49/250]: loss 0.7209, auc 0.6031, ap 0.5929
2024-01-10 22:13:45,950 - GAugM EPNet train, Epoch [ 50/250]: loss 0.7210, auc 0.4797, ap 0.4722
2024-01-10 22:13:46,031 - GAugM EPNet train, Epoch [ 51/250]: loss 0.7210, auc 0.4555, ap 0.4690
2024-01-10 22:13:46,105 - GAugM EPNet train, Epoch [ 52/250]: loss 0.7209, auc 0.4551, ap 0.4715
2024-01-10 22:13:46,179 - GAugM EPNet train, Epoch [ 53/250]: loss 0.7209, auc 0.5157, ap 0.5107
2024-01-10 22:13:46,257 - GAugM EPNet train, Epoch [ 54/250]: loss 0.7211, auc 0.5550, ap 0.5146
2024-01-10 22:13:46,332 - GAugM EPNet train, Epoch [ 55/250]: loss 0.7209, auc 0.5815, ap 0.5685
2024-01-10 22:13:46,411 - GAugM EPNet train, Epoch [ 56/250]: loss 0.7208, auc 0.4822, ap 0.4605
2024-01-10 22:13:46,494 - GAugM EPNet train, Epoch [ 57/250]: loss 0.7209, auc 0.4316, ap 0.4342
2024-01-10 22:13:46,569 - GAugM EPNet train, Epoch [ 58/250]: loss 0.7210, auc 0.4970, ap 0.5517
2024-01-10 22:13:46,645 - GAugM EPNet train, Epoch [ 59/250]: loss 0.7211, auc 0.5322, ap 0.4918
2024-01-10 22:13:46,720 - GAugM EPNet train, Epoch [ 60/250]: loss 0.7210, auc 0.4988, ap 0.4710
2024-01-10 22:13:46,804 - GAugM EPNet train, Epoch [ 61/250]: loss 0.7209, auc 0.5555, ap 0.5465
2024-01-10 22:13:46,881 - GAugM EPNet train, Epoch [ 62/250]: loss 0.7210, auc 0.5586, ap 0.5540
2024-01-10 22:13:46,956 - GAugM EPNet train, Epoch [ 63/250]: loss 0.7208, auc 0.4178, ap 0.4313
2024-01-10 22:13:47,034 - GAugM EPNet train, Epoch [ 64/250]: loss 0.7208, auc 0.4939, ap 0.5232
2024-01-10 22:13:47,108 - GAugM EPNet train, Epoch [ 65/250]: loss 0.7208, auc 0.6095, ap 0.5894
2024-01-10 22:13:47,182 - GAugM EPNet train, Epoch [ 66/250]: loss 0.7209, auc 0.4400, ap 0.4718
2024-01-10 22:13:47,256 - GAugM EPNet train, Epoch [ 67/250]: loss 0.7209, auc 0.5812, ap 0.5461
2024-01-10 22:13:47,331 - GAugM EPNet train, Epoch [ 68/250]: loss 0.7210, auc 0.5482, ap 0.5399
2024-01-10 22:13:47,409 - GAugM EPNet train, Epoch [ 69/250]: loss 0.7210, auc 0.4669, ap 0.4842
2024-01-10 22:13:47,483 - GAugM EPNet train, Epoch [ 70/250]: loss 0.7210, auc 0.5345, ap 0.5016
2024-01-10 22:13:47,558 - GAugM EPNet train, Epoch [ 71/250]: loss 0.7210, auc 0.5740, ap 0.5709
2024-01-10 22:13:47,642 - GAugM EPNet train, Epoch [ 72/250]: loss 0.7210, auc 0.4057, ap 0.4380
2024-01-10 22:13:47,720 - GAugM EPNet train, Epoch [ 73/250]: loss 0.7209, auc 0.5183, ap 0.4876
2024-01-10 22:13:47,803 - GAugM EPNet train, Epoch [ 74/250]: loss 0.7209, auc 0.5728, ap 0.5519
2024-01-10 22:13:47,881 - GAugM EPNet train, Epoch [ 75/250]: loss 0.7210, auc 0.3975, ap 0.4293
2024-01-10 22:13:47,959 - GAugM EPNet train, Epoch [ 76/250]: loss 0.7209, auc 0.4019, ap 0.4372
2024-01-10 22:13:48,040 - GAugM EPNet train, Epoch [ 77/250]: loss 0.7208, auc 0.5208, ap 0.5236
2024-01-10 22:13:48,118 - GAugM EPNet train, Epoch [ 78/250]: loss 0.7209, auc 0.5185, ap 0.4971
2024-01-10 22:13:48,201 - GAugM EPNet train, Epoch [ 79/250]: loss 0.7208, auc 0.4722, ap 0.4691
2024-01-10 22:13:48,280 - GAugM EPNet train, Epoch [ 80/250]: loss 0.7209, auc 0.5110, ap 0.4994
2024-01-10 22:13:48,363 - GAugM EPNet train, Epoch [ 81/250]: loss 0.7209, auc 0.4834, ap 0.4920
2024-01-10 22:13:48,437 - GAugM EPNet train, Epoch [ 82/250]: loss 0.7210, auc 0.5297, ap 0.5070
2024-01-10 22:13:48,511 - GAugM EPNet train, Epoch [ 83/250]: loss 0.7209, auc 0.4794, ap 0.5193
2024-01-10 22:13:48,584 - GAugM EPNet train, Epoch [ 84/250]: loss 0.7209, auc 0.4824, ap 0.4620
2024-01-10 22:13:48,658 - GAugM EPNet train, Epoch [ 85/250]: loss 0.7210, auc 0.5016, ap 0.4975
2024-01-10 22:13:48,737 - GAugM EPNet train, Epoch [ 86/250]: loss 0.7208, auc 0.5205, ap 0.5161
2024-01-10 22:13:48,811 - GAugM EPNet train, Epoch [ 87/250]: loss 0.7209, auc 0.5390, ap 0.5314
2024-01-10 22:13:48,891 - GAugM EPNet train, Epoch [ 88/250]: loss 0.7210, auc 0.4094, ap 0.4298
2024-01-10 22:13:48,967 - GAugM EPNet train, Epoch [ 89/250]: loss 0.7210, auc 0.4000, ap 0.4370
2024-01-10 22:13:49,046 - GAugM EPNet train, Epoch [ 90/250]: loss 0.7209, auc 0.4138, ap 0.4663
2024-01-10 22:13:49,122 - GAugM EPNet train, Epoch [ 91/250]: loss 0.7208, auc 0.5819, ap 0.5405
2024-01-10 22:13:49,196 - GAugM EPNet train, Epoch [ 92/250]: loss 0.7209, auc 0.6248, ap 0.5933
2024-01-10 22:13:49,272 - GAugM EPNet train, Epoch [ 93/250]: loss 0.7209, auc 0.3581, ap 0.4165
2024-01-10 22:13:49,353 - GAugM EPNet train, Epoch [ 94/250]: loss 0.7210, auc 0.4519, ap 0.4678
2024-01-10 22:13:49,428 - GAugM EPNet train, Epoch [ 95/250]: loss 0.7210, auc 0.5174, ap 0.5098
2024-01-10 22:13:49,503 - GAugM EPNet train, Epoch [ 96/250]: loss 0.7209, auc 0.4770, ap 0.4634
2024-01-10 22:13:49,578 - GAugM EPNet train, Epoch [ 97/250]: loss 0.7209, auc 0.5046, ap 0.5014
2024-01-10 22:13:49,653 - GAugM EPNet train, Epoch [ 98/250]: loss 0.7209, auc 0.4402, ap 0.4534
2024-01-10 22:13:49,726 - GAugM EPNet train, Epoch [ 99/250]: loss 0.7209, auc 0.5425, ap 0.5339
2024-01-10 22:13:49,806 - GAugM EPNet train, Epoch [100/250]: loss 0.7210, auc 0.4290, ap 0.4402
2024-01-10 22:13:49,880 - GAugM EPNet train, Epoch [101/250]: loss 0.7210, auc 0.4591, ap 0.5000
2024-01-10 22:13:49,956 - GAugM EPNet train, Epoch [102/250]: loss 0.7209, auc 0.4461, ap 0.4507
2024-01-10 22:13:50,049 - GAugM EPNet train, Epoch [103/250]: loss 0.7209, auc 0.5541, ap 0.5517
2024-01-10 22:13:50,126 - GAugM EPNet train, Epoch [104/250]: loss 0.7209, auc 0.5023, ap 0.5162
2024-01-10 22:13:50,200 - GAugM EPNet train, Epoch [105/250]: loss 0.7209, auc 0.4489, ap 0.4690
2024-01-10 22:13:50,279 - GAugM EPNet train, Epoch [106/250]: loss 0.7210, auc 0.4487, ap 0.4634
2024-01-10 22:13:50,353 - GAugM EPNet train, Epoch [107/250]: loss 0.7210, auc 0.4859, ap 0.4968
2024-01-10 22:13:50,428 - GAugM EPNet train, Epoch [108/250]: loss 0.7208, auc 0.5481, ap 0.5487
2024-01-10 22:13:50,509 - GAugM EPNet train, Epoch [109/250]: loss 0.7210, auc 0.4703, ap 0.4652
2024-01-10 22:13:50,584 - GAugM EPNet train, Epoch [110/250]: loss 0.7209, auc 0.4199, ap 0.4515
2024-01-10 22:13:50,657 - GAugM EPNet train, Epoch [111/250]: loss 0.7210, auc 0.5443, ap 0.5155
2024-01-10 22:13:50,730 - GAugM EPNet train, Epoch [112/250]: loss 0.7209, auc 0.5582, ap 0.5523
2024-01-10 22:13:50,803 - GAugM EPNet train, Epoch [113/250]: loss 0.7210, auc 0.4749, ap 0.4933
2024-01-10 22:13:50,879 - GAugM EPNet train, Epoch [114/250]: loss 0.7209, auc 0.4847, ap 0.4680
2024-01-10 22:13:50,956 - GAugM EPNet train, Epoch [115/250]: loss 0.7210, auc 0.4877, ap 0.5012
2024-01-10 22:13:51,040 - GAugM EPNet train, Epoch [116/250]: loss 0.7209, auc 0.4778, ap 0.4846
2024-01-10 22:13:51,117 - GAugM EPNet train, Epoch [117/250]: loss 0.7208, auc 0.4098, ap 0.4404
2024-01-10 22:13:51,192 - GAugM EPNet train, Epoch [118/250]: loss 0.7209, auc 0.5554, ap 0.5647
2024-01-10 22:13:51,271 - GAugM EPNet train, Epoch [119/250]: loss 0.7209, auc 0.4632, ap 0.4958
2024-01-10 22:13:51,345 - GAugM EPNet train, Epoch [120/250]: loss 0.7210, auc 0.4528, ap 0.4510
2024-01-10 22:13:51,424 - GAugM EPNet train, Epoch [121/250]: loss 0.7210, auc 0.5101, ap 0.5040
2024-01-10 22:13:51,509 - GAugM EPNet train, Epoch [122/250]: loss 0.7209, auc 0.5402, ap 0.5261
2024-01-10 22:13:51,586 - GAugM EPNet train, Epoch [123/250]: loss 0.7209, auc 0.4598, ap 0.4924
2024-01-10 22:13:51,662 - GAugM EPNet train, Epoch [124/250]: loss 0.7210, auc 0.4133, ap 0.4262
2024-01-10 22:13:51,737 - GAugM EPNet train, Epoch [125/250]: loss 0.7209, auc 0.5205, ap 0.5133
2024-01-10 22:13:51,816 - GAugM EPNet train, Epoch [126/250]: loss 0.7210, auc 0.5498, ap 0.5326
2024-01-10 22:13:51,891 - GAugM EPNet train, Epoch [127/250]: loss 0.7209, auc 0.5000, ap 0.4863
2024-01-10 22:13:51,967 - GAugM EPNet train, Epoch [128/250]: loss 0.7210, auc 0.4934, ap 0.5107
2024-01-10 22:13:52,049 - GAugM EPNet train, Epoch [129/250]: loss 0.7208, auc 0.4156, ap 0.4410
2024-01-10 22:13:52,123 - GAugM EPNet train, Epoch [130/250]: loss 0.7210, auc 0.5112, ap 0.5271
2024-01-10 22:13:52,198 - GAugM EPNet train, Epoch [131/250]: loss 0.7210, auc 0.5262, ap 0.5508
2024-01-10 22:13:52,271 - GAugM EPNet train, Epoch [132/250]: loss 0.7209, auc 0.5361, ap 0.5049
2024-01-10 22:13:52,344 - GAugM EPNet train, Epoch [133/250]: loss 0.7209, auc 0.4692, ap 0.4956
2024-01-10 22:13:52,420 - GAugM EPNet train, Epoch [134/250]: loss 0.7210, auc 0.4596, ap 0.4538
2024-01-10 22:13:52,498 - GAugM EPNet train, Epoch [135/250]: loss 0.7209, auc 0.4274, ap 0.4620
2024-01-10 22:13:52,573 - GAugM EPNet train, Epoch [136/250]: loss 0.7209, auc 0.5253, ap 0.5065
2024-01-10 22:13:52,651 - GAugM EPNet train, Epoch [137/250]: loss 0.7210, auc 0.4429, ap 0.4659
2024-01-10 22:13:52,725 - GAugM EPNet train, Epoch [138/250]: loss 0.7210, auc 0.5406, ap 0.5228
2024-01-10 22:13:52,800 - GAugM EPNet train, Epoch [139/250]: loss 0.7210, auc 0.4026, ap 0.4265
2024-01-10 22:13:52,879 - GAugM EPNet train, Epoch [140/250]: loss 0.7209, auc 0.5468, ap 0.5283
2024-01-10 22:13:52,952 - GAugM EPNet train, Epoch [141/250]: loss 0.7209, auc 0.5418, ap 0.5268
2024-01-10 22:13:53,025 - GAugM EPNet train, Epoch [142/250]: loss 0.7209, auc 0.5166, ap 0.5047
2024-01-10 22:13:53,102 - GAugM EPNet train, Epoch [143/250]: loss 0.7209, auc 0.4174, ap 0.4374
2024-01-10 22:13:53,176 - GAugM EPNet train, Epoch [144/250]: loss 0.7209, auc 0.4365, ap 0.4480
2024-01-10 22:13:53,253 - GAugM EPNet train, Epoch [145/250]: loss 0.7209, auc 0.3928, ap 0.4503
2024-01-10 22:13:53,333 - GAugM EPNet train, Epoch [146/250]: loss 0.7209, auc 0.4669, ap 0.4972
2024-01-10 22:13:53,409 - GAugM EPNet train, Epoch [147/250]: loss 0.7209, auc 0.6148, ap 0.6293
2024-01-10 22:13:53,486 - GAugM EPNet train, Epoch [148/250]: loss 0.7209, auc 0.4642, ap 0.4701
2024-01-10 22:13:53,559 - GAugM EPNet train, Epoch [149/250]: loss 0.7208, auc 0.4872, ap 0.4690
2024-01-10 22:13:53,636 - GAugM EPNet train, Epoch [150/250]: loss 0.7209, auc 0.5041, ap 0.4950
2024-01-10 22:13:53,711 - GAugM EPNet train, Epoch [151/250]: loss 0.7209, auc 0.5205, ap 0.5072
2024-01-10 22:13:53,792 - GAugM EPNet train, Epoch [152/250]: loss 0.7209, auc 0.5484, ap 0.5172
2024-01-10 22:13:53,867 - GAugM EPNet train, Epoch [153/250]: loss 0.7209, auc 0.4236, ap 0.4601
2024-01-10 22:13:53,946 - GAugM EPNet train, Epoch [154/250]: loss 0.7209, auc 0.5420, ap 0.5198
2024-01-10 22:13:54,023 - GAugM EPNet train, Epoch [155/250]: loss 0.7209, auc 0.4660, ap 0.4726
2024-01-10 22:13:54,098 - GAugM EPNet train, Epoch [156/250]: loss 0.7209, auc 0.4012, ap 0.4446
2024-01-10 22:13:54,175 - GAugM EPNet train, Epoch [157/250]: loss 0.7209, auc 0.4907, ap 0.4675
2024-01-10 22:13:54,248 - GAugM EPNet train, Epoch [158/250]: loss 0.7208, auc 0.4279, ap 0.4509
2024-01-10 22:13:54,321 - GAugM EPNet train, Epoch [159/250]: loss 0.7208, auc 0.4156, ap 0.4466
2024-01-10 22:13:54,396 - GAugM EPNet train, Epoch [160/250]: loss 0.7209, auc 0.5363, ap 0.5393
2024-01-10 22:13:54,471 - GAugM EPNet train, Epoch [161/250]: loss 0.7209, auc 0.5561, ap 0.5099
2024-01-10 22:13:54,547 - GAugM EPNet train, Epoch [162/250]: loss 0.7209, auc 0.4407, ap 0.4469
2024-01-10 22:13:54,622 - GAugM EPNet train, Epoch [163/250]: loss 0.7209, auc 0.5011, ap 0.4929
2024-01-10 22:13:54,700 - GAugM EPNet train, Epoch [164/250]: loss 0.7211, auc 0.4829, ap 0.4761
2024-01-10 22:13:54,777 - GAugM EPNet train, Epoch [165/250]: loss 0.7210, auc 0.4617, ap 0.4561
2024-01-10 22:13:54,851 - GAugM EPNet train, Epoch [166/250]: loss 0.7208, auc 0.5516, ap 0.5432
2024-01-10 22:13:54,925 - GAugM EPNet train, Epoch [167/250]: loss 0.7209, auc 0.4792, ap 0.4759
2024-01-10 22:13:55,005 - GAugM EPNet train, Epoch [168/250]: loss 0.7209, auc 0.4511, ap 0.5225
2024-01-10 22:13:55,079 - GAugM EPNet train, Epoch [169/250]: loss 0.7209, auc 0.5522, ap 0.5427
2024-01-10 22:13:55,165 - GAugM EPNet train, Epoch [170/250]: loss 0.7210, auc 0.4361, ap 0.4388
2024-01-10 22:13:55,241 - GAugM EPNet train, Epoch [171/250]: loss 0.7209, auc 0.3669, ap 0.4120
2024-01-10 22:13:55,320 - GAugM EPNet train, Epoch [172/250]: loss 0.7208, auc 0.4922, ap 0.4943
2024-01-10 22:13:55,395 - GAugM EPNet train, Epoch [173/250]: loss 0.7209, auc 0.4555, ap 0.4625
2024-01-10 22:13:55,470 - GAugM EPNet train, Epoch [174/250]: loss 0.7209, auc 0.4772, ap 0.4734
2024-01-10 22:13:55,555 - GAugM EPNet train, Epoch [175/250]: loss 0.7209, auc 0.6540, ap 0.6202
2024-01-10 22:13:55,629 - GAugM EPNet train, Epoch [176/250]: loss 0.7209, auc 0.4891, ap 0.4850
2024-01-10 22:13:55,704 - GAugM EPNet train, Epoch [177/250]: loss 0.7210, auc 0.4785, ap 0.4851
2024-01-10 22:13:55,779 - GAugM EPNet train, Epoch [178/250]: loss 0.7210, auc 0.5509, ap 0.5337
2024-01-10 22:13:55,857 - GAugM EPNet train, Epoch [179/250]: loss 0.7210, auc 0.4931, ap 0.5156
2024-01-10 22:13:55,931 - GAugM EPNet train, Epoch [180/250]: loss 0.7210, auc 0.5456, ap 0.5527
2024-01-10 22:13:56,005 - GAugM EPNet train, Epoch [181/250]: loss 0.7209, auc 0.3791, ap 0.4195
2024-01-10 22:13:56,078 - GAugM EPNet train, Epoch [182/250]: loss 0.7209, auc 0.4770, ap 0.4985
2024-01-10 22:13:56,151 - GAugM EPNet train, Epoch [183/250]: loss 0.7210, auc 0.5812, ap 0.5467
2024-01-10 22:13:56,227 - GAugM EPNet train, Epoch [184/250]: loss 0.7209, auc 0.5545, ap 0.5332
2024-01-10 22:13:56,307 - GAugM EPNet train, Epoch [185/250]: loss 0.7209, auc 0.4870, ap 0.4990
2024-01-10 22:13:56,381 - GAugM EPNet train, Epoch [186/250]: loss 0.7208, auc 0.4491, ap 0.4716
2024-01-10 22:13:56,455 - GAugM EPNet train, Epoch [187/250]: loss 0.7209, auc 0.4911, ap 0.4854
2024-01-10 22:13:56,530 - GAugM EPNet train, Epoch [188/250]: loss 0.7209, auc 0.4760, ap 0.4786
2024-01-10 22:13:56,604 - GAugM EPNet train, Epoch [189/250]: loss 0.7209, auc 0.5813, ap 0.5605
2024-01-10 22:13:56,679 - GAugM EPNet train, Epoch [190/250]: loss 0.7209, auc 0.4080, ap 0.4264
2024-01-10 22:13:56,760 - GAugM EPNet train, Epoch [191/250]: loss 0.7209, auc 0.4591, ap 0.4978
2024-01-10 22:13:56,835 - GAugM EPNet train, Epoch [192/250]: loss 0.7209, auc 0.4916, ap 0.4764
2024-01-10 22:13:56,909 - GAugM EPNet train, Epoch [193/250]: loss 0.7209, auc 0.4587, ap 0.4537
2024-01-10 22:13:56,990 - GAugM EPNet train, Epoch [194/250]: loss 0.7209, auc 0.4820, ap 0.4850
2024-01-10 22:13:57,066 - GAugM EPNet train, Epoch [195/250]: loss 0.7209, auc 0.5383, ap 0.5347
2024-01-10 22:13:57,140 - GAugM EPNet train, Epoch [196/250]: loss 0.7208, auc 0.5379, ap 0.5033
2024-01-10 22:13:57,221 - GAugM EPNet train, Epoch [197/250]: loss 0.7210, auc 0.5139, ap 0.5015
2024-01-10 22:13:57,300 - GAugM EPNet train, Epoch [198/250]: loss 0.7210, auc 0.5552, ap 0.5195
2024-01-10 22:13:57,375 - GAugM EPNet train, Epoch [199/250]: loss 0.7209, auc 0.4936, ap 0.5031
2024-01-10 22:13:57,449 - GAugM EPNet train, Epoch [200/250]: loss 0.7210, auc 0.5116, ap 0.5247
2024-01-10 22:13:57,525 - GAugM EPNet train, Epoch [201/250]: loss 0.7209, auc 0.4389, ap 0.4382
2024-01-10 22:13:57,606 - GAugM EPNet train, Epoch [202/250]: loss 0.7210, auc 0.4806, ap 0.5295
2024-01-10 22:13:57,681 - GAugM EPNet train, Epoch [203/250]: loss 0.7210, auc 0.5614, ap 0.5465
2024-01-10 22:13:57,765 - GAugM EPNet train, Epoch [204/250]: loss 0.7209, auc 0.4694, ap 0.4686
2024-01-10 22:13:57,843 - GAugM EPNet train, Epoch [205/250]: loss 0.7209, auc 0.4373, ap 0.4597
2024-01-10 22:13:57,921 - GAugM EPNet train, Epoch [206/250]: loss 0.7209, auc 0.4760, ap 0.4755
2024-01-10 22:13:58,001 - GAugM EPNet train, Epoch [207/250]: loss 0.7210, auc 0.4772, ap 0.4948
2024-01-10 22:13:58,081 - GAugM EPNet train, Epoch [208/250]: loss 0.7209, auc 0.4557, ap 0.5057
2024-01-10 22:13:58,170 - GAugM EPNet train, Epoch [209/250]: loss 0.7210, auc 0.5874, ap 0.5799
2024-01-10 22:13:58,249 - GAugM EPNet train, Epoch [210/250]: loss 0.7209, auc 0.4546, ap 0.4563
2024-01-10 22:13:58,322 - GAugM EPNet train, Epoch [211/250]: loss 0.7210, auc 0.5602, ap 0.5489
2024-01-10 22:13:58,399 - GAugM EPNet train, Epoch [212/250]: loss 0.7210, auc 0.4534, ap 0.4622
2024-01-10 22:13:58,479 - GAugM EPNet train, Epoch [213/250]: loss 0.7208, auc 0.5509, ap 0.5577
2024-01-10 22:13:58,560 - GAugM EPNet train, Epoch [214/250]: loss 0.7210, auc 0.5011, ap 0.4984
2024-01-10 22:13:58,639 - GAugM EPNet train, Epoch [215/250]: loss 0.7210, auc 0.4534, ap 0.4635
2024-01-10 22:13:58,716 - GAugM EPNet train, Epoch [216/250]: loss 0.7209, auc 0.5507, ap 0.5357
2024-01-10 22:13:58,796 - GAugM EPNet train, Epoch [217/250]: loss 0.7209, auc 0.5833, ap 0.6206
2024-01-10 22:13:58,872 - GAugM EPNet train, Epoch [218/250]: loss 0.7209, auc 0.5422, ap 0.5317
2024-01-10 22:13:58,948 - GAugM EPNet train, Epoch [219/250]: loss 0.7208, auc 0.4939, ap 0.4768
2024-01-10 22:13:59,032 - GAugM EPNet train, Epoch [220/250]: loss 0.7210, auc 0.4345, ap 0.4793
2024-01-10 22:13:59,109 - GAugM EPNet train, Epoch [221/250]: loss 0.7209, auc 0.5630, ap 0.5311
2024-01-10 22:13:59,183 - GAugM EPNet train, Epoch [222/250]: loss 0.7209, auc 0.5112, ap 0.4892
2024-01-10 22:13:59,259 - GAugM EPNet train, Epoch [223/250]: loss 0.7209, auc 0.5892, ap 0.5686
2024-01-10 22:13:59,333 - GAugM EPNet train, Epoch [224/250]: loss 0.7210, auc 0.4391, ap 0.4681
2024-01-10 22:13:59,407 - GAugM EPNet train, Epoch [225/250]: loss 0.7209, auc 0.4847, ap 0.4853
2024-01-10 22:13:59,489 - GAugM EPNet train, Epoch [226/250]: loss 0.7210, auc 0.5023, ap 0.4997
2024-01-10 22:13:59,565 - GAugM EPNet train, Epoch [227/250]: loss 0.7210, auc 0.5876, ap 0.5566
2024-01-10 22:13:59,641 - GAugM EPNet train, Epoch [228/250]: loss 0.7209, auc 0.5164, ap 0.5245
2024-01-10 22:13:59,715 - GAugM EPNet train, Epoch [229/250]: loss 0.7209, auc 0.5128, ap 0.5410
2024-01-10 22:13:59,793 - GAugM EPNet train, Epoch [230/250]: loss 0.7209, auc 0.5228, ap 0.5228
2024-01-10 22:13:59,875 - GAugM EPNet train, Epoch [231/250]: loss 0.7209, auc 0.4927, ap 0.4923
2024-01-10 22:13:59,949 - GAugM EPNet train, Epoch [232/250]: loss 0.7209, auc 0.5764, ap 0.5586
2024-01-10 22:14:00,023 - GAugM EPNet train, Epoch [233/250]: loss 0.7210, auc 0.5758, ap 0.5721
2024-01-10 22:14:00,098 - GAugM EPNet train, Epoch [234/250]: loss 0.7209, auc 0.4519, ap 0.4731
2024-01-10 22:14:00,171 - GAugM EPNet train, Epoch [235/250]: loss 0.7209, auc 0.4729, ap 0.4643
2024-01-10 22:14:00,245 - GAugM EPNet train, Epoch [236/250]: loss 0.7209, auc 0.5580, ap 0.5767
2024-01-10 22:14:00,323 - GAugM EPNet train, Epoch [237/250]: loss 0.7210, auc 0.5117, ap 0.5425
2024-01-10 22:14:00,400 - GAugM EPNet train, Epoch [238/250]: loss 0.7210, auc 0.4854, ap 0.4706
2024-01-10 22:14:00,478 - GAugM EPNet train, Epoch [239/250]: loss 0.7209, auc 0.4938, ap 0.5105
2024-01-10 22:14:00,551 - GAugM EPNet train, Epoch [240/250]: loss 0.7209, auc 0.5388, ap 0.5002
2024-01-10 22:14:00,624 - GAugM EPNet train, Epoch [241/250]: loss 0.7209, auc 0.5158, ap 0.5075
2024-01-10 22:14:00,703 - GAugM EPNet train, Epoch [242/250]: loss 0.7210, auc 0.4210, ap 0.4395
2024-01-10 22:14:00,780 - GAugM EPNet train, Epoch [243/250]: loss 0.7210, auc 0.5363, ap 0.5814
2024-01-10 22:14:00,857 - GAugM EPNet train, Epoch [244/250]: loss 0.7209, auc 0.5319, ap 0.5046
2024-01-10 22:14:00,931 - GAugM EPNet train, Epoch [245/250]: loss 0.7210, auc 0.4489, ap 0.4553
2024-01-10 22:14:01,005 - GAugM EPNet train, Epoch [246/250]: loss 0.7208, auc 0.5107, ap 0.5037
2024-01-10 22:14:01,085 - GAugM EPNet train, Epoch [247/250]: loss 0.7209, auc 0.5514, ap 0.5165
2024-01-10 22:14:01,159 - GAugM EPNet train, Epoch [248/250]: loss 0.7211, auc 0.5561, ap 0.5421
2024-01-10 22:14:01,234 - GAugM EPNet train, Epoch [249/250]: loss 0.7209, auc 0.4503, ap 0.4479
2024-01-10 22:14:01,307 - GAugM EPNet train, Epoch [250/250]: loss 0.7208, auc 0.5648, ap 0.5297
2024-01-10 22:14:01,317 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f0cfa0d43d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-10 22:14:02,057 - GAugM EPNet train, Epoch [  1/250]: loss 0.7210, auc 0.4874, ap 0.4954
2024-01-10 22:14:02,143 - GAugM EPNet train, Epoch [  2/250]: loss 0.7210, auc 0.5276, ap 0.5197
2024-01-10 22:14:02,219 - GAugM EPNet train, Epoch [  3/250]: loss 0.7209, auc 0.5582, ap 0.5672
2024-01-10 22:14:02,294 - GAugM EPNet train, Epoch [  4/250]: loss 0.7209, auc 0.4735, ap 0.4924
2024-01-10 22:14:02,373 - GAugM EPNet train, Epoch [  5/250]: loss 0.7209, auc 0.5340, ap 0.5430
2024-01-10 22:14:02,449 - GAugM EPNet train, Epoch [  6/250]: loss 0.7209, auc 0.5279, ap 0.5007
2024-01-10 22:14:02,532 - GAugM EPNet train, Epoch [  7/250]: loss 0.7209, auc 0.4770, ap 0.4822
2024-01-10 22:14:02,606 - GAugM EPNet train, Epoch [  8/250]: loss 0.7210, auc 0.5457, ap 0.5728
2024-01-10 22:14:02,689 - GAugM EPNet train, Epoch [  9/250]: loss 0.7209, auc 0.4646, ap 0.4748
2024-01-10 22:14:02,775 - GAugM EPNet train, Epoch [ 10/250]: loss 0.7208, auc 0.4585, ap 0.4846
2024-01-10 22:14:02,853 - GAugM EPNet train, Epoch [ 11/250]: loss 0.7209, auc 0.4436, ap 0.4847
2024-01-10 22:14:02,930 - GAugM EPNet train, Epoch [ 12/250]: loss 0.7210, auc 0.5550, ap 0.5459
2024-01-10 22:14:03,003 - GAugM EPNet train, Epoch [ 13/250]: loss 0.7209, auc 0.6159, ap 0.5995
2024-01-10 22:14:03,076 - GAugM EPNet train, Epoch [ 14/250]: loss 0.7209, auc 0.5151, ap 0.5167
2024-01-10 22:14:03,159 - GAugM EPNet train, Epoch [ 15/250]: loss 0.7210, auc 0.3969, ap 0.4468
2024-01-10 22:14:03,235 - GAugM EPNet train, Epoch [ 16/250]: loss 0.7209, auc 0.5041, ap 0.5158
2024-01-10 22:14:03,314 - GAugM EPNet train, Epoch [ 17/250]: loss 0.7210, auc 0.5504, ap 0.5470
2024-01-10 22:14:03,395 - GAugM EPNet train, Epoch [ 18/250]: loss 0.7210, auc 0.5789, ap 0.5808
2024-01-10 22:14:03,474 - GAugM EPNet train, Epoch [ 19/250]: loss 0.7209, auc 0.5336, ap 0.5212
2024-01-10 22:14:03,551 - GAugM EPNet train, Epoch [ 20/250]: loss 0.7210, auc 0.4500, ap 0.5065
2024-01-10 22:14:03,624 - GAugM EPNet train, Epoch [ 21/250]: loss 0.7209, auc 0.5201, ap 0.5401
2024-01-10 22:14:03,705 - GAugM EPNet train, Epoch [ 22/250]: loss 0.7210, auc 0.3396, ap 0.4311
2024-01-10 22:14:03,779 - GAugM EPNet train, Epoch [ 23/250]: loss 0.7208, auc 0.4745, ap 0.4946
2024-01-10 22:14:03,856 - GAugM EPNet train, Epoch [ 24/250]: loss 0.7209, auc 0.4849, ap 0.4667
2024-01-10 22:14:03,929 - GAugM EPNet train, Epoch [ 25/250]: loss 0.7209, auc 0.4710, ap 0.4763
2024-01-10 22:14:04,012 - GAugM EPNet train, Epoch [ 26/250]: loss 0.7210, auc 0.4998, ap 0.5315
2024-01-10 22:14:04,085 - GAugM EPNet train, Epoch [ 27/250]: loss 0.7209, auc 0.5073, ap 0.5229
2024-01-10 22:14:04,162 - GAugM EPNet train, Epoch [ 28/250]: loss 0.7209, auc 0.5685, ap 0.5599
2024-01-10 22:14:04,238 - GAugM EPNet train, Epoch [ 29/250]: loss 0.7210, auc 0.5012, ap 0.5258
2024-01-10 22:14:04,315 - GAugM EPNet train, Epoch [ 30/250]: loss 0.7209, auc 0.5087, ap 0.5501
2024-01-10 22:14:04,388 - GAugM EPNet train, Epoch [ 31/250]: loss 0.7208, auc 0.5329, ap 0.5382
2024-01-10 22:14:04,477 - GAugM EPNet train, Epoch [ 32/250]: loss 0.7210, auc 0.5728, ap 0.5417
2024-01-10 22:14:04,550 - GAugM EPNet train, Epoch [ 33/250]: loss 0.7209, auc 0.5183, ap 0.5469
2024-01-10 22:14:04,626 - GAugM EPNet train, Epoch [ 34/250]: loss 0.7209, auc 0.4699, ap 0.4881
2024-01-10 22:14:04,708 - GAugM EPNet train, Epoch [ 35/250]: loss 0.7209, auc 0.5361, ap 0.5086
2024-01-10 22:14:04,783 - GAugM EPNet train, Epoch [ 36/250]: loss 0.7209, auc 0.6006, ap 0.5971
2024-01-10 22:14:04,857 - GAugM EPNet train, Epoch [ 37/250]: loss 0.7209, auc 0.5336, ap 0.5239
2024-01-10 22:14:04,929 - GAugM EPNet train, Epoch [ 38/250]: loss 0.7209, auc 0.4799, ap 0.4763
2024-01-10 22:14:05,004 - GAugM EPNet train, Epoch [ 39/250]: loss 0.7208, auc 0.4187, ap 0.4709
2024-01-10 22:14:05,082 - GAugM EPNet train, Epoch [ 40/250]: loss 0.7210, auc 0.5518, ap 0.5303
2024-01-10 22:14:05,156 - GAugM EPNet train, Epoch [ 41/250]: loss 0.7210, auc 0.4596, ap 0.5025
2024-01-10 22:14:05,241 - GAugM EPNet train, Epoch [ 42/250]: loss 0.7209, auc 0.5422, ap 0.5781
2024-01-10 22:14:05,317 - GAugM EPNet train, Epoch [ 43/250]: loss 0.7208, auc 0.4582, ap 0.4854
2024-01-10 22:14:05,389 - GAugM EPNet train, Epoch [ 44/250]: loss 0.7208, auc 0.4204, ap 0.4559
2024-01-10 22:14:05,471 - GAugM EPNet train, Epoch [ 45/250]: loss 0.7209, auc 0.5465, ap 0.5566
2024-01-10 22:14:05,543 - GAugM EPNet train, Epoch [ 46/250]: loss 0.7209, auc 0.4781, ap 0.5178
2024-01-10 22:14:05,617 - GAugM EPNet train, Epoch [ 47/250]: loss 0.7210, auc 0.4350, ap 0.4612
2024-01-10 22:14:05,690 - GAugM EPNet train, Epoch [ 48/250]: loss 0.7210, auc 0.5340, ap 0.5610
2024-01-10 22:14:05,762 - GAugM EPNet train, Epoch [ 49/250]: loss 0.7209, auc 0.4991, ap 0.5110
2024-01-10 22:14:05,835 - GAugM EPNet train, Epoch [ 50/250]: loss 0.7210, auc 0.5119, ap 0.5164
2024-01-10 22:14:05,913 - GAugM EPNet train, Epoch [ 51/250]: loss 0.7210, auc 0.4867, ap 0.5198
2024-01-10 22:14:05,989 - GAugM EPNet train, Epoch [ 52/250]: loss 0.7209, auc 0.4820, ap 0.5259
2024-01-10 22:14:06,061 - GAugM EPNet train, Epoch [ 53/250]: loss 0.7209, auc 0.5052, ap 0.5334
2024-01-10 22:14:06,136 - GAugM EPNet train, Epoch [ 54/250]: loss 0.7211, auc 0.5187, ap 0.5263
2024-01-10 22:14:06,209 - GAugM EPNet train, Epoch [ 55/250]: loss 0.7209, auc 0.5767, ap 0.5758
2024-01-10 22:14:06,282 - GAugM EPNet train, Epoch [ 56/250]: loss 0.7208, auc 0.5155, ap 0.4948
2024-01-10 22:14:06,359 - GAugM EPNet train, Epoch [ 57/250]: loss 0.7209, auc 0.4781, ap 0.4858
2024-01-10 22:14:06,438 - GAugM EPNet train, Epoch [ 58/250]: loss 0.7210, auc 0.5344, ap 0.5668
2024-01-10 22:14:06,509 - GAugM EPNet train, Epoch [ 59/250]: loss 0.7211, auc 0.5336, ap 0.5183
2024-01-10 22:14:06,590 - GAugM EPNet train, Epoch [ 60/250]: loss 0.7210, auc 0.5233, ap 0.5045
2024-01-10 22:14:06,663 - GAugM EPNet train, Epoch [ 61/250]: loss 0.7209, auc 0.5578, ap 0.5754
2024-01-10 22:14:06,743 - GAugM EPNet train, Epoch [ 62/250]: loss 0.7210, auc 0.5543, ap 0.5690
2024-01-10 22:14:06,817 - GAugM EPNet train, Epoch [ 63/250]: loss 0.7208, auc 0.4806, ap 0.5067
2024-01-10 22:14:06,888 - GAugM EPNet train, Epoch [ 64/250]: loss 0.7208, auc 0.4585, ap 0.4866
2024-01-10 22:14:06,961 - GAugM EPNet train, Epoch [ 65/250]: loss 0.7208, auc 0.5208, ap 0.5393
2024-01-10 22:14:07,034 - GAugM EPNet train, Epoch [ 66/250]: loss 0.7209, auc 0.4635, ap 0.5213
2024-01-10 22:14:07,109 - GAugM EPNet train, Epoch [ 67/250]: loss 0.7209, auc 0.5354, ap 0.5364
2024-01-10 22:14:07,180 - GAugM EPNet train, Epoch [ 68/250]: loss 0.7210, auc 0.5126, ap 0.5341
2024-01-10 22:14:07,253 - GAugM EPNet train, Epoch [ 69/250]: loss 0.7210, auc 0.5130, ap 0.5426
2024-01-10 22:14:07,334 - GAugM EPNet train, Epoch [ 70/250]: loss 0.7210, auc 0.5190, ap 0.4977
2024-01-10 22:14:07,412 - GAugM EPNet train, Epoch [ 71/250]: loss 0.7210, auc 0.5012, ap 0.4830
2024-01-10 22:14:07,483 - GAugM EPNet train, Epoch [ 72/250]: loss 0.7210, auc 0.4016, ap 0.4401
2024-01-10 22:14:07,559 - GAugM EPNet train, Epoch [ 73/250]: loss 0.7209, auc 0.5247, ap 0.5141
2024-01-10 22:14:07,632 - GAugM EPNet train, Epoch [ 74/250]: loss 0.7209, auc 0.4404, ap 0.4654
2024-01-10 22:14:07,709 - GAugM EPNet train, Epoch [ 75/250]: loss 0.7210, auc 0.4724, ap 0.4892
2024-01-10 22:14:07,785 - GAugM EPNet train, Epoch [ 76/250]: loss 0.7209, auc 0.4443, ap 0.4700
2024-01-10 22:14:07,857 - GAugM EPNet train, Epoch [ 77/250]: loss 0.7208, auc 0.5586, ap 0.5595
2024-01-10 22:14:07,931 - GAugM EPNet train, Epoch [ 78/250]: loss 0.7209, auc 0.5333, ap 0.5284
2024-01-10 22:14:08,007 - GAugM EPNet train, Epoch [ 79/250]: loss 0.7208, auc 0.4923, ap 0.4913
2024-01-10 22:14:08,078 - GAugM EPNet train, Epoch [ 80/250]: loss 0.7209, auc 0.5746, ap 0.5492
2024-01-10 22:14:08,161 - GAugM EPNet train, Epoch [ 81/250]: loss 0.7209, auc 0.5504, ap 0.5376
2024-01-10 22:14:08,237 - GAugM EPNet train, Epoch [ 82/250]: loss 0.7210, auc 0.4977, ap 0.4920
2024-01-10 22:14:08,312 - GAugM EPNet train, Epoch [ 83/250]: loss 0.7209, auc 0.4493, ap 0.5117
2024-01-10 22:14:08,384 - GAugM EPNet train, Epoch [ 84/250]: loss 0.7209, auc 0.4713, ap 0.4884
2024-01-10 22:14:08,465 - GAugM EPNet train, Epoch [ 85/250]: loss 0.7210, auc 0.4785, ap 0.5046
2024-01-10 22:14:08,538 - GAugM EPNet train, Epoch [ 86/250]: loss 0.7208, auc 0.4664, ap 0.4875
2024-01-10 22:14:08,618 - GAugM EPNet train, Epoch [ 87/250]: loss 0.7209, auc 0.5276, ap 0.5285
2024-01-10 22:14:08,691 - GAugM EPNet train, Epoch [ 88/250]: loss 0.7210, auc 0.4653, ap 0.4771
2024-01-10 22:14:08,765 - GAugM EPNet train, Epoch [ 89/250]: loss 0.7210, auc 0.5112, ap 0.5478
2024-01-10 22:14:08,840 - GAugM EPNet train, Epoch [ 90/250]: loss 0.7209, auc 0.4596, ap 0.5001
2024-01-10 22:14:08,923 - GAugM EPNet train, Epoch [ 91/250]: loss 0.7208, auc 0.5322, ap 0.5066
2024-01-10 22:14:08,998 - GAugM EPNet train, Epoch [ 92/250]: loss 0.7209, auc 0.6070, ap 0.5978
2024-01-10 22:14:09,070 - GAugM EPNet train, Epoch [ 93/250]: loss 0.7209, auc 0.5109, ap 0.5157
2024-01-10 22:14:09,140 - GAugM EPNet train, Epoch [ 94/250]: loss 0.7210, auc 0.4457, ap 0.4591
2024-01-10 22:14:09,213 - GAugM EPNet train, Epoch [ 95/250]: loss 0.7210, auc 0.4429, ap 0.4524
2024-01-10 22:14:09,284 - GAugM EPNet train, Epoch [ 96/250]: loss 0.7209, auc 0.5618, ap 0.5461
2024-01-10 22:14:09,360 - GAugM EPNet train, Epoch [ 97/250]: loss 0.7209, auc 0.4475, ap 0.4703
2024-01-10 22:14:09,432 - GAugM EPNet train, Epoch [ 98/250]: loss 0.7209, auc 0.4539, ap 0.4835
2024-01-10 22:14:09,504 - GAugM EPNet train, Epoch [ 99/250]: loss 0.7209, auc 0.5020, ap 0.5167
2024-01-10 22:14:09,576 - GAugM EPNet train, Epoch [100/250]: loss 0.7210, auc 0.4778, ap 0.4793
2024-01-10 22:14:09,657 - GAugM EPNet train, Epoch [101/250]: loss 0.7210, auc 0.4920, ap 0.5540
2024-01-10 22:14:09,734 - GAugM EPNet train, Epoch [102/250]: loss 0.7209, auc 0.4265, ap 0.4571
2024-01-10 22:14:09,811 - GAugM EPNet train, Epoch [103/250]: loss 0.7209, auc 0.4788, ap 0.5235
2024-01-10 22:14:09,884 - GAugM EPNet train, Epoch [104/250]: loss 0.7209, auc 0.4867, ap 0.4976
2024-01-10 22:14:09,957 - GAugM EPNet train, Epoch [105/250]: loss 0.7209, auc 0.4870, ap 0.4951
2024-01-10 22:14:10,027 - GAugM EPNet train, Epoch [106/250]: loss 0.7210, auc 0.4614, ap 0.4745
2024-01-10 22:14:10,101 - GAugM EPNet train, Epoch [107/250]: loss 0.7210, auc 0.4543, ap 0.4740
2024-01-10 22:14:10,174 - GAugM EPNet train, Epoch [108/250]: loss 0.7208, auc 0.4906, ap 0.4898
2024-01-10 22:14:10,245 - GAugM EPNet train, Epoch [109/250]: loss 0.7210, auc 0.4567, ap 0.4908
2024-01-10 22:14:10,331 - GAugM EPNet train, Epoch [110/250]: loss 0.7209, auc 0.4970, ap 0.5181
2024-01-10 22:14:10,409 - GAugM EPNet train, Epoch [111/250]: loss 0.7210, auc 0.5746, ap 0.5928
2024-01-10 22:14:10,482 - GAugM EPNet train, Epoch [112/250]: loss 0.7209, auc 0.5489, ap 0.5464
2024-01-10 22:14:10,558 - GAugM EPNet train, Epoch [113/250]: loss 0.7210, auc 0.4642, ap 0.5156
2024-01-10 22:14:10,629 - GAugM EPNet train, Epoch [114/250]: loss 0.7209, auc 0.4372, ap 0.4588
2024-01-10 22:14:10,707 - GAugM EPNet train, Epoch [115/250]: loss 0.7210, auc 0.5315, ap 0.5443
2024-01-10 22:14:10,778 - GAugM EPNet train, Epoch [116/250]: loss 0.7209, auc 0.4863, ap 0.4969
2024-01-10 22:14:10,851 - GAugM EPNet train, Epoch [117/250]: loss 0.7208, auc 0.4713, ap 0.4660
2024-01-10 22:14:10,927 - GAugM EPNet train, Epoch [118/250]: loss 0.7209, auc 0.5180, ap 0.5225
2024-01-10 22:14:11,004 - GAugM EPNet train, Epoch [119/250]: loss 0.7209, auc 0.4276, ap 0.4522
2024-01-10 22:14:11,084 - GAugM EPNet train, Epoch [120/250]: loss 0.7210, auc 0.4642, ap 0.4588
2024-01-10 22:14:11,158 - GAugM EPNet train, Epoch [121/250]: loss 0.7210, auc 0.5030, ap 0.5004
2024-01-10 22:14:11,231 - GAugM EPNet train, Epoch [122/250]: loss 0.7209, auc 0.5073, ap 0.5288
2024-01-10 22:14:11,313 - GAugM EPNet train, Epoch [123/250]: loss 0.7209, auc 0.5767, ap 0.5965
2024-01-10 22:14:11,388 - GAugM EPNet train, Epoch [124/250]: loss 0.7210, auc 0.4386, ap 0.4816
2024-01-10 22:14:11,467 - GAugM EPNet train, Epoch [125/250]: loss 0.7209, auc 0.4639, ap 0.4756
2024-01-10 22:14:11,542 - GAugM EPNet train, Epoch [126/250]: loss 0.7210, auc 0.5023, ap 0.4848
2024-01-10 22:14:11,617 - GAugM EPNet train, Epoch [127/250]: loss 0.7209, auc 0.4076, ap 0.4358
2024-01-10 22:14:11,690 - GAugM EPNet train, Epoch [128/250]: loss 0.7210, auc 0.5347, ap 0.5273
2024-01-10 22:14:11,778 - GAugM EPNet train, Epoch [129/250]: loss 0.7208, auc 0.4425, ap 0.4656
2024-01-10 22:14:11,859 - GAugM EPNet train, Epoch [130/250]: loss 0.7210, auc 0.4439, ap 0.4852
2024-01-10 22:14:11,940 - GAugM EPNet train, Epoch [131/250]: loss 0.7210, auc 0.5746, ap 0.6010
2024-01-10 22:14:12,017 - GAugM EPNet train, Epoch [132/250]: loss 0.7209, auc 0.4806, ap 0.4909
2024-01-10 22:14:12,092 - GAugM EPNet train, Epoch [133/250]: loss 0.7209, auc 0.4393, ap 0.4544
2024-01-10 22:14:12,174 - GAugM EPNet train, Epoch [134/250]: loss 0.7210, auc 0.4980, ap 0.5188
2024-01-10 22:14:12,254 - GAugM EPNet train, Epoch [135/250]: loss 0.7209, auc 0.4179, ap 0.4760
2024-01-10 22:14:12,329 - GAugM EPNet train, Epoch [136/250]: loss 0.7209, auc 0.4656, ap 0.4772
2024-01-10 22:14:12,404 - GAugM EPNet train, Epoch [137/250]: loss 0.7210, auc 0.4560, ap 0.5277
2024-01-10 22:14:12,479 - GAugM EPNet train, Epoch [138/250]: loss 0.7210, auc 0.5411, ap 0.5153
2024-01-10 22:14:12,554 - GAugM EPNet train, Epoch [139/250]: loss 0.7210, auc 0.5087, ap 0.5178
2024-01-10 22:14:12,626 - GAugM EPNet train, Epoch [140/250]: loss 0.7209, auc 0.4735, ap 0.4903
2024-01-10 22:14:12,698 - GAugM EPNet train, Epoch [141/250]: loss 0.7209, auc 0.5190, ap 0.5308
2024-01-10 22:14:12,774 - GAugM EPNet train, Epoch [142/250]: loss 0.7209, auc 0.5201, ap 0.5294
2024-01-10 22:14:12,849 - GAugM EPNet train, Epoch [143/250]: loss 0.7209, auc 0.4845, ap 0.4763
2024-01-10 22:14:12,920 - GAugM EPNet train, Epoch [144/250]: loss 0.7209, auc 0.4735, ap 0.4854
2024-01-10 22:14:13,001 - GAugM EPNet train, Epoch [145/250]: loss 0.7209, auc 0.4023, ap 0.4680
2024-01-10 22:14:13,072 - GAugM EPNet train, Epoch [146/250]: loss 0.7209, auc 0.4874, ap 0.5166
2024-01-10 22:14:13,142 - GAugM EPNet train, Epoch [147/250]: loss 0.7209, auc 0.5806, ap 0.6045
2024-01-10 22:14:13,217 - GAugM EPNet train, Epoch [148/250]: loss 0.7209, auc 0.4454, ap 0.4512
2024-01-10 22:14:13,289 - GAugM EPNet train, Epoch [149/250]: loss 0.7208, auc 0.5404, ap 0.5676
2024-01-10 22:14:13,361 - GAugM EPNet train, Epoch [150/250]: loss 0.7209, auc 0.4909, ap 0.4868
2024-01-10 22:14:13,435 - GAugM EPNet train, Epoch [151/250]: loss 0.7209, auc 0.4578, ap 0.4678
2024-01-10 22:14:13,506 - GAugM EPNet train, Epoch [152/250]: loss 0.7209, auc 0.5333, ap 0.5405
2024-01-10 22:14:13,583 - GAugM EPNet train, Epoch [153/250]: loss 0.7209, auc 0.4162, ap 0.4752
2024-01-10 22:14:13,655 - GAugM EPNet train, Epoch [154/250]: loss 0.7209, auc 0.5272, ap 0.5824
2024-01-10 22:14:13,728 - GAugM EPNet train, Epoch [155/250]: loss 0.7209, auc 0.5247, ap 0.5442
2024-01-10 22:14:13,798 - GAugM EPNet train, Epoch [156/250]: loss 0.7209, auc 0.4048, ap 0.4339
2024-01-10 22:14:13,875 - GAugM EPNet train, Epoch [157/250]: loss 0.7209, auc 0.5368, ap 0.5076
2024-01-10 22:14:13,945 - GAugM EPNet train, Epoch [158/250]: loss 0.7208, auc 0.4867, ap 0.4978
2024-01-10 22:14:14,018 - GAugM EPNet train, Epoch [159/250]: loss 0.7208, auc 0.5069, ap 0.5032
2024-01-10 22:14:14,092 - GAugM EPNet train, Epoch [160/250]: loss 0.7209, auc 0.6476, ap 0.6645
2024-01-10 22:14:14,163 - GAugM EPNet train, Epoch [161/250]: loss 0.7209, auc 0.5048, ap 0.5164
2024-01-10 22:14:14,238 - GAugM EPNet train, Epoch [162/250]: loss 0.7209, auc 0.4176, ap 0.4415
2024-01-10 22:14:14,309 - GAugM EPNet train, Epoch [163/250]: loss 0.7209, auc 0.5041, ap 0.5051
2024-01-10 22:14:14,381 - GAugM EPNet train, Epoch [164/250]: loss 0.7211, auc 0.4738, ap 0.4810
2024-01-10 22:14:14,453 - GAugM EPNet train, Epoch [165/250]: loss 0.7210, auc 0.4411, ap 0.4597
2024-01-10 22:14:14,525 - GAugM EPNet train, Epoch [166/250]: loss 0.7208, auc 0.5069, ap 0.5148
2024-01-10 22:14:14,596 - GAugM EPNet train, Epoch [167/250]: loss 0.7209, auc 0.4852, ap 0.4873
2024-01-10 22:14:14,674 - GAugM EPNet train, Epoch [168/250]: loss 0.7209, auc 0.5091, ap 0.5514
2024-01-10 22:14:14,745 - GAugM EPNet train, Epoch [169/250]: loss 0.7209, auc 0.5415, ap 0.5467
2024-01-10 22:14:14,816 - GAugM EPNet train, Epoch [170/250]: loss 0.7210, auc 0.5027, ap 0.5061
2024-01-10 22:14:14,887 - GAugM EPNet train, Epoch [171/250]: loss 0.7209, auc 0.4204, ap 0.4699
2024-01-10 22:14:14,965 - GAugM EPNet train, Epoch [172/250]: loss 0.7208, auc 0.4112, ap 0.4440
2024-01-10 22:14:15,036 - GAugM EPNet train, Epoch [173/250]: loss 0.7209, auc 0.4753, ap 0.4929
2024-01-10 22:14:15,109 - GAugM EPNet train, Epoch [174/250]: loss 0.7209, auc 0.4389, ap 0.4696
2024-01-10 22:14:15,187 - GAugM EPNet train, Epoch [175/250]: loss 0.7209, auc 0.6337, ap 0.6235
2024-01-10 22:14:15,258 - GAugM EPNet train, Epoch [176/250]: loss 0.7209, auc 0.5169, ap 0.5374
2024-01-10 22:14:15,329 - GAugM EPNet train, Epoch [177/250]: loss 0.7210, auc 0.4870, ap 0.4871
2024-01-10 22:14:15,402 - GAugM EPNet train, Epoch [178/250]: loss 0.7210, auc 0.6070, ap 0.6008
2024-01-10 22:14:15,478 - GAugM EPNet train, Epoch [179/250]: loss 0.7210, auc 0.4578, ap 0.4807
2024-01-10 22:14:15,549 - GAugM EPNet train, Epoch [180/250]: loss 0.7210, auc 0.5468, ap 0.5605
2024-01-10 22:14:15,628 - GAugM EPNet train, Epoch [181/250]: loss 0.7209, auc 0.3596, ap 0.4167
2024-01-10 22:14:15,705 - GAugM EPNet train, Epoch [182/250]: loss 0.7209, auc 0.5205, ap 0.5572
2024-01-10 22:14:15,778 - GAugM EPNet train, Epoch [183/250]: loss 0.7210, auc 0.5066, ap 0.4895
2024-01-10 22:14:15,855 - GAugM EPNet train, Epoch [184/250]: loss 0.7209, auc 0.5735, ap 0.5703
2024-01-10 22:14:15,927 - GAugM EPNet train, Epoch [185/250]: loss 0.7209, auc 0.3930, ap 0.4287
2024-01-10 22:14:15,999 - GAugM EPNet train, Epoch [186/250]: loss 0.7208, auc 0.4518, ap 0.4815
2024-01-10 22:14:16,075 - GAugM EPNet train, Epoch [187/250]: loss 0.7209, auc 0.4311, ap 0.4463
2024-01-10 22:14:16,150 - GAugM EPNet train, Epoch [188/250]: loss 0.7209, auc 0.4717, ap 0.4896
2024-01-10 22:14:16,222 - GAugM EPNet train, Epoch [189/250]: loss 0.7209, auc 0.5546, ap 0.5729
2024-01-10 22:14:16,293 - GAugM EPNet train, Epoch [190/250]: loss 0.7209, auc 0.4249, ap 0.4728
2024-01-10 22:14:16,372 - GAugM EPNet train, Epoch [191/250]: loss 0.7209, auc 0.5098, ap 0.5681
2024-01-10 22:14:16,446 - GAugM EPNet train, Epoch [192/250]: loss 0.7209, auc 0.5344, ap 0.5284
2024-01-10 22:14:16,522 - GAugM EPNet train, Epoch [193/250]: loss 0.7209, auc 0.5233, ap 0.5171
2024-01-10 22:14:16,597 - GAugM EPNet train, Epoch [194/250]: loss 0.7209, auc 0.4600, ap 0.4836
2024-01-10 22:14:16,669 - GAugM EPNet train, Epoch [195/250]: loss 0.7209, auc 0.4745, ap 0.4832
2024-01-10 22:14:16,741 - GAugM EPNet train, Epoch [196/250]: loss 0.7208, auc 0.5233, ap 0.5042
2024-01-10 22:14:16,816 - GAugM EPNet train, Epoch [197/250]: loss 0.7210, auc 0.4721, ap 0.4881
2024-01-10 22:14:16,903 - GAugM EPNet train, Epoch [198/250]: loss 0.7210, auc 0.5504, ap 0.5435
2024-01-10 22:14:16,986 - GAugM EPNet train, Epoch [199/250]: loss 0.7209, auc 0.4813, ap 0.5131
2024-01-10 22:14:17,061 - GAugM EPNet train, Epoch [200/250]: loss 0.7210, auc 0.4792, ap 0.4974
2024-01-10 22:14:17,143 - GAugM EPNet train, Epoch [201/250]: loss 0.7209, auc 0.4503, ap 0.4741
2024-01-10 22:14:17,219 - GAugM EPNet train, Epoch [202/250]: loss 0.7210, auc 0.4959, ap 0.5182
2024-01-10 22:14:17,297 - GAugM EPNet train, Epoch [203/250]: loss 0.7210, auc 0.5433, ap 0.5705
2024-01-10 22:14:17,370 - GAugM EPNet train, Epoch [204/250]: loss 0.7209, auc 0.5137, ap 0.5148
2024-01-10 22:14:17,448 - GAugM EPNet train, Epoch [205/250]: loss 0.7209, auc 0.5141, ap 0.5272
2024-01-10 22:14:17,532 - GAugM EPNet train, Epoch [206/250]: loss 0.7209, auc 0.4852, ap 0.5097
2024-01-10 22:14:17,607 - GAugM EPNet train, Epoch [207/250]: loss 0.7210, auc 0.4649, ap 0.4881
2024-01-10 22:14:17,680 - GAugM EPNet train, Epoch [208/250]: loss 0.7209, auc 0.4333, ap 0.4906
2024-01-10 22:14:17,755 - GAugM EPNet train, Epoch [209/250]: loss 0.7210, auc 0.5586, ap 0.5508
2024-01-10 22:14:17,834 - GAugM EPNet train, Epoch [210/250]: loss 0.7209, auc 0.4792, ap 0.4979
2024-01-10 22:14:17,910 - GAugM EPNet train, Epoch [211/250]: loss 0.7210, auc 0.4938, ap 0.5205
2024-01-10 22:14:17,982 - GAugM EPNet train, Epoch [212/250]: loss 0.7210, auc 0.4731, ap 0.5027
2024-01-10 22:14:18,060 - GAugM EPNet train, Epoch [213/250]: loss 0.7208, auc 0.6251, ap 0.6406
2024-01-10 22:14:18,130 - GAugM EPNet train, Epoch [214/250]: loss 0.7210, auc 0.5329, ap 0.5382
2024-01-10 22:14:18,203 - GAugM EPNet train, Epoch [215/250]: loss 0.7210, auc 0.5123, ap 0.5090
2024-01-10 22:14:18,274 - GAugM EPNet train, Epoch [216/250]: loss 0.7209, auc 0.5247, ap 0.5227
2024-01-10 22:14:18,352 - GAugM EPNet train, Epoch [217/250]: loss 0.7209, auc 0.5842, ap 0.5952
2024-01-10 22:14:18,425 - GAugM EPNet train, Epoch [218/250]: loss 0.7209, auc 0.4692, ap 0.4969
2024-01-10 22:14:18,496 - GAugM EPNet train, Epoch [219/250]: loss 0.7208, auc 0.5130, ap 0.5132
2024-01-10 22:14:18,573 - GAugM EPNet train, Epoch [220/250]: loss 0.7210, auc 0.4486, ap 0.4799
2024-01-10 22:14:18,644 - GAugM EPNet train, Epoch [221/250]: loss 0.7209, auc 0.5212, ap 0.5145
2024-01-10 22:14:18,717 - GAugM EPNet train, Epoch [222/250]: loss 0.7209, auc 0.4760, ap 0.4988
2024-01-10 22:14:18,792 - GAugM EPNet train, Epoch [223/250]: loss 0.7209, auc 0.5290, ap 0.5386
2024-01-10 22:14:18,862 - GAugM EPNet train, Epoch [224/250]: loss 0.7210, auc 0.4710, ap 0.4796
2024-01-10 22:14:18,934 - GAugM EPNet train, Epoch [225/250]: loss 0.7209, auc 0.5012, ap 0.5015
2024-01-10 22:14:19,004 - GAugM EPNet train, Epoch [226/250]: loss 0.7210, auc 0.4642, ap 0.4825
2024-01-10 22:14:19,076 - GAugM EPNet train, Epoch [227/250]: loss 0.7210, auc 0.5447, ap 0.5576
2024-01-10 22:14:19,148 - GAugM EPNet train, Epoch [228/250]: loss 0.7209, auc 0.4033, ap 0.4558
2024-01-10 22:14:19,219 - GAugM EPNet train, Epoch [229/250]: loss 0.7209, auc 0.4767, ap 0.5009
2024-01-10 22:14:19,298 - GAugM EPNet train, Epoch [230/250]: loss 0.7209, auc 0.4938, ap 0.5368
2024-01-10 22:14:19,373 - GAugM EPNet train, Epoch [231/250]: loss 0.7209, auc 0.4881, ap 0.4847
2024-01-10 22:14:19,456 - GAugM EPNet train, Epoch [232/250]: loss 0.7209, auc 0.5304, ap 0.5415
2024-01-10 22:14:19,532 - GAugM EPNet train, Epoch [233/250]: loss 0.7210, auc 0.5269, ap 0.5445
2024-01-10 22:14:19,608 - GAugM EPNet train, Epoch [234/250]: loss 0.7209, auc 0.3909, ap 0.4588
2024-01-10 22:14:19,680 - GAugM EPNet train, Epoch [235/250]: loss 0.7209, auc 0.4219, ap 0.4528
2024-01-10 22:14:19,755 - GAugM EPNet train, Epoch [236/250]: loss 0.7209, auc 0.5287, ap 0.5470
2024-01-10 22:14:19,827 - GAugM EPNet train, Epoch [237/250]: loss 0.7210, auc 0.5934, ap 0.6099
2024-01-10 22:14:19,898 - GAugM EPNet train, Epoch [238/250]: loss 0.7210, auc 0.5194, ap 0.5401
2024-01-10 22:14:19,975 - GAugM EPNet train, Epoch [239/250]: loss 0.7209, auc 0.5215, ap 0.5855
2024-01-10 22:14:20,049 - GAugM EPNet train, Epoch [240/250]: loss 0.7209, auc 0.5511, ap 0.5282
2024-01-10 22:14:20,123 - GAugM EPNet train, Epoch [241/250]: loss 0.7209, auc 0.5158, ap 0.5098
2024-01-10 22:14:20,204 - GAugM EPNet train, Epoch [242/250]: loss 0.7210, auc 0.4970, ap 0.5225
2024-01-10 22:14:20,284 - GAugM EPNet train, Epoch [243/250]: loss 0.7210, auc 0.4977, ap 0.5470
2024-01-10 22:14:20,363 - GAugM EPNet train, Epoch [244/250]: loss 0.7209, auc 0.5593, ap 0.5370
2024-01-10 22:14:20,436 - GAugM EPNet train, Epoch [245/250]: loss 0.7210, auc 0.4407, ap 0.4830
2024-01-10 22:14:20,513 - GAugM EPNet train, Epoch [246/250]: loss 0.7208, auc 0.4133, ap 0.4386
2024-01-10 22:14:20,588 - GAugM EPNet train, Epoch [247/250]: loss 0.7209, auc 0.5603, ap 0.5491
2024-01-10 22:14:20,668 - GAugM EPNet train, Epoch [248/250]: loss 0.7211, auc 0.5383, ap 0.5324
2024-01-10 22:14:20,742 - GAugM EPNet train, Epoch [249/250]: loss 0.7209, auc 0.4372, ap 0.4659
2024-01-10 22:14:20,822 - GAugM EPNet train, Epoch [250/250]: loss 0.7208, auc 0.5354, ap 0.5468
2024-01-12 05:34:17,973 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7fed1aeeced0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-12 05:39:48,026 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f2d5edd4d10>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-12 05:40:34,186 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7fcab562a4d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-12 06:00:55,992 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f5340500710>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-12 06:01:14,238 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7fe28aea88d0>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-12 06:04:04,277 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f8d32f82650>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-12 06:04:34,442 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7f1a54cf4790>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
2024-01-12 06:05:02,748 - Parameters: {'self': <models.HGAug.HyperGAug object at 0x7efeda1d0890>, 'data': This is coauthorship_cora dataset:
  ->  num_classes
  ->  num_vertices
  ->  num_edges
  ->  dim_features
  ->  features
  ->  edge_list
  ->  labels
  ->  train_mask
  ->  val_mask
  ->  test_mask
Please try `data['name']` to get the specified data., 'use_bn': False, 'cuda': -1, 'hidden_size': 128, 'emb_size': 32, 'epochs': 200, 'seed': 42, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.5, 'beta': 0.5, 'temperature': 0.2, 'log': True, 'name': 'debug', 'warmup': 3, 'gnnlayer_type': 'gcn', 'alpha': 1, 'sample_type': 'add_sample'}
